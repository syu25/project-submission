{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Generation Using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real World Problem\n",
    "\n",
    "This project focuses on generating music automatically using Recurrent Neural Network(RNN).<br> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source:\n",
    "1. http://abc.sourceforge.net/NMD/\n",
    "2. http://trillian.mit.edu/~jc/music/book/oneills/1850/X/\n",
    "\n",
    "### From first data-source, we have downloaded first two files:\n",
    "* Jigs (340 tunes)\n",
    "* Hornpipes (65 tunes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../Data/\"\n",
    "data_file = \"Data_Tunes.txt\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "model_weights_directory = '../Data/Model_Weights/'\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batches(all_chars, unique_chars):\n",
    "    length = all_chars.shape[0]\n",
    "    batch_chars = int(length / BATCH_SIZE) #155222/16 = 9701\n",
    "    \n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, 64):  #(0, 9637, 64)  #it denotes number of batches. It runs everytime when\n",
    "        #new batch is created. We have a total of 151 batches.\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))    #(16, 64)\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))   #(16, 64, 87)\n",
    "        for batch_index in range(0, 16):  #it denotes each row in a batch.  \n",
    "            for i in range(0, 64):  #it denotes each column in a batch. Each column represents each character means \n",
    "                #each time-step character in a sequence.\n",
    "                X[batch_index, i] = all_chars[batch_index * batch_chars + start + i]\n",
    "                Y[batch_index, i, all_chars[batch_index * batch_chars + start + i + 1]] = 1 #here we have added '1' because the\n",
    "                #correct label will be the next character in the sequence. So, the next character will be denoted by\n",
    "                #all_chars[batch_index * batch_chars + start + i + 1]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(batch_size, seq_length, unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (batch_size, seq_length))) \n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(128, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(unique_chars)))\n",
    "\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(data, epochs = 80):\n",
    "    #mapping character to index\n",
    "    char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(data))))}\n",
    "    print(\"Number of unique characters in our whole tunes database = {}\".format(len(char_to_index))) #87\n",
    "    \n",
    "    with open(os.path.join(data_directory, charIndex_json), mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "    unique_chars = len(char_to_index)\n",
    "    \n",
    "    model = built_model(BATCH_SIZE, SEQ_LENGTH, unique_chars)\n",
    "    model.summary()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    all_characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    print(\"Total number of characters = \"+str(all_characters.shape[0])) #155222\n",
    "    \n",
    "    epoch_number, loss, accuracy = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        final_epoch_loss, final_epoch_accuracy = 0, 0\n",
    "        epoch_number.append(epoch+1)\n",
    "        \n",
    "        for i, (x, y) in enumerate(read_batches(all_characters, unique_chars)):\n",
    "            final_epoch_loss, final_epoch_accuracy = model.train_on_batch(x, y) \n",
    "            print(\"Batch: {}, Loss: {}, Accuracy: {}\".format(i+1, final_epoch_loss, final_epoch_accuracy))\n",
    "            #here, above we are reading the batches one-by-one and train our model on each batch one-by-one.\n",
    "        loss.append(final_epoch_loss)\n",
    "        accuracy.append(final_epoch_accuracy)\n",
    "        \n",
    "        #saving weights after every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(model_weights_directory):\n",
    "                os.makedirs(model_weights_directory)\n",
    "            model.save_weights(os.path.join(model_weights_directory, \"Weights_{}.h5\".format(epoch+1)))\n",
    "            print('Saved Weights at epoch {} to file Weights_{}.h5'.format(epoch+1, epoch+1))\n",
    "    \n",
    "    #creating dataframe and record all the losses and accuracies at each epoch\n",
    "    log_frame = pd.DataFrame(columns = [\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "    log_frame[\"Epoch\"] = epoch_number\n",
    "    log_frame[\"Loss\"] = loss\n",
    "    log_frame[\"Accuracy\"] = accuracy\n",
    "    log_frame.to_csv(\"../Data/log.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 87\n",
      "WARNING:tensorflow:From C:\\Users\\Madhava\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Madhava\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (16, 64, 512)             44544     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (16, 64, 128)             197120    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (16, 64, 128)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (16, 64, 87)              11223     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (16, 64, 87)              0         \n",
      "=================================================================\n",
      "Total params: 1,040,343\n",
      "Trainable params: 1,040,343\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Total number of characters = 155222\n",
      "Epoch 1/80\n",
      "WARNING:tensorflow:From C:\\Users\\Madhava\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Madhava\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Batch: 1, Loss: 4.465154647827148, Accuracy: 0.015625\n",
      "Batch: 2, Loss: 4.444737911224365, Accuracy: 0.173828125\n",
      "Batch: 3, Loss: 4.425626754760742, Accuracy: 0.134765625\n",
      "Batch: 4, Loss: 4.400317192077637, Accuracy: 0.1025390625\n",
      "Batch: 5, Loss: 4.253597259521484, Accuracy: 0.1435546875\n",
      "Batch: 6, Loss: 3.9361233711242676, Accuracy: 0.166015625\n",
      "Batch: 7, Loss: 3.8129405975341797, Accuracy: 0.1630859375\n",
      "Batch: 8, Loss: 3.8199334144592285, Accuracy: 0.142578125\n",
      "Batch: 9, Loss: 3.826658248901367, Accuracy: 0.13671875\n",
      "Batch: 10, Loss: 3.6187901496887207, Accuracy: 0.16015625\n",
      "Batch: 11, Loss: 3.3635854721069336, Accuracy: 0.1669921875\n",
      "Batch: 12, Loss: 3.572265148162842, Accuracy: 0.150390625\n",
      "Batch: 13, Loss: 3.7801365852355957, Accuracy: 0.115234375\n",
      "Batch: 14, Loss: 3.5016908645629883, Accuracy: 0.1494140625\n",
      "Batch: 15, Loss: 3.7531065940856934, Accuracy: 0.1240234375\n",
      "Batch: 16, Loss: 3.439709186553955, Accuracy: 0.1640625\n",
      "Batch: 17, Loss: 3.3491618633270264, Accuracy: 0.1728515625\n",
      "Batch: 18, Loss: 3.346707820892334, Accuracy: 0.1650390625\n",
      "Batch: 19, Loss: 3.6135573387145996, Accuracy: 0.1279296875\n",
      "Batch: 20, Loss: 3.75144362449646, Accuracy: 0.111328125\n",
      "Batch: 21, Loss: 3.571152687072754, Accuracy: 0.1259765625\n",
      "Batch: 22, Loss: 3.318424701690674, Accuracy: 0.166015625\n",
      "Batch: 23, Loss: 3.4340381622314453, Accuracy: 0.1513671875\n",
      "Batch: 24, Loss: 3.613658905029297, Accuracy: 0.1181640625\n",
      "Batch: 25, Loss: 3.5064468383789062, Accuracy: 0.1259765625\n",
      "Batch: 26, Loss: 3.492931604385376, Accuracy: 0.1279296875\n",
      "Batch: 27, Loss: 3.4265737533569336, Accuracy: 0.1298828125\n",
      "Batch: 28, Loss: 3.280618906021118, Accuracy: 0.1494140625\n",
      "Batch: 29, Loss: 3.48746919631958, Accuracy: 0.1328125\n",
      "Batch: 30, Loss: 3.79897141456604, Accuracy: 0.0908203125\n",
      "Batch: 31, Loss: 3.6570169925689697, Accuracy: 0.1220703125\n",
      "Batch: 32, Loss: 3.435227155685425, Accuracy: 0.1220703125\n",
      "Batch: 33, Loss: 3.430788516998291, Accuracy: 0.1494140625\n",
      "Batch: 34, Loss: 3.4022216796875, Accuracy: 0.1455078125\n",
      "Batch: 35, Loss: 3.502272605895996, Accuracy: 0.1103515625\n",
      "Batch: 36, Loss: 3.62911057472229, Accuracy: 0.0986328125\n",
      "Batch: 37, Loss: 3.4928579330444336, Accuracy: 0.115234375\n",
      "Batch: 38, Loss: 3.397225856781006, Accuracy: 0.13671875\n",
      "Batch: 39, Loss: 3.50422739982605, Accuracy: 0.1396484375\n",
      "Batch: 40, Loss: 3.623507261276245, Accuracy: 0.119140625\n",
      "Batch: 41, Loss: 3.6147403717041016, Accuracy: 0.119140625\n",
      "Batch: 42, Loss: 3.445265769958496, Accuracy: 0.146484375\n",
      "Batch: 43, Loss: 3.319398880004883, Accuracy: 0.166015625\n",
      "Batch: 44, Loss: 3.3260984420776367, Accuracy: 0.16015625\n",
      "Batch: 45, Loss: 3.3372156620025635, Accuracy: 0.1533203125\n",
      "Batch: 46, Loss: 3.68135404586792, Accuracy: 0.1123046875\n",
      "Batch: 47, Loss: 3.650310754776001, Accuracy: 0.10546875\n",
      "Batch: 48, Loss: 3.43111515045166, Accuracy: 0.1416015625\n",
      "Batch: 49, Loss: 3.3870935440063477, Accuracy: 0.1376953125\n",
      "Batch: 50, Loss: 3.3620810508728027, Accuracy: 0.1416015625\n",
      "Batch: 51, Loss: 3.368633270263672, Accuracy: 0.1357421875\n",
      "Batch: 52, Loss: 3.4537086486816406, Accuracy: 0.126953125\n",
      "Batch: 53, Loss: 3.4090218544006348, Accuracy: 0.13671875\n",
      "Batch: 54, Loss: 3.4581186771392822, Accuracy: 0.1259765625\n",
      "Batch: 55, Loss: 3.3792054653167725, Accuracy: 0.146484375\n",
      "Batch: 56, Loss: 3.4557313919067383, Accuracy: 0.1494140625\n",
      "Batch: 57, Loss: 3.451449394226074, Accuracy: 0.12890625\n",
      "Batch: 58, Loss: 3.3528451919555664, Accuracy: 0.1416015625\n",
      "Batch: 59, Loss: 3.6150424480438232, Accuracy: 0.119140625\n",
      "Batch: 60, Loss: 3.386385917663574, Accuracy: 0.138671875\n",
      "Batch: 61, Loss: 3.3637380599975586, Accuracy: 0.1572265625\n",
      "Batch: 62, Loss: 3.490933895111084, Accuracy: 0.1376953125\n",
      "Batch: 63, Loss: 3.386200428009033, Accuracy: 0.1455078125\n",
      "Batch: 64, Loss: 3.431502342224121, Accuracy: 0.1435546875\n",
      "Batch: 65, Loss: 3.394726514816284, Accuracy: 0.1591796875\n",
      "Batch: 66, Loss: 3.376002311706543, Accuracy: 0.1552734375\n",
      "Batch: 67, Loss: 3.230358600616455, Accuracy: 0.1787109375\n",
      "Batch: 68, Loss: 3.3005623817443848, Accuracy: 0.1875\n",
      "Batch: 69, Loss: 3.401453971862793, Accuracy: 0.1494140625\n",
      "Batch: 70, Loss: 3.3483777046203613, Accuracy: 0.1708984375\n",
      "Batch: 71, Loss: 3.2805254459381104, Accuracy: 0.16796875\n",
      "Batch: 72, Loss: 3.3012611865997314, Accuracy: 0.16015625\n",
      "Batch: 73, Loss: 3.4083669185638428, Accuracy: 0.1455078125\n",
      "Batch: 74, Loss: 3.97556209564209, Accuracy: 0.1103515625\n",
      "Batch: 75, Loss: 3.940493583679199, Accuracy: 0.1123046875\n",
      "Batch: 76, Loss: 3.720480442047119, Accuracy: 0.1298828125\n",
      "Batch: 77, Loss: 3.678062915802002, Accuracy: 0.1328125\n",
      "Batch: 78, Loss: 3.7562713623046875, Accuracy: 0.1142578125\n",
      "Batch: 79, Loss: 3.8351235389709473, Accuracy: 0.095703125\n",
      "Batch: 80, Loss: 3.4655256271362305, Accuracy: 0.1396484375\n",
      "Batch: 81, Loss: 3.3242435455322266, Accuracy: 0.1884765625\n",
      "Batch: 82, Loss: 3.3453426361083984, Accuracy: 0.185546875\n",
      "Batch: 83, Loss: 3.494023323059082, Accuracy: 0.1708984375\n",
      "Batch: 84, Loss: 3.557548999786377, Accuracy: 0.15234375\n",
      "Batch: 85, Loss: 3.480651617050171, Accuracy: 0.1416015625\n",
      "Batch: 86, Loss: 3.329685688018799, Accuracy: 0.16796875\n",
      "Batch: 87, Loss: 3.4217941761016846, Accuracy: 0.1669921875\n",
      "Batch: 88, Loss: 3.3912465572357178, Accuracy: 0.1787109375\n",
      "Batch: 89, Loss: 3.396373748779297, Accuracy: 0.1572265625\n",
      "Batch: 90, Loss: 3.3846333026885986, Accuracy: 0.162109375\n",
      "Batch: 91, Loss: 3.359692096710205, Accuracy: 0.1513671875\n",
      "Batch: 92, Loss: 3.311087131500244, Accuracy: 0.166015625\n",
      "Batch: 93, Loss: 3.316746950149536, Accuracy: 0.177734375\n",
      "Batch: 94, Loss: 3.24251389503479, Accuracy: 0.1884765625\n",
      "Batch: 95, Loss: 3.044501781463623, Accuracy: 0.228515625\n",
      "Batch: 96, Loss: 3.323845624923706, Accuracy: 0.1845703125\n",
      "Batch: 97, Loss: 3.304516315460205, Accuracy: 0.1748046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 98, Loss: 3.321146249771118, Accuracy: 0.169921875\n",
      "Batch: 99, Loss: 3.143916130065918, Accuracy: 0.2060546875\n",
      "Batch: 100, Loss: 3.023836135864258, Accuracy: 0.2265625\n",
      "Batch: 101, Loss: 3.135915994644165, Accuracy: 0.2041015625\n",
      "Batch: 102, Loss: 3.1474051475524902, Accuracy: 0.19921875\n",
      "Batch: 103, Loss: 3.306168794631958, Accuracy: 0.16796875\n",
      "Batch: 104, Loss: 3.147277355194092, Accuracy: 0.2021484375\n",
      "Batch: 105, Loss: 3.1113381385803223, Accuracy: 0.2294921875\n",
      "Batch: 106, Loss: 3.168510675430298, Accuracy: 0.2080078125\n",
      "Batch: 107, Loss: 3.1889185905456543, Accuracy: 0.20703125\n",
      "Batch: 108, Loss: 3.1826817989349365, Accuracy: 0.1923828125\n",
      "Batch: 109, Loss: 3.079822301864624, Accuracy: 0.220703125\n",
      "Batch: 110, Loss: 3.0613369941711426, Accuracy: 0.2216796875\n",
      "Batch: 111, Loss: 2.9389488697052, Accuracy: 0.240234375\n",
      "Batch: 112, Loss: 3.1887259483337402, Accuracy: 0.20703125\n",
      "Batch: 113, Loss: 3.1958529949188232, Accuracy: 0.205078125\n",
      "Batch: 114, Loss: 2.9258370399475098, Accuracy: 0.2451171875\n",
      "Batch: 115, Loss: 3.017115592956543, Accuracy: 0.2412109375\n",
      "Batch: 116, Loss: 3.0315868854522705, Accuracy: 0.2255859375\n",
      "Batch: 117, Loss: 3.183739185333252, Accuracy: 0.197265625\n",
      "Batch: 118, Loss: 3.210416793823242, Accuracy: 0.1865234375\n",
      "Batch: 119, Loss: 3.1605186462402344, Accuracy: 0.193359375\n",
      "Batch: 120, Loss: 2.8755946159362793, Accuracy: 0.228515625\n",
      "Batch: 121, Loss: 2.9055728912353516, Accuracy: 0.2490234375\n",
      "Batch: 122, Loss: 3.2622432708740234, Accuracy: 0.1796875\n",
      "Batch: 123, Loss: 3.1094157695770264, Accuracy: 0.203125\n",
      "Batch: 124, Loss: 3.0692615509033203, Accuracy: 0.2099609375\n",
      "Batch: 125, Loss: 2.963717222213745, Accuracy: 0.2255859375\n",
      "Batch: 126, Loss: 2.963458776473999, Accuracy: 0.2216796875\n",
      "Batch: 127, Loss: 3.140068531036377, Accuracy: 0.1904296875\n",
      "Batch: 128, Loss: 3.0412211418151855, Accuracy: 0.20703125\n",
      "Batch: 129, Loss: 3.019209861755371, Accuracy: 0.23046875\n",
      "Batch: 130, Loss: 3.028249740600586, Accuracy: 0.21484375\n",
      "Batch: 131, Loss: 3.081925630569458, Accuracy: 0.197265625\n",
      "Batch: 132, Loss: 3.1576151847839355, Accuracy: 0.18359375\n",
      "Batch: 133, Loss: 3.0267066955566406, Accuracy: 0.224609375\n",
      "Batch: 134, Loss: 2.9953718185424805, Accuracy: 0.2314453125\n",
      "Batch: 135, Loss: 2.896711587905884, Accuracy: 0.244140625\n",
      "Batch: 136, Loss: 2.883666515350342, Accuracy: 0.2607421875\n",
      "Batch: 137, Loss: 2.695535659790039, Accuracy: 0.2763671875\n",
      "Batch: 138, Loss: 2.9006478786468506, Accuracy: 0.2470703125\n",
      "Batch: 139, Loss: 2.838517189025879, Accuracy: 0.244140625\n",
      "Batch: 140, Loss: 2.916013717651367, Accuracy: 0.2392578125\n",
      "Batch: 141, Loss: 2.8983635902404785, Accuracy: 0.240234375\n",
      "Batch: 142, Loss: 2.8811235427856445, Accuracy: 0.255859375\n",
      "Batch: 143, Loss: 2.987825870513916, Accuracy: 0.224609375\n",
      "Batch: 144, Loss: 2.982654094696045, Accuracy: 0.228515625\n",
      "Batch: 145, Loss: 2.884206771850586, Accuracy: 0.2421875\n",
      "Batch: 146, Loss: 2.956057071685791, Accuracy: 0.2275390625\n",
      "Batch: 147, Loss: 2.895659923553467, Accuracy: 0.2373046875\n",
      "Batch: 148, Loss: 2.821566343307495, Accuracy: 0.2607421875\n",
      "Batch: 149, Loss: 2.933690071105957, Accuracy: 0.224609375\n",
      "Batch: 150, Loss: 2.8809666633605957, Accuracy: 0.2587890625\n",
      "Batch: 151, Loss: 3.0489234924316406, Accuracy: 0.20703125\n",
      "Epoch 2/80\n",
      "Batch: 1, Loss: 2.725001573562622, Accuracy: 0.259765625\n",
      "Batch: 2, Loss: 2.6205546855926514, Accuracy: 0.283203125\n",
      "Batch: 3, Loss: 2.898987293243408, Accuracy: 0.240234375\n",
      "Batch: 4, Loss: 3.1213788986206055, Accuracy: 0.2119140625\n",
      "Batch: 5, Loss: 2.89565372467041, Accuracy: 0.2548828125\n",
      "Batch: 6, Loss: 2.6754229068756104, Accuracy: 0.2705078125\n",
      "Batch: 7, Loss: 2.6954843997955322, Accuracy: 0.2724609375\n",
      "Batch: 8, Loss: 2.796553373336792, Accuracy: 0.2529296875\n",
      "Batch: 9, Loss: 2.826406478881836, Accuracy: 0.248046875\n",
      "Batch: 10, Loss: 2.773005247116089, Accuracy: 0.2490234375\n",
      "Batch: 11, Loss: 2.549464225769043, Accuracy: 0.3125\n",
      "Batch: 12, Loss: 2.794429302215576, Accuracy: 0.25390625\n",
      "Batch: 13, Loss: 2.940429210662842, Accuracy: 0.259765625\n",
      "Batch: 14, Loss: 2.7177984714508057, Accuracy: 0.2646484375\n",
      "Batch: 15, Loss: 2.9416110515594482, Accuracy: 0.2392578125\n",
      "Batch: 16, Loss: 2.6689109802246094, Accuracy: 0.27734375\n",
      "Batch: 17, Loss: 2.6930160522460938, Accuracy: 0.2685546875\n",
      "Batch: 18, Loss: 2.6837334632873535, Accuracy: 0.2744140625\n",
      "Batch: 19, Loss: 2.8088412284851074, Accuracy: 0.26171875\n",
      "Batch: 20, Loss: 2.949791431427002, Accuracy: 0.2490234375\n",
      "Batch: 21, Loss: 2.7290430068969727, Accuracy: 0.287109375\n",
      "Batch: 22, Loss: 2.6295063495635986, Accuracy: 0.2919921875\n",
      "Batch: 23, Loss: 2.665374755859375, Accuracy: 0.2724609375\n",
      "Batch: 24, Loss: 2.806765079498291, Accuracy: 0.236328125\n",
      "Batch: 25, Loss: 2.6857385635375977, Accuracy: 0.2646484375\n",
      "Batch: 26, Loss: 2.6584813594818115, Accuracy: 0.2783203125\n",
      "Batch: 27, Loss: 2.705563545227051, Accuracy: 0.2587890625\n",
      "Batch: 28, Loss: 2.591517448425293, Accuracy: 0.2861328125\n",
      "Batch: 29, Loss: 2.681877851486206, Accuracy: 0.2587890625\n",
      "Batch: 30, Loss: 2.9675350189208984, Accuracy: 0.236328125\n",
      "Batch: 31, Loss: 2.877256155014038, Accuracy: 0.2548828125\n",
      "Batch: 32, Loss: 2.673464775085449, Accuracy: 0.2685546875\n",
      "Batch: 33, Loss: 2.681671619415283, Accuracy: 0.275390625\n",
      "Batch: 34, Loss: 2.682344913482666, Accuracy: 0.271484375\n",
      "Batch: 35, Loss: 2.7099671363830566, Accuracy: 0.2646484375\n",
      "Batch: 36, Loss: 2.8255088329315186, Accuracy: 0.26171875\n",
      "Batch: 37, Loss: 2.7194929122924805, Accuracy: 0.2880859375\n",
      "Batch: 38, Loss: 2.646791458129883, Accuracy: 0.271484375\n",
      "Batch: 39, Loss: 2.7129411697387695, Accuracy: 0.2734375\n",
      "Batch: 40, Loss: 2.8243415355682373, Accuracy: 0.2685546875\n",
      "Batch: 41, Loss: 2.711276054382324, Accuracy: 0.294921875\n",
      "Batch: 42, Loss: 2.554871082305908, Accuracy: 0.3115234375\n",
      "Batch: 43, Loss: 2.463831901550293, Accuracy: 0.328125\n",
      "Batch: 44, Loss: 2.4634618759155273, Accuracy: 0.32421875\n",
      "Batch: 45, Loss: 2.5055413246154785, Accuracy: 0.3310546875\n",
      "Batch: 46, Loss: 2.7338290214538574, Accuracy: 0.2939453125\n",
      "Batch: 47, Loss: 2.794652223587036, Accuracy: 0.2763671875\n",
      "Batch: 48, Loss: 2.661618709564209, Accuracy: 0.291015625\n",
      "Batch: 49, Loss: 2.622648000717163, Accuracy: 0.294921875\n",
      "Batch: 50, Loss: 2.564276695251465, Accuracy: 0.3037109375\n",
      "Batch: 51, Loss: 2.625417709350586, Accuracy: 0.2861328125\n",
      "Batch: 52, Loss: 2.7094919681549072, Accuracy: 0.2958984375\n",
      "Batch: 53, Loss: 2.5429553985595703, Accuracy: 0.3193359375\n",
      "Batch: 54, Loss: 2.62506103515625, Accuracy: 0.2880859375\n",
      "Batch: 55, Loss: 2.5430760383605957, Accuracy: 0.3017578125\n",
      "Batch: 56, Loss: 2.596714735031128, Accuracy: 0.3154296875\n",
      "Batch: 57, Loss: 2.6443371772766113, Accuracy: 0.298828125\n",
      "Batch: 58, Loss: 2.6147732734680176, Accuracy: 0.294921875\n",
      "Batch: 59, Loss: 2.6790003776550293, Accuracy: 0.2861328125\n",
      "Batch: 60, Loss: 2.526320457458496, Accuracy: 0.3134765625\n",
      "Batch: 61, Loss: 2.560086250305176, Accuracy: 0.30078125\n",
      "Batch: 62, Loss: 2.726102352142334, Accuracy: 0.2802734375\n",
      "Batch: 63, Loss: 2.562344789505005, Accuracy: 0.30078125\n",
      "Batch: 64, Loss: 2.5740838050842285, Accuracy: 0.2978515625\n",
      "Batch: 65, Loss: 2.583709716796875, Accuracy: 0.2890625\n",
      "Batch: 66, Loss: 2.50576114654541, Accuracy: 0.322265625\n",
      "Batch: 67, Loss: 2.444754123687744, Accuracy: 0.3330078125\n",
      "Batch: 68, Loss: 2.5461177825927734, Accuracy: 0.3310546875\n",
      "Batch: 69, Loss: 2.5745689868927, Accuracy: 0.32421875\n",
      "Batch: 70, Loss: 2.6254866123199463, Accuracy: 0.3076171875\n",
      "Batch: 71, Loss: 2.4898955821990967, Accuracy: 0.328125\n",
      "Batch: 72, Loss: 2.518977165222168, Accuracy: 0.3193359375\n",
      "Batch: 73, Loss: 2.7140440940856934, Accuracy: 0.2822265625\n",
      "Batch: 74, Loss: 2.5838191509246826, Accuracy: 0.2958984375\n",
      "Batch: 75, Loss: 2.4652254581451416, Accuracy: 0.3271484375\n",
      "Batch: 76, Loss: 2.4270083904266357, Accuracy: 0.3271484375\n",
      "Batch: 77, Loss: 2.510192394256592, Accuracy: 0.3076171875\n",
      "Batch: 78, Loss: 2.7194325923919678, Accuracy: 0.2880859375\n",
      "Batch: 79, Loss: 2.688129425048828, Accuracy: 0.30859375\n",
      "Batch: 80, Loss: 2.3640952110290527, Accuracy: 0.357421875\n",
      "Batch: 81, Loss: 2.3206467628479004, Accuracy: 0.3388671875\n",
      "Batch: 82, Loss: 2.3325629234313965, Accuracy: 0.365234375\n",
      "Batch: 83, Loss: 2.5003442764282227, Accuracy: 0.3291015625\n",
      "Batch: 84, Loss: 2.5144262313842773, Accuracy: 0.3310546875\n",
      "Batch: 85, Loss: 2.537670850753784, Accuracy: 0.3173828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 86, Loss: 2.464176893234253, Accuracy: 0.322265625\n",
      "Batch: 87, Loss: 2.4873833656311035, Accuracy: 0.328125\n",
      "Batch: 88, Loss: 2.4784650802612305, Accuracy: 0.341796875\n",
      "Batch: 89, Loss: 2.4915523529052734, Accuracy: 0.3154296875\n",
      "Batch: 90, Loss: 2.4709630012512207, Accuracy: 0.3154296875\n",
      "Batch: 91, Loss: 2.4291648864746094, Accuracy: 0.3359375\n",
      "Batch: 92, Loss: 2.471133232116699, Accuracy: 0.31640625\n",
      "Batch: 93, Loss: 2.4541542530059814, Accuracy: 0.333984375\n",
      "Batch: 94, Loss: 2.398630380630493, Accuracy: 0.3447265625\n",
      "Batch: 95, Loss: 2.266941785812378, Accuracy: 0.3720703125\n",
      "Batch: 96, Loss: 2.5147109031677246, Accuracy: 0.3232421875\n",
      "Batch: 97, Loss: 2.425522804260254, Accuracy: 0.3466796875\n",
      "Batch: 98, Loss: 2.4308316707611084, Accuracy: 0.357421875\n",
      "Batch: 99, Loss: 2.3059072494506836, Accuracy: 0.3603515625\n",
      "Batch: 100, Loss: 2.230618953704834, Accuracy: 0.3662109375\n",
      "Batch: 101, Loss: 2.351395606994629, Accuracy: 0.3662109375\n",
      "Batch: 102, Loss: 2.268540382385254, Accuracy: 0.37890625\n",
      "Batch: 103, Loss: 2.544003963470459, Accuracy: 0.3330078125\n",
      "Batch: 104, Loss: 2.3040037155151367, Accuracy: 0.380859375\n",
      "Batch: 105, Loss: 2.3172056674957275, Accuracy: 0.357421875\n",
      "Batch: 106, Loss: 2.3774542808532715, Accuracy: 0.3564453125\n",
      "Batch: 107, Loss: 2.504183292388916, Accuracy: 0.34765625\n",
      "Batch: 108, Loss: 2.519073009490967, Accuracy: 0.3486328125\n",
      "Batch: 109, Loss: 2.4680395126342773, Accuracy: 0.3662109375\n",
      "Batch: 110, Loss: 2.2716064453125, Accuracy: 0.3837890625\n",
      "Batch: 111, Loss: 2.236647129058838, Accuracy: 0.396484375\n",
      "Batch: 112, Loss: 2.447413921356201, Accuracy: 0.359375\n",
      "Batch: 113, Loss: 2.4897279739379883, Accuracy: 0.357421875\n",
      "Batch: 114, Loss: 2.32173228263855, Accuracy: 0.349609375\n",
      "Batch: 115, Loss: 2.422417640686035, Accuracy: 0.365234375\n",
      "Batch: 116, Loss: 2.3986849784851074, Accuracy: 0.3408203125\n",
      "Batch: 117, Loss: 2.4931082725524902, Accuracy: 0.3525390625\n",
      "Batch: 118, Loss: 2.405843734741211, Accuracy: 0.3427734375\n",
      "Batch: 119, Loss: 2.402257204055786, Accuracy: 0.3671875\n",
      "Batch: 120, Loss: 2.2608909606933594, Accuracy: 0.38671875\n",
      "Batch: 121, Loss: 2.3253955841064453, Accuracy: 0.37890625\n",
      "Batch: 122, Loss: 2.5303218364715576, Accuracy: 0.31640625\n",
      "Batch: 123, Loss: 2.3927626609802246, Accuracy: 0.35546875\n",
      "Batch: 124, Loss: 2.3869166374206543, Accuracy: 0.365234375\n",
      "Batch: 125, Loss: 2.3483400344848633, Accuracy: 0.3515625\n",
      "Batch: 126, Loss: 2.3762195110321045, Accuracy: 0.3505859375\n",
      "Batch: 127, Loss: 2.3647823333740234, Accuracy: 0.3505859375\n",
      "Batch: 128, Loss: 2.4771595001220703, Accuracy: 0.330078125\n",
      "Batch: 129, Loss: 2.343243360519409, Accuracy: 0.375\n",
      "Batch: 130, Loss: 2.5035762786865234, Accuracy: 0.3359375\n",
      "Batch: 131, Loss: 2.458857536315918, Accuracy: 0.3447265625\n",
      "Batch: 132, Loss: 2.4788403511047363, Accuracy: 0.353515625\n",
      "Batch: 133, Loss: 2.4088311195373535, Accuracy: 0.3681640625\n",
      "Batch: 134, Loss: 2.382256031036377, Accuracy: 0.369140625\n",
      "Batch: 135, Loss: 2.238971710205078, Accuracy: 0.4052734375\n",
      "Batch: 136, Loss: 2.2116587162017822, Accuracy: 0.4111328125\n",
      "Batch: 137, Loss: 2.100053071975708, Accuracy: 0.4208984375\n",
      "Batch: 138, Loss: 2.1813747882843018, Accuracy: 0.40234375\n",
      "Batch: 139, Loss: 2.1740360260009766, Accuracy: 0.3984375\n",
      "Batch: 140, Loss: 2.3221187591552734, Accuracy: 0.3818359375\n",
      "Batch: 141, Loss: 2.281923532485962, Accuracy: 0.3876953125\n",
      "Batch: 142, Loss: 2.2508039474487305, Accuracy: 0.3916015625\n",
      "Batch: 143, Loss: 2.3538832664489746, Accuracy: 0.3662109375\n",
      "Batch: 144, Loss: 2.3360037803649902, Accuracy: 0.3828125\n",
      "Batch: 145, Loss: 2.2522225379943848, Accuracy: 0.380859375\n",
      "Batch: 146, Loss: 2.350738525390625, Accuracy: 0.3779296875\n",
      "Batch: 147, Loss: 2.2821788787841797, Accuracy: 0.3779296875\n",
      "Batch: 148, Loss: 2.304274082183838, Accuracy: 0.37109375\n",
      "Batch: 149, Loss: 2.3385300636291504, Accuracy: 0.3740234375\n",
      "Batch: 150, Loss: 2.23930025100708, Accuracy: 0.392578125\n",
      "Batch: 151, Loss: 2.367002010345459, Accuracy: 0.3720703125\n",
      "Epoch 3/80\n",
      "Batch: 1, Loss: 2.225146770477295, Accuracy: 0.369140625\n",
      "Batch: 2, Loss: 2.057406425476074, Accuracy: 0.4150390625\n",
      "Batch: 3, Loss: 2.2185704708099365, Accuracy: 0.4033203125\n",
      "Batch: 4, Loss: 2.3316233158111572, Accuracy: 0.3916015625\n",
      "Batch: 5, Loss: 2.2643985748291016, Accuracy: 0.396484375\n",
      "Batch: 6, Loss: 2.124671459197998, Accuracy: 0.4189453125\n",
      "Batch: 7, Loss: 2.0754785537719727, Accuracy: 0.41015625\n",
      "Batch: 8, Loss: 2.145693302154541, Accuracy: 0.4052734375\n",
      "Batch: 9, Loss: 2.119619607925415, Accuracy: 0.423828125\n",
      "Batch: 10, Loss: 2.1472525596618652, Accuracy: 0.400390625\n",
      "Batch: 11, Loss: 2.0510575771331787, Accuracy: 0.423828125\n",
      "Batch: 12, Loss: 2.260025978088379, Accuracy: 0.376953125\n",
      "Batch: 13, Loss: 2.2081031799316406, Accuracy: 0.41015625\n",
      "Batch: 14, Loss: 2.182408332824707, Accuracy: 0.3955078125\n",
      "Batch: 15, Loss: 2.2566921710968018, Accuracy: 0.408203125\n",
      "Batch: 16, Loss: 2.0730834007263184, Accuracy: 0.4326171875\n",
      "Batch: 17, Loss: 2.1562561988830566, Accuracy: 0.396484375\n",
      "Batch: 18, Loss: 2.1939947605133057, Accuracy: 0.392578125\n",
      "Batch: 19, Loss: 2.282102584838867, Accuracy: 0.3818359375\n",
      "Batch: 20, Loss: 2.289435386657715, Accuracy: 0.392578125\n",
      "Batch: 21, Loss: 2.0773863792419434, Accuracy: 0.4228515625\n",
      "Batch: 22, Loss: 2.1653518676757812, Accuracy: 0.392578125\n",
      "Batch: 23, Loss: 2.1351263523101807, Accuracy: 0.4052734375\n",
      "Batch: 24, Loss: 2.2531819343566895, Accuracy: 0.3818359375\n",
      "Batch: 25, Loss: 2.1189489364624023, Accuracy: 0.4150390625\n",
      "Batch: 26, Loss: 2.0381083488464355, Accuracy: 0.4453125\n",
      "Batch: 27, Loss: 2.145040512084961, Accuracy: 0.3916015625\n",
      "Batch: 28, Loss: 2.1084089279174805, Accuracy: 0.3955078125\n",
      "Batch: 29, Loss: 2.1321334838867188, Accuracy: 0.408203125\n",
      "Batch: 30, Loss: 2.3048269748687744, Accuracy: 0.40234375\n",
      "Batch: 31, Loss: 2.2536518573760986, Accuracy: 0.4052734375\n",
      "Batch: 32, Loss: 2.0852296352386475, Accuracy: 0.4287109375\n",
      "Batch: 33, Loss: 2.1834964752197266, Accuracy: 0.4072265625\n",
      "Batch: 34, Loss: 2.2424063682556152, Accuracy: 0.3818359375\n",
      "Batch: 35, Loss: 2.1596860885620117, Accuracy: 0.4208984375\n",
      "Batch: 36, Loss: 2.245485544204712, Accuracy: 0.412109375\n",
      "Batch: 37, Loss: 2.183643102645874, Accuracy: 0.408203125\n",
      "Batch: 38, Loss: 2.120664596557617, Accuracy: 0.404296875\n",
      "Batch: 39, Loss: 2.190692901611328, Accuracy: 0.40234375\n",
      "Batch: 40, Loss: 2.253347158432007, Accuracy: 0.4208984375\n",
      "Batch: 41, Loss: 2.12139892578125, Accuracy: 0.44140625\n",
      "Batch: 42, Loss: 1.9915363788604736, Accuracy: 0.443359375\n",
      "Batch: 43, Loss: 1.9812610149383545, Accuracy: 0.4501953125\n",
      "Batch: 44, Loss: 1.9514825344085693, Accuracy: 0.4658203125\n",
      "Batch: 45, Loss: 1.9372868537902832, Accuracy: 0.474609375\n",
      "Batch: 46, Loss: 2.1901934146881104, Accuracy: 0.4248046875\n",
      "Batch: 47, Loss: 2.2491021156311035, Accuracy: 0.4033203125\n",
      "Batch: 48, Loss: 2.1759796142578125, Accuracy: 0.404296875\n",
      "Batch: 49, Loss: 2.1400299072265625, Accuracy: 0.404296875\n",
      "Batch: 50, Loss: 2.1132946014404297, Accuracy: 0.408203125\n",
      "Batch: 51, Loss: 2.230480909347534, Accuracy: 0.3876953125\n",
      "Batch: 52, Loss: 2.2259490489959717, Accuracy: 0.4052734375\n",
      "Batch: 53, Loss: 1.9888842105865479, Accuracy: 0.451171875\n",
      "Batch: 54, Loss: 2.060025215148926, Accuracy: 0.4521484375\n",
      "Batch: 55, Loss: 2.059494972229004, Accuracy: 0.4208984375\n",
      "Batch: 56, Loss: 2.1706812381744385, Accuracy: 0.4208984375\n",
      "Batch: 57, Loss: 2.1736526489257812, Accuracy: 0.400390625\n",
      "Batch: 58, Loss: 2.1683454513549805, Accuracy: 0.392578125\n",
      "Batch: 59, Loss: 2.0684142112731934, Accuracy: 0.4599609375\n",
      "Batch: 60, Loss: 1.9816681146621704, Accuracy: 0.44140625\n",
      "Batch: 61, Loss: 2.1115214824676514, Accuracy: 0.4140625\n",
      "Batch: 62, Loss: 2.254098415374756, Accuracy: 0.388671875\n",
      "Batch: 63, Loss: 2.1064233779907227, Accuracy: 0.4208984375\n",
      "Batch: 64, Loss: 2.008114814758301, Accuracy: 0.4541015625\n",
      "Batch: 65, Loss: 2.12656307220459, Accuracy: 0.419921875\n",
      "Batch: 66, Loss: 2.0397026538848877, Accuracy: 0.4482421875\n",
      "Batch: 67, Loss: 2.059401035308838, Accuracy: 0.44921875\n",
      "Batch: 68, Loss: 2.1119749546051025, Accuracy: 0.4443359375\n",
      "Batch: 69, Loss: 2.097827434539795, Accuracy: 0.4365234375\n",
      "Batch: 70, Loss: 2.1231348514556885, Accuracy: 0.423828125\n",
      "Batch: 71, Loss: 2.008094072341919, Accuracy: 0.4423828125\n",
      "Batch: 72, Loss: 1.9888036251068115, Accuracy: 0.4375\n",
      "Batch: 73, Loss: 2.2599985599517822, Accuracy: 0.3916015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 74, Loss: 2.089238166809082, Accuracy: 0.423828125\n",
      "Batch: 75, Loss: 1.928659200668335, Accuracy: 0.458984375\n",
      "Batch: 76, Loss: 2.003109931945801, Accuracy: 0.4375\n",
      "Batch: 77, Loss: 2.0673952102661133, Accuracy: 0.412109375\n",
      "Batch: 78, Loss: 2.2576541900634766, Accuracy: 0.41015625\n",
      "Batch: 79, Loss: 2.0381343364715576, Accuracy: 0.474609375\n",
      "Batch: 80, Loss: 1.9272329807281494, Accuracy: 0.4462890625\n",
      "Batch: 81, Loss: 1.9447200298309326, Accuracy: 0.421875\n",
      "Batch: 82, Loss: 1.935229778289795, Accuracy: 0.447265625\n",
      "Batch: 83, Loss: 1.9926490783691406, Accuracy: 0.45703125\n",
      "Batch: 84, Loss: 1.996907353401184, Accuracy: 0.4638671875\n",
      "Batch: 85, Loss: 2.059488296508789, Accuracy: 0.431640625\n",
      "Batch: 86, Loss: 2.089843273162842, Accuracy: 0.4130859375\n",
      "Batch: 87, Loss: 2.052381992340088, Accuracy: 0.4423828125\n",
      "Batch: 88, Loss: 2.061427116394043, Accuracy: 0.43359375\n",
      "Batch: 89, Loss: 2.063239336013794, Accuracy: 0.4326171875\n",
      "Batch: 90, Loss: 2.0261666774749756, Accuracy: 0.4228515625\n",
      "Batch: 91, Loss: 1.9799084663391113, Accuracy: 0.4326171875\n",
      "Batch: 92, Loss: 2.0595595836639404, Accuracy: 0.4189453125\n",
      "Batch: 93, Loss: 2.0469558238983154, Accuracy: 0.4375\n",
      "Batch: 94, Loss: 2.0133004188537598, Accuracy: 0.4501953125\n",
      "Batch: 95, Loss: 1.9019644260406494, Accuracy: 0.4638671875\n",
      "Batch: 96, Loss: 2.07966947555542, Accuracy: 0.453125\n",
      "Batch: 97, Loss: 1.953572154045105, Accuracy: 0.4560546875\n",
      "Batch: 98, Loss: 1.9329659938812256, Accuracy: 0.498046875\n",
      "Batch: 99, Loss: 1.8978805541992188, Accuracy: 0.4619140625\n",
      "Batch: 100, Loss: 1.9152922630310059, Accuracy: 0.458984375\n",
      "Batch: 101, Loss: 1.9241007566452026, Accuracy: 0.458984375\n",
      "Batch: 102, Loss: 1.8777687549591064, Accuracy: 0.4541015625\n",
      "Batch: 103, Loss: 2.1067121028900146, Accuracy: 0.4375\n",
      "Batch: 104, Loss: 1.9259554147720337, Accuracy: 0.453125\n",
      "Batch: 105, Loss: 1.9860318899154663, Accuracy: 0.435546875\n",
      "Batch: 106, Loss: 1.9815301895141602, Accuracy: 0.4521484375\n",
      "Batch: 107, Loss: 2.118117570877075, Accuracy: 0.43359375\n",
      "Batch: 108, Loss: 2.1752030849456787, Accuracy: 0.40625\n",
      "Batch: 109, Loss: 2.1179447174072266, Accuracy: 0.42578125\n",
      "Batch: 110, Loss: 1.864182949066162, Accuracy: 0.4677734375\n",
      "Batch: 111, Loss: 1.916019320487976, Accuracy: 0.4501953125\n",
      "Batch: 112, Loss: 2.082127571105957, Accuracy: 0.4326171875\n",
      "Batch: 113, Loss: 2.1100709438323975, Accuracy: 0.423828125\n",
      "Batch: 114, Loss: 2.0252761840820312, Accuracy: 0.412109375\n",
      "Batch: 115, Loss: 2.0886120796203613, Accuracy: 0.431640625\n",
      "Batch: 116, Loss: 2.0640006065368652, Accuracy: 0.4345703125\n",
      "Batch: 117, Loss: 2.162458896636963, Accuracy: 0.421875\n",
      "Batch: 118, Loss: 1.9844634532928467, Accuracy: 0.4541015625\n",
      "Batch: 119, Loss: 1.9853651523590088, Accuracy: 0.4697265625\n",
      "Batch: 120, Loss: 1.9724957942962646, Accuracy: 0.4462890625\n",
      "Batch: 121, Loss: 2.0259618759155273, Accuracy: 0.4423828125\n",
      "Batch: 122, Loss: 2.1229424476623535, Accuracy: 0.4375\n",
      "Batch: 123, Loss: 1.9975066184997559, Accuracy: 0.470703125\n",
      "Batch: 124, Loss: 2.038079023361206, Accuracy: 0.4638671875\n",
      "Batch: 125, Loss: 2.029649019241333, Accuracy: 0.4248046875\n",
      "Batch: 126, Loss: 2.038214921951294, Accuracy: 0.4130859375\n",
      "Batch: 127, Loss: 1.9476014375686646, Accuracy: 0.4853515625\n",
      "Batch: 128, Loss: 2.153278350830078, Accuracy: 0.4140625\n",
      "Batch: 129, Loss: 1.9953958988189697, Accuracy: 0.4365234375\n",
      "Batch: 130, Loss: 2.1712775230407715, Accuracy: 0.4111328125\n",
      "Batch: 131, Loss: 2.1010265350341797, Accuracy: 0.4228515625\n",
      "Batch: 132, Loss: 2.0932769775390625, Accuracy: 0.4345703125\n",
      "Batch: 133, Loss: 2.0174317359924316, Accuracy: 0.455078125\n",
      "Batch: 134, Loss: 2.0408411026000977, Accuracy: 0.423828125\n",
      "Batch: 135, Loss: 1.8965187072753906, Accuracy: 0.490234375\n",
      "Batch: 136, Loss: 1.8851842880249023, Accuracy: 0.4736328125\n",
      "Batch: 137, Loss: 1.8092485666275024, Accuracy: 0.4560546875\n",
      "Batch: 138, Loss: 1.8210101127624512, Accuracy: 0.470703125\n",
      "Batch: 139, Loss: 1.8902943134307861, Accuracy: 0.4541015625\n",
      "Batch: 140, Loss: 2.0251433849334717, Accuracy: 0.4345703125\n",
      "Batch: 141, Loss: 1.970201849937439, Accuracy: 0.455078125\n",
      "Batch: 142, Loss: 1.9549919366836548, Accuracy: 0.4521484375\n",
      "Batch: 143, Loss: 2.025839328765869, Accuracy: 0.4287109375\n",
      "Batch: 144, Loss: 1.972623586654663, Accuracy: 0.447265625\n",
      "Batch: 145, Loss: 1.903328776359558, Accuracy: 0.4501953125\n",
      "Batch: 146, Loss: 2.051100254058838, Accuracy: 0.416015625\n",
      "Batch: 147, Loss: 1.9315686225891113, Accuracy: 0.46484375\n",
      "Batch: 148, Loss: 2.006829261779785, Accuracy: 0.4228515625\n",
      "Batch: 149, Loss: 1.9807043075561523, Accuracy: 0.4345703125\n",
      "Batch: 150, Loss: 1.9345335960388184, Accuracy: 0.4521484375\n",
      "Batch: 151, Loss: 2.0170836448669434, Accuracy: 0.4658203125\n",
      "Epoch 4/80\n",
      "Batch: 1, Loss: 1.9576212167739868, Accuracy: 0.400390625\n",
      "Batch: 2, Loss: 1.7889848947525024, Accuracy: 0.4609375\n",
      "Batch: 3, Loss: 1.8499622344970703, Accuracy: 0.478515625\n",
      "Batch: 4, Loss: 1.94273042678833, Accuracy: 0.478515625\n",
      "Batch: 5, Loss: 1.9555318355560303, Accuracy: 0.4384765625\n",
      "Batch: 6, Loss: 1.8185757398605347, Accuracy: 0.4794921875\n",
      "Batch: 7, Loss: 1.7702082395553589, Accuracy: 0.490234375\n",
      "Batch: 8, Loss: 1.8036895990371704, Accuracy: 0.46875\n",
      "Batch: 9, Loss: 1.8051316738128662, Accuracy: 0.494140625\n",
      "Batch: 10, Loss: 1.7889869213104248, Accuracy: 0.466796875\n",
      "Batch: 11, Loss: 1.786412000656128, Accuracy: 0.447265625\n",
      "Batch: 12, Loss: 1.9886393547058105, Accuracy: 0.4384765625\n",
      "Batch: 13, Loss: 1.8494541645050049, Accuracy: 0.498046875\n",
      "Batch: 14, Loss: 1.8791186809539795, Accuracy: 0.4599609375\n",
      "Batch: 15, Loss: 1.8841185569763184, Accuracy: 0.478515625\n",
      "Batch: 16, Loss: 1.8098812103271484, Accuracy: 0.486328125\n",
      "Batch: 17, Loss: 1.8399536609649658, Accuracy: 0.4482421875\n",
      "Batch: 18, Loss: 1.8989017009735107, Accuracy: 0.4365234375\n",
      "Batch: 19, Loss: 1.9621798992156982, Accuracy: 0.455078125\n",
      "Batch: 20, Loss: 1.9345998764038086, Accuracy: 0.4677734375\n",
      "Batch: 21, Loss: 1.7689218521118164, Accuracy: 0.5068359375\n",
      "Batch: 22, Loss: 1.9088430404663086, Accuracy: 0.4326171875\n",
      "Batch: 23, Loss: 1.860212802886963, Accuracy: 0.455078125\n",
      "Batch: 24, Loss: 1.9357316493988037, Accuracy: 0.455078125\n",
      "Batch: 25, Loss: 1.820824384689331, Accuracy: 0.4716796875\n",
      "Batch: 26, Loss: 1.7274523973464966, Accuracy: 0.49609375\n",
      "Batch: 27, Loss: 1.82033109664917, Accuracy: 0.453125\n",
      "Batch: 28, Loss: 1.8498533964157104, Accuracy: 0.44140625\n",
      "Batch: 29, Loss: 1.8644111156463623, Accuracy: 0.462890625\n",
      "Batch: 30, Loss: 1.9502960443496704, Accuracy: 0.470703125\n",
      "Batch: 31, Loss: 1.956221103668213, Accuracy: 0.4619140625\n",
      "Batch: 32, Loss: 1.8004786968231201, Accuracy: 0.486328125\n",
      "Batch: 33, Loss: 1.9484872817993164, Accuracy: 0.4306640625\n",
      "Batch: 34, Loss: 2.0165584087371826, Accuracy: 0.4287109375\n",
      "Batch: 35, Loss: 1.8753125667572021, Accuracy: 0.470703125\n",
      "Batch: 36, Loss: 1.9312816858291626, Accuracy: 0.4638671875\n",
      "Batch: 37, Loss: 1.8970484733581543, Accuracy: 0.4580078125\n",
      "Batch: 38, Loss: 1.861932396888733, Accuracy: 0.4423828125\n",
      "Batch: 39, Loss: 1.9148141145706177, Accuracy: 0.4609375\n",
      "Batch: 40, Loss: 1.9189698696136475, Accuracy: 0.4833984375\n",
      "Batch: 41, Loss: 1.8447370529174805, Accuracy: 0.5\n",
      "Batch: 42, Loss: 1.697991132736206, Accuracy: 0.505859375\n",
      "Batch: 43, Loss: 1.725061058998108, Accuracy: 0.4833984375\n",
      "Batch: 44, Loss: 1.717725157737732, Accuracy: 0.4931640625\n",
      "Batch: 45, Loss: 1.6447213888168335, Accuracy: 0.5205078125\n",
      "Batch: 46, Loss: 1.9063549041748047, Accuracy: 0.4912109375\n",
      "Batch: 47, Loss: 1.9259483814239502, Accuracy: 0.453125\n",
      "Batch: 48, Loss: 1.8883800506591797, Accuracy: 0.4501953125\n",
      "Batch: 49, Loss: 1.9013469219207764, Accuracy: 0.4482421875\n",
      "Batch: 50, Loss: 1.8563514947891235, Accuracy: 0.4541015625\n",
      "Batch: 51, Loss: 1.9964137077331543, Accuracy: 0.421875\n",
      "Batch: 52, Loss: 1.97617769241333, Accuracy: 0.451171875\n",
      "Batch: 53, Loss: 1.7061183452606201, Accuracy: 0.505859375\n",
      "Batch: 54, Loss: 1.812937617301941, Accuracy: 0.494140625\n",
      "Batch: 55, Loss: 1.7999465465545654, Accuracy: 0.4658203125\n",
      "Batch: 56, Loss: 1.9309401512145996, Accuracy: 0.44921875\n",
      "Batch: 57, Loss: 1.8988523483276367, Accuracy: 0.455078125\n",
      "Batch: 58, Loss: 1.9037848711013794, Accuracy: 0.4541015625\n",
      "Batch: 59, Loss: 1.7481307983398438, Accuracy: 0.5458984375\n",
      "Batch: 60, Loss: 1.7349493503570557, Accuracy: 0.4970703125\n",
      "Batch: 61, Loss: 1.873138189315796, Accuracy: 0.4619140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 62, Loss: 1.9393606185913086, Accuracy: 0.4443359375\n",
      "Batch: 63, Loss: 1.8628721237182617, Accuracy: 0.453125\n",
      "Batch: 64, Loss: 1.7662676572799683, Accuracy: 0.505859375\n",
      "Batch: 65, Loss: 1.8555322885513306, Accuracy: 0.458984375\n",
      "Batch: 66, Loss: 1.7880455255508423, Accuracy: 0.48828125\n",
      "Batch: 67, Loss: 1.8351154327392578, Accuracy: 0.4697265625\n",
      "Batch: 68, Loss: 1.8825585842132568, Accuracy: 0.4833984375\n",
      "Batch: 69, Loss: 1.8486523628234863, Accuracy: 0.4833984375\n",
      "Batch: 70, Loss: 1.8474675416946411, Accuracy: 0.4755859375\n",
      "Batch: 71, Loss: 1.761519432067871, Accuracy: 0.486328125\n",
      "Batch: 72, Loss: 1.7285078763961792, Accuracy: 0.4970703125\n",
      "Batch: 73, Loss: 1.9754691123962402, Accuracy: 0.4287109375\n",
      "Batch: 74, Loss: 1.7967535257339478, Accuracy: 0.4697265625\n",
      "Batch: 75, Loss: 1.6481338739395142, Accuracy: 0.515625\n",
      "Batch: 76, Loss: 1.7765843868255615, Accuracy: 0.453125\n",
      "Batch: 77, Loss: 1.8342986106872559, Accuracy: 0.4560546875\n",
      "Batch: 78, Loss: 1.9798691272735596, Accuracy: 0.462890625\n",
      "Batch: 79, Loss: 1.7405292987823486, Accuracy: 0.5302734375\n",
      "Batch: 80, Loss: 1.6472387313842773, Accuracy: 0.5166015625\n",
      "Batch: 81, Loss: 1.7336291074752808, Accuracy: 0.45703125\n",
      "Batch: 82, Loss: 1.7273378372192383, Accuracy: 0.46875\n",
      "Batch: 83, Loss: 1.7160682678222656, Accuracy: 0.5078125\n",
      "Batch: 84, Loss: 1.734388828277588, Accuracy: 0.5146484375\n",
      "Batch: 85, Loss: 1.7863038778305054, Accuracy: 0.4716796875\n",
      "Batch: 86, Loss: 1.9140617847442627, Accuracy: 0.443359375\n",
      "Batch: 87, Loss: 1.817870855331421, Accuracy: 0.482421875\n",
      "Batch: 88, Loss: 1.8085086345672607, Accuracy: 0.474609375\n",
      "Batch: 89, Loss: 1.8108656406402588, Accuracy: 0.46875\n",
      "Batch: 90, Loss: 1.757906436920166, Accuracy: 0.4931640625\n",
      "Batch: 91, Loss: 1.7439627647399902, Accuracy: 0.4775390625\n",
      "Batch: 92, Loss: 1.8440399169921875, Accuracy: 0.45703125\n",
      "Batch: 93, Loss: 1.7745747566223145, Accuracy: 0.4833984375\n",
      "Batch: 94, Loss: 1.7754063606262207, Accuracy: 0.482421875\n",
      "Batch: 95, Loss: 1.7152420282363892, Accuracy: 0.4892578125\n",
      "Batch: 96, Loss: 1.8213850259780884, Accuracy: 0.494140625\n",
      "Batch: 97, Loss: 1.6921470165252686, Accuracy: 0.5166015625\n",
      "Batch: 98, Loss: 1.659703016281128, Accuracy: 0.5400390625\n",
      "Batch: 99, Loss: 1.6777541637420654, Accuracy: 0.5126953125\n",
      "Batch: 100, Loss: 1.716529369354248, Accuracy: 0.4951171875\n",
      "Batch: 101, Loss: 1.7277873754501343, Accuracy: 0.4912109375\n",
      "Batch: 102, Loss: 1.653237223625183, Accuracy: 0.5087890625\n",
      "Batch: 103, Loss: 1.838823914527893, Accuracy: 0.4921875\n",
      "Batch: 104, Loss: 1.7131731510162354, Accuracy: 0.501953125\n",
      "Batch: 105, Loss: 1.7778041362762451, Accuracy: 0.4912109375\n",
      "Batch: 106, Loss: 1.7638978958129883, Accuracy: 0.474609375\n",
      "Batch: 107, Loss: 1.890667200088501, Accuracy: 0.45703125\n",
      "Batch: 108, Loss: 1.9343702793121338, Accuracy: 0.4560546875\n",
      "Batch: 109, Loss: 1.9019438028335571, Accuracy: 0.44921875\n",
      "Batch: 110, Loss: 1.6249966621398926, Accuracy: 0.51953125\n",
      "Batch: 111, Loss: 1.7660226821899414, Accuracy: 0.470703125\n",
      "Batch: 112, Loss: 1.8368968963623047, Accuracy: 0.48046875\n",
      "Batch: 113, Loss: 1.9307256937026978, Accuracy: 0.4560546875\n",
      "Batch: 114, Loss: 1.8400694131851196, Accuracy: 0.4638671875\n",
      "Batch: 115, Loss: 1.9111382961273193, Accuracy: 0.46875\n",
      "Batch: 116, Loss: 1.8626518249511719, Accuracy: 0.4541015625\n",
      "Batch: 117, Loss: 1.9124168157577515, Accuracy: 0.494140625\n",
      "Batch: 118, Loss: 1.7314305305480957, Accuracy: 0.517578125\n",
      "Batch: 119, Loss: 1.761038899421692, Accuracy: 0.515625\n",
      "Batch: 120, Loss: 1.784792423248291, Accuracy: 0.4736328125\n",
      "Batch: 121, Loss: 1.8313379287719727, Accuracy: 0.470703125\n",
      "Batch: 122, Loss: 1.8766143321990967, Accuracy: 0.474609375\n",
      "Batch: 123, Loss: 1.794008731842041, Accuracy: 0.5078125\n",
      "Batch: 124, Loss: 1.824779748916626, Accuracy: 0.49609375\n",
      "Batch: 125, Loss: 1.8490352630615234, Accuracy: 0.4541015625\n",
      "Batch: 126, Loss: 1.8293983936309814, Accuracy: 0.4501953125\n",
      "Batch: 127, Loss: 1.7248854637145996, Accuracy: 0.5283203125\n",
      "Batch: 128, Loss: 1.9710431098937988, Accuracy: 0.4541015625\n",
      "Batch: 129, Loss: 1.7953720092773438, Accuracy: 0.48046875\n",
      "Batch: 130, Loss: 2.004800796508789, Accuracy: 0.427734375\n",
      "Batch: 131, Loss: 1.9170584678649902, Accuracy: 0.455078125\n",
      "Batch: 132, Loss: 1.893897294998169, Accuracy: 0.4658203125\n",
      "Batch: 133, Loss: 1.7962037324905396, Accuracy: 0.4970703125\n",
      "Batch: 134, Loss: 1.8528400659561157, Accuracy: 0.4423828125\n",
      "Batch: 135, Loss: 1.708727478981018, Accuracy: 0.5029296875\n",
      "Batch: 136, Loss: 1.7181553840637207, Accuracy: 0.4990234375\n",
      "Batch: 137, Loss: 1.6602469682693481, Accuracy: 0.48828125\n",
      "Batch: 138, Loss: 1.6054779291152954, Accuracy: 0.521484375\n",
      "Batch: 139, Loss: 1.6821520328521729, Accuracy: 0.4912109375\n",
      "Batch: 140, Loss: 1.820610761642456, Accuracy: 0.4658203125\n",
      "Batch: 141, Loss: 1.7705037593841553, Accuracy: 0.4892578125\n",
      "Batch: 142, Loss: 1.7753350734710693, Accuracy: 0.4853515625\n",
      "Batch: 143, Loss: 1.794661283493042, Accuracy: 0.482421875\n",
      "Batch: 144, Loss: 1.7680943012237549, Accuracy: 0.498046875\n",
      "Batch: 145, Loss: 1.710835576057434, Accuracy: 0.4921875\n",
      "Batch: 146, Loss: 1.8612205982208252, Accuracy: 0.4482421875\n",
      "Batch: 147, Loss: 1.732590913772583, Accuracy: 0.4970703125\n",
      "Batch: 148, Loss: 1.8780183792114258, Accuracy: 0.4267578125\n",
      "Batch: 149, Loss: 1.8102235794067383, Accuracy: 0.4609375\n",
      "Batch: 150, Loss: 1.7326136827468872, Accuracy: 0.486328125\n",
      "Batch: 151, Loss: 1.8115403652191162, Accuracy: 0.5\n",
      "Epoch 5/80\n",
      "Batch: 1, Loss: 1.7938584089279175, Accuracy: 0.4384765625\n",
      "Batch: 2, Loss: 1.647713303565979, Accuracy: 0.494140625\n",
      "Batch: 3, Loss: 1.6436467170715332, Accuracy: 0.5224609375\n",
      "Batch: 4, Loss: 1.7125639915466309, Accuracy: 0.51953125\n",
      "Batch: 5, Loss: 1.7490465641021729, Accuracy: 0.4853515625\n",
      "Batch: 6, Loss: 1.6488947868347168, Accuracy: 0.490234375\n",
      "Batch: 7, Loss: 1.620330572128296, Accuracy: 0.51171875\n",
      "Batch: 8, Loss: 1.5934149026870728, Accuracy: 0.521484375\n",
      "Batch: 9, Loss: 1.5974429845809937, Accuracy: 0.5341796875\n",
      "Batch: 10, Loss: 1.6140985488891602, Accuracy: 0.5166015625\n",
      "Batch: 11, Loss: 1.656698226928711, Accuracy: 0.4814453125\n",
      "Batch: 12, Loss: 1.827603816986084, Accuracy: 0.4521484375\n",
      "Batch: 13, Loss: 1.6300342082977295, Accuracy: 0.5234375\n",
      "Batch: 14, Loss: 1.713142991065979, Accuracy: 0.4990234375\n",
      "Batch: 15, Loss: 1.695373773574829, Accuracy: 0.5244140625\n",
      "Batch: 16, Loss: 1.6158263683319092, Accuracy: 0.5224609375\n",
      "Batch: 17, Loss: 1.695190191268921, Accuracy: 0.4619140625\n",
      "Batch: 18, Loss: 1.7316030263900757, Accuracy: 0.4677734375\n",
      "Batch: 19, Loss: 1.8004279136657715, Accuracy: 0.4736328125\n",
      "Batch: 20, Loss: 1.7296415567398071, Accuracy: 0.5166015625\n",
      "Batch: 21, Loss: 1.598617672920227, Accuracy: 0.5166015625\n",
      "Batch: 22, Loss: 1.7724648714065552, Accuracy: 0.4658203125\n",
      "Batch: 23, Loss: 1.6972678899765015, Accuracy: 0.48046875\n",
      "Batch: 24, Loss: 1.750823974609375, Accuracy: 0.4970703125\n",
      "Batch: 25, Loss: 1.6493926048278809, Accuracy: 0.5009765625\n",
      "Batch: 26, Loss: 1.5496138334274292, Accuracy: 0.5419921875\n",
      "Batch: 27, Loss: 1.6488738059997559, Accuracy: 0.498046875\n",
      "Batch: 28, Loss: 1.704366683959961, Accuracy: 0.482421875\n",
      "Batch: 29, Loss: 1.692481517791748, Accuracy: 0.4697265625\n",
      "Batch: 30, Loss: 1.7459275722503662, Accuracy: 0.513671875\n",
      "Batch: 31, Loss: 1.7225821018218994, Accuracy: 0.51953125\n",
      "Batch: 32, Loss: 1.634169340133667, Accuracy: 0.5166015625\n",
      "Batch: 33, Loss: 1.7937259674072266, Accuracy: 0.470703125\n",
      "Batch: 34, Loss: 1.8855903148651123, Accuracy: 0.462890625\n",
      "Batch: 35, Loss: 1.7130746841430664, Accuracy: 0.474609375\n",
      "Batch: 36, Loss: 1.7538961172103882, Accuracy: 0.4892578125\n",
      "Batch: 37, Loss: 1.729461431503296, Accuracy: 0.4990234375\n",
      "Batch: 38, Loss: 1.6974087953567505, Accuracy: 0.4892578125\n",
      "Batch: 39, Loss: 1.7665505409240723, Accuracy: 0.4912109375\n",
      "Batch: 40, Loss: 1.7694032192230225, Accuracy: 0.5205078125\n",
      "Batch: 41, Loss: 1.6842460632324219, Accuracy: 0.51953125\n",
      "Batch: 42, Loss: 1.5239981412887573, Accuracy: 0.546875\n",
      "Batch: 43, Loss: 1.5923768281936646, Accuracy: 0.5107421875\n",
      "Batch: 44, Loss: 1.5900260210037231, Accuracy: 0.5087890625\n",
      "Batch: 45, Loss: 1.4743084907531738, Accuracy: 0.5556640625\n",
      "Batch: 46, Loss: 1.7348018884658813, Accuracy: 0.51953125\n",
      "Batch: 47, Loss: 1.7576649188995361, Accuracy: 0.482421875\n",
      "Batch: 48, Loss: 1.762204647064209, Accuracy: 0.474609375\n",
      "Batch: 49, Loss: 1.773627519607544, Accuracy: 0.46484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Loss: 1.7653019428253174, Accuracy: 0.474609375\n",
      "Batch: 51, Loss: 1.8729467391967773, Accuracy: 0.4501953125\n",
      "Batch: 52, Loss: 1.8223884105682373, Accuracy: 0.4736328125\n",
      "Batch: 53, Loss: 1.554664969444275, Accuracy: 0.517578125\n",
      "Batch: 54, Loss: 1.6634877920150757, Accuracy: 0.521484375\n",
      "Batch: 55, Loss: 1.6780991554260254, Accuracy: 0.486328125\n",
      "Batch: 56, Loss: 1.800785779953003, Accuracy: 0.4638671875\n",
      "Batch: 57, Loss: 1.753739356994629, Accuracy: 0.4990234375\n",
      "Batch: 58, Loss: 1.77245032787323, Accuracy: 0.4814453125\n",
      "Batch: 59, Loss: 1.5707523822784424, Accuracy: 0.55859375\n",
      "Batch: 60, Loss: 1.5746904611587524, Accuracy: 0.521484375\n",
      "Batch: 61, Loss: 1.6865227222442627, Accuracy: 0.494140625\n",
      "Batch: 62, Loss: 1.791327714920044, Accuracy: 0.484375\n",
      "Batch: 63, Loss: 1.7010560035705566, Accuracy: 0.4853515625\n",
      "Batch: 64, Loss: 1.6428682804107666, Accuracy: 0.5185546875\n",
      "Batch: 65, Loss: 1.7380667924880981, Accuracy: 0.4755859375\n",
      "Batch: 66, Loss: 1.6082816123962402, Accuracy: 0.5283203125\n",
      "Batch: 67, Loss: 1.7248518466949463, Accuracy: 0.4873046875\n",
      "Batch: 68, Loss: 1.743940830230713, Accuracy: 0.5146484375\n",
      "Batch: 69, Loss: 1.6978482007980347, Accuracy: 0.5068359375\n",
      "Batch: 70, Loss: 1.6986973285675049, Accuracy: 0.5009765625\n",
      "Batch: 71, Loss: 1.6297746896743774, Accuracy: 0.517578125\n",
      "Batch: 72, Loss: 1.570921540260315, Accuracy: 0.5185546875\n",
      "Batch: 73, Loss: 1.8025600910186768, Accuracy: 0.48828125\n",
      "Batch: 74, Loss: 1.6362626552581787, Accuracy: 0.51953125\n",
      "Batch: 75, Loss: 1.5266715288162231, Accuracy: 0.5361328125\n",
      "Batch: 76, Loss: 1.643712043762207, Accuracy: 0.455078125\n",
      "Batch: 77, Loss: 1.6720420122146606, Accuracy: 0.4833984375\n",
      "Batch: 78, Loss: 1.8148490190505981, Accuracy: 0.4970703125\n",
      "Batch: 79, Loss: 1.5700721740722656, Accuracy: 0.5693359375\n",
      "Batch: 80, Loss: 1.5423052310943604, Accuracy: 0.51953125\n",
      "Batch: 81, Loss: 1.6368257999420166, Accuracy: 0.4765625\n",
      "Batch: 82, Loss: 1.6158041954040527, Accuracy: 0.48828125\n",
      "Batch: 83, Loss: 1.5476280450820923, Accuracy: 0.537109375\n",
      "Batch: 84, Loss: 1.562617301940918, Accuracy: 0.5556640625\n",
      "Batch: 85, Loss: 1.6005568504333496, Accuracy: 0.5283203125\n",
      "Batch: 86, Loss: 1.7952603101730347, Accuracy: 0.458984375\n",
      "Batch: 87, Loss: 1.6368110179901123, Accuracy: 0.5205078125\n",
      "Batch: 88, Loss: 1.6841883659362793, Accuracy: 0.505859375\n",
      "Batch: 89, Loss: 1.683794617652893, Accuracy: 0.50390625\n",
      "Batch: 90, Loss: 1.5942490100860596, Accuracy: 0.515625\n",
      "Batch: 91, Loss: 1.5850979089736938, Accuracy: 0.525390625\n",
      "Batch: 92, Loss: 1.7180333137512207, Accuracy: 0.48046875\n",
      "Batch: 93, Loss: 1.633914828300476, Accuracy: 0.5244140625\n",
      "Batch: 94, Loss: 1.6266502141952515, Accuracy: 0.509765625\n",
      "Batch: 95, Loss: 1.6007635593414307, Accuracy: 0.505859375\n",
      "Batch: 96, Loss: 1.6583603620529175, Accuracy: 0.5166015625\n",
      "Batch: 97, Loss: 1.534804105758667, Accuracy: 0.5419921875\n",
      "Batch: 98, Loss: 1.5270593166351318, Accuracy: 0.560546875\n",
      "Batch: 99, Loss: 1.5133788585662842, Accuracy: 0.5380859375\n",
      "Batch: 100, Loss: 1.6037007570266724, Accuracy: 0.521484375\n",
      "Batch: 101, Loss: 1.6372777223587036, Accuracy: 0.50390625\n",
      "Batch: 102, Loss: 1.5241568088531494, Accuracy: 0.529296875\n",
      "Batch: 103, Loss: 1.6913392543792725, Accuracy: 0.53515625\n",
      "Batch: 104, Loss: 1.583809494972229, Accuracy: 0.5244140625\n",
      "Batch: 105, Loss: 1.6781566143035889, Accuracy: 0.494140625\n",
      "Batch: 106, Loss: 1.6366106271743774, Accuracy: 0.515625\n",
      "Batch: 107, Loss: 1.7677080631256104, Accuracy: 0.4716796875\n",
      "Batch: 108, Loss: 1.7855303287506104, Accuracy: 0.4765625\n",
      "Batch: 109, Loss: 1.7660465240478516, Accuracy: 0.4736328125\n",
      "Batch: 110, Loss: 1.4926509857177734, Accuracy: 0.537109375\n",
      "Batch: 111, Loss: 1.66965913772583, Accuracy: 0.486328125\n",
      "Batch: 112, Loss: 1.675492525100708, Accuracy: 0.515625\n",
      "Batch: 113, Loss: 1.7950043678283691, Accuracy: 0.494140625\n",
      "Batch: 114, Loss: 1.7569094896316528, Accuracy: 0.4755859375\n",
      "Batch: 115, Loss: 1.7873740196228027, Accuracy: 0.4990234375\n",
      "Batch: 116, Loss: 1.6993505954742432, Accuracy: 0.48046875\n",
      "Batch: 117, Loss: 1.7879483699798584, Accuracy: 0.4931640625\n",
      "Batch: 118, Loss: 1.5671169757843018, Accuracy: 0.5478515625\n",
      "Batch: 119, Loss: 1.6017651557922363, Accuracy: 0.5419921875\n",
      "Batch: 120, Loss: 1.6903618574142456, Accuracy: 0.4892578125\n",
      "Batch: 121, Loss: 1.707147479057312, Accuracy: 0.494140625\n",
      "Batch: 122, Loss: 1.699290156364441, Accuracy: 0.51171875\n",
      "Batch: 123, Loss: 1.628068208694458, Accuracy: 0.541015625\n",
      "Batch: 124, Loss: 1.6936880350112915, Accuracy: 0.5068359375\n",
      "Batch: 125, Loss: 1.7199440002441406, Accuracy: 0.482421875\n",
      "Batch: 126, Loss: 1.6947882175445557, Accuracy: 0.47265625\n",
      "Batch: 127, Loss: 1.5736818313598633, Accuracy: 0.5458984375\n",
      "Batch: 128, Loss: 1.8274927139282227, Accuracy: 0.4931640625\n",
      "Batch: 129, Loss: 1.6607369184494019, Accuracy: 0.509765625\n",
      "Batch: 130, Loss: 1.8699017763137817, Accuracy: 0.4521484375\n",
      "Batch: 131, Loss: 1.754676342010498, Accuracy: 0.48046875\n",
      "Batch: 132, Loss: 1.7355952262878418, Accuracy: 0.50390625\n",
      "Batch: 133, Loss: 1.6189491748809814, Accuracy: 0.53515625\n",
      "Batch: 134, Loss: 1.7021678686141968, Accuracy: 0.48828125\n",
      "Batch: 135, Loss: 1.6051292419433594, Accuracy: 0.5166015625\n",
      "Batch: 136, Loss: 1.6230884790420532, Accuracy: 0.5126953125\n",
      "Batch: 137, Loss: 1.5300952196121216, Accuracy: 0.517578125\n",
      "Batch: 138, Loss: 1.460667371749878, Accuracy: 0.5537109375\n",
      "Batch: 139, Loss: 1.5552606582641602, Accuracy: 0.5078125\n",
      "Batch: 140, Loss: 1.6978425979614258, Accuracy: 0.486328125\n",
      "Batch: 141, Loss: 1.6272807121276855, Accuracy: 0.5087890625\n",
      "Batch: 142, Loss: 1.66571044921875, Accuracy: 0.4951171875\n",
      "Batch: 143, Loss: 1.6765203475952148, Accuracy: 0.4990234375\n",
      "Batch: 144, Loss: 1.6315505504608154, Accuracy: 0.50390625\n",
      "Batch: 145, Loss: 1.585654854774475, Accuracy: 0.5185546875\n",
      "Batch: 146, Loss: 1.740632176399231, Accuracy: 0.4833984375\n",
      "Batch: 147, Loss: 1.618826150894165, Accuracy: 0.5107421875\n",
      "Batch: 148, Loss: 1.7742786407470703, Accuracy: 0.45703125\n",
      "Batch: 149, Loss: 1.665173888206482, Accuracy: 0.4892578125\n",
      "Batch: 150, Loss: 1.5904395580291748, Accuracy: 0.5126953125\n",
      "Batch: 151, Loss: 1.6534316539764404, Accuracy: 0.52734375\n",
      "Epoch 6/80\n",
      "Batch: 1, Loss: 1.7259461879730225, Accuracy: 0.455078125\n",
      "Batch: 2, Loss: 1.5463966131210327, Accuracy: 0.51171875\n",
      "Batch: 3, Loss: 1.5224366188049316, Accuracy: 0.552734375\n",
      "Batch: 4, Loss: 1.5314230918884277, Accuracy: 0.576171875\n",
      "Batch: 5, Loss: 1.616379737854004, Accuracy: 0.5185546875\n",
      "Batch: 6, Loss: 1.5186917781829834, Accuracy: 0.5107421875\n",
      "Batch: 7, Loss: 1.5036389827728271, Accuracy: 0.541015625\n",
      "Batch: 8, Loss: 1.496166467666626, Accuracy: 0.525390625\n",
      "Batch: 9, Loss: 1.4784014225006104, Accuracy: 0.5498046875\n",
      "Batch: 10, Loss: 1.4840848445892334, Accuracy: 0.5341796875\n",
      "Batch: 11, Loss: 1.583918809890747, Accuracy: 0.48046875\n",
      "Batch: 12, Loss: 1.6974989175796509, Accuracy: 0.4990234375\n",
      "Batch: 13, Loss: 1.4791496992111206, Accuracy: 0.5615234375\n",
      "Batch: 14, Loss: 1.6176948547363281, Accuracy: 0.5029296875\n",
      "Batch: 15, Loss: 1.5617780685424805, Accuracy: 0.556640625\n",
      "Batch: 16, Loss: 1.4927978515625, Accuracy: 0.529296875\n",
      "Batch: 17, Loss: 1.5989350080490112, Accuracy: 0.5078125\n",
      "Batch: 18, Loss: 1.6513034105300903, Accuracy: 0.4853515625\n",
      "Batch: 19, Loss: 1.6559557914733887, Accuracy: 0.5068359375\n",
      "Batch: 20, Loss: 1.603811502456665, Accuracy: 0.541015625\n",
      "Batch: 21, Loss: 1.5033421516418457, Accuracy: 0.55078125\n",
      "Batch: 22, Loss: 1.650336503982544, Accuracy: 0.498046875\n",
      "Batch: 23, Loss: 1.5839608907699585, Accuracy: 0.4970703125\n",
      "Batch: 24, Loss: 1.6208207607269287, Accuracy: 0.513671875\n",
      "Batch: 25, Loss: 1.5345301628112793, Accuracy: 0.525390625\n",
      "Batch: 26, Loss: 1.432243824005127, Accuracy: 0.5439453125\n",
      "Batch: 27, Loss: 1.539996862411499, Accuracy: 0.5146484375\n",
      "Batch: 28, Loss: 1.5872092247009277, Accuracy: 0.517578125\n",
      "Batch: 29, Loss: 1.5787312984466553, Accuracy: 0.5048828125\n",
      "Batch: 30, Loss: 1.6035453081130981, Accuracy: 0.5517578125\n",
      "Batch: 31, Loss: 1.5525128841400146, Accuracy: 0.560546875\n",
      "Batch: 32, Loss: 1.502434492111206, Accuracy: 0.5439453125\n",
      "Batch: 33, Loss: 1.6687856912612915, Accuracy: 0.4853515625\n",
      "Batch: 34, Loss: 1.763308048248291, Accuracy: 0.4697265625\n",
      "Batch: 35, Loss: 1.5857688188552856, Accuracy: 0.5009765625\n",
      "Batch: 36, Loss: 1.633025050163269, Accuracy: 0.51953125\n",
      "Batch: 37, Loss: 1.6017298698425293, Accuracy: 0.5087890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 38, Loss: 1.5705597400665283, Accuracy: 0.5126953125\n",
      "Batch: 39, Loss: 1.6335821151733398, Accuracy: 0.515625\n",
      "Batch: 40, Loss: 1.6497440338134766, Accuracy: 0.5302734375\n",
      "Batch: 41, Loss: 1.599128246307373, Accuracy: 0.5302734375\n",
      "Batch: 42, Loss: 1.4002199172973633, Accuracy: 0.5625\n",
      "Batch: 43, Loss: 1.5134806632995605, Accuracy: 0.51953125\n",
      "Batch: 44, Loss: 1.4915125370025635, Accuracy: 0.533203125\n",
      "Batch: 45, Loss: 1.381709337234497, Accuracy: 0.5693359375\n",
      "Batch: 46, Loss: 1.5918986797332764, Accuracy: 0.556640625\n",
      "Batch: 47, Loss: 1.6309332847595215, Accuracy: 0.50390625\n",
      "Batch: 48, Loss: 1.6004233360290527, Accuracy: 0.5234375\n",
      "Batch: 49, Loss: 1.652410864830017, Accuracy: 0.498046875\n",
      "Batch: 50, Loss: 1.625101089477539, Accuracy: 0.501953125\n",
      "Batch: 51, Loss: 1.7652251720428467, Accuracy: 0.4658203125\n",
      "Batch: 52, Loss: 1.6987581253051758, Accuracy: 0.51171875\n",
      "Batch: 53, Loss: 1.4377611875534058, Accuracy: 0.5576171875\n",
      "Batch: 54, Loss: 1.532872200012207, Accuracy: 0.5478515625\n",
      "Batch: 55, Loss: 1.559739589691162, Accuracy: 0.52734375\n",
      "Batch: 56, Loss: 1.6723668575286865, Accuracy: 0.4990234375\n",
      "Batch: 57, Loss: 1.6240583658218384, Accuracy: 0.5166015625\n",
      "Batch: 58, Loss: 1.6668356657028198, Accuracy: 0.51171875\n",
      "Batch: 59, Loss: 1.456518530845642, Accuracy: 0.576171875\n",
      "Batch: 60, Loss: 1.4520976543426514, Accuracy: 0.564453125\n",
      "Batch: 61, Loss: 1.584970235824585, Accuracy: 0.51953125\n",
      "Batch: 62, Loss: 1.6138126850128174, Accuracy: 0.5283203125\n",
      "Batch: 63, Loss: 1.6119087934494019, Accuracy: 0.5107421875\n",
      "Batch: 64, Loss: 1.5428460836410522, Accuracy: 0.53515625\n",
      "Batch: 65, Loss: 1.630636215209961, Accuracy: 0.5078125\n",
      "Batch: 66, Loss: 1.485559105873108, Accuracy: 0.548828125\n",
      "Batch: 67, Loss: 1.6400142908096313, Accuracy: 0.5087890625\n",
      "Batch: 68, Loss: 1.668242335319519, Accuracy: 0.5234375\n",
      "Batch: 69, Loss: 1.6047084331512451, Accuracy: 0.546875\n",
      "Batch: 70, Loss: 1.5556488037109375, Accuracy: 0.5361328125\n",
      "Batch: 71, Loss: 1.5488775968551636, Accuracy: 0.5205078125\n",
      "Batch: 72, Loss: 1.4667556285858154, Accuracy: 0.5458984375\n",
      "Batch: 73, Loss: 1.6602635383605957, Accuracy: 0.5283203125\n",
      "Batch: 74, Loss: 1.513227939605713, Accuracy: 0.5478515625\n",
      "Batch: 75, Loss: 1.4353724718093872, Accuracy: 0.5634765625\n",
      "Batch: 76, Loss: 1.5696437358856201, Accuracy: 0.48828125\n",
      "Batch: 77, Loss: 1.6030395030975342, Accuracy: 0.51171875\n",
      "Batch: 78, Loss: 1.659287691116333, Accuracy: 0.5302734375\n",
      "Batch: 79, Loss: 1.4457917213439941, Accuracy: 0.595703125\n",
      "Batch: 80, Loss: 1.442678451538086, Accuracy: 0.552734375\n",
      "Batch: 81, Loss: 1.5650670528411865, Accuracy: 0.5\n",
      "Batch: 82, Loss: 1.5245317220687866, Accuracy: 0.5234375\n",
      "Batch: 83, Loss: 1.4307230710983276, Accuracy: 0.5849609375\n",
      "Batch: 84, Loss: 1.4473146200180054, Accuracy: 0.5751953125\n",
      "Batch: 85, Loss: 1.5080231428146362, Accuracy: 0.564453125\n",
      "Batch: 86, Loss: 1.7014697790145874, Accuracy: 0.4912109375\n",
      "Batch: 87, Loss: 1.5172523260116577, Accuracy: 0.5625\n",
      "Batch: 88, Loss: 1.5670688152313232, Accuracy: 0.5361328125\n",
      "Batch: 89, Loss: 1.600826382637024, Accuracy: 0.52734375\n",
      "Batch: 90, Loss: 1.4674675464630127, Accuracy: 0.5537109375\n",
      "Batch: 91, Loss: 1.4881869554519653, Accuracy: 0.54296875\n",
      "Batch: 92, Loss: 1.6222436428070068, Accuracy: 0.5224609375\n",
      "Batch: 93, Loss: 1.5030971765518188, Accuracy: 0.5390625\n",
      "Batch: 94, Loss: 1.5444951057434082, Accuracy: 0.5263671875\n",
      "Batch: 95, Loss: 1.51088547706604, Accuracy: 0.5263671875\n",
      "Batch: 96, Loss: 1.5434823036193848, Accuracy: 0.546875\n",
      "Batch: 97, Loss: 1.4251717329025269, Accuracy: 0.576171875\n",
      "Batch: 98, Loss: 1.4127492904663086, Accuracy: 0.6015625\n",
      "Batch: 99, Loss: 1.438783049583435, Accuracy: 0.556640625\n",
      "Batch: 100, Loss: 1.4998903274536133, Accuracy: 0.5419921875\n",
      "Batch: 101, Loss: 1.5238746404647827, Accuracy: 0.5302734375\n",
      "Batch: 102, Loss: 1.4322459697723389, Accuracy: 0.5537109375\n",
      "Batch: 103, Loss: 1.5988335609436035, Accuracy: 0.55078125\n",
      "Batch: 104, Loss: 1.4710760116577148, Accuracy: 0.5478515625\n",
      "Batch: 105, Loss: 1.5935561656951904, Accuracy: 0.5166015625\n",
      "Batch: 106, Loss: 1.5451104640960693, Accuracy: 0.53125\n",
      "Batch: 107, Loss: 1.6642673015594482, Accuracy: 0.5068359375\n",
      "Batch: 108, Loss: 1.6666336059570312, Accuracy: 0.5244140625\n",
      "Batch: 109, Loss: 1.6710214614868164, Accuracy: 0.49609375\n",
      "Batch: 110, Loss: 1.381016731262207, Accuracy: 0.5751953125\n",
      "Batch: 111, Loss: 1.5701857805252075, Accuracy: 0.513671875\n",
      "Batch: 112, Loss: 1.5729570388793945, Accuracy: 0.54296875\n",
      "Batch: 113, Loss: 1.6870545148849487, Accuracy: 0.515625\n",
      "Batch: 114, Loss: 1.649214744567871, Accuracy: 0.501953125\n",
      "Batch: 115, Loss: 1.7011981010437012, Accuracy: 0.5107421875\n",
      "Batch: 116, Loss: 1.6257212162017822, Accuracy: 0.5009765625\n",
      "Batch: 117, Loss: 1.6377990245819092, Accuracy: 0.5341796875\n",
      "Batch: 118, Loss: 1.4386578798294067, Accuracy: 0.578125\n",
      "Batch: 119, Loss: 1.4944393634796143, Accuracy: 0.5703125\n",
      "Batch: 120, Loss: 1.6025316715240479, Accuracy: 0.51171875\n",
      "Batch: 121, Loss: 1.5972349643707275, Accuracy: 0.5146484375\n",
      "Batch: 122, Loss: 1.5710315704345703, Accuracy: 0.5439453125\n",
      "Batch: 123, Loss: 1.5374324321746826, Accuracy: 0.552734375\n",
      "Batch: 124, Loss: 1.5728758573532104, Accuracy: 0.533203125\n",
      "Batch: 125, Loss: 1.6091976165771484, Accuracy: 0.501953125\n",
      "Batch: 126, Loss: 1.598830223083496, Accuracy: 0.517578125\n",
      "Batch: 127, Loss: 1.4576294422149658, Accuracy: 0.595703125\n",
      "Batch: 128, Loss: 1.725315809249878, Accuracy: 0.53515625\n",
      "Batch: 129, Loss: 1.542561650276184, Accuracy: 0.5302734375\n",
      "Batch: 130, Loss: 1.7831854820251465, Accuracy: 0.4658203125\n",
      "Batch: 131, Loss: 1.6435935497283936, Accuracy: 0.517578125\n",
      "Batch: 132, Loss: 1.6342175006866455, Accuracy: 0.51953125\n",
      "Batch: 133, Loss: 1.510932445526123, Accuracy: 0.5380859375\n",
      "Batch: 134, Loss: 1.5935146808624268, Accuracy: 0.525390625\n",
      "Batch: 135, Loss: 1.502566933631897, Accuracy: 0.5537109375\n",
      "Batch: 136, Loss: 1.533595085144043, Accuracy: 0.5302734375\n",
      "Batch: 137, Loss: 1.4466711282730103, Accuracy: 0.533203125\n",
      "Batch: 138, Loss: 1.3670305013656616, Accuracy: 0.5732421875\n",
      "Batch: 139, Loss: 1.441637635231018, Accuracy: 0.5400390625\n",
      "Batch: 140, Loss: 1.5926954746246338, Accuracy: 0.513671875\n",
      "Batch: 141, Loss: 1.540587306022644, Accuracy: 0.552734375\n",
      "Batch: 142, Loss: 1.5792700052261353, Accuracy: 0.5078125\n",
      "Batch: 143, Loss: 1.5650975704193115, Accuracy: 0.533203125\n",
      "Batch: 144, Loss: 1.5477222204208374, Accuracy: 0.5361328125\n",
      "Batch: 145, Loss: 1.4775362014770508, Accuracy: 0.546875\n",
      "Batch: 146, Loss: 1.6238051652908325, Accuracy: 0.5146484375\n",
      "Batch: 147, Loss: 1.5522383451461792, Accuracy: 0.529296875\n",
      "Batch: 148, Loss: 1.7101693153381348, Accuracy: 0.4833984375\n",
      "Batch: 149, Loss: 1.5456373691558838, Accuracy: 0.529296875\n",
      "Batch: 150, Loss: 1.5065521001815796, Accuracy: 0.5419921875\n",
      "Batch: 151, Loss: 1.518595576286316, Accuracy: 0.5625\n",
      "Epoch 7/80\n",
      "Batch: 1, Loss: 1.6349124908447266, Accuracy: 0.482421875\n",
      "Batch: 2, Loss: 1.4527878761291504, Accuracy: 0.5166015625\n",
      "Batch: 3, Loss: 1.4396429061889648, Accuracy: 0.5498046875\n",
      "Batch: 4, Loss: 1.4193029403686523, Accuracy: 0.59375\n",
      "Batch: 5, Loss: 1.5010230541229248, Accuracy: 0.556640625\n",
      "Batch: 6, Loss: 1.4805744886398315, Accuracy: 0.5234375\n",
      "Batch: 7, Loss: 1.4498404264450073, Accuracy: 0.54296875\n",
      "Batch: 8, Loss: 1.417133092880249, Accuracy: 0.564453125\n",
      "Batch: 9, Loss: 1.391218900680542, Accuracy: 0.578125\n",
      "Batch: 10, Loss: 1.3972022533416748, Accuracy: 0.580078125\n",
      "Batch: 11, Loss: 1.5327482223510742, Accuracy: 0.5048828125\n",
      "Batch: 12, Loss: 1.6059199571609497, Accuracy: 0.5078125\n",
      "Batch: 13, Loss: 1.3614095449447632, Accuracy: 0.595703125\n",
      "Batch: 14, Loss: 1.532537817955017, Accuracy: 0.529296875\n",
      "Batch: 15, Loss: 1.4608874320983887, Accuracy: 0.5849609375\n",
      "Batch: 16, Loss: 1.4186677932739258, Accuracy: 0.5478515625\n",
      "Batch: 17, Loss: 1.488289475440979, Accuracy: 0.5244140625\n",
      "Batch: 18, Loss: 1.5739378929138184, Accuracy: 0.51171875\n",
      "Batch: 19, Loss: 1.5737484693527222, Accuracy: 0.52734375\n",
      "Batch: 20, Loss: 1.4906806945800781, Accuracy: 0.5712890625\n",
      "Batch: 21, Loss: 1.3967087268829346, Accuracy: 0.5791015625\n",
      "Batch: 22, Loss: 1.5838756561279297, Accuracy: 0.5283203125\n",
      "Batch: 23, Loss: 1.4971911907196045, Accuracy: 0.529296875\n",
      "Batch: 24, Loss: 1.5181140899658203, Accuracy: 0.5380859375\n",
      "Batch: 25, Loss: 1.4453320503234863, Accuracy: 0.5595703125\n",
      "Batch: 26, Loss: 1.334256887435913, Accuracy: 0.599609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 27, Loss: 1.423978328704834, Accuracy: 0.5498046875\n",
      "Batch: 28, Loss: 1.5099623203277588, Accuracy: 0.5205078125\n",
      "Batch: 29, Loss: 1.5229988098144531, Accuracy: 0.52734375\n",
      "Batch: 30, Loss: 1.4932467937469482, Accuracy: 0.5712890625\n",
      "Batch: 31, Loss: 1.4534118175506592, Accuracy: 0.587890625\n",
      "Batch: 32, Loss: 1.3889408111572266, Accuracy: 0.5693359375\n",
      "Batch: 33, Loss: 1.5916250944137573, Accuracy: 0.5224609375\n",
      "Batch: 34, Loss: 1.6769601106643677, Accuracy: 0.498046875\n",
      "Batch: 35, Loss: 1.5000345706939697, Accuracy: 0.52734375\n",
      "Batch: 36, Loss: 1.542626142501831, Accuracy: 0.5419921875\n",
      "Batch: 37, Loss: 1.514568567276001, Accuracy: 0.54296875\n",
      "Batch: 38, Loss: 1.4521510601043701, Accuracy: 0.544921875\n",
      "Batch: 39, Loss: 1.5375430583953857, Accuracy: 0.548828125\n",
      "Batch: 40, Loss: 1.543723464012146, Accuracy: 0.5654296875\n",
      "Batch: 41, Loss: 1.5240345001220703, Accuracy: 0.55078125\n",
      "Batch: 42, Loss: 1.2806049585342407, Accuracy: 0.6201171875\n",
      "Batch: 43, Loss: 1.422442078590393, Accuracy: 0.5498046875\n",
      "Batch: 44, Loss: 1.418576717376709, Accuracy: 0.5400390625\n",
      "Batch: 45, Loss: 1.3008828163146973, Accuracy: 0.5888671875\n",
      "Batch: 46, Loss: 1.5079792737960815, Accuracy: 0.5712890625\n",
      "Batch: 47, Loss: 1.5113916397094727, Accuracy: 0.54296875\n",
      "Batch: 48, Loss: 1.5001734495162964, Accuracy: 0.5439453125\n",
      "Batch: 49, Loss: 1.5588703155517578, Accuracy: 0.5205078125\n",
      "Batch: 50, Loss: 1.550330400466919, Accuracy: 0.5322265625\n",
      "Batch: 51, Loss: 1.6467580795288086, Accuracy: 0.5009765625\n",
      "Batch: 52, Loss: 1.6342592239379883, Accuracy: 0.54296875\n",
      "Batch: 53, Loss: 1.3624993562698364, Accuracy: 0.5849609375\n",
      "Batch: 54, Loss: 1.4391579627990723, Accuracy: 0.580078125\n",
      "Batch: 55, Loss: 1.4908344745635986, Accuracy: 0.546875\n",
      "Batch: 56, Loss: 1.5465152263641357, Accuracy: 0.537109375\n",
      "Batch: 57, Loss: 1.5195231437683105, Accuracy: 0.5537109375\n",
      "Batch: 58, Loss: 1.570276141166687, Accuracy: 0.5380859375\n",
      "Batch: 59, Loss: 1.3600571155548096, Accuracy: 0.6015625\n",
      "Batch: 60, Loss: 1.3793964385986328, Accuracy: 0.5771484375\n",
      "Batch: 61, Loss: 1.4946634769439697, Accuracy: 0.5390625\n",
      "Batch: 62, Loss: 1.543684959411621, Accuracy: 0.53515625\n",
      "Batch: 63, Loss: 1.5459845066070557, Accuracy: 0.5517578125\n",
      "Batch: 64, Loss: 1.4545402526855469, Accuracy: 0.560546875\n",
      "Batch: 65, Loss: 1.5283151865005493, Accuracy: 0.552734375\n",
      "Batch: 66, Loss: 1.4082212448120117, Accuracy: 0.5751953125\n",
      "Batch: 67, Loss: 1.569164514541626, Accuracy: 0.52734375\n",
      "Batch: 68, Loss: 1.5886468887329102, Accuracy: 0.529296875\n",
      "Batch: 69, Loss: 1.520670771598816, Accuracy: 0.5576171875\n",
      "Batch: 70, Loss: 1.4941109418869019, Accuracy: 0.55078125\n",
      "Batch: 71, Loss: 1.4811220169067383, Accuracy: 0.541015625\n",
      "Batch: 72, Loss: 1.4045027494430542, Accuracy: 0.578125\n",
      "Batch: 73, Loss: 1.5348961353302002, Accuracy: 0.5400390625\n",
      "Batch: 74, Loss: 1.4423046112060547, Accuracy: 0.5771484375\n",
      "Batch: 75, Loss: 1.3548593521118164, Accuracy: 0.58203125\n",
      "Batch: 76, Loss: 1.4868861436843872, Accuracy: 0.513671875\n",
      "Batch: 77, Loss: 1.495496153831482, Accuracy: 0.5185546875\n",
      "Batch: 78, Loss: 1.5439302921295166, Accuracy: 0.560546875\n",
      "Batch: 79, Loss: 1.346166729927063, Accuracy: 0.6328125\n",
      "Batch: 80, Loss: 1.389858365058899, Accuracy: 0.5546875\n",
      "Batch: 81, Loss: 1.4986850023269653, Accuracy: 0.521484375\n",
      "Batch: 82, Loss: 1.434286117553711, Accuracy: 0.568359375\n",
      "Batch: 83, Loss: 1.3393884897232056, Accuracy: 0.6083984375\n",
      "Batch: 84, Loss: 1.384042501449585, Accuracy: 0.591796875\n",
      "Batch: 85, Loss: 1.3941445350646973, Accuracy: 0.6025390625\n",
      "Batch: 86, Loss: 1.6345058679580688, Accuracy: 0.5205078125\n",
      "Batch: 87, Loss: 1.4294871091842651, Accuracy: 0.578125\n",
      "Batch: 88, Loss: 1.505843162536621, Accuracy: 0.548828125\n",
      "Batch: 89, Loss: 1.5275192260742188, Accuracy: 0.54296875\n",
      "Batch: 90, Loss: 1.4271447658538818, Accuracy: 0.556640625\n",
      "Batch: 91, Loss: 1.4164328575134277, Accuracy: 0.564453125\n",
      "Batch: 92, Loss: 1.5284099578857422, Accuracy: 0.552734375\n",
      "Batch: 93, Loss: 1.450677514076233, Accuracy: 0.576171875\n",
      "Batch: 94, Loss: 1.4690570831298828, Accuracy: 0.5546875\n",
      "Batch: 95, Loss: 1.4484457969665527, Accuracy: 0.5498046875\n",
      "Batch: 96, Loss: 1.4338774681091309, Accuracy: 0.5888671875\n",
      "Batch: 97, Loss: 1.3292335271835327, Accuracy: 0.5927734375\n",
      "Batch: 98, Loss: 1.3626744747161865, Accuracy: 0.609375\n",
      "Batch: 99, Loss: 1.3508000373840332, Accuracy: 0.5771484375\n",
      "Batch: 100, Loss: 1.43390691280365, Accuracy: 0.5703125\n",
      "Batch: 101, Loss: 1.4438549280166626, Accuracy: 0.560546875\n",
      "Batch: 102, Loss: 1.3838361501693726, Accuracy: 0.5654296875\n",
      "Batch: 103, Loss: 1.4925837516784668, Accuracy: 0.568359375\n",
      "Batch: 104, Loss: 1.4065784215927124, Accuracy: 0.564453125\n",
      "Batch: 105, Loss: 1.525948166847229, Accuracy: 0.5283203125\n",
      "Batch: 106, Loss: 1.4647164344787598, Accuracy: 0.5458984375\n",
      "Batch: 107, Loss: 1.575548768043518, Accuracy: 0.5205078125\n",
      "Batch: 108, Loss: 1.549570083618164, Accuracy: 0.53125\n",
      "Batch: 109, Loss: 1.5458310842514038, Accuracy: 0.5146484375\n",
      "Batch: 110, Loss: 1.3157707452774048, Accuracy: 0.59375\n",
      "Batch: 111, Loss: 1.4934771060943604, Accuracy: 0.52734375\n",
      "Batch: 112, Loss: 1.4630498886108398, Accuracy: 0.564453125\n",
      "Batch: 113, Loss: 1.5739998817443848, Accuracy: 0.541015625\n",
      "Batch: 114, Loss: 1.5678679943084717, Accuracy: 0.5224609375\n",
      "Batch: 115, Loss: 1.6373717784881592, Accuracy: 0.5400390625\n",
      "Batch: 116, Loss: 1.5775569677352905, Accuracy: 0.5185546875\n",
      "Batch: 117, Loss: 1.566251516342163, Accuracy: 0.5458984375\n",
      "Batch: 118, Loss: 1.3470783233642578, Accuracy: 0.6064453125\n",
      "Batch: 119, Loss: 1.3967440128326416, Accuracy: 0.5966796875\n",
      "Batch: 120, Loss: 1.517317295074463, Accuracy: 0.525390625\n",
      "Batch: 121, Loss: 1.5598077774047852, Accuracy: 0.537109375\n",
      "Batch: 122, Loss: 1.4749850034713745, Accuracy: 0.5693359375\n",
      "Batch: 123, Loss: 1.457263469696045, Accuracy: 0.5771484375\n",
      "Batch: 124, Loss: 1.5086991786956787, Accuracy: 0.5537109375\n",
      "Batch: 125, Loss: 1.524125576019287, Accuracy: 0.544921875\n",
      "Batch: 126, Loss: 1.5358688831329346, Accuracy: 0.5146484375\n",
      "Batch: 127, Loss: 1.3811390399932861, Accuracy: 0.58984375\n",
      "Batch: 128, Loss: 1.6264431476593018, Accuracy: 0.533203125\n",
      "Batch: 129, Loss: 1.470253825187683, Accuracy: 0.544921875\n",
      "Batch: 130, Loss: 1.6889116764068604, Accuracy: 0.4921875\n",
      "Batch: 131, Loss: 1.5588468313217163, Accuracy: 0.53125\n",
      "Batch: 132, Loss: 1.5432755947113037, Accuracy: 0.5390625\n",
      "Batch: 133, Loss: 1.411844253540039, Accuracy: 0.5732421875\n",
      "Batch: 134, Loss: 1.4984185695648193, Accuracy: 0.541015625\n",
      "Batch: 135, Loss: 1.4341745376586914, Accuracy: 0.5859375\n",
      "Batch: 136, Loss: 1.4740447998046875, Accuracy: 0.53515625\n",
      "Batch: 137, Loss: 1.3672950267791748, Accuracy: 0.5673828125\n",
      "Batch: 138, Loss: 1.2744731903076172, Accuracy: 0.587890625\n",
      "Batch: 139, Loss: 1.3582392930984497, Accuracy: 0.578125\n",
      "Batch: 140, Loss: 1.47987961769104, Accuracy: 0.53515625\n",
      "Batch: 141, Loss: 1.4788695573806763, Accuracy: 0.568359375\n",
      "Batch: 142, Loss: 1.5255016088485718, Accuracy: 0.529296875\n",
      "Batch: 143, Loss: 1.4913294315338135, Accuracy: 0.5390625\n",
      "Batch: 144, Loss: 1.4640756845474243, Accuracy: 0.5537109375\n",
      "Batch: 145, Loss: 1.4071249961853027, Accuracy: 0.5400390625\n",
      "Batch: 146, Loss: 1.5525527000427246, Accuracy: 0.529296875\n",
      "Batch: 147, Loss: 1.4967695474624634, Accuracy: 0.5595703125\n",
      "Batch: 148, Loss: 1.610117793083191, Accuracy: 0.5068359375\n",
      "Batch: 149, Loss: 1.4808331727981567, Accuracy: 0.533203125\n",
      "Batch: 150, Loss: 1.4238773584365845, Accuracy: 0.5732421875\n",
      "Batch: 151, Loss: 1.422270655632019, Accuracy: 0.591796875\n",
      "Epoch 8/80\n",
      "Batch: 1, Loss: 1.5781465768814087, Accuracy: 0.4931640625\n",
      "Batch: 2, Loss: 1.396816611289978, Accuracy: 0.5390625\n",
      "Batch: 3, Loss: 1.358957052230835, Accuracy: 0.58203125\n",
      "Batch: 4, Loss: 1.332957148551941, Accuracy: 0.611328125\n",
      "Batch: 5, Loss: 1.3957788944244385, Accuracy: 0.5703125\n",
      "Batch: 6, Loss: 1.4203311204910278, Accuracy: 0.5419921875\n",
      "Batch: 7, Loss: 1.387951374053955, Accuracy: 0.556640625\n",
      "Batch: 8, Loss: 1.3166098594665527, Accuracy: 0.57421875\n",
      "Batch: 9, Loss: 1.314347505569458, Accuracy: 0.6064453125\n",
      "Batch: 10, Loss: 1.3251898288726807, Accuracy: 0.59375\n",
      "Batch: 11, Loss: 1.4597468376159668, Accuracy: 0.5185546875\n",
      "Batch: 12, Loss: 1.5530332326889038, Accuracy: 0.5146484375\n",
      "Batch: 13, Loss: 1.2746381759643555, Accuracy: 0.6123046875\n",
      "Batch: 14, Loss: 1.4808297157287598, Accuracy: 0.521484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 15, Loss: 1.3981318473815918, Accuracy: 0.5888671875\n",
      "Batch: 16, Loss: 1.3597331047058105, Accuracy: 0.583984375\n",
      "Batch: 17, Loss: 1.436802864074707, Accuracy: 0.5458984375\n",
      "Batch: 18, Loss: 1.4876267910003662, Accuracy: 0.5341796875\n",
      "Batch: 19, Loss: 1.5227317810058594, Accuracy: 0.53515625\n",
      "Batch: 20, Loss: 1.4265637397766113, Accuracy: 0.576171875\n",
      "Batch: 21, Loss: 1.3450132608413696, Accuracy: 0.5791015625\n",
      "Batch: 22, Loss: 1.500192642211914, Accuracy: 0.5517578125\n",
      "Batch: 23, Loss: 1.3958539962768555, Accuracy: 0.5634765625\n",
      "Batch: 24, Loss: 1.4705393314361572, Accuracy: 0.5498046875\n",
      "Batch: 25, Loss: 1.3899611234664917, Accuracy: 0.578125\n",
      "Batch: 26, Loss: 1.2816706895828247, Accuracy: 0.595703125\n",
      "Batch: 27, Loss: 1.3909368515014648, Accuracy: 0.544921875\n",
      "Batch: 28, Loss: 1.442025899887085, Accuracy: 0.5498046875\n",
      "Batch: 29, Loss: 1.446165680885315, Accuracy: 0.5400390625\n",
      "Batch: 30, Loss: 1.4045038223266602, Accuracy: 0.5908203125\n",
      "Batch: 31, Loss: 1.377823829650879, Accuracy: 0.6015625\n",
      "Batch: 32, Loss: 1.321812629699707, Accuracy: 0.59765625\n",
      "Batch: 33, Loss: 1.5213096141815186, Accuracy: 0.537109375\n",
      "Batch: 34, Loss: 1.5950238704681396, Accuracy: 0.5185546875\n",
      "Batch: 35, Loss: 1.453232765197754, Accuracy: 0.5419921875\n",
      "Batch: 36, Loss: 1.4507545232772827, Accuracy: 0.5654296875\n",
      "Batch: 37, Loss: 1.4602627754211426, Accuracy: 0.5498046875\n",
      "Batch: 38, Loss: 1.4018915891647339, Accuracy: 0.546875\n",
      "Batch: 39, Loss: 1.4507927894592285, Accuracy: 0.57421875\n",
      "Batch: 40, Loss: 1.4634642601013184, Accuracy: 0.5947265625\n",
      "Batch: 41, Loss: 1.4527084827423096, Accuracy: 0.5595703125\n",
      "Batch: 42, Loss: 1.222987413406372, Accuracy: 0.62109375\n",
      "Batch: 43, Loss: 1.380610466003418, Accuracy: 0.5576171875\n",
      "Batch: 44, Loss: 1.358616590499878, Accuracy: 0.5537109375\n",
      "Batch: 45, Loss: 1.2324129343032837, Accuracy: 0.6201171875\n",
      "Batch: 46, Loss: 1.4077210426330566, Accuracy: 0.60546875\n",
      "Batch: 47, Loss: 1.461445927619934, Accuracy: 0.564453125\n",
      "Batch: 48, Loss: 1.4368524551391602, Accuracy: 0.5703125\n",
      "Batch: 49, Loss: 1.5017281770706177, Accuracy: 0.5380859375\n",
      "Batch: 50, Loss: 1.4882886409759521, Accuracy: 0.5498046875\n",
      "Batch: 51, Loss: 1.5873517990112305, Accuracy: 0.5263671875\n",
      "Batch: 52, Loss: 1.5739728212356567, Accuracy: 0.5498046875\n",
      "Batch: 53, Loss: 1.288935899734497, Accuracy: 0.59765625\n",
      "Batch: 54, Loss: 1.3837320804595947, Accuracy: 0.58203125\n",
      "Batch: 55, Loss: 1.4247727394104004, Accuracy: 0.544921875\n",
      "Batch: 56, Loss: 1.4917293787002563, Accuracy: 0.548828125\n",
      "Batch: 57, Loss: 1.4712224006652832, Accuracy: 0.5634765625\n",
      "Batch: 58, Loss: 1.5068087577819824, Accuracy: 0.5576171875\n",
      "Batch: 59, Loss: 1.294216513633728, Accuracy: 0.6240234375\n",
      "Batch: 60, Loss: 1.2879739999771118, Accuracy: 0.6005859375\n",
      "Batch: 61, Loss: 1.4338152408599854, Accuracy: 0.5517578125\n",
      "Batch: 62, Loss: 1.4624264240264893, Accuracy: 0.5556640625\n",
      "Batch: 63, Loss: 1.4819700717926025, Accuracy: 0.537109375\n",
      "Batch: 64, Loss: 1.4243794679641724, Accuracy: 0.5654296875\n",
      "Batch: 65, Loss: 1.454426884651184, Accuracy: 0.548828125\n",
      "Batch: 66, Loss: 1.337600588798523, Accuracy: 0.5791015625\n",
      "Batch: 67, Loss: 1.51967453956604, Accuracy: 0.533203125\n",
      "Batch: 68, Loss: 1.5254039764404297, Accuracy: 0.5576171875\n",
      "Batch: 69, Loss: 1.4446851015090942, Accuracy: 0.55859375\n",
      "Batch: 70, Loss: 1.4300401210784912, Accuracy: 0.58203125\n",
      "Batch: 71, Loss: 1.425093173980713, Accuracy: 0.564453125\n",
      "Batch: 72, Loss: 1.3114278316497803, Accuracy: 0.591796875\n",
      "Batch: 73, Loss: 1.4492707252502441, Accuracy: 0.5751953125\n",
      "Batch: 74, Loss: 1.3589602708816528, Accuracy: 0.57421875\n",
      "Batch: 75, Loss: 1.324340581893921, Accuracy: 0.59765625\n",
      "Batch: 76, Loss: 1.4467484951019287, Accuracy: 0.533203125\n",
      "Batch: 77, Loss: 1.4258712530136108, Accuracy: 0.5517578125\n",
      "Batch: 78, Loss: 1.4512319564819336, Accuracy: 0.59375\n",
      "Batch: 79, Loss: 1.2740304470062256, Accuracy: 0.6376953125\n",
      "Batch: 80, Loss: 1.3137505054473877, Accuracy: 0.5771484375\n",
      "Batch: 81, Loss: 1.4569730758666992, Accuracy: 0.5205078125\n",
      "Batch: 82, Loss: 1.3880469799041748, Accuracy: 0.5732421875\n",
      "Batch: 83, Loss: 1.2735427618026733, Accuracy: 0.6337890625\n",
      "Batch: 84, Loss: 1.363438606262207, Accuracy: 0.5966796875\n",
      "Batch: 85, Loss: 1.314941644668579, Accuracy: 0.6064453125\n",
      "Batch: 86, Loss: 1.5750436782836914, Accuracy: 0.52734375\n",
      "Batch: 87, Loss: 1.3663430213928223, Accuracy: 0.6015625\n",
      "Batch: 88, Loss: 1.467987298965454, Accuracy: 0.5751953125\n",
      "Batch: 89, Loss: 1.4658254384994507, Accuracy: 0.55859375\n",
      "Batch: 90, Loss: 1.3611149787902832, Accuracy: 0.5712890625\n",
      "Batch: 91, Loss: 1.3620986938476562, Accuracy: 0.5869140625\n",
      "Batch: 92, Loss: 1.464752435684204, Accuracy: 0.5498046875\n",
      "Batch: 93, Loss: 1.3543059825897217, Accuracy: 0.587890625\n",
      "Batch: 94, Loss: 1.396461009979248, Accuracy: 0.5791015625\n",
      "Batch: 95, Loss: 1.3702692985534668, Accuracy: 0.5615234375\n",
      "Batch: 96, Loss: 1.387986183166504, Accuracy: 0.5849609375\n",
      "Batch: 97, Loss: 1.2562081813812256, Accuracy: 0.61328125\n",
      "Batch: 98, Loss: 1.2844157218933105, Accuracy: 0.626953125\n",
      "Batch: 99, Loss: 1.3084884881973267, Accuracy: 0.5947265625\n",
      "Batch: 100, Loss: 1.3811100721359253, Accuracy: 0.5654296875\n",
      "Batch: 101, Loss: 1.3905246257781982, Accuracy: 0.5654296875\n",
      "Batch: 102, Loss: 1.3170859813690186, Accuracy: 0.5947265625\n",
      "Batch: 103, Loss: 1.4641391038894653, Accuracy: 0.5771484375\n",
      "Batch: 104, Loss: 1.3305763006210327, Accuracy: 0.5849609375\n",
      "Batch: 105, Loss: 1.466901183128357, Accuracy: 0.5341796875\n",
      "Batch: 106, Loss: 1.41787850856781, Accuracy: 0.5673828125\n",
      "Batch: 107, Loss: 1.5176348686218262, Accuracy: 0.5380859375\n",
      "Batch: 108, Loss: 1.5004292726516724, Accuracy: 0.5517578125\n",
      "Batch: 109, Loss: 1.5354911088943481, Accuracy: 0.5283203125\n",
      "Batch: 110, Loss: 1.2212762832641602, Accuracy: 0.6171875\n",
      "Batch: 111, Loss: 1.4211450815200806, Accuracy: 0.5263671875\n",
      "Batch: 112, Loss: 1.4002563953399658, Accuracy: 0.580078125\n",
      "Batch: 113, Loss: 1.487007975578308, Accuracy: 0.578125\n",
      "Batch: 114, Loss: 1.5102412700653076, Accuracy: 0.5400390625\n",
      "Batch: 115, Loss: 1.5686984062194824, Accuracy: 0.5341796875\n",
      "Batch: 116, Loss: 1.4982781410217285, Accuracy: 0.541015625\n",
      "Batch: 117, Loss: 1.491050362586975, Accuracy: 0.5595703125\n",
      "Batch: 118, Loss: 1.2781119346618652, Accuracy: 0.6171875\n",
      "Batch: 119, Loss: 1.3400404453277588, Accuracy: 0.6044921875\n",
      "Batch: 120, Loss: 1.4679917097091675, Accuracy: 0.541015625\n",
      "Batch: 121, Loss: 1.4741309881210327, Accuracy: 0.5439453125\n",
      "Batch: 122, Loss: 1.3751236200332642, Accuracy: 0.5869140625\n",
      "Batch: 123, Loss: 1.4020887613296509, Accuracy: 0.5849609375\n",
      "Batch: 124, Loss: 1.4187480211257935, Accuracy: 0.5703125\n",
      "Batch: 125, Loss: 1.4648628234863281, Accuracy: 0.5576171875\n",
      "Batch: 126, Loss: 1.4692277908325195, Accuracy: 0.5322265625\n",
      "Batch: 127, Loss: 1.3091801404953003, Accuracy: 0.6083984375\n",
      "Batch: 128, Loss: 1.601708173751831, Accuracy: 0.548828125\n",
      "Batch: 129, Loss: 1.402069091796875, Accuracy: 0.5673828125\n",
      "Batch: 130, Loss: 1.6447854042053223, Accuracy: 0.517578125\n",
      "Batch: 131, Loss: 1.4835439920425415, Accuracy: 0.5478515625\n",
      "Batch: 132, Loss: 1.4757205247879028, Accuracy: 0.55078125\n",
      "Batch: 133, Loss: 1.3730391263961792, Accuracy: 0.578125\n",
      "Batch: 134, Loss: 1.4371509552001953, Accuracy: 0.564453125\n",
      "Batch: 135, Loss: 1.3747282028198242, Accuracy: 0.58203125\n",
      "Batch: 136, Loss: 1.420719027519226, Accuracy: 0.5537109375\n",
      "Batch: 137, Loss: 1.3145636320114136, Accuracy: 0.5751953125\n",
      "Batch: 138, Loss: 1.227829933166504, Accuracy: 0.607421875\n",
      "Batch: 139, Loss: 1.3108959197998047, Accuracy: 0.5830078125\n",
      "Batch: 140, Loss: 1.4335495233535767, Accuracy: 0.548828125\n",
      "Batch: 141, Loss: 1.414506196975708, Accuracy: 0.5751953125\n",
      "Batch: 142, Loss: 1.4493224620819092, Accuracy: 0.5458984375\n",
      "Batch: 143, Loss: 1.4471172094345093, Accuracy: 0.5615234375\n",
      "Batch: 144, Loss: 1.40987229347229, Accuracy: 0.556640625\n",
      "Batch: 145, Loss: 1.3330767154693604, Accuracy: 0.576171875\n",
      "Batch: 146, Loss: 1.4886466264724731, Accuracy: 0.5390625\n",
      "Batch: 147, Loss: 1.397827386856079, Accuracy: 0.5654296875\n",
      "Batch: 148, Loss: 1.5654973983764648, Accuracy: 0.515625\n",
      "Batch: 149, Loss: 1.4204480648040771, Accuracy: 0.5517578125\n",
      "Batch: 150, Loss: 1.3856449127197266, Accuracy: 0.5791015625\n",
      "Batch: 151, Loss: 1.345085859298706, Accuracy: 0.6025390625\n",
      "Epoch 9/80\n",
      "Batch: 1, Loss: 1.5207852125167847, Accuracy: 0.5146484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2, Loss: 1.3864281177520752, Accuracy: 0.5341796875\n",
      "Batch: 3, Loss: 1.2880165576934814, Accuracy: 0.6025390625\n",
      "Batch: 4, Loss: 1.2745709419250488, Accuracy: 0.6279296875\n",
      "Batch: 5, Loss: 1.3437342643737793, Accuracy: 0.5859375\n",
      "Batch: 6, Loss: 1.3727024793624878, Accuracy: 0.55859375\n",
      "Batch: 7, Loss: 1.315739393234253, Accuracy: 0.58984375\n",
      "Batch: 8, Loss: 1.2750647068023682, Accuracy: 0.5830078125\n",
      "Batch: 9, Loss: 1.2825809717178345, Accuracy: 0.6142578125\n",
      "Batch: 10, Loss: 1.2794272899627686, Accuracy: 0.6083984375\n",
      "Batch: 11, Loss: 1.436647891998291, Accuracy: 0.5439453125\n",
      "Batch: 12, Loss: 1.4769270420074463, Accuracy: 0.5419921875\n",
      "Batch: 13, Loss: 1.2275121212005615, Accuracy: 0.6201171875\n",
      "Batch: 14, Loss: 1.4386478662490845, Accuracy: 0.5458984375\n",
      "Batch: 15, Loss: 1.3188765048980713, Accuracy: 0.6123046875\n",
      "Batch: 16, Loss: 1.3077189922332764, Accuracy: 0.591796875\n",
      "Batch: 17, Loss: 1.3705155849456787, Accuracy: 0.568359375\n",
      "Batch: 18, Loss: 1.4368693828582764, Accuracy: 0.552734375\n",
      "Batch: 19, Loss: 1.4473183155059814, Accuracy: 0.580078125\n",
      "Batch: 20, Loss: 1.3831260204315186, Accuracy: 0.583984375\n",
      "Batch: 21, Loss: 1.2800076007843018, Accuracy: 0.6015625\n",
      "Batch: 22, Loss: 1.4490400552749634, Accuracy: 0.5673828125\n",
      "Batch: 23, Loss: 1.337682843208313, Accuracy: 0.5634765625\n",
      "Batch: 24, Loss: 1.4005869626998901, Accuracy: 0.55078125\n",
      "Batch: 25, Loss: 1.3375835418701172, Accuracy: 0.576171875\n",
      "Batch: 26, Loss: 1.2350023984909058, Accuracy: 0.615234375\n",
      "Batch: 27, Loss: 1.2985708713531494, Accuracy: 0.58203125\n",
      "Batch: 28, Loss: 1.4014911651611328, Accuracy: 0.5498046875\n",
      "Batch: 29, Loss: 1.4082462787628174, Accuracy: 0.5615234375\n",
      "Batch: 30, Loss: 1.3602588176727295, Accuracy: 0.603515625\n",
      "Batch: 31, Loss: 1.3158936500549316, Accuracy: 0.603515625\n",
      "Batch: 32, Loss: 1.288442850112915, Accuracy: 0.59765625\n",
      "Batch: 33, Loss: 1.481797695159912, Accuracy: 0.548828125\n",
      "Batch: 34, Loss: 1.5450907945632935, Accuracy: 0.525390625\n",
      "Batch: 35, Loss: 1.380261778831482, Accuracy: 0.5654296875\n",
      "Batch: 36, Loss: 1.409339427947998, Accuracy: 0.5595703125\n",
      "Batch: 37, Loss: 1.384500503540039, Accuracy: 0.5830078125\n",
      "Batch: 38, Loss: 1.341090440750122, Accuracy: 0.5615234375\n",
      "Batch: 39, Loss: 1.41581392288208, Accuracy: 0.5693359375\n",
      "Batch: 40, Loss: 1.4122865200042725, Accuracy: 0.5859375\n",
      "Batch: 41, Loss: 1.4113380908966064, Accuracy: 0.5869140625\n",
      "Batch: 42, Loss: 1.1410634517669678, Accuracy: 0.6455078125\n",
      "Batch: 43, Loss: 1.3537392616271973, Accuracy: 0.5703125\n",
      "Batch: 44, Loss: 1.34416925907135, Accuracy: 0.55859375\n",
      "Batch: 45, Loss: 1.1822209358215332, Accuracy: 0.6181640625\n",
      "Batch: 46, Loss: 1.3675603866577148, Accuracy: 0.623046875\n",
      "Batch: 47, Loss: 1.4090914726257324, Accuracy: 0.578125\n",
      "Batch: 48, Loss: 1.3346843719482422, Accuracy: 0.5947265625\n",
      "Batch: 49, Loss: 1.4669651985168457, Accuracy: 0.52734375\n",
      "Batch: 50, Loss: 1.450047492980957, Accuracy: 0.54296875\n",
      "Batch: 51, Loss: 1.528124213218689, Accuracy: 0.5205078125\n",
      "Batch: 52, Loss: 1.5279685258865356, Accuracy: 0.546875\n",
      "Batch: 53, Loss: 1.2278193235397339, Accuracy: 0.6142578125\n",
      "Batch: 54, Loss: 1.3340717554092407, Accuracy: 0.609375\n",
      "Batch: 55, Loss: 1.3512241840362549, Accuracy: 0.564453125\n",
      "Batch: 56, Loss: 1.4631495475769043, Accuracy: 0.548828125\n",
      "Batch: 57, Loss: 1.404105544090271, Accuracy: 0.56640625\n",
      "Batch: 58, Loss: 1.4626843929290771, Accuracy: 0.5703125\n",
      "Batch: 59, Loss: 1.2597862482070923, Accuracy: 0.6162109375\n",
      "Batch: 60, Loss: 1.2531580924987793, Accuracy: 0.6162109375\n",
      "Batch: 61, Loss: 1.3920236825942993, Accuracy: 0.5712890625\n",
      "Batch: 62, Loss: 1.4002151489257812, Accuracy: 0.5654296875\n",
      "Batch: 63, Loss: 1.4130489826202393, Accuracy: 0.55859375\n",
      "Batch: 64, Loss: 1.366455316543579, Accuracy: 0.5830078125\n",
      "Batch: 65, Loss: 1.4115378856658936, Accuracy: 0.5751953125\n",
      "Batch: 66, Loss: 1.2860578298568726, Accuracy: 0.6005859375\n",
      "Batch: 67, Loss: 1.469696044921875, Accuracy: 0.5537109375\n",
      "Batch: 68, Loss: 1.4674112796783447, Accuracy: 0.5673828125\n",
      "Batch: 69, Loss: 1.4027771949768066, Accuracy: 0.5888671875\n",
      "Batch: 70, Loss: 1.3839943408966064, Accuracy: 0.578125\n",
      "Batch: 71, Loss: 1.3759522438049316, Accuracy: 0.5888671875\n",
      "Batch: 72, Loss: 1.244062900543213, Accuracy: 0.6162109375\n",
      "Batch: 73, Loss: 1.3915646076202393, Accuracy: 0.5810546875\n",
      "Batch: 74, Loss: 1.3130614757537842, Accuracy: 0.5810546875\n",
      "Batch: 75, Loss: 1.2581074237823486, Accuracy: 0.611328125\n",
      "Batch: 76, Loss: 1.373246192932129, Accuracy: 0.5498046875\n",
      "Batch: 77, Loss: 1.3978817462921143, Accuracy: 0.5498046875\n",
      "Batch: 78, Loss: 1.3671083450317383, Accuracy: 0.607421875\n",
      "Batch: 79, Loss: 1.218428373336792, Accuracy: 0.6416015625\n",
      "Batch: 80, Loss: 1.2752447128295898, Accuracy: 0.5908203125\n",
      "Batch: 81, Loss: 1.3871397972106934, Accuracy: 0.54296875\n",
      "Batch: 82, Loss: 1.350764274597168, Accuracy: 0.5849609375\n",
      "Batch: 83, Loss: 1.228537678718567, Accuracy: 0.6259765625\n",
      "Batch: 84, Loss: 1.2935354709625244, Accuracy: 0.61328125\n",
      "Batch: 85, Loss: 1.2656738758087158, Accuracy: 0.609375\n",
      "Batch: 86, Loss: 1.534989833831787, Accuracy: 0.5302734375\n",
      "Batch: 87, Loss: 1.321324348449707, Accuracy: 0.6025390625\n",
      "Batch: 88, Loss: 1.4135181903839111, Accuracy: 0.580078125\n",
      "Batch: 89, Loss: 1.4152483940124512, Accuracy: 0.5771484375\n",
      "Batch: 90, Loss: 1.307132601737976, Accuracy: 0.58984375\n",
      "Batch: 91, Loss: 1.3196911811828613, Accuracy: 0.5908203125\n",
      "Batch: 92, Loss: 1.4246699810028076, Accuracy: 0.5673828125\n",
      "Batch: 93, Loss: 1.332779884338379, Accuracy: 0.59375\n",
      "Batch: 94, Loss: 1.3460921049118042, Accuracy: 0.5791015625\n",
      "Batch: 95, Loss: 1.3399226665496826, Accuracy: 0.5830078125\n",
      "Batch: 96, Loss: 1.3213400840759277, Accuracy: 0.5986328125\n",
      "Batch: 97, Loss: 1.2192518711090088, Accuracy: 0.6220703125\n",
      "Batch: 98, Loss: 1.235496997833252, Accuracy: 0.630859375\n",
      "Batch: 99, Loss: 1.2615739107131958, Accuracy: 0.609375\n",
      "Batch: 100, Loss: 1.334118127822876, Accuracy: 0.5859375\n",
      "Batch: 101, Loss: 1.3656177520751953, Accuracy: 0.5791015625\n",
      "Batch: 102, Loss: 1.2759976387023926, Accuracy: 0.58984375\n",
      "Batch: 103, Loss: 1.3987840414047241, Accuracy: 0.5947265625\n",
      "Batch: 104, Loss: 1.2811057567596436, Accuracy: 0.6103515625\n",
      "Batch: 105, Loss: 1.4118447303771973, Accuracy: 0.5595703125\n",
      "Batch: 106, Loss: 1.358830213546753, Accuracy: 0.580078125\n",
      "Batch: 107, Loss: 1.4769227504730225, Accuracy: 0.544921875\n",
      "Batch: 108, Loss: 1.4278945922851562, Accuracy: 0.55859375\n",
      "Batch: 109, Loss: 1.4747692346572876, Accuracy: 0.541015625\n",
      "Batch: 110, Loss: 1.1936821937561035, Accuracy: 0.6298828125\n",
      "Batch: 111, Loss: 1.3910967111587524, Accuracy: 0.5673828125\n",
      "Batch: 112, Loss: 1.3629218339920044, Accuracy: 0.595703125\n",
      "Batch: 113, Loss: 1.4142217636108398, Accuracy: 0.5830078125\n",
      "Batch: 114, Loss: 1.4490492343902588, Accuracy: 0.556640625\n",
      "Batch: 115, Loss: 1.5056474208831787, Accuracy: 0.548828125\n",
      "Batch: 116, Loss: 1.4459468126296997, Accuracy: 0.5537109375\n",
      "Batch: 117, Loss: 1.44477117061615, Accuracy: 0.5751953125\n",
      "Batch: 118, Loss: 1.237696886062622, Accuracy: 0.630859375\n",
      "Batch: 119, Loss: 1.2843809127807617, Accuracy: 0.6171875\n",
      "Batch: 120, Loss: 1.4255951642990112, Accuracy: 0.5576171875\n",
      "Batch: 121, Loss: 1.4396847486495972, Accuracy: 0.5537109375\n",
      "Batch: 122, Loss: 1.3388111591339111, Accuracy: 0.603515625\n",
      "Batch: 123, Loss: 1.3524305820465088, Accuracy: 0.59765625\n",
      "Batch: 124, Loss: 1.3789722919464111, Accuracy: 0.58203125\n",
      "Batch: 125, Loss: 1.4060149192810059, Accuracy: 0.578125\n",
      "Batch: 126, Loss: 1.4233291149139404, Accuracy: 0.546875\n",
      "Batch: 127, Loss: 1.2617931365966797, Accuracy: 0.630859375\n",
      "Batch: 128, Loss: 1.5350958108901978, Accuracy: 0.5634765625\n",
      "Batch: 129, Loss: 1.3220252990722656, Accuracy: 0.587890625\n",
      "Batch: 130, Loss: 1.5759193897247314, Accuracy: 0.53515625\n",
      "Batch: 131, Loss: 1.446711540222168, Accuracy: 0.5517578125\n",
      "Batch: 132, Loss: 1.4258277416229248, Accuracy: 0.5673828125\n",
      "Batch: 133, Loss: 1.317111849784851, Accuracy: 0.58984375\n",
      "Batch: 134, Loss: 1.404608964920044, Accuracy: 0.548828125\n",
      "Batch: 135, Loss: 1.3313463926315308, Accuracy: 0.591796875\n",
      "Batch: 136, Loss: 1.3707120418548584, Accuracy: 0.568359375\n",
      "Batch: 137, Loss: 1.260977029800415, Accuracy: 0.5771484375\n",
      "Batch: 138, Loss: 1.1909517049789429, Accuracy: 0.607421875\n",
      "Batch: 139, Loss: 1.2639403343200684, Accuracy: 0.6064453125\n",
      "Batch: 140, Loss: 1.3900766372680664, Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 141, Loss: 1.3808085918426514, Accuracy: 0.5732421875\n",
      "Batch: 142, Loss: 1.4048655033111572, Accuracy: 0.5634765625\n",
      "Batch: 143, Loss: 1.3733465671539307, Accuracy: 0.5654296875\n",
      "Batch: 144, Loss: 1.3693878650665283, Accuracy: 0.5732421875\n",
      "Batch: 145, Loss: 1.2912070751190186, Accuracy: 0.5830078125\n",
      "Batch: 146, Loss: 1.4418270587921143, Accuracy: 0.546875\n",
      "Batch: 147, Loss: 1.3443191051483154, Accuracy: 0.5703125\n",
      "Batch: 148, Loss: 1.5057461261749268, Accuracy: 0.515625\n",
      "Batch: 149, Loss: 1.3803560733795166, Accuracy: 0.5654296875\n",
      "Batch: 150, Loss: 1.3316842317581177, Accuracy: 0.5791015625\n",
      "Batch: 151, Loss: 1.2875927686691284, Accuracy: 0.61328125\n",
      "Epoch 10/80\n",
      "Batch: 1, Loss: 1.507850170135498, Accuracy: 0.5107421875\n",
      "Batch: 2, Loss: 1.3455454111099243, Accuracy: 0.541015625\n",
      "Batch: 3, Loss: 1.2790300846099854, Accuracy: 0.5888671875\n",
      "Batch: 4, Loss: 1.2055286169052124, Accuracy: 0.6435546875\n",
      "Batch: 5, Loss: 1.2913258075714111, Accuracy: 0.60546875\n",
      "Batch: 6, Loss: 1.3512505292892456, Accuracy: 0.55859375\n",
      "Batch: 7, Loss: 1.3006247282028198, Accuracy: 0.587890625\n",
      "Batch: 8, Loss: 1.2363418340682983, Accuracy: 0.5947265625\n",
      "Batch: 9, Loss: 1.1974515914916992, Accuracy: 0.6318359375\n",
      "Batch: 10, Loss: 1.249835729598999, Accuracy: 0.6103515625\n",
      "Batch: 11, Loss: 1.380071759223938, Accuracy: 0.5537109375\n",
      "Batch: 12, Loss: 1.448290467262268, Accuracy: 0.541015625\n",
      "Batch: 13, Loss: 1.1741247177124023, Accuracy: 0.650390625\n",
      "Batch: 14, Loss: 1.4064278602600098, Accuracy: 0.544921875\n",
      "Batch: 15, Loss: 1.2833908796310425, Accuracy: 0.6279296875\n",
      "Batch: 16, Loss: 1.2494994401931763, Accuracy: 0.615234375\n",
      "Batch: 17, Loss: 1.3495737314224243, Accuracy: 0.5693359375\n",
      "Batch: 18, Loss: 1.3717764616012573, Accuracy: 0.5712890625\n",
      "Batch: 19, Loss: 1.3896478414535522, Accuracy: 0.5908203125\n",
      "Batch: 20, Loss: 1.3170113563537598, Accuracy: 0.607421875\n",
      "Batch: 21, Loss: 1.2527600526809692, Accuracy: 0.6083984375\n",
      "Batch: 22, Loss: 1.4083563089370728, Accuracy: 0.5654296875\n",
      "Batch: 23, Loss: 1.2819011211395264, Accuracy: 0.5869140625\n",
      "Batch: 24, Loss: 1.3240118026733398, Accuracy: 0.5927734375\n",
      "Batch: 25, Loss: 1.2858775854110718, Accuracy: 0.595703125\n",
      "Batch: 26, Loss: 1.1901763677597046, Accuracy: 0.638671875\n",
      "Batch: 27, Loss: 1.2766062021255493, Accuracy: 0.58203125\n",
      "Batch: 28, Loss: 1.3231861591339111, Accuracy: 0.5849609375\n",
      "Batch: 29, Loss: 1.352252721786499, Accuracy: 0.57421875\n",
      "Batch: 30, Loss: 1.3228211402893066, Accuracy: 0.61328125\n",
      "Batch: 31, Loss: 1.2737656831741333, Accuracy: 0.626953125\n",
      "Batch: 32, Loss: 1.2279021739959717, Accuracy: 0.595703125\n",
      "Batch: 33, Loss: 1.4225807189941406, Accuracy: 0.556640625\n",
      "Batch: 34, Loss: 1.5057672262191772, Accuracy: 0.552734375\n",
      "Batch: 35, Loss: 1.349139928817749, Accuracy: 0.5673828125\n",
      "Batch: 36, Loss: 1.3685550689697266, Accuracy: 0.58984375\n",
      "Batch: 37, Loss: 1.3296000957489014, Accuracy: 0.5888671875\n",
      "Batch: 38, Loss: 1.321502923965454, Accuracy: 0.55859375\n",
      "Batch: 39, Loss: 1.3693697452545166, Accuracy: 0.5888671875\n",
      "Batch: 40, Loss: 1.3840715885162354, Accuracy: 0.6064453125\n",
      "Batch: 41, Loss: 1.3335716724395752, Accuracy: 0.603515625\n",
      "Batch: 42, Loss: 1.109253168106079, Accuracy: 0.650390625\n",
      "Batch: 43, Loss: 1.3046305179595947, Accuracy: 0.5732421875\n",
      "Batch: 44, Loss: 1.291995644569397, Accuracy: 0.576171875\n",
      "Batch: 45, Loss: 1.1603926420211792, Accuracy: 0.625\n",
      "Batch: 46, Loss: 1.322060465812683, Accuracy: 0.6181640625\n",
      "Batch: 47, Loss: 1.349456548690796, Accuracy: 0.6005859375\n",
      "Batch: 48, Loss: 1.312901258468628, Accuracy: 0.599609375\n",
      "Batch: 49, Loss: 1.4263485670089722, Accuracy: 0.5517578125\n",
      "Batch: 50, Loss: 1.401723027229309, Accuracy: 0.5546875\n",
      "Batch: 51, Loss: 1.490696668624878, Accuracy: 0.541015625\n",
      "Batch: 52, Loss: 1.4665464162826538, Accuracy: 0.55859375\n",
      "Batch: 53, Loss: 1.197232961654663, Accuracy: 0.6201171875\n",
      "Batch: 54, Loss: 1.2970606088638306, Accuracy: 0.6083984375\n",
      "Batch: 55, Loss: 1.350441813468933, Accuracy: 0.578125\n",
      "Batch: 56, Loss: 1.3984066247940063, Accuracy: 0.5751953125\n",
      "Batch: 57, Loss: 1.344833493232727, Accuracy: 0.6025390625\n",
      "Batch: 58, Loss: 1.4173108339309692, Accuracy: 0.580078125\n",
      "Batch: 59, Loss: 1.2131084203720093, Accuracy: 0.6513671875\n",
      "Batch: 60, Loss: 1.1846728324890137, Accuracy: 0.626953125\n",
      "Batch: 61, Loss: 1.332756757736206, Accuracy: 0.5830078125\n",
      "Batch: 62, Loss: 1.3592418432235718, Accuracy: 0.5888671875\n",
      "Batch: 63, Loss: 1.3749170303344727, Accuracy: 0.572265625\n",
      "Batch: 64, Loss: 1.3042362928390503, Accuracy: 0.5966796875\n",
      "Batch: 65, Loss: 1.3587350845336914, Accuracy: 0.580078125\n",
      "Batch: 66, Loss: 1.2508318424224854, Accuracy: 0.6123046875\n",
      "Batch: 67, Loss: 1.4415934085845947, Accuracy: 0.5654296875\n",
      "Batch: 68, Loss: 1.4303516149520874, Accuracy: 0.580078125\n",
      "Batch: 69, Loss: 1.3379844427108765, Accuracy: 0.591796875\n",
      "Batch: 70, Loss: 1.3360823392868042, Accuracy: 0.5986328125\n",
      "Batch: 71, Loss: 1.3535265922546387, Accuracy: 0.5791015625\n",
      "Batch: 72, Loss: 1.2270820140838623, Accuracy: 0.6064453125\n",
      "Batch: 73, Loss: 1.3335968255996704, Accuracy: 0.5888671875\n",
      "Batch: 74, Loss: 1.2663676738739014, Accuracy: 0.5927734375\n",
      "Batch: 75, Loss: 1.1931273937225342, Accuracy: 0.6240234375\n",
      "Batch: 76, Loss: 1.315699815750122, Accuracy: 0.56640625\n",
      "Batch: 77, Loss: 1.3174488544464111, Accuracy: 0.578125\n",
      "Batch: 78, Loss: 1.3367507457733154, Accuracy: 0.62109375\n",
      "Batch: 79, Loss: 1.1960456371307373, Accuracy: 0.6533203125\n",
      "Batch: 80, Loss: 1.2362383604049683, Accuracy: 0.6064453125\n",
      "Batch: 81, Loss: 1.3667281866073608, Accuracy: 0.556640625\n",
      "Batch: 82, Loss: 1.309786319732666, Accuracy: 0.5849609375\n",
      "Batch: 83, Loss: 1.1614406108856201, Accuracy: 0.658203125\n",
      "Batch: 84, Loss: 1.251320719718933, Accuracy: 0.625\n",
      "Batch: 85, Loss: 1.2226293087005615, Accuracy: 0.630859375\n",
      "Batch: 86, Loss: 1.4807484149932861, Accuracy: 0.5458984375\n",
      "Batch: 87, Loss: 1.279819369316101, Accuracy: 0.619140625\n",
      "Batch: 88, Loss: 1.370528221130371, Accuracy: 0.5927734375\n",
      "Batch: 89, Loss: 1.3840115070343018, Accuracy: 0.5703125\n",
      "Batch: 90, Loss: 1.2556483745574951, Accuracy: 0.6220703125\n",
      "Batch: 91, Loss: 1.2798733711242676, Accuracy: 0.6025390625\n",
      "Batch: 92, Loss: 1.3725242614746094, Accuracy: 0.5751953125\n",
      "Batch: 93, Loss: 1.2620116472244263, Accuracy: 0.6083984375\n",
      "Batch: 94, Loss: 1.281747817993164, Accuracy: 0.609375\n",
      "Batch: 95, Loss: 1.2953170537948608, Accuracy: 0.576171875\n",
      "Batch: 96, Loss: 1.2781236171722412, Accuracy: 0.6005859375\n",
      "Batch: 97, Loss: 1.1624481678009033, Accuracy: 0.6357421875\n",
      "Batch: 98, Loss: 1.20988130569458, Accuracy: 0.6337890625\n",
      "Batch: 99, Loss: 1.231703519821167, Accuracy: 0.61328125\n",
      "Batch: 100, Loss: 1.2802848815917969, Accuracy: 0.6103515625\n",
      "Batch: 101, Loss: 1.3354809284210205, Accuracy: 0.5810546875\n",
      "Batch: 102, Loss: 1.2363088130950928, Accuracy: 0.6064453125\n",
      "Batch: 103, Loss: 1.3586416244506836, Accuracy: 0.619140625\n",
      "Batch: 104, Loss: 1.2407859563827515, Accuracy: 0.619140625\n",
      "Batch: 105, Loss: 1.3543286323547363, Accuracy: 0.5693359375\n",
      "Batch: 106, Loss: 1.3308682441711426, Accuracy: 0.583984375\n",
      "Batch: 107, Loss: 1.4240365028381348, Accuracy: 0.5595703125\n",
      "Batch: 108, Loss: 1.3817293643951416, Accuracy: 0.56640625\n",
      "Batch: 109, Loss: 1.4348719120025635, Accuracy: 0.5458984375\n",
      "Batch: 110, Loss: 1.1344959735870361, Accuracy: 0.6220703125\n",
      "Batch: 111, Loss: 1.359208583831787, Accuracy: 0.560546875\n",
      "Batch: 112, Loss: 1.3098304271697998, Accuracy: 0.5947265625\n",
      "Batch: 113, Loss: 1.353322982788086, Accuracy: 0.59765625\n",
      "Batch: 114, Loss: 1.414522409439087, Accuracy: 0.5576171875\n",
      "Batch: 115, Loss: 1.4711134433746338, Accuracy: 0.5615234375\n",
      "Batch: 116, Loss: 1.4123154878616333, Accuracy: 0.564453125\n",
      "Batch: 117, Loss: 1.3979768753051758, Accuracy: 0.59765625\n",
      "Batch: 118, Loss: 1.176650881767273, Accuracy: 0.646484375\n",
      "Batch: 119, Loss: 1.2436442375183105, Accuracy: 0.6328125\n",
      "Batch: 120, Loss: 1.3689513206481934, Accuracy: 0.580078125\n",
      "Batch: 121, Loss: 1.4060890674591064, Accuracy: 0.564453125\n",
      "Batch: 122, Loss: 1.303362250328064, Accuracy: 0.6083984375\n",
      "Batch: 123, Loss: 1.299079418182373, Accuracy: 0.6025390625\n",
      "Batch: 124, Loss: 1.3333325386047363, Accuracy: 0.5947265625\n",
      "Batch: 125, Loss: 1.3806970119476318, Accuracy: 0.580078125\n",
      "Batch: 126, Loss: 1.3610141277313232, Accuracy: 0.56640625\n",
      "Batch: 127, Loss: 1.2265424728393555, Accuracy: 0.623046875\n",
      "Batch: 128, Loss: 1.4876947402954102, Accuracy: 0.57421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 129, Loss: 1.2962284088134766, Accuracy: 0.5986328125\n",
      "Batch: 130, Loss: 1.5223571062088013, Accuracy: 0.5439453125\n",
      "Batch: 131, Loss: 1.3928987979888916, Accuracy: 0.5771484375\n",
      "Batch: 132, Loss: 1.403136968612671, Accuracy: 0.5625\n",
      "Batch: 133, Loss: 1.2534193992614746, Accuracy: 0.607421875\n",
      "Batch: 134, Loss: 1.3356139659881592, Accuracy: 0.5703125\n",
      "Batch: 135, Loss: 1.3010729551315308, Accuracy: 0.6025390625\n",
      "Batch: 136, Loss: 1.338241696357727, Accuracy: 0.5927734375\n",
      "Batch: 137, Loss: 1.209909439086914, Accuracy: 0.6044921875\n",
      "Batch: 138, Loss: 1.135443925857544, Accuracy: 0.6328125\n",
      "Batch: 139, Loss: 1.2158780097961426, Accuracy: 0.6123046875\n",
      "Batch: 140, Loss: 1.3225988149642944, Accuracy: 0.5732421875\n",
      "Batch: 141, Loss: 1.3183857202529907, Accuracy: 0.5947265625\n",
      "Batch: 142, Loss: 1.361137866973877, Accuracy: 0.58203125\n",
      "Batch: 143, Loss: 1.3529993295669556, Accuracy: 0.56640625\n",
      "Batch: 144, Loss: 1.310483694076538, Accuracy: 0.5908203125\n",
      "Batch: 145, Loss: 1.2496414184570312, Accuracy: 0.5791015625\n",
      "Batch: 146, Loss: 1.4026501178741455, Accuracy: 0.5517578125\n",
      "Batch: 147, Loss: 1.3233129978179932, Accuracy: 0.5888671875\n",
      "Batch: 148, Loss: 1.4670922756195068, Accuracy: 0.5302734375\n",
      "Batch: 149, Loss: 1.3263487815856934, Accuracy: 0.5751953125\n",
      "Batch: 150, Loss: 1.2661993503570557, Accuracy: 0.6005859375\n",
      "Batch: 151, Loss: 1.2391412258148193, Accuracy: 0.62109375\n",
      "Saved Weights at epoch 10 to file Weights_10.h5\n",
      "Epoch 11/80\n",
      "Batch: 1, Loss: 1.4686243534088135, Accuracy: 0.5283203125\n",
      "Batch: 2, Loss: 1.2888901233673096, Accuracy: 0.572265625\n",
      "Batch: 3, Loss: 1.2257776260375977, Accuracy: 0.6064453125\n",
      "Batch: 4, Loss: 1.1821953058242798, Accuracy: 0.6494140625\n",
      "Batch: 5, Loss: 1.221644639968872, Accuracy: 0.6240234375\n",
      "Batch: 6, Loss: 1.3247764110565186, Accuracy: 0.5517578125\n",
      "Batch: 7, Loss: 1.2679475545883179, Accuracy: 0.5966796875\n",
      "Batch: 8, Loss: 1.2149784564971924, Accuracy: 0.60546875\n",
      "Batch: 9, Loss: 1.1638543605804443, Accuracy: 0.6455078125\n",
      "Batch: 10, Loss: 1.203635334968567, Accuracy: 0.619140625\n",
      "Batch: 11, Loss: 1.3694206476211548, Accuracy: 0.5576171875\n",
      "Batch: 12, Loss: 1.3969085216522217, Accuracy: 0.5732421875\n",
      "Batch: 13, Loss: 1.1387712955474854, Accuracy: 0.6494140625\n",
      "Batch: 14, Loss: 1.3738737106323242, Accuracy: 0.560546875\n",
      "Batch: 15, Loss: 1.25479257106781, Accuracy: 0.62109375\n",
      "Batch: 16, Loss: 1.2307868003845215, Accuracy: 0.6181640625\n",
      "Batch: 17, Loss: 1.3177361488342285, Accuracy: 0.57421875\n",
      "Batch: 18, Loss: 1.3619697093963623, Accuracy: 0.576171875\n",
      "Batch: 19, Loss: 1.3528484106063843, Accuracy: 0.6083984375\n",
      "Batch: 20, Loss: 1.244216799736023, Accuracy: 0.6201171875\n",
      "Batch: 21, Loss: 1.2175750732421875, Accuracy: 0.611328125\n",
      "Batch: 22, Loss: 1.382932424545288, Accuracy: 0.5673828125\n",
      "Batch: 23, Loss: 1.2547593116760254, Accuracy: 0.60546875\n",
      "Batch: 24, Loss: 1.2871053218841553, Accuracy: 0.6044921875\n",
      "Batch: 25, Loss: 1.2464182376861572, Accuracy: 0.599609375\n",
      "Batch: 26, Loss: 1.1704144477844238, Accuracy: 0.6357421875\n",
      "Batch: 27, Loss: 1.2401975393295288, Accuracy: 0.60546875\n",
      "Batch: 28, Loss: 1.3222050666809082, Accuracy: 0.5908203125\n",
      "Batch: 29, Loss: 1.3045899868011475, Accuracy: 0.599609375\n",
      "Batch: 30, Loss: 1.2713996171951294, Accuracy: 0.615234375\n",
      "Batch: 31, Loss: 1.2418826818466187, Accuracy: 0.6259765625\n",
      "Batch: 32, Loss: 1.204801082611084, Accuracy: 0.6015625\n",
      "Batch: 33, Loss: 1.3946127891540527, Accuracy: 0.5693359375\n",
      "Batch: 34, Loss: 1.4669448137283325, Accuracy: 0.55078125\n",
      "Batch: 35, Loss: 1.3208658695220947, Accuracy: 0.58203125\n",
      "Batch: 36, Loss: 1.3131710290908813, Accuracy: 0.5966796875\n",
      "Batch: 37, Loss: 1.2904322147369385, Accuracy: 0.5849609375\n",
      "Batch: 38, Loss: 1.298365592956543, Accuracy: 0.580078125\n",
      "Batch: 39, Loss: 1.321751594543457, Accuracy: 0.59765625\n",
      "Batch: 40, Loss: 1.3549020290374756, Accuracy: 0.599609375\n",
      "Batch: 41, Loss: 1.315915584564209, Accuracy: 0.5849609375\n",
      "Batch: 42, Loss: 1.0642309188842773, Accuracy: 0.6689453125\n",
      "Batch: 43, Loss: 1.2547742128372192, Accuracy: 0.5869140625\n",
      "Batch: 44, Loss: 1.254173755645752, Accuracy: 0.5869140625\n",
      "Batch: 45, Loss: 1.115316390991211, Accuracy: 0.6298828125\n",
      "Batch: 46, Loss: 1.2579734325408936, Accuracy: 0.6259765625\n",
      "Batch: 47, Loss: 1.2903789281845093, Accuracy: 0.6083984375\n",
      "Batch: 48, Loss: 1.2564219236373901, Accuracy: 0.6025390625\n",
      "Batch: 49, Loss: 1.3913286924362183, Accuracy: 0.55078125\n",
      "Batch: 50, Loss: 1.361534833908081, Accuracy: 0.5751953125\n",
      "Batch: 51, Loss: 1.4747726917266846, Accuracy: 0.55078125\n",
      "Batch: 52, Loss: 1.4443660974502563, Accuracy: 0.583984375\n",
      "Batch: 53, Loss: 1.1827099323272705, Accuracy: 0.6201171875\n",
      "Batch: 54, Loss: 1.258194923400879, Accuracy: 0.6181640625\n",
      "Batch: 55, Loss: 1.3158860206604004, Accuracy: 0.576171875\n",
      "Batch: 56, Loss: 1.3456368446350098, Accuracy: 0.5869140625\n",
      "Batch: 57, Loss: 1.3227680921554565, Accuracy: 0.6005859375\n",
      "Batch: 58, Loss: 1.3628430366516113, Accuracy: 0.6064453125\n",
      "Batch: 59, Loss: 1.1612154245376587, Accuracy: 0.640625\n",
      "Batch: 60, Loss: 1.149656057357788, Accuracy: 0.6279296875\n",
      "Batch: 61, Loss: 1.3061625957489014, Accuracy: 0.587890625\n",
      "Batch: 62, Loss: 1.3081293106079102, Accuracy: 0.59765625\n",
      "Batch: 63, Loss: 1.3295178413391113, Accuracy: 0.5849609375\n",
      "Batch: 64, Loss: 1.2695121765136719, Accuracy: 0.6005859375\n",
      "Batch: 65, Loss: 1.329657793045044, Accuracy: 0.5927734375\n",
      "Batch: 66, Loss: 1.21665620803833, Accuracy: 0.623046875\n",
      "Batch: 67, Loss: 1.3890382051467896, Accuracy: 0.580078125\n",
      "Batch: 68, Loss: 1.3923332691192627, Accuracy: 0.55859375\n",
      "Batch: 69, Loss: 1.325801134109497, Accuracy: 0.59375\n",
      "Batch: 70, Loss: 1.2921620607376099, Accuracy: 0.607421875\n",
      "Batch: 71, Loss: 1.3043596744537354, Accuracy: 0.5751953125\n",
      "Batch: 72, Loss: 1.2083570957183838, Accuracy: 0.6220703125\n",
      "Batch: 73, Loss: 1.2883274555206299, Accuracy: 0.6162109375\n",
      "Batch: 74, Loss: 1.252169132232666, Accuracy: 0.6025390625\n",
      "Batch: 75, Loss: 1.15304696559906, Accuracy: 0.6396484375\n",
      "Batch: 76, Loss: 1.3091516494750977, Accuracy: 0.5693359375\n",
      "Batch: 77, Loss: 1.2885154485702515, Accuracy: 0.5791015625\n",
      "Batch: 78, Loss: 1.2897671461105347, Accuracy: 0.6279296875\n",
      "Batch: 79, Loss: 1.1492743492126465, Accuracy: 0.6689453125\n",
      "Batch: 80, Loss: 1.2049801349639893, Accuracy: 0.6162109375\n",
      "Batch: 81, Loss: 1.322414755821228, Accuracy: 0.5556640625\n",
      "Batch: 82, Loss: 1.281919240951538, Accuracy: 0.5859375\n",
      "Batch: 83, Loss: 1.140726089477539, Accuracy: 0.666015625\n",
      "Batch: 84, Loss: 1.2018940448760986, Accuracy: 0.634765625\n",
      "Batch: 85, Loss: 1.1679267883300781, Accuracy: 0.64453125\n",
      "Batch: 86, Loss: 1.4636908769607544, Accuracy: 0.5537109375\n",
      "Batch: 87, Loss: 1.244712471961975, Accuracy: 0.611328125\n",
      "Batch: 88, Loss: 1.3536207675933838, Accuracy: 0.5966796875\n",
      "Batch: 89, Loss: 1.356596827507019, Accuracy: 0.595703125\n",
      "Batch: 90, Loss: 1.2131893634796143, Accuracy: 0.625\n",
      "Batch: 91, Loss: 1.226076364517212, Accuracy: 0.61328125\n",
      "Batch: 92, Loss: 1.3113794326782227, Accuracy: 0.59375\n",
      "Batch: 93, Loss: 1.2359906435012817, Accuracy: 0.619140625\n",
      "Batch: 94, Loss: 1.2668864727020264, Accuracy: 0.615234375\n",
      "Batch: 95, Loss: 1.2796815633773804, Accuracy: 0.591796875\n",
      "Batch: 96, Loss: 1.2361736297607422, Accuracy: 0.6142578125\n",
      "Batch: 97, Loss: 1.140981912612915, Accuracy: 0.6298828125\n",
      "Batch: 98, Loss: 1.183417558670044, Accuracy: 0.6328125\n",
      "Batch: 99, Loss: 1.1691588163375854, Accuracy: 0.62890625\n",
      "Batch: 100, Loss: 1.252537488937378, Accuracy: 0.599609375\n",
      "Batch: 101, Loss: 1.2887288331985474, Accuracy: 0.5927734375\n",
      "Batch: 102, Loss: 1.2142270803451538, Accuracy: 0.6259765625\n",
      "Batch: 103, Loss: 1.3252389430999756, Accuracy: 0.6123046875\n",
      "Batch: 104, Loss: 1.1934106349945068, Accuracy: 0.619140625\n",
      "Batch: 105, Loss: 1.3316692113876343, Accuracy: 0.5771484375\n",
      "Batch: 106, Loss: 1.280198574066162, Accuracy: 0.59375\n",
      "Batch: 107, Loss: 1.3802893161773682, Accuracy: 0.5751953125\n",
      "Batch: 108, Loss: 1.3436241149902344, Accuracy: 0.572265625\n",
      "Batch: 109, Loss: 1.406540036201477, Accuracy: 0.5478515625\n",
      "Batch: 110, Loss: 1.1167359352111816, Accuracy: 0.6357421875\n",
      "Batch: 111, Loss: 1.3077247142791748, Accuracy: 0.5654296875\n",
      "Batch: 112, Loss: 1.2829047441482544, Accuracy: 0.59765625\n",
      "Batch: 113, Loss: 1.3191134929656982, Accuracy: 0.60546875\n",
      "Batch: 114, Loss: 1.3683857917785645, Accuracy: 0.5712890625\n",
      "Batch: 115, Loss: 1.4355238676071167, Accuracy: 0.58203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 116, Loss: 1.3449461460113525, Accuracy: 0.5732421875\n",
      "Batch: 117, Loss: 1.360686182975769, Accuracy: 0.5908203125\n",
      "Batch: 118, Loss: 1.1382989883422852, Accuracy: 0.642578125\n",
      "Batch: 119, Loss: 1.2108855247497559, Accuracy: 0.63671875\n",
      "Batch: 120, Loss: 1.3405921459197998, Accuracy: 0.5859375\n",
      "Batch: 121, Loss: 1.3532642126083374, Accuracy: 0.576171875\n",
      "Batch: 122, Loss: 1.235490083694458, Accuracy: 0.6259765625\n",
      "Batch: 123, Loss: 1.2672810554504395, Accuracy: 0.607421875\n",
      "Batch: 124, Loss: 1.291275978088379, Accuracy: 0.5947265625\n",
      "Batch: 125, Loss: 1.317535638809204, Accuracy: 0.578125\n",
      "Batch: 126, Loss: 1.3096928596496582, Accuracy: 0.5791015625\n",
      "Batch: 127, Loss: 1.1702580451965332, Accuracy: 0.6416015625\n",
      "Batch: 128, Loss: 1.4204068183898926, Accuracy: 0.580078125\n",
      "Batch: 129, Loss: 1.2323799133300781, Accuracy: 0.615234375\n",
      "Batch: 130, Loss: 1.4765406847000122, Accuracy: 0.546875\n",
      "Batch: 131, Loss: 1.3446416854858398, Accuracy: 0.57421875\n",
      "Batch: 132, Loss: 1.3629658222198486, Accuracy: 0.580078125\n",
      "Batch: 133, Loss: 1.22409987449646, Accuracy: 0.630859375\n",
      "Batch: 134, Loss: 1.2944124937057495, Accuracy: 0.5849609375\n",
      "Batch: 135, Loss: 1.257437825202942, Accuracy: 0.6279296875\n",
      "Batch: 136, Loss: 1.2948670387268066, Accuracy: 0.6025390625\n",
      "Batch: 137, Loss: 1.1984115839004517, Accuracy: 0.6103515625\n",
      "Batch: 138, Loss: 1.1045911312103271, Accuracy: 0.6318359375\n",
      "Batch: 139, Loss: 1.1637916564941406, Accuracy: 0.6240234375\n",
      "Batch: 140, Loss: 1.3033273220062256, Accuracy: 0.5830078125\n",
      "Batch: 141, Loss: 1.268049955368042, Accuracy: 0.6025390625\n",
      "Batch: 142, Loss: 1.3069441318511963, Accuracy: 0.5908203125\n",
      "Batch: 143, Loss: 1.3136284351348877, Accuracy: 0.58203125\n",
      "Batch: 144, Loss: 1.2846651077270508, Accuracy: 0.595703125\n",
      "Batch: 145, Loss: 1.2023111581802368, Accuracy: 0.6005859375\n",
      "Batch: 146, Loss: 1.345909595489502, Accuracy: 0.58984375\n",
      "Batch: 147, Loss: 1.280266523361206, Accuracy: 0.6025390625\n",
      "Batch: 148, Loss: 1.4186341762542725, Accuracy: 0.54296875\n",
      "Batch: 149, Loss: 1.2871326208114624, Accuracy: 0.583984375\n",
      "Batch: 150, Loss: 1.2265031337738037, Accuracy: 0.6220703125\n",
      "Batch: 151, Loss: 1.2293391227722168, Accuracy: 0.6220703125\n",
      "Epoch 12/80\n",
      "Batch: 1, Loss: 1.4282160997390747, Accuracy: 0.53515625\n",
      "Batch: 2, Loss: 1.2642176151275635, Accuracy: 0.5693359375\n",
      "Batch: 3, Loss: 1.1840925216674805, Accuracy: 0.607421875\n",
      "Batch: 4, Loss: 1.1446523666381836, Accuracy: 0.6484375\n",
      "Batch: 5, Loss: 1.2065627574920654, Accuracy: 0.62890625\n",
      "Batch: 6, Loss: 1.2780237197875977, Accuracy: 0.5654296875\n",
      "Batch: 7, Loss: 1.2260663509368896, Accuracy: 0.6025390625\n",
      "Batch: 8, Loss: 1.196410894393921, Accuracy: 0.609375\n",
      "Batch: 9, Loss: 1.156980276107788, Accuracy: 0.6611328125\n",
      "Batch: 10, Loss: 1.1725776195526123, Accuracy: 0.6171875\n",
      "Batch: 11, Loss: 1.3243279457092285, Accuracy: 0.578125\n",
      "Batch: 12, Loss: 1.3658058643341064, Accuracy: 0.560546875\n",
      "Batch: 13, Loss: 1.0997796058654785, Accuracy: 0.662109375\n",
      "Batch: 14, Loss: 1.33954918384552, Accuracy: 0.5732421875\n",
      "Batch: 15, Loss: 1.220283031463623, Accuracy: 0.62890625\n",
      "Batch: 16, Loss: 1.1806418895721436, Accuracy: 0.63671875\n",
      "Batch: 17, Loss: 1.28446364402771, Accuracy: 0.5986328125\n",
      "Batch: 18, Loss: 1.3267042636871338, Accuracy: 0.5888671875\n",
      "Batch: 19, Loss: 1.3255350589752197, Accuracy: 0.609375\n",
      "Batch: 20, Loss: 1.2352712154388428, Accuracy: 0.638671875\n",
      "Batch: 21, Loss: 1.1877937316894531, Accuracy: 0.615234375\n",
      "Batch: 22, Loss: 1.3601946830749512, Accuracy: 0.59765625\n",
      "Batch: 23, Loss: 1.216127872467041, Accuracy: 0.6181640625\n",
      "Batch: 24, Loss: 1.2312157154083252, Accuracy: 0.609375\n",
      "Batch: 25, Loss: 1.2288051843643188, Accuracy: 0.61328125\n",
      "Batch: 26, Loss: 1.1412866115570068, Accuracy: 0.6494140625\n",
      "Batch: 27, Loss: 1.166628122329712, Accuracy: 0.6162109375\n",
      "Batch: 28, Loss: 1.2692766189575195, Accuracy: 0.5830078125\n",
      "Batch: 29, Loss: 1.292602300643921, Accuracy: 0.5859375\n",
      "Batch: 30, Loss: 1.228090524673462, Accuracy: 0.634765625\n",
      "Batch: 31, Loss: 1.1746808290481567, Accuracy: 0.6533203125\n",
      "Batch: 32, Loss: 1.149850845336914, Accuracy: 0.630859375\n",
      "Batch: 33, Loss: 1.3652451038360596, Accuracy: 0.5732421875\n",
      "Batch: 34, Loss: 1.4246917963027954, Accuracy: 0.552734375\n",
      "Batch: 35, Loss: 1.2738680839538574, Accuracy: 0.58984375\n",
      "Batch: 36, Loss: 1.2948435544967651, Accuracy: 0.603515625\n",
      "Batch: 37, Loss: 1.2523754835128784, Accuracy: 0.607421875\n",
      "Batch: 38, Loss: 1.287769079208374, Accuracy: 0.5869140625\n",
      "Batch: 39, Loss: 1.3024598360061646, Accuracy: 0.611328125\n",
      "Batch: 40, Loss: 1.3285021781921387, Accuracy: 0.6123046875\n",
      "Batch: 41, Loss: 1.2885810136795044, Accuracy: 0.60546875\n",
      "Batch: 42, Loss: 1.0440837144851685, Accuracy: 0.6787109375\n",
      "Batch: 43, Loss: 1.246739387512207, Accuracy: 0.5810546875\n",
      "Batch: 44, Loss: 1.2318027019500732, Accuracy: 0.5908203125\n",
      "Batch: 45, Loss: 1.0895724296569824, Accuracy: 0.6455078125\n",
      "Batch: 46, Loss: 1.2489397525787354, Accuracy: 0.634765625\n",
      "Batch: 47, Loss: 1.2439919710159302, Accuracy: 0.6123046875\n",
      "Batch: 48, Loss: 1.2436145544052124, Accuracy: 0.61328125\n",
      "Batch: 49, Loss: 1.3574347496032715, Accuracy: 0.5634765625\n",
      "Batch: 50, Loss: 1.3149341344833374, Accuracy: 0.576171875\n",
      "Batch: 51, Loss: 1.4407296180725098, Accuracy: 0.5419921875\n",
      "Batch: 52, Loss: 1.3803791999816895, Accuracy: 0.576171875\n",
      "Batch: 53, Loss: 1.1496552228927612, Accuracy: 0.6240234375\n",
      "Batch: 54, Loss: 1.2193148136138916, Accuracy: 0.6220703125\n",
      "Batch: 55, Loss: 1.3043949604034424, Accuracy: 0.5810546875\n",
      "Batch: 56, Loss: 1.3404126167297363, Accuracy: 0.5751953125\n",
      "Batch: 57, Loss: 1.266374111175537, Accuracy: 0.6240234375\n",
      "Batch: 58, Loss: 1.3741204738616943, Accuracy: 0.58203125\n",
      "Batch: 59, Loss: 1.1361682415008545, Accuracy: 0.6650390625\n",
      "Batch: 60, Loss: 1.1257307529449463, Accuracy: 0.6416015625\n",
      "Batch: 61, Loss: 1.267619252204895, Accuracy: 0.5966796875\n",
      "Batch: 62, Loss: 1.2880593538284302, Accuracy: 0.607421875\n",
      "Batch: 63, Loss: 1.2741482257843018, Accuracy: 0.599609375\n",
      "Batch: 64, Loss: 1.224492073059082, Accuracy: 0.6162109375\n",
      "Batch: 65, Loss: 1.2761865854263306, Accuracy: 0.6103515625\n",
      "Batch: 66, Loss: 1.1747491359710693, Accuracy: 0.6328125\n",
      "Batch: 67, Loss: 1.3716881275177002, Accuracy: 0.578125\n",
      "Batch: 68, Loss: 1.367812991142273, Accuracy: 0.5908203125\n",
      "Batch: 69, Loss: 1.2848443984985352, Accuracy: 0.6025390625\n",
      "Batch: 70, Loss: 1.2857321500778198, Accuracy: 0.59765625\n",
      "Batch: 71, Loss: 1.2862969636917114, Accuracy: 0.5947265625\n",
      "Batch: 72, Loss: 1.1443195343017578, Accuracy: 0.626953125\n",
      "Batch: 73, Loss: 1.2522454261779785, Accuracy: 0.619140625\n",
      "Batch: 74, Loss: 1.2065505981445312, Accuracy: 0.609375\n",
      "Batch: 75, Loss: 1.135297179222107, Accuracy: 0.6279296875\n",
      "Batch: 76, Loss: 1.2743819952011108, Accuracy: 0.58984375\n",
      "Batch: 77, Loss: 1.2508188486099243, Accuracy: 0.5986328125\n",
      "Batch: 78, Loss: 1.2397503852844238, Accuracy: 0.6435546875\n",
      "Batch: 79, Loss: 1.1196327209472656, Accuracy: 0.6748046875\n",
      "Batch: 80, Loss: 1.1683409214019775, Accuracy: 0.6201171875\n",
      "Batch: 81, Loss: 1.3068554401397705, Accuracy: 0.576171875\n",
      "Batch: 82, Loss: 1.2383235692977905, Accuracy: 0.6064453125\n",
      "Batch: 83, Loss: 1.106569766998291, Accuracy: 0.6611328125\n",
      "Batch: 84, Loss: 1.1638267040252686, Accuracy: 0.6416015625\n",
      "Batch: 85, Loss: 1.1582812070846558, Accuracy: 0.64453125\n",
      "Batch: 86, Loss: 1.3942618370056152, Accuracy: 0.5771484375\n",
      "Batch: 87, Loss: 1.2024450302124023, Accuracy: 0.6416015625\n",
      "Batch: 88, Loss: 1.3338377475738525, Accuracy: 0.611328125\n",
      "Batch: 89, Loss: 1.3138556480407715, Accuracy: 0.599609375\n",
      "Batch: 90, Loss: 1.186903715133667, Accuracy: 0.62890625\n",
      "Batch: 91, Loss: 1.206125020980835, Accuracy: 0.623046875\n",
      "Batch: 92, Loss: 1.2908761501312256, Accuracy: 0.591796875\n",
      "Batch: 93, Loss: 1.210710048675537, Accuracy: 0.6171875\n",
      "Batch: 94, Loss: 1.2450840473175049, Accuracy: 0.6171875\n",
      "Batch: 95, Loss: 1.2405030727386475, Accuracy: 0.6083984375\n",
      "Batch: 96, Loss: 1.2171483039855957, Accuracy: 0.626953125\n",
      "Batch: 97, Loss: 1.0996830463409424, Accuracy: 0.650390625\n",
      "Batch: 98, Loss: 1.1419456005096436, Accuracy: 0.6435546875\n",
      "Batch: 99, Loss: 1.137515902519226, Accuracy: 0.6435546875\n",
      "Batch: 100, Loss: 1.221906065940857, Accuracy: 0.615234375\n",
      "Batch: 101, Loss: 1.2743396759033203, Accuracy: 0.59765625\n",
      "Batch: 102, Loss: 1.184230923652649, Accuracy: 0.6259765625\n",
      "Batch: 103, Loss: 1.2886545658111572, Accuracy: 0.6201171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 104, Loss: 1.1470650434494019, Accuracy: 0.63671875\n",
      "Batch: 105, Loss: 1.274078369140625, Accuracy: 0.5849609375\n",
      "Batch: 106, Loss: 1.2179323434829712, Accuracy: 0.6103515625\n",
      "Batch: 107, Loss: 1.3374403715133667, Accuracy: 0.572265625\n",
      "Batch: 108, Loss: 1.2956874370574951, Accuracy: 0.5859375\n",
      "Batch: 109, Loss: 1.387193202972412, Accuracy: 0.5595703125\n",
      "Batch: 110, Loss: 1.0802013874053955, Accuracy: 0.654296875\n",
      "Batch: 111, Loss: 1.300790548324585, Accuracy: 0.5859375\n",
      "Batch: 112, Loss: 1.2474614381790161, Accuracy: 0.611328125\n",
      "Batch: 113, Loss: 1.2916616201400757, Accuracy: 0.60546875\n",
      "Batch: 114, Loss: 1.342176079750061, Accuracy: 0.5751953125\n",
      "Batch: 115, Loss: 1.405649185180664, Accuracy: 0.5693359375\n",
      "Batch: 116, Loss: 1.3070240020751953, Accuracy: 0.580078125\n",
      "Batch: 117, Loss: 1.3155440092086792, Accuracy: 0.611328125\n",
      "Batch: 118, Loss: 1.1246745586395264, Accuracy: 0.6484375\n",
      "Batch: 119, Loss: 1.1817564964294434, Accuracy: 0.6376953125\n",
      "Batch: 120, Loss: 1.3169231414794922, Accuracy: 0.576171875\n",
      "Batch: 121, Loss: 1.3105460405349731, Accuracy: 0.5791015625\n",
      "Batch: 122, Loss: 1.2125530242919922, Accuracy: 0.634765625\n",
      "Batch: 123, Loss: 1.221940517425537, Accuracy: 0.6220703125\n",
      "Batch: 124, Loss: 1.2512612342834473, Accuracy: 0.6064453125\n",
      "Batch: 125, Loss: 1.298255443572998, Accuracy: 0.6015625\n",
      "Batch: 126, Loss: 1.2837334871292114, Accuracy: 0.5859375\n",
      "Batch: 127, Loss: 1.130387544631958, Accuracy: 0.6728515625\n",
      "Batch: 128, Loss: 1.3953810930252075, Accuracy: 0.59375\n",
      "Batch: 129, Loss: 1.2129976749420166, Accuracy: 0.62109375\n",
      "Batch: 130, Loss: 1.4389902353286743, Accuracy: 0.5703125\n",
      "Batch: 131, Loss: 1.3317911624908447, Accuracy: 0.576171875\n",
      "Batch: 132, Loss: 1.3393620252609253, Accuracy: 0.5830078125\n",
      "Batch: 133, Loss: 1.1880139112472534, Accuracy: 0.6181640625\n",
      "Batch: 134, Loss: 1.2548809051513672, Accuracy: 0.5947265625\n",
      "Batch: 135, Loss: 1.2116731405258179, Accuracy: 0.6416015625\n",
      "Batch: 136, Loss: 1.2632946968078613, Accuracy: 0.6181640625\n",
      "Batch: 137, Loss: 1.1736611127853394, Accuracy: 0.6103515625\n",
      "Batch: 138, Loss: 1.063927412033081, Accuracy: 0.658203125\n",
      "Batch: 139, Loss: 1.137589454650879, Accuracy: 0.6298828125\n",
      "Batch: 140, Loss: 1.2692457437515259, Accuracy: 0.591796875\n",
      "Batch: 141, Loss: 1.2554662227630615, Accuracy: 0.6201171875\n",
      "Batch: 142, Loss: 1.2964807748794556, Accuracy: 0.59765625\n",
      "Batch: 143, Loss: 1.2652428150177002, Accuracy: 0.5849609375\n",
      "Batch: 144, Loss: 1.2526881694793701, Accuracy: 0.6142578125\n",
      "Batch: 145, Loss: 1.1685340404510498, Accuracy: 0.60546875\n",
      "Batch: 146, Loss: 1.2867364883422852, Accuracy: 0.599609375\n",
      "Batch: 147, Loss: 1.2542152404785156, Accuracy: 0.5830078125\n",
      "Batch: 148, Loss: 1.3922765254974365, Accuracy: 0.5439453125\n",
      "Batch: 149, Loss: 1.2227987051010132, Accuracy: 0.607421875\n",
      "Batch: 150, Loss: 1.2012557983398438, Accuracy: 0.61328125\n",
      "Batch: 151, Loss: 1.1637643575668335, Accuracy: 0.640625\n",
      "Epoch 13/80\n",
      "Batch: 1, Loss: 1.4160230159759521, Accuracy: 0.5390625\n",
      "Batch: 2, Loss: 1.2307711839675903, Accuracy: 0.5751953125\n",
      "Batch: 3, Loss: 1.161787509918213, Accuracy: 0.6142578125\n",
      "Batch: 4, Loss: 1.118295669555664, Accuracy: 0.66015625\n",
      "Batch: 5, Loss: 1.176628589630127, Accuracy: 0.64453125\n",
      "Batch: 6, Loss: 1.2480040788650513, Accuracy: 0.578125\n",
      "Batch: 7, Loss: 1.213200330734253, Accuracy: 0.603515625\n",
      "Batch: 8, Loss: 1.15500807762146, Accuracy: 0.62109375\n",
      "Batch: 9, Loss: 1.124751091003418, Accuracy: 0.6474609375\n",
      "Batch: 10, Loss: 1.1479411125183105, Accuracy: 0.6337890625\n",
      "Batch: 11, Loss: 1.3176608085632324, Accuracy: 0.57421875\n",
      "Batch: 12, Loss: 1.3239524364471436, Accuracy: 0.5888671875\n",
      "Batch: 13, Loss: 1.0661455392837524, Accuracy: 0.6796875\n",
      "Batch: 14, Loss: 1.3022162914276123, Accuracy: 0.57421875\n",
      "Batch: 15, Loss: 1.1874586343765259, Accuracy: 0.6416015625\n",
      "Batch: 16, Loss: 1.1626858711242676, Accuracy: 0.634765625\n",
      "Batch: 17, Loss: 1.2564774751663208, Accuracy: 0.5986328125\n",
      "Batch: 18, Loss: 1.277057409286499, Accuracy: 0.595703125\n",
      "Batch: 19, Loss: 1.2900536060333252, Accuracy: 0.607421875\n",
      "Batch: 20, Loss: 1.2180202007293701, Accuracy: 0.634765625\n",
      "Batch: 21, Loss: 1.1528384685516357, Accuracy: 0.6318359375\n",
      "Batch: 22, Loss: 1.3120110034942627, Accuracy: 0.599609375\n",
      "Batch: 23, Loss: 1.190026044845581, Accuracy: 0.623046875\n",
      "Batch: 24, Loss: 1.2291885614395142, Accuracy: 0.615234375\n",
      "Batch: 25, Loss: 1.1974691152572632, Accuracy: 0.615234375\n",
      "Batch: 26, Loss: 1.0916374921798706, Accuracy: 0.66015625\n",
      "Batch: 27, Loss: 1.1410436630249023, Accuracy: 0.626953125\n",
      "Batch: 28, Loss: 1.2501128911972046, Accuracy: 0.5927734375\n",
      "Batch: 29, Loss: 1.2355432510375977, Accuracy: 0.6162109375\n",
      "Batch: 30, Loss: 1.196164608001709, Accuracy: 0.638671875\n",
      "Batch: 31, Loss: 1.147317886352539, Accuracy: 0.640625\n",
      "Batch: 32, Loss: 1.1261613368988037, Accuracy: 0.6376953125\n",
      "Batch: 33, Loss: 1.3329968452453613, Accuracy: 0.58203125\n",
      "Batch: 34, Loss: 1.3961553573608398, Accuracy: 0.5595703125\n",
      "Batch: 35, Loss: 1.25142240524292, Accuracy: 0.59765625\n",
      "Batch: 36, Loss: 1.250367522239685, Accuracy: 0.6025390625\n",
      "Batch: 37, Loss: 1.2124980688095093, Accuracy: 0.607421875\n",
      "Batch: 38, Loss: 1.2402814626693726, Accuracy: 0.58984375\n",
      "Batch: 39, Loss: 1.25046968460083, Accuracy: 0.619140625\n",
      "Batch: 40, Loss: 1.2706905603408813, Accuracy: 0.6220703125\n",
      "Batch: 41, Loss: 1.248182773590088, Accuracy: 0.611328125\n",
      "Batch: 42, Loss: 1.0192756652832031, Accuracy: 0.673828125\n",
      "Batch: 43, Loss: 1.1977829933166504, Accuracy: 0.6064453125\n",
      "Batch: 44, Loss: 1.2042313814163208, Accuracy: 0.60546875\n",
      "Batch: 45, Loss: 1.0730445384979248, Accuracy: 0.6513671875\n",
      "Batch: 46, Loss: 1.2086915969848633, Accuracy: 0.638671875\n",
      "Batch: 47, Loss: 1.2223724126815796, Accuracy: 0.6337890625\n",
      "Batch: 48, Loss: 1.1643036603927612, Accuracy: 0.6279296875\n",
      "Batch: 49, Loss: 1.3406212329864502, Accuracy: 0.576171875\n",
      "Batch: 50, Loss: 1.3017550706863403, Accuracy: 0.5791015625\n",
      "Batch: 51, Loss: 1.4240210056304932, Accuracy: 0.5732421875\n",
      "Batch: 52, Loss: 1.3358007669448853, Accuracy: 0.607421875\n",
      "Batch: 53, Loss: 1.1268329620361328, Accuracy: 0.640625\n",
      "Batch: 54, Loss: 1.2027314901351929, Accuracy: 0.6328125\n",
      "Batch: 55, Loss: 1.2622824907302856, Accuracy: 0.5966796875\n",
      "Batch: 56, Loss: 1.2961993217468262, Accuracy: 0.60546875\n",
      "Batch: 57, Loss: 1.2135536670684814, Accuracy: 0.62109375\n",
      "Batch: 58, Loss: 1.3202195167541504, Accuracy: 0.59375\n",
      "Batch: 59, Loss: 1.128354787826538, Accuracy: 0.671875\n",
      "Batch: 60, Loss: 1.1079734563827515, Accuracy: 0.63671875\n",
      "Batch: 61, Loss: 1.2283672094345093, Accuracy: 0.6240234375\n",
      "Batch: 62, Loss: 1.240017294883728, Accuracy: 0.6171875\n",
      "Batch: 63, Loss: 1.2664000988006592, Accuracy: 0.599609375\n",
      "Batch: 64, Loss: 1.1827834844589233, Accuracy: 0.619140625\n",
      "Batch: 65, Loss: 1.2493939399719238, Accuracy: 0.60546875\n",
      "Batch: 66, Loss: 1.1836520433425903, Accuracy: 0.6298828125\n",
      "Batch: 67, Loss: 1.3410669565200806, Accuracy: 0.5859375\n",
      "Batch: 68, Loss: 1.3323287963867188, Accuracy: 0.5908203125\n",
      "Batch: 69, Loss: 1.2715208530426025, Accuracy: 0.6005859375\n",
      "Batch: 70, Loss: 1.232104778289795, Accuracy: 0.6337890625\n",
      "Batch: 71, Loss: 1.242687463760376, Accuracy: 0.6103515625\n",
      "Batch: 72, Loss: 1.1405317783355713, Accuracy: 0.63671875\n",
      "Batch: 73, Loss: 1.2263013124465942, Accuracy: 0.6240234375\n",
      "Batch: 74, Loss: 1.1648375988006592, Accuracy: 0.6328125\n",
      "Batch: 75, Loss: 1.0941247940063477, Accuracy: 0.6572265625\n",
      "Batch: 76, Loss: 1.2361488342285156, Accuracy: 0.5771484375\n",
      "Batch: 77, Loss: 1.2336809635162354, Accuracy: 0.59375\n",
      "Batch: 78, Loss: 1.2189202308654785, Accuracy: 0.6455078125\n",
      "Batch: 79, Loss: 1.1057684421539307, Accuracy: 0.6767578125\n",
      "Batch: 80, Loss: 1.1256000995635986, Accuracy: 0.630859375\n",
      "Batch: 81, Loss: 1.2694562673568726, Accuracy: 0.576171875\n",
      "Batch: 82, Loss: 1.2179218530654907, Accuracy: 0.6220703125\n",
      "Batch: 83, Loss: 1.056566596031189, Accuracy: 0.6806640625\n",
      "Batch: 84, Loss: 1.1593868732452393, Accuracy: 0.6552734375\n",
      "Batch: 85, Loss: 1.1249494552612305, Accuracy: 0.6650390625\n",
      "Batch: 86, Loss: 1.361621379852295, Accuracy: 0.5859375\n",
      "Batch: 87, Loss: 1.172701120376587, Accuracy: 0.6416015625\n",
      "Batch: 88, Loss: 1.2812052965164185, Accuracy: 0.6142578125\n",
      "Batch: 89, Loss: 1.278479814529419, Accuracy: 0.609375\n",
      "Batch: 90, Loss: 1.1425728797912598, Accuracy: 0.625\n",
      "Batch: 91, Loss: 1.196601152420044, Accuracy: 0.625\n",
      "Batch: 92, Loss: 1.2575938701629639, Accuracy: 0.599609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 93, Loss: 1.1658881902694702, Accuracy: 0.6376953125\n",
      "Batch: 94, Loss: 1.2073922157287598, Accuracy: 0.6259765625\n",
      "Batch: 95, Loss: 1.1866381168365479, Accuracy: 0.6142578125\n",
      "Batch: 96, Loss: 1.167072057723999, Accuracy: 0.638671875\n",
      "Batch: 97, Loss: 1.0883350372314453, Accuracy: 0.65625\n",
      "Batch: 98, Loss: 1.1076233386993408, Accuracy: 0.6552734375\n",
      "Batch: 99, Loss: 1.1055269241333008, Accuracy: 0.6513671875\n",
      "Batch: 100, Loss: 1.172143578529358, Accuracy: 0.626953125\n",
      "Batch: 101, Loss: 1.2425388097763062, Accuracy: 0.603515625\n",
      "Batch: 102, Loss: 1.1495773792266846, Accuracy: 0.6298828125\n",
      "Batch: 103, Loss: 1.2687578201293945, Accuracy: 0.6240234375\n",
      "Batch: 104, Loss: 1.1323113441467285, Accuracy: 0.6357421875\n",
      "Batch: 105, Loss: 1.2573204040527344, Accuracy: 0.58984375\n",
      "Batch: 106, Loss: 1.1937928199768066, Accuracy: 0.6162109375\n",
      "Batch: 107, Loss: 1.314047932624817, Accuracy: 0.580078125\n",
      "Batch: 108, Loss: 1.2779043912887573, Accuracy: 0.5908203125\n",
      "Batch: 109, Loss: 1.3451340198516846, Accuracy: 0.55859375\n",
      "Batch: 110, Loss: 1.0678536891937256, Accuracy: 0.65234375\n",
      "Batch: 111, Loss: 1.2661060094833374, Accuracy: 0.5986328125\n",
      "Batch: 112, Loss: 1.1992847919464111, Accuracy: 0.625\n",
      "Batch: 113, Loss: 1.2580314874649048, Accuracy: 0.619140625\n",
      "Batch: 114, Loss: 1.3146917819976807, Accuracy: 0.583984375\n",
      "Batch: 115, Loss: 1.367910623550415, Accuracy: 0.59375\n",
      "Batch: 116, Loss: 1.29259192943573, Accuracy: 0.58203125\n",
      "Batch: 117, Loss: 1.289534091949463, Accuracy: 0.6123046875\n",
      "Batch: 118, Loss: 1.1003776788711548, Accuracy: 0.6533203125\n",
      "Batch: 119, Loss: 1.1630988121032715, Accuracy: 0.6416015625\n",
      "Batch: 120, Loss: 1.283165693283081, Accuracy: 0.5888671875\n",
      "Batch: 121, Loss: 1.295159101486206, Accuracy: 0.587890625\n",
      "Batch: 122, Loss: 1.159132480621338, Accuracy: 0.6357421875\n",
      "Batch: 123, Loss: 1.1938050985336304, Accuracy: 0.634765625\n",
      "Batch: 124, Loss: 1.2132158279418945, Accuracy: 0.6162109375\n",
      "Batch: 125, Loss: 1.2475225925445557, Accuracy: 0.6181640625\n",
      "Batch: 126, Loss: 1.2471367120742798, Accuracy: 0.6005859375\n",
      "Batch: 127, Loss: 1.1109392642974854, Accuracy: 0.6533203125\n",
      "Batch: 128, Loss: 1.3770840167999268, Accuracy: 0.595703125\n",
      "Batch: 129, Loss: 1.1695624589920044, Accuracy: 0.6337890625\n",
      "Batch: 130, Loss: 1.419684886932373, Accuracy: 0.5625\n",
      "Batch: 131, Loss: 1.2972197532653809, Accuracy: 0.603515625\n",
      "Batch: 132, Loss: 1.295434832572937, Accuracy: 0.6005859375\n",
      "Batch: 133, Loss: 1.1381535530090332, Accuracy: 0.6455078125\n",
      "Batch: 134, Loss: 1.2440119981765747, Accuracy: 0.603515625\n",
      "Batch: 135, Loss: 1.178584098815918, Accuracy: 0.6474609375\n",
      "Batch: 136, Loss: 1.2134687900543213, Accuracy: 0.623046875\n",
      "Batch: 137, Loss: 1.134155035018921, Accuracy: 0.6103515625\n",
      "Batch: 138, Loss: 1.035853385925293, Accuracy: 0.6552734375\n",
      "Batch: 139, Loss: 1.111335039138794, Accuracy: 0.634765625\n",
      "Batch: 140, Loss: 1.2436447143554688, Accuracy: 0.5947265625\n",
      "Batch: 141, Loss: 1.2432098388671875, Accuracy: 0.6064453125\n",
      "Batch: 142, Loss: 1.2542316913604736, Accuracy: 0.607421875\n",
      "Batch: 143, Loss: 1.2549149990081787, Accuracy: 0.6123046875\n",
      "Batch: 144, Loss: 1.2086105346679688, Accuracy: 0.61328125\n",
      "Batch: 145, Loss: 1.1368465423583984, Accuracy: 0.6220703125\n",
      "Batch: 146, Loss: 1.2808542251586914, Accuracy: 0.587890625\n",
      "Batch: 147, Loss: 1.21048104763031, Accuracy: 0.61328125\n",
      "Batch: 148, Loss: 1.351876974105835, Accuracy: 0.5576171875\n",
      "Batch: 149, Loss: 1.2222435474395752, Accuracy: 0.59375\n",
      "Batch: 150, Loss: 1.1906838417053223, Accuracy: 0.6103515625\n",
      "Batch: 151, Loss: 1.1266639232635498, Accuracy: 0.646484375\n",
      "Epoch 14/80\n",
      "Batch: 1, Loss: 1.3766226768493652, Accuracy: 0.5478515625\n",
      "Batch: 2, Loss: 1.2048065662384033, Accuracy: 0.5986328125\n",
      "Batch: 3, Loss: 1.1419497728347778, Accuracy: 0.62890625\n",
      "Batch: 4, Loss: 1.1078191995620728, Accuracy: 0.662109375\n",
      "Batch: 5, Loss: 1.132960319519043, Accuracy: 0.650390625\n",
      "Batch: 6, Loss: 1.2132929563522339, Accuracy: 0.5986328125\n",
      "Batch: 7, Loss: 1.1671123504638672, Accuracy: 0.6123046875\n",
      "Batch: 8, Loss: 1.1406564712524414, Accuracy: 0.6318359375\n",
      "Batch: 9, Loss: 1.082834005355835, Accuracy: 0.654296875\n",
      "Batch: 10, Loss: 1.1114720106124878, Accuracy: 0.6318359375\n",
      "Batch: 11, Loss: 1.2934603691101074, Accuracy: 0.5810546875\n",
      "Batch: 12, Loss: 1.301669955253601, Accuracy: 0.5888671875\n",
      "Batch: 13, Loss: 1.0570194721221924, Accuracy: 0.6669921875\n",
      "Batch: 14, Loss: 1.2889561653137207, Accuracy: 0.5732421875\n",
      "Batch: 15, Loss: 1.1664116382598877, Accuracy: 0.646484375\n",
      "Batch: 16, Loss: 1.1366469860076904, Accuracy: 0.650390625\n",
      "Batch: 17, Loss: 1.2141764163970947, Accuracy: 0.6181640625\n",
      "Batch: 18, Loss: 1.2562822103500366, Accuracy: 0.6044921875\n",
      "Batch: 19, Loss: 1.258289098739624, Accuracy: 0.6240234375\n",
      "Batch: 20, Loss: 1.193152666091919, Accuracy: 0.6240234375\n",
      "Batch: 21, Loss: 1.129085898399353, Accuracy: 0.6455078125\n",
      "Batch: 22, Loss: 1.2573399543762207, Accuracy: 0.6025390625\n",
      "Batch: 23, Loss: 1.1774643659591675, Accuracy: 0.61328125\n",
      "Batch: 24, Loss: 1.2112188339233398, Accuracy: 0.625\n",
      "Batch: 25, Loss: 1.162917137145996, Accuracy: 0.626953125\n",
      "Batch: 26, Loss: 1.0814332962036133, Accuracy: 0.6572265625\n",
      "Batch: 27, Loss: 1.1113157272338867, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.2014565467834473, Accuracy: 0.6005859375\n",
      "Batch: 29, Loss: 1.2207123041152954, Accuracy: 0.6171875\n",
      "Batch: 30, Loss: 1.1675057411193848, Accuracy: 0.64453125\n",
      "Batch: 31, Loss: 1.1445001363754272, Accuracy: 0.6552734375\n",
      "Batch: 32, Loss: 1.1100225448608398, Accuracy: 0.6416015625\n",
      "Batch: 33, Loss: 1.3196665048599243, Accuracy: 0.591796875\n",
      "Batch: 34, Loss: 1.3613183498382568, Accuracy: 0.5751953125\n",
      "Batch: 35, Loss: 1.1943782567977905, Accuracy: 0.6103515625\n",
      "Batch: 36, Loss: 1.2203335762023926, Accuracy: 0.6220703125\n",
      "Batch: 37, Loss: 1.1993370056152344, Accuracy: 0.60546875\n",
      "Batch: 38, Loss: 1.2131797075271606, Accuracy: 0.587890625\n",
      "Batch: 39, Loss: 1.2333604097366333, Accuracy: 0.603515625\n",
      "Batch: 40, Loss: 1.2367116212844849, Accuracy: 0.623046875\n",
      "Batch: 41, Loss: 1.2482985258102417, Accuracy: 0.6044921875\n",
      "Batch: 42, Loss: 0.9896127581596375, Accuracy: 0.6884765625\n",
      "Batch: 43, Loss: 1.1893044710159302, Accuracy: 0.6064453125\n",
      "Batch: 44, Loss: 1.1821813583374023, Accuracy: 0.599609375\n",
      "Batch: 45, Loss: 1.0424044132232666, Accuracy: 0.654296875\n",
      "Batch: 46, Loss: 1.16935396194458, Accuracy: 0.642578125\n",
      "Batch: 47, Loss: 1.1737067699432373, Accuracy: 0.6484375\n",
      "Batch: 48, Loss: 1.149440050125122, Accuracy: 0.640625\n",
      "Batch: 49, Loss: 1.293408751487732, Accuracy: 0.5966796875\n",
      "Batch: 50, Loss: 1.2809265851974487, Accuracy: 0.5888671875\n",
      "Batch: 51, Loss: 1.363851547241211, Accuracy: 0.572265625\n",
      "Batch: 52, Loss: 1.326500415802002, Accuracy: 0.599609375\n",
      "Batch: 53, Loss: 1.1066226959228516, Accuracy: 0.6328125\n",
      "Batch: 54, Loss: 1.1736159324645996, Accuracy: 0.6416015625\n",
      "Batch: 55, Loss: 1.2186901569366455, Accuracy: 0.6015625\n",
      "Batch: 56, Loss: 1.2512750625610352, Accuracy: 0.6201171875\n",
      "Batch: 57, Loss: 1.191969394683838, Accuracy: 0.63671875\n",
      "Batch: 58, Loss: 1.3206560611724854, Accuracy: 0.59765625\n",
      "Batch: 59, Loss: 1.0771878957748413, Accuracy: 0.67578125\n",
      "Batch: 60, Loss: 1.082207441329956, Accuracy: 0.6611328125\n",
      "Batch: 61, Loss: 1.1834301948547363, Accuracy: 0.625\n",
      "Batch: 62, Loss: 1.2078601121902466, Accuracy: 0.626953125\n",
      "Batch: 63, Loss: 1.219639778137207, Accuracy: 0.609375\n",
      "Batch: 64, Loss: 1.178943157196045, Accuracy: 0.626953125\n",
      "Batch: 65, Loss: 1.2255254983901978, Accuracy: 0.6162109375\n",
      "Batch: 66, Loss: 1.1264369487762451, Accuracy: 0.6552734375\n",
      "Batch: 67, Loss: 1.2965773344039917, Accuracy: 0.6064453125\n",
      "Batch: 68, Loss: 1.2845429182052612, Accuracy: 0.615234375\n",
      "Batch: 69, Loss: 1.2416186332702637, Accuracy: 0.6259765625\n",
      "Batch: 70, Loss: 1.1935402154922485, Accuracy: 0.6337890625\n",
      "Batch: 71, Loss: 1.2482062578201294, Accuracy: 0.6220703125\n",
      "Batch: 72, Loss: 1.1108077764511108, Accuracy: 0.642578125\n",
      "Batch: 73, Loss: 1.1763441562652588, Accuracy: 0.623046875\n",
      "Batch: 74, Loss: 1.1465568542480469, Accuracy: 0.64453125\n",
      "Batch: 75, Loss: 1.0656554698944092, Accuracy: 0.6396484375\n",
      "Batch: 76, Loss: 1.1942005157470703, Accuracy: 0.609375\n",
      "Batch: 77, Loss: 1.1729168891906738, Accuracy: 0.6142578125\n",
      "Batch: 78, Loss: 1.1631330251693726, Accuracy: 0.654296875\n",
      "Batch: 79, Loss: 1.0781410932540894, Accuracy: 0.6611328125\n",
      "Batch: 80, Loss: 1.1136882305145264, Accuracy: 0.6328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 81, Loss: 1.2427160739898682, Accuracy: 0.587890625\n",
      "Batch: 82, Loss: 1.2018706798553467, Accuracy: 0.615234375\n",
      "Batch: 83, Loss: 1.0528295040130615, Accuracy: 0.689453125\n",
      "Batch: 84, Loss: 1.1233962774276733, Accuracy: 0.669921875\n",
      "Batch: 85, Loss: 1.1032928228378296, Accuracy: 0.6630859375\n",
      "Batch: 86, Loss: 1.3364760875701904, Accuracy: 0.5810546875\n",
      "Batch: 87, Loss: 1.1461901664733887, Accuracy: 0.6591796875\n",
      "Batch: 88, Loss: 1.239635705947876, Accuracy: 0.630859375\n",
      "Batch: 89, Loss: 1.2453079223632812, Accuracy: 0.623046875\n",
      "Batch: 90, Loss: 1.1404857635498047, Accuracy: 0.62890625\n",
      "Batch: 91, Loss: 1.166848063468933, Accuracy: 0.6279296875\n",
      "Batch: 92, Loss: 1.218740701675415, Accuracy: 0.609375\n",
      "Batch: 93, Loss: 1.128857135772705, Accuracy: 0.6396484375\n",
      "Batch: 94, Loss: 1.1845545768737793, Accuracy: 0.6123046875\n",
      "Batch: 95, Loss: 1.1901724338531494, Accuracy: 0.6044921875\n",
      "Batch: 96, Loss: 1.1453423500061035, Accuracy: 0.640625\n",
      "Batch: 97, Loss: 1.056579828262329, Accuracy: 0.6689453125\n",
      "Batch: 98, Loss: 1.1049301624298096, Accuracy: 0.662109375\n",
      "Batch: 99, Loss: 1.0764083862304688, Accuracy: 0.66015625\n",
      "Batch: 100, Loss: 1.1576348543167114, Accuracy: 0.6435546875\n",
      "Batch: 101, Loss: 1.2152177095413208, Accuracy: 0.6064453125\n",
      "Batch: 102, Loss: 1.1409838199615479, Accuracy: 0.6337890625\n",
      "Batch: 103, Loss: 1.2462035417556763, Accuracy: 0.6201171875\n",
      "Batch: 104, Loss: 1.1097681522369385, Accuracy: 0.64453125\n",
      "Batch: 105, Loss: 1.236402988433838, Accuracy: 0.60546875\n",
      "Batch: 106, Loss: 1.1833757162094116, Accuracy: 0.634765625\n",
      "Batch: 107, Loss: 1.2618675231933594, Accuracy: 0.6201171875\n",
      "Batch: 108, Loss: 1.2430753707885742, Accuracy: 0.6083984375\n",
      "Batch: 109, Loss: 1.296022891998291, Accuracy: 0.5751953125\n",
      "Batch: 110, Loss: 1.042330265045166, Accuracy: 0.662109375\n",
      "Batch: 111, Loss: 1.2371292114257812, Accuracy: 0.5859375\n",
      "Batch: 112, Loss: 1.2094064950942993, Accuracy: 0.6181640625\n",
      "Batch: 113, Loss: 1.210565447807312, Accuracy: 0.630859375\n",
      "Batch: 114, Loss: 1.2833125591278076, Accuracy: 0.5869140625\n",
      "Batch: 115, Loss: 1.3383312225341797, Accuracy: 0.603515625\n",
      "Batch: 116, Loss: 1.262390375137329, Accuracy: 0.5966796875\n",
      "Batch: 117, Loss: 1.2747665643692017, Accuracy: 0.6142578125\n",
      "Batch: 118, Loss: 1.063432216644287, Accuracy: 0.65234375\n",
      "Batch: 119, Loss: 1.0979797840118408, Accuracy: 0.6630859375\n",
      "Batch: 120, Loss: 1.2628850936889648, Accuracy: 0.5927734375\n",
      "Batch: 121, Loss: 1.2627674341201782, Accuracy: 0.5966796875\n",
      "Batch: 122, Loss: 1.155873417854309, Accuracy: 0.6376953125\n",
      "Batch: 123, Loss: 1.1825966835021973, Accuracy: 0.634765625\n",
      "Batch: 124, Loss: 1.2152754068374634, Accuracy: 0.6201171875\n",
      "Batch: 125, Loss: 1.2463493347167969, Accuracy: 0.609375\n",
      "Batch: 126, Loss: 1.2130793333053589, Accuracy: 0.6064453125\n",
      "Batch: 127, Loss: 1.0912140607833862, Accuracy: 0.671875\n",
      "Batch: 128, Loss: 1.340296983718872, Accuracy: 0.6005859375\n",
      "Batch: 129, Loss: 1.1653919219970703, Accuracy: 0.640625\n",
      "Batch: 130, Loss: 1.3879450559616089, Accuracy: 0.5888671875\n",
      "Batch: 131, Loss: 1.2750664949417114, Accuracy: 0.60546875\n",
      "Batch: 132, Loss: 1.2998356819152832, Accuracy: 0.59375\n",
      "Batch: 133, Loss: 1.1396920680999756, Accuracy: 0.6171875\n",
      "Batch: 134, Loss: 1.2307181358337402, Accuracy: 0.58984375\n",
      "Batch: 135, Loss: 1.1686592102050781, Accuracy: 0.6435546875\n",
      "Batch: 136, Loss: 1.2075327634811401, Accuracy: 0.6162109375\n",
      "Batch: 137, Loss: 1.1057270765304565, Accuracy: 0.6201171875\n",
      "Batch: 138, Loss: 1.0288925170898438, Accuracy: 0.6513671875\n",
      "Batch: 139, Loss: 1.0768451690673828, Accuracy: 0.634765625\n",
      "Batch: 140, Loss: 1.1888686418533325, Accuracy: 0.6142578125\n",
      "Batch: 141, Loss: 1.2033867835998535, Accuracy: 0.615234375\n",
      "Batch: 142, Loss: 1.2418081760406494, Accuracy: 0.607421875\n",
      "Batch: 143, Loss: 1.2123692035675049, Accuracy: 0.626953125\n",
      "Batch: 144, Loss: 1.2047429084777832, Accuracy: 0.626953125\n",
      "Batch: 145, Loss: 1.129006028175354, Accuracy: 0.609375\n",
      "Batch: 146, Loss: 1.2593930959701538, Accuracy: 0.591796875\n",
      "Batch: 147, Loss: 1.1888327598571777, Accuracy: 0.6181640625\n",
      "Batch: 148, Loss: 1.3290225267410278, Accuracy: 0.560546875\n",
      "Batch: 149, Loss: 1.1911317110061646, Accuracy: 0.60546875\n",
      "Batch: 150, Loss: 1.1479212045669556, Accuracy: 0.63671875\n",
      "Batch: 151, Loss: 1.1072883605957031, Accuracy: 0.6591796875\n",
      "Epoch 15/80\n",
      "Batch: 1, Loss: 1.3559291362762451, Accuracy: 0.5537109375\n",
      "Batch: 2, Loss: 1.2185468673706055, Accuracy: 0.5859375\n",
      "Batch: 3, Loss: 1.1300022602081299, Accuracy: 0.6337890625\n",
      "Batch: 4, Loss: 1.0743827819824219, Accuracy: 0.6748046875\n",
      "Batch: 5, Loss: 1.1153903007507324, Accuracy: 0.658203125\n",
      "Batch: 6, Loss: 1.1963611841201782, Accuracy: 0.5966796875\n",
      "Batch: 7, Loss: 1.1270579099655151, Accuracy: 0.6328125\n",
      "Batch: 8, Loss: 1.109714150428772, Accuracy: 0.62890625\n",
      "Batch: 9, Loss: 1.0888251066207886, Accuracy: 0.650390625\n",
      "Batch: 10, Loss: 1.0913771390914917, Accuracy: 0.64453125\n",
      "Batch: 11, Loss: 1.2613736391067505, Accuracy: 0.5791015625\n",
      "Batch: 12, Loss: 1.272690773010254, Accuracy: 0.587890625\n",
      "Batch: 13, Loss: 1.0358166694641113, Accuracy: 0.6689453125\n",
      "Batch: 14, Loss: 1.2647783756256104, Accuracy: 0.5751953125\n",
      "Batch: 15, Loss: 1.1277313232421875, Accuracy: 0.65625\n",
      "Batch: 16, Loss: 1.1140105724334717, Accuracy: 0.65234375\n",
      "Batch: 17, Loss: 1.223950743675232, Accuracy: 0.6044921875\n",
      "Batch: 18, Loss: 1.2096340656280518, Accuracy: 0.611328125\n",
      "Batch: 19, Loss: 1.2613072395324707, Accuracy: 0.6171875\n",
      "Batch: 20, Loss: 1.1445353031158447, Accuracy: 0.6474609375\n",
      "Batch: 21, Loss: 1.1009572744369507, Accuracy: 0.63671875\n",
      "Batch: 22, Loss: 1.2457993030548096, Accuracy: 0.623046875\n",
      "Batch: 23, Loss: 1.1321039199829102, Accuracy: 0.638671875\n",
      "Batch: 24, Loss: 1.1943004131317139, Accuracy: 0.609375\n",
      "Batch: 25, Loss: 1.1502952575683594, Accuracy: 0.626953125\n",
      "Batch: 26, Loss: 1.0522210597991943, Accuracy: 0.6591796875\n",
      "Batch: 27, Loss: 1.0950324535369873, Accuracy: 0.625\n",
      "Batch: 28, Loss: 1.1925218105316162, Accuracy: 0.599609375\n",
      "Batch: 29, Loss: 1.170069694519043, Accuracy: 0.634765625\n",
      "Batch: 30, Loss: 1.1310094594955444, Accuracy: 0.666015625\n",
      "Batch: 31, Loss: 1.0939910411834717, Accuracy: 0.666015625\n",
      "Batch: 32, Loss: 1.0946712493896484, Accuracy: 0.63671875\n",
      "Batch: 33, Loss: 1.2776648998260498, Accuracy: 0.6005859375\n",
      "Batch: 34, Loss: 1.3291692733764648, Accuracy: 0.5849609375\n",
      "Batch: 35, Loss: 1.183147668838501, Accuracy: 0.61328125\n",
      "Batch: 36, Loss: 1.219160795211792, Accuracy: 0.6181640625\n",
      "Batch: 37, Loss: 1.1736195087432861, Accuracy: 0.63671875\n",
      "Batch: 38, Loss: 1.1901335716247559, Accuracy: 0.6083984375\n",
      "Batch: 39, Loss: 1.204399824142456, Accuracy: 0.6259765625\n",
      "Batch: 40, Loss: 1.2386479377746582, Accuracy: 0.6259765625\n",
      "Batch: 41, Loss: 1.1911596059799194, Accuracy: 0.6318359375\n",
      "Batch: 42, Loss: 0.9395617246627808, Accuracy: 0.6875\n",
      "Batch: 43, Loss: 1.1573059558868408, Accuracy: 0.6064453125\n",
      "Batch: 44, Loss: 1.1611833572387695, Accuracy: 0.6162109375\n",
      "Batch: 45, Loss: 1.0221517086029053, Accuracy: 0.6591796875\n",
      "Batch: 46, Loss: 1.1474381685256958, Accuracy: 0.6494140625\n",
      "Batch: 47, Loss: 1.1600052118301392, Accuracy: 0.6416015625\n",
      "Batch: 48, Loss: 1.0841513872146606, Accuracy: 0.640625\n",
      "Batch: 49, Loss: 1.2864453792572021, Accuracy: 0.5947265625\n",
      "Batch: 50, Loss: 1.2480556964874268, Accuracy: 0.5966796875\n",
      "Batch: 51, Loss: 1.3489582538604736, Accuracy: 0.5908203125\n",
      "Batch: 52, Loss: 1.298600196838379, Accuracy: 0.6083984375\n",
      "Batch: 53, Loss: 1.0569764375686646, Accuracy: 0.66796875\n",
      "Batch: 54, Loss: 1.143701195716858, Accuracy: 0.650390625\n",
      "Batch: 55, Loss: 1.22181236743927, Accuracy: 0.5947265625\n",
      "Batch: 56, Loss: 1.2437279224395752, Accuracy: 0.6171875\n",
      "Batch: 57, Loss: 1.161397933959961, Accuracy: 0.638671875\n",
      "Batch: 58, Loss: 1.2738747596740723, Accuracy: 0.6171875\n",
      "Batch: 59, Loss: 1.0684571266174316, Accuracy: 0.67578125\n",
      "Batch: 60, Loss: 1.0641870498657227, Accuracy: 0.6591796875\n",
      "Batch: 61, Loss: 1.206385612487793, Accuracy: 0.609375\n",
      "Batch: 62, Loss: 1.184999704360962, Accuracy: 0.6298828125\n",
      "Batch: 63, Loss: 1.2269911766052246, Accuracy: 0.6142578125\n",
      "Batch: 64, Loss: 1.149680495262146, Accuracy: 0.62109375\n",
      "Batch: 65, Loss: 1.1853302717208862, Accuracy: 0.626953125\n",
      "Batch: 66, Loss: 1.117195963859558, Accuracy: 0.6572265625\n",
      "Batch: 67, Loss: 1.2909127473831177, Accuracy: 0.6015625\n",
      "Batch: 68, Loss: 1.266096591949463, Accuracy: 0.6142578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 69, Loss: 1.2111005783081055, Accuracy: 0.6240234375\n",
      "Batch: 70, Loss: 1.1693544387817383, Accuracy: 0.646484375\n",
      "Batch: 71, Loss: 1.1883186101913452, Accuracy: 0.638671875\n",
      "Batch: 72, Loss: 1.0679491758346558, Accuracy: 0.6650390625\n",
      "Batch: 73, Loss: 1.1616253852844238, Accuracy: 0.650390625\n",
      "Batch: 74, Loss: 1.1125829219818115, Accuracy: 0.6484375\n",
      "Batch: 75, Loss: 1.0533902645111084, Accuracy: 0.66015625\n",
      "Batch: 76, Loss: 1.1544100046157837, Accuracy: 0.6201171875\n",
      "Batch: 77, Loss: 1.142334222793579, Accuracy: 0.638671875\n",
      "Batch: 78, Loss: 1.1405787467956543, Accuracy: 0.66796875\n",
      "Batch: 79, Loss: 1.0541504621505737, Accuracy: 0.6767578125\n",
      "Batch: 80, Loss: 1.0995817184448242, Accuracy: 0.646484375\n",
      "Batch: 81, Loss: 1.2279534339904785, Accuracy: 0.583984375\n",
      "Batch: 82, Loss: 1.1812077760696411, Accuracy: 0.6123046875\n",
      "Batch: 83, Loss: 1.0162956714630127, Accuracy: 0.685546875\n",
      "Batch: 84, Loss: 1.1184719800949097, Accuracy: 0.673828125\n",
      "Batch: 85, Loss: 1.088517427444458, Accuracy: 0.6513671875\n",
      "Batch: 86, Loss: 1.3306329250335693, Accuracy: 0.5771484375\n",
      "Batch: 87, Loss: 1.111847996711731, Accuracy: 0.642578125\n",
      "Batch: 88, Loss: 1.2131088972091675, Accuracy: 0.6337890625\n",
      "Batch: 89, Loss: 1.210942268371582, Accuracy: 0.6259765625\n",
      "Batch: 90, Loss: 1.1168309450149536, Accuracy: 0.6328125\n",
      "Batch: 91, Loss: 1.1469459533691406, Accuracy: 0.63671875\n",
      "Batch: 92, Loss: 1.1791715621948242, Accuracy: 0.62890625\n",
      "Batch: 93, Loss: 1.1237224340438843, Accuracy: 0.6513671875\n",
      "Batch: 94, Loss: 1.1567736864089966, Accuracy: 0.634765625\n",
      "Batch: 95, Loss: 1.1422512531280518, Accuracy: 0.6328125\n",
      "Batch: 96, Loss: 1.1405236721038818, Accuracy: 0.638671875\n",
      "Batch: 97, Loss: 1.0435857772827148, Accuracy: 0.6689453125\n",
      "Batch: 98, Loss: 1.0817759037017822, Accuracy: 0.6640625\n",
      "Batch: 99, Loss: 1.0762770175933838, Accuracy: 0.6611328125\n",
      "Batch: 100, Loss: 1.1426159143447876, Accuracy: 0.62109375\n",
      "Batch: 101, Loss: 1.2195101976394653, Accuracy: 0.6142578125\n",
      "Batch: 102, Loss: 1.1210410594940186, Accuracy: 0.6318359375\n",
      "Batch: 103, Loss: 1.2056293487548828, Accuracy: 0.6328125\n",
      "Batch: 104, Loss: 1.079186201095581, Accuracy: 0.64453125\n",
      "Batch: 105, Loss: 1.2113065719604492, Accuracy: 0.6005859375\n",
      "Batch: 106, Loss: 1.138148307800293, Accuracy: 0.634765625\n",
      "Batch: 107, Loss: 1.2264071702957153, Accuracy: 0.6005859375\n",
      "Batch: 108, Loss: 1.1872155666351318, Accuracy: 0.61328125\n",
      "Batch: 109, Loss: 1.2930166721343994, Accuracy: 0.5673828125\n",
      "Batch: 110, Loss: 1.0291740894317627, Accuracy: 0.6767578125\n",
      "Batch: 111, Loss: 1.211513876914978, Accuracy: 0.5908203125\n",
      "Batch: 112, Loss: 1.1685748100280762, Accuracy: 0.6220703125\n",
      "Batch: 113, Loss: 1.1778368949890137, Accuracy: 0.6259765625\n",
      "Batch: 114, Loss: 1.264562726020813, Accuracy: 0.5849609375\n",
      "Batch: 115, Loss: 1.2993743419647217, Accuracy: 0.619140625\n",
      "Batch: 116, Loss: 1.2293493747711182, Accuracy: 0.6123046875\n",
      "Batch: 117, Loss: 1.2562713623046875, Accuracy: 0.630859375\n",
      "Batch: 118, Loss: 1.0522223711013794, Accuracy: 0.669921875\n",
      "Batch: 119, Loss: 1.1065689325332642, Accuracy: 0.6650390625\n",
      "Batch: 120, Loss: 1.2251834869384766, Accuracy: 0.603515625\n",
      "Batch: 121, Loss: 1.2498080730438232, Accuracy: 0.6083984375\n",
      "Batch: 122, Loss: 1.123199224472046, Accuracy: 0.6484375\n",
      "Batch: 123, Loss: 1.1526849269866943, Accuracy: 0.6455078125\n",
      "Batch: 124, Loss: 1.189083218574524, Accuracy: 0.6279296875\n",
      "Batch: 125, Loss: 1.2090363502502441, Accuracy: 0.6181640625\n",
      "Batch: 126, Loss: 1.1938239336013794, Accuracy: 0.611328125\n",
      "Batch: 127, Loss: 1.0643144845962524, Accuracy: 0.6904296875\n",
      "Batch: 128, Loss: 1.2930504083633423, Accuracy: 0.6103515625\n",
      "Batch: 129, Loss: 1.1190247535705566, Accuracy: 0.6484375\n",
      "Batch: 130, Loss: 1.3550214767456055, Accuracy: 0.572265625\n",
      "Batch: 131, Loss: 1.2447805404663086, Accuracy: 0.6123046875\n",
      "Batch: 132, Loss: 1.2680673599243164, Accuracy: 0.6220703125\n",
      "Batch: 133, Loss: 1.111301302909851, Accuracy: 0.6376953125\n",
      "Batch: 134, Loss: 1.2003920078277588, Accuracy: 0.6064453125\n",
      "Batch: 135, Loss: 1.1451224088668823, Accuracy: 0.6513671875\n",
      "Batch: 136, Loss: 1.1669070720672607, Accuracy: 0.63671875\n",
      "Batch: 137, Loss: 1.0888614654541016, Accuracy: 0.6279296875\n",
      "Batch: 138, Loss: 0.9828042387962341, Accuracy: 0.6748046875\n",
      "Batch: 139, Loss: 1.078680157661438, Accuracy: 0.6533203125\n",
      "Batch: 140, Loss: 1.1831843852996826, Accuracy: 0.619140625\n",
      "Batch: 141, Loss: 1.1415718793869019, Accuracy: 0.642578125\n",
      "Batch: 142, Loss: 1.2378172874450684, Accuracy: 0.6171875\n",
      "Batch: 143, Loss: 1.194687008857727, Accuracy: 0.62890625\n",
      "Batch: 144, Loss: 1.17061185836792, Accuracy: 0.6337890625\n",
      "Batch: 145, Loss: 1.116549015045166, Accuracy: 0.62109375\n",
      "Batch: 146, Loss: 1.2380281686782837, Accuracy: 0.6044921875\n",
      "Batch: 147, Loss: 1.1696182489395142, Accuracy: 0.619140625\n",
      "Batch: 148, Loss: 1.3062758445739746, Accuracy: 0.5693359375\n",
      "Batch: 149, Loss: 1.147807240486145, Accuracy: 0.6201171875\n",
      "Batch: 150, Loss: 1.1351338624954224, Accuracy: 0.642578125\n",
      "Batch: 151, Loss: 1.078864336013794, Accuracy: 0.6533203125\n",
      "Epoch 16/80\n",
      "Batch: 1, Loss: 1.3549541234970093, Accuracy: 0.5615234375\n",
      "Batch: 2, Loss: 1.1622719764709473, Accuracy: 0.6044921875\n",
      "Batch: 3, Loss: 1.1049227714538574, Accuracy: 0.6328125\n",
      "Batch: 4, Loss: 1.039064884185791, Accuracy: 0.67578125\n",
      "Batch: 5, Loss: 1.0780103206634521, Accuracy: 0.669921875\n",
      "Batch: 6, Loss: 1.1743810176849365, Accuracy: 0.6083984375\n",
      "Batch: 7, Loss: 1.116943597793579, Accuracy: 0.634765625\n",
      "Batch: 8, Loss: 1.0964891910552979, Accuracy: 0.6396484375\n",
      "Batch: 9, Loss: 1.0507899522781372, Accuracy: 0.6787109375\n",
      "Batch: 10, Loss: 1.0658010244369507, Accuracy: 0.65625\n",
      "Batch: 11, Loss: 1.2345112562179565, Accuracy: 0.5869140625\n",
      "Batch: 12, Loss: 1.2215086221694946, Accuracy: 0.6005859375\n",
      "Batch: 13, Loss: 1.019632339477539, Accuracy: 0.6689453125\n",
      "Batch: 14, Loss: 1.2277206182479858, Accuracy: 0.6025390625\n",
      "Batch: 15, Loss: 1.0974968671798706, Accuracy: 0.654296875\n",
      "Batch: 16, Loss: 1.091454029083252, Accuracy: 0.65234375\n",
      "Batch: 17, Loss: 1.179814338684082, Accuracy: 0.6181640625\n",
      "Batch: 18, Loss: 1.1854952573776245, Accuracy: 0.609375\n",
      "Batch: 19, Loss: 1.2071177959442139, Accuracy: 0.626953125\n",
      "Batch: 20, Loss: 1.1218667030334473, Accuracy: 0.65234375\n",
      "Batch: 21, Loss: 1.111145257949829, Accuracy: 0.6396484375\n",
      "Batch: 22, Loss: 1.226043462753296, Accuracy: 0.609375\n",
      "Batch: 23, Loss: 1.1105597019195557, Accuracy: 0.6435546875\n",
      "Batch: 24, Loss: 1.156631350517273, Accuracy: 0.6171875\n",
      "Batch: 25, Loss: 1.0996853113174438, Accuracy: 0.6484375\n",
      "Batch: 26, Loss: 1.024874210357666, Accuracy: 0.6796875\n",
      "Batch: 27, Loss: 1.0736844539642334, Accuracy: 0.6435546875\n",
      "Batch: 28, Loss: 1.1561580896377563, Accuracy: 0.626953125\n",
      "Batch: 29, Loss: 1.1605963706970215, Accuracy: 0.634765625\n",
      "Batch: 30, Loss: 1.1120657920837402, Accuracy: 0.669921875\n",
      "Batch: 31, Loss: 1.0942285060882568, Accuracy: 0.6669921875\n",
      "Batch: 32, Loss: 1.0506577491760254, Accuracy: 0.654296875\n",
      "Batch: 33, Loss: 1.2437543869018555, Accuracy: 0.6064453125\n",
      "Batch: 34, Loss: 1.3158502578735352, Accuracy: 0.5908203125\n",
      "Batch: 35, Loss: 1.1658079624176025, Accuracy: 0.6220703125\n",
      "Batch: 36, Loss: 1.1680155992507935, Accuracy: 0.6318359375\n",
      "Batch: 37, Loss: 1.1578681468963623, Accuracy: 0.6328125\n",
      "Batch: 38, Loss: 1.1552841663360596, Accuracy: 0.62890625\n",
      "Batch: 39, Loss: 1.1715906858444214, Accuracy: 0.6416015625\n",
      "Batch: 40, Loss: 1.1950920820236206, Accuracy: 0.630859375\n",
      "Batch: 41, Loss: 1.151625156402588, Accuracy: 0.642578125\n",
      "Batch: 42, Loss: 0.9304507374763489, Accuracy: 0.69140625\n",
      "Batch: 43, Loss: 1.1217625141143799, Accuracy: 0.625\n",
      "Batch: 44, Loss: 1.1585713624954224, Accuracy: 0.6181640625\n",
      "Batch: 45, Loss: 1.0129369497299194, Accuracy: 0.6552734375\n",
      "Batch: 46, Loss: 1.111816644668579, Accuracy: 0.6591796875\n",
      "Batch: 47, Loss: 1.1358869075775146, Accuracy: 0.6435546875\n",
      "Batch: 48, Loss: 1.0979268550872803, Accuracy: 0.65625\n",
      "Batch: 49, Loss: 1.2774021625518799, Accuracy: 0.5869140625\n",
      "Batch: 50, Loss: 1.2258130311965942, Accuracy: 0.60546875\n",
      "Batch: 51, Loss: 1.3034694194793701, Accuracy: 0.5947265625\n",
      "Batch: 52, Loss: 1.2676912546157837, Accuracy: 0.6103515625\n",
      "Batch: 53, Loss: 1.0360150337219238, Accuracy: 0.66015625\n",
      "Batch: 54, Loss: 1.1050268411636353, Accuracy: 0.65625\n",
      "Batch: 55, Loss: 1.1891039609909058, Accuracy: 0.6044921875\n",
      "Batch: 56, Loss: 1.180109977722168, Accuracy: 0.630859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 57, Loss: 1.1327385902404785, Accuracy: 0.662109375\n",
      "Batch: 58, Loss: 1.246959924697876, Accuracy: 0.6181640625\n",
      "Batch: 59, Loss: 1.07243812084198, Accuracy: 0.6650390625\n",
      "Batch: 60, Loss: 1.0132238864898682, Accuracy: 0.67578125\n",
      "Batch: 61, Loss: 1.1512234210968018, Accuracy: 0.623046875\n",
      "Batch: 62, Loss: 1.1215293407440186, Accuracy: 0.6396484375\n",
      "Batch: 63, Loss: 1.200217366218567, Accuracy: 0.6240234375\n",
      "Batch: 64, Loss: 1.1316471099853516, Accuracy: 0.6474609375\n",
      "Batch: 65, Loss: 1.1808834075927734, Accuracy: 0.61328125\n",
      "Batch: 66, Loss: 1.097995638847351, Accuracy: 0.66015625\n",
      "Batch: 67, Loss: 1.2774044275283813, Accuracy: 0.6103515625\n",
      "Batch: 68, Loss: 1.2380847930908203, Accuracy: 0.6171875\n",
      "Batch: 69, Loss: 1.1860227584838867, Accuracy: 0.638671875\n",
      "Batch: 70, Loss: 1.1712881326675415, Accuracy: 0.642578125\n",
      "Batch: 71, Loss: 1.1709340810775757, Accuracy: 0.63671875\n",
      "Batch: 72, Loss: 1.0521844625473022, Accuracy: 0.6572265625\n",
      "Batch: 73, Loss: 1.1390609741210938, Accuracy: 0.642578125\n",
      "Batch: 74, Loss: 1.0791833400726318, Accuracy: 0.658203125\n",
      "Batch: 75, Loss: 1.020218849182129, Accuracy: 0.68359375\n",
      "Batch: 76, Loss: 1.1583099365234375, Accuracy: 0.61328125\n",
      "Batch: 77, Loss: 1.129689335823059, Accuracy: 0.6328125\n",
      "Batch: 78, Loss: 1.1070621013641357, Accuracy: 0.6708984375\n",
      "Batch: 79, Loss: 1.054572582244873, Accuracy: 0.6904296875\n",
      "Batch: 80, Loss: 1.080925464630127, Accuracy: 0.6396484375\n",
      "Batch: 81, Loss: 1.2107309103012085, Accuracy: 0.595703125\n",
      "Batch: 82, Loss: 1.144737958908081, Accuracy: 0.62890625\n",
      "Batch: 83, Loss: 1.002148151397705, Accuracy: 0.6923828125\n",
      "Batch: 84, Loss: 1.0987548828125, Accuracy: 0.6689453125\n",
      "Batch: 85, Loss: 1.0408861637115479, Accuracy: 0.6748046875\n",
      "Batch: 86, Loss: 1.2665129899978638, Accuracy: 0.59765625\n",
      "Batch: 87, Loss: 1.0807791948318481, Accuracy: 0.671875\n",
      "Batch: 88, Loss: 1.208909273147583, Accuracy: 0.640625\n",
      "Batch: 89, Loss: 1.1589950323104858, Accuracy: 0.6396484375\n",
      "Batch: 90, Loss: 1.0868992805480957, Accuracy: 0.6474609375\n",
      "Batch: 91, Loss: 1.132936716079712, Accuracy: 0.642578125\n",
      "Batch: 92, Loss: 1.161449670791626, Accuracy: 0.619140625\n",
      "Batch: 93, Loss: 1.1078916788101196, Accuracy: 0.6552734375\n",
      "Batch: 94, Loss: 1.1187353134155273, Accuracy: 0.6357421875\n",
      "Batch: 95, Loss: 1.1260955333709717, Accuracy: 0.6171875\n",
      "Batch: 96, Loss: 1.1073395013809204, Accuracy: 0.6396484375\n",
      "Batch: 97, Loss: 0.9916240572929382, Accuracy: 0.6748046875\n",
      "Batch: 98, Loss: 1.0629805326461792, Accuracy: 0.6669921875\n",
      "Batch: 99, Loss: 1.0521458387374878, Accuracy: 0.6689453125\n",
      "Batch: 100, Loss: 1.0954798460006714, Accuracy: 0.6484375\n",
      "Batch: 101, Loss: 1.191885232925415, Accuracy: 0.6142578125\n",
      "Batch: 102, Loss: 1.1101934909820557, Accuracy: 0.6416015625\n",
      "Batch: 103, Loss: 1.1936860084533691, Accuracy: 0.6455078125\n",
      "Batch: 104, Loss: 1.076080322265625, Accuracy: 0.654296875\n",
      "Batch: 105, Loss: 1.1892588138580322, Accuracy: 0.6142578125\n",
      "Batch: 106, Loss: 1.1244217157363892, Accuracy: 0.640625\n",
      "Batch: 107, Loss: 1.2126367092132568, Accuracy: 0.6240234375\n",
      "Batch: 108, Loss: 1.1594181060791016, Accuracy: 0.619140625\n",
      "Batch: 109, Loss: 1.256927251815796, Accuracy: 0.5888671875\n",
      "Batch: 110, Loss: 0.9800714254379272, Accuracy: 0.6865234375\n",
      "Batch: 111, Loss: 1.1646111011505127, Accuracy: 0.6123046875\n",
      "Batch: 112, Loss: 1.1322519779205322, Accuracy: 0.6357421875\n",
      "Batch: 113, Loss: 1.1744608879089355, Accuracy: 0.6376953125\n",
      "Batch: 114, Loss: 1.232813835144043, Accuracy: 0.5908203125\n",
      "Batch: 115, Loss: 1.2660813331604004, Accuracy: 0.611328125\n",
      "Batch: 116, Loss: 1.178281307220459, Accuracy: 0.615234375\n",
      "Batch: 117, Loss: 1.1803865432739258, Accuracy: 0.6376953125\n",
      "Batch: 118, Loss: 1.0229167938232422, Accuracy: 0.671875\n",
      "Batch: 119, Loss: 1.061881422996521, Accuracy: 0.673828125\n",
      "Batch: 120, Loss: 1.1900783777236938, Accuracy: 0.62109375\n",
      "Batch: 121, Loss: 1.186705231666565, Accuracy: 0.6123046875\n",
      "Batch: 122, Loss: 1.118584156036377, Accuracy: 0.654296875\n",
      "Batch: 123, Loss: 1.1141849756240845, Accuracy: 0.6484375\n",
      "Batch: 124, Loss: 1.171259880065918, Accuracy: 0.6376953125\n",
      "Batch: 125, Loss: 1.2029224634170532, Accuracy: 0.623046875\n",
      "Batch: 126, Loss: 1.162291169166565, Accuracy: 0.623046875\n",
      "Batch: 127, Loss: 1.0476949214935303, Accuracy: 0.6806640625\n",
      "Batch: 128, Loss: 1.2859807014465332, Accuracy: 0.6220703125\n",
      "Batch: 129, Loss: 1.0685648918151855, Accuracy: 0.671875\n",
      "Batch: 130, Loss: 1.339931845664978, Accuracy: 0.576171875\n",
      "Batch: 131, Loss: 1.2161191701889038, Accuracy: 0.6123046875\n",
      "Batch: 132, Loss: 1.2224488258361816, Accuracy: 0.62890625\n",
      "Batch: 133, Loss: 1.0564721822738647, Accuracy: 0.6484375\n",
      "Batch: 134, Loss: 1.1633963584899902, Accuracy: 0.626953125\n",
      "Batch: 135, Loss: 1.100689172744751, Accuracy: 0.677734375\n",
      "Batch: 136, Loss: 1.153509497642517, Accuracy: 0.63671875\n",
      "Batch: 137, Loss: 1.0517892837524414, Accuracy: 0.6416015625\n",
      "Batch: 138, Loss: 0.9911264181137085, Accuracy: 0.671875\n",
      "Batch: 139, Loss: 1.0405449867248535, Accuracy: 0.6572265625\n",
      "Batch: 140, Loss: 1.1507184505462646, Accuracy: 0.6044921875\n",
      "Batch: 141, Loss: 1.1461611986160278, Accuracy: 0.634765625\n",
      "Batch: 142, Loss: 1.215130090713501, Accuracy: 0.6162109375\n",
      "Batch: 143, Loss: 1.1827056407928467, Accuracy: 0.64453125\n",
      "Batch: 144, Loss: 1.1626513004302979, Accuracy: 0.6357421875\n",
      "Batch: 145, Loss: 1.0922372341156006, Accuracy: 0.6240234375\n",
      "Batch: 146, Loss: 1.2107032537460327, Accuracy: 0.615234375\n",
      "Batch: 147, Loss: 1.1494730710983276, Accuracy: 0.625\n",
      "Batch: 148, Loss: 1.244713544845581, Accuracy: 0.5859375\n",
      "Batch: 149, Loss: 1.1355715990066528, Accuracy: 0.630859375\n",
      "Batch: 150, Loss: 1.1266546249389648, Accuracy: 0.6279296875\n",
      "Batch: 151, Loss: 1.0354276895523071, Accuracy: 0.6630859375\n",
      "Epoch 17/80\n",
      "Batch: 1, Loss: 1.3048774003982544, Accuracy: 0.572265625\n",
      "Batch: 2, Loss: 1.1165704727172852, Accuracy: 0.623046875\n",
      "Batch: 3, Loss: 1.0651237964630127, Accuracy: 0.6328125\n",
      "Batch: 4, Loss: 1.0347487926483154, Accuracy: 0.6845703125\n",
      "Batch: 5, Loss: 1.062795877456665, Accuracy: 0.6728515625\n",
      "Batch: 6, Loss: 1.1337437629699707, Accuracy: 0.6337890625\n",
      "Batch: 7, Loss: 1.114230751991272, Accuracy: 0.6474609375\n",
      "Batch: 8, Loss: 1.0575391054153442, Accuracy: 0.638671875\n",
      "Batch: 9, Loss: 1.0513824224472046, Accuracy: 0.67578125\n",
      "Batch: 10, Loss: 1.056173324584961, Accuracy: 0.6552734375\n",
      "Batch: 11, Loss: 1.2011783123016357, Accuracy: 0.619140625\n",
      "Batch: 12, Loss: 1.2159639596939087, Accuracy: 0.6044921875\n",
      "Batch: 13, Loss: 0.9782853722572327, Accuracy: 0.697265625\n",
      "Batch: 14, Loss: 1.2270314693450928, Accuracy: 0.6123046875\n",
      "Batch: 15, Loss: 1.0504997968673706, Accuracy: 0.6796875\n",
      "Batch: 16, Loss: 1.0755155086517334, Accuracy: 0.6611328125\n",
      "Batch: 17, Loss: 1.1382129192352295, Accuracy: 0.6201171875\n",
      "Batch: 18, Loss: 1.158995270729065, Accuracy: 0.6162109375\n",
      "Batch: 19, Loss: 1.2020704746246338, Accuracy: 0.623046875\n",
      "Batch: 20, Loss: 1.0860261917114258, Accuracy: 0.6767578125\n",
      "Batch: 21, Loss: 1.0671720504760742, Accuracy: 0.6416015625\n",
      "Batch: 22, Loss: 1.1850535869598389, Accuracy: 0.6318359375\n",
      "Batch: 23, Loss: 1.1262893676757812, Accuracy: 0.638671875\n",
      "Batch: 24, Loss: 1.1532942056655884, Accuracy: 0.6240234375\n",
      "Batch: 25, Loss: 1.1188124418258667, Accuracy: 0.6376953125\n",
      "Batch: 26, Loss: 1.015023946762085, Accuracy: 0.6767578125\n",
      "Batch: 27, Loss: 1.0410908460617065, Accuracy: 0.6396484375\n",
      "Batch: 28, Loss: 1.166019320487976, Accuracy: 0.6181640625\n",
      "Batch: 29, Loss: 1.1223078966140747, Accuracy: 0.646484375\n",
      "Batch: 30, Loss: 1.1218795776367188, Accuracy: 0.662109375\n",
      "Batch: 31, Loss: 1.0975935459136963, Accuracy: 0.6611328125\n",
      "Batch: 32, Loss: 1.0404423475265503, Accuracy: 0.67578125\n",
      "Batch: 33, Loss: 1.2229958772659302, Accuracy: 0.6201171875\n",
      "Batch: 34, Loss: 1.2739529609680176, Accuracy: 0.58984375\n",
      "Batch: 35, Loss: 1.1577632427215576, Accuracy: 0.6103515625\n",
      "Batch: 36, Loss: 1.1590512990951538, Accuracy: 0.6279296875\n",
      "Batch: 37, Loss: 1.115504503250122, Accuracy: 0.6416015625\n",
      "Batch: 38, Loss: 1.1299809217453003, Accuracy: 0.6201171875\n",
      "Batch: 39, Loss: 1.1400775909423828, Accuracy: 0.64453125\n",
      "Batch: 40, Loss: 1.1535720825195312, Accuracy: 0.6435546875\n",
      "Batch: 41, Loss: 1.142081618309021, Accuracy: 0.6533203125\n",
      "Batch: 42, Loss: 0.9133163094520569, Accuracy: 0.7080078125\n",
      "Batch: 43, Loss: 1.0870771408081055, Accuracy: 0.6376953125\n",
      "Batch: 44, Loss: 1.137325644493103, Accuracy: 0.626953125\n",
      "Batch: 45, Loss: 0.995050847530365, Accuracy: 0.6748046875\n",
      "Batch: 46, Loss: 1.1092009544372559, Accuracy: 0.654296875\n",
      "Batch: 47, Loss: 1.1244800090789795, Accuracy: 0.64453125\n",
      "Batch: 48, Loss: 1.0755078792572021, Accuracy: 0.6494140625\n",
      "Batch: 49, Loss: 1.245969533920288, Accuracy: 0.6083984375\n",
      "Batch: 50, Loss: 1.2073098421096802, Accuracy: 0.62109375\n",
      "Batch: 51, Loss: 1.2745130062103271, Accuracy: 0.5830078125\n",
      "Batch: 52, Loss: 1.247814416885376, Accuracy: 0.6123046875\n",
      "Batch: 53, Loss: 1.0473023653030396, Accuracy: 0.6669921875\n",
      "Batch: 54, Loss: 1.091583013534546, Accuracy: 0.6533203125\n",
      "Batch: 55, Loss: 1.1499700546264648, Accuracy: 0.6103515625\n",
      "Batch: 56, Loss: 1.175734519958496, Accuracy: 0.615234375\n",
      "Batch: 57, Loss: 1.0866291522979736, Accuracy: 0.6611328125\n",
      "Batch: 58, Loss: 1.254424810409546, Accuracy: 0.6201171875\n",
      "Batch: 59, Loss: 1.0473495721817017, Accuracy: 0.6767578125\n",
      "Batch: 60, Loss: 1.0006630420684814, Accuracy: 0.6767578125\n",
      "Batch: 61, Loss: 1.1328659057617188, Accuracy: 0.6357421875\n",
      "Batch: 62, Loss: 1.110824704170227, Accuracy: 0.6396484375\n",
      "Batch: 63, Loss: 1.1658326387405396, Accuracy: 0.638671875\n",
      "Batch: 64, Loss: 1.0858898162841797, Accuracy: 0.65625\n",
      "Batch: 65, Loss: 1.1500195264816284, Accuracy: 0.640625\n",
      "Batch: 66, Loss: 1.080727458000183, Accuracy: 0.6552734375\n",
      "Batch: 67, Loss: 1.2287507057189941, Accuracy: 0.619140625\n",
      "Batch: 68, Loss: 1.224515438079834, Accuracy: 0.625\n",
      "Batch: 69, Loss: 1.1954292058944702, Accuracy: 0.6318359375\n",
      "Batch: 70, Loss: 1.1494767665863037, Accuracy: 0.6640625\n",
      "Batch: 71, Loss: 1.1384520530700684, Accuracy: 0.6396484375\n",
      "Batch: 72, Loss: 0.9973788857460022, Accuracy: 0.6787109375\n",
      "Batch: 73, Loss: 1.0979578495025635, Accuracy: 0.6708984375\n",
      "Batch: 74, Loss: 1.0456645488739014, Accuracy: 0.66796875\n",
      "Batch: 75, Loss: 0.9715977907180786, Accuracy: 0.6875\n",
      "Batch: 76, Loss: 1.1162235736846924, Accuracy: 0.6328125\n",
      "Batch: 77, Loss: 1.0922725200653076, Accuracy: 0.6513671875\n",
      "Batch: 78, Loss: 1.0971589088439941, Accuracy: 0.6611328125\n",
      "Batch: 79, Loss: 1.009047269821167, Accuracy: 0.6953125\n",
      "Batch: 80, Loss: 1.0561617612838745, Accuracy: 0.6552734375\n",
      "Batch: 81, Loss: 1.1737254858016968, Accuracy: 0.5908203125\n",
      "Batch: 82, Loss: 1.1183240413665771, Accuracy: 0.6484375\n",
      "Batch: 83, Loss: 0.9886738061904907, Accuracy: 0.703125\n",
      "Batch: 84, Loss: 1.0671138763427734, Accuracy: 0.67578125\n",
      "Batch: 85, Loss: 1.0429376363754272, Accuracy: 0.677734375\n",
      "Batch: 86, Loss: 1.2415332794189453, Accuracy: 0.623046875\n",
      "Batch: 87, Loss: 1.0340030193328857, Accuracy: 0.6787109375\n",
      "Batch: 88, Loss: 1.1791660785675049, Accuracy: 0.65234375\n",
      "Batch: 89, Loss: 1.1578891277313232, Accuracy: 0.6357421875\n",
      "Batch: 90, Loss: 1.0405919551849365, Accuracy: 0.6767578125\n",
      "Batch: 91, Loss: 1.1016454696655273, Accuracy: 0.6513671875\n",
      "Batch: 92, Loss: 1.1533390283584595, Accuracy: 0.615234375\n",
      "Batch: 93, Loss: 1.0577712059020996, Accuracy: 0.6650390625\n",
      "Batch: 94, Loss: 1.0992008447647095, Accuracy: 0.6572265625\n",
      "Batch: 95, Loss: 1.0929441452026367, Accuracy: 0.6376953125\n",
      "Batch: 96, Loss: 1.0840238332748413, Accuracy: 0.65234375\n",
      "Batch: 97, Loss: 0.9690079689025879, Accuracy: 0.6728515625\n",
      "Batch: 98, Loss: 1.0598466396331787, Accuracy: 0.6640625\n",
      "Batch: 99, Loss: 1.0292482376098633, Accuracy: 0.66015625\n",
      "Batch: 100, Loss: 1.0536060333251953, Accuracy: 0.6640625\n",
      "Batch: 101, Loss: 1.1661458015441895, Accuracy: 0.6181640625\n",
      "Batch: 102, Loss: 1.0842475891113281, Accuracy: 0.658203125\n",
      "Batch: 103, Loss: 1.1490113735198975, Accuracy: 0.6435546875\n",
      "Batch: 104, Loss: 1.0224034786224365, Accuracy: 0.6767578125\n",
      "Batch: 105, Loss: 1.1664870977401733, Accuracy: 0.6279296875\n",
      "Batch: 106, Loss: 1.0963506698608398, Accuracy: 0.6435546875\n",
      "Batch: 107, Loss: 1.1813026666641235, Accuracy: 0.625\n",
      "Batch: 108, Loss: 1.1224603652954102, Accuracy: 0.6337890625\n",
      "Batch: 109, Loss: 1.228498935699463, Accuracy: 0.5908203125\n",
      "Batch: 110, Loss: 0.9462536573410034, Accuracy: 0.689453125\n",
      "Batch: 111, Loss: 1.147573471069336, Accuracy: 0.6142578125\n",
      "Batch: 112, Loss: 1.0982102155685425, Accuracy: 0.6455078125\n",
      "Batch: 113, Loss: 1.1451749801635742, Accuracy: 0.6474609375\n",
      "Batch: 114, Loss: 1.2182672023773193, Accuracy: 0.611328125\n",
      "Batch: 115, Loss: 1.2501654624938965, Accuracy: 0.6220703125\n",
      "Batch: 116, Loss: 1.1687242984771729, Accuracy: 0.6298828125\n",
      "Batch: 117, Loss: 1.2083195447921753, Accuracy: 0.6328125\n",
      "Batch: 118, Loss: 1.0052578449249268, Accuracy: 0.68359375\n",
      "Batch: 119, Loss: 1.0361422300338745, Accuracy: 0.681640625\n",
      "Batch: 120, Loss: 1.1422232389450073, Accuracy: 0.62890625\n",
      "Batch: 121, Loss: 1.1856024265289307, Accuracy: 0.615234375\n",
      "Batch: 122, Loss: 1.0562225580215454, Accuracy: 0.6630859375\n",
      "Batch: 123, Loss: 1.089503526687622, Accuracy: 0.658203125\n",
      "Batch: 124, Loss: 1.115206003189087, Accuracy: 0.6396484375\n",
      "Batch: 125, Loss: 1.1901061534881592, Accuracy: 0.6376953125\n",
      "Batch: 126, Loss: 1.1561936140060425, Accuracy: 0.6279296875\n",
      "Batch: 127, Loss: 1.018664836883545, Accuracy: 0.6904296875\n",
      "Batch: 128, Loss: 1.2715773582458496, Accuracy: 0.623046875\n",
      "Batch: 129, Loss: 1.077366828918457, Accuracy: 0.6630859375\n",
      "Batch: 130, Loss: 1.3016496896743774, Accuracy: 0.580078125\n",
      "Batch: 131, Loss: 1.1797248125076294, Accuracy: 0.625\n",
      "Batch: 132, Loss: 1.2102667093276978, Accuracy: 0.623046875\n",
      "Batch: 133, Loss: 1.0731149911880493, Accuracy: 0.6640625\n",
      "Batch: 134, Loss: 1.1497117280960083, Accuracy: 0.6240234375\n",
      "Batch: 135, Loss: 1.0853970050811768, Accuracy: 0.6826171875\n",
      "Batch: 136, Loss: 1.1590576171875, Accuracy: 0.65234375\n",
      "Batch: 137, Loss: 1.0492279529571533, Accuracy: 0.646484375\n",
      "Batch: 138, Loss: 0.9399785995483398, Accuracy: 0.7021484375\n",
      "Batch: 139, Loss: 0.9912087321281433, Accuracy: 0.66796875\n",
      "Batch: 140, Loss: 1.1356735229492188, Accuracy: 0.634765625\n",
      "Batch: 141, Loss: 1.1218106746673584, Accuracy: 0.6455078125\n",
      "Batch: 142, Loss: 1.1862249374389648, Accuracy: 0.6201171875\n",
      "Batch: 143, Loss: 1.138343095779419, Accuracy: 0.6484375\n",
      "Batch: 144, Loss: 1.114004373550415, Accuracy: 0.6396484375\n",
      "Batch: 145, Loss: 1.07053542137146, Accuracy: 0.6416015625\n",
      "Batch: 146, Loss: 1.1887471675872803, Accuracy: 0.609375\n",
      "Batch: 147, Loss: 1.1376664638519287, Accuracy: 0.6396484375\n",
      "Batch: 148, Loss: 1.2545603513717651, Accuracy: 0.578125\n",
      "Batch: 149, Loss: 1.1291775703430176, Accuracy: 0.6171875\n",
      "Batch: 150, Loss: 1.0768710374832153, Accuracy: 0.6513671875\n",
      "Batch: 151, Loss: 1.0285165309906006, Accuracy: 0.666015625\n",
      "Epoch 18/80\n",
      "Batch: 1, Loss: 1.3053470849990845, Accuracy: 0.564453125\n",
      "Batch: 2, Loss: 1.1201519966125488, Accuracy: 0.609375\n",
      "Batch: 3, Loss: 1.063765287399292, Accuracy: 0.6494140625\n",
      "Batch: 4, Loss: 1.0084588527679443, Accuracy: 0.68359375\n",
      "Batch: 5, Loss: 1.0555812120437622, Accuracy: 0.67578125\n",
      "Batch: 6, Loss: 1.10553777217865, Accuracy: 0.6357421875\n",
      "Batch: 7, Loss: 1.0888855457305908, Accuracy: 0.6396484375\n",
      "Batch: 8, Loss: 1.0342531204223633, Accuracy: 0.66796875\n",
      "Batch: 9, Loss: 0.9894012212753296, Accuracy: 0.693359375\n",
      "Batch: 10, Loss: 1.0320987701416016, Accuracy: 0.6591796875\n",
      "Batch: 11, Loss: 1.18220853805542, Accuracy: 0.6181640625\n",
      "Batch: 12, Loss: 1.1884398460388184, Accuracy: 0.626953125\n",
      "Batch: 13, Loss: 0.9348546862602234, Accuracy: 0.708984375\n",
      "Batch: 14, Loss: 1.2029603719711304, Accuracy: 0.595703125\n",
      "Batch: 15, Loss: 1.0819799900054932, Accuracy: 0.6708984375\n",
      "Batch: 16, Loss: 1.0640777349472046, Accuracy: 0.666015625\n",
      "Batch: 17, Loss: 1.1232237815856934, Accuracy: 0.638671875\n",
      "Batch: 18, Loss: 1.1243317127227783, Accuracy: 0.6376953125\n",
      "Batch: 19, Loss: 1.1672468185424805, Accuracy: 0.6259765625\n",
      "Batch: 20, Loss: 1.0858168601989746, Accuracy: 0.6640625\n",
      "Batch: 21, Loss: 1.058699131011963, Accuracy: 0.66015625\n",
      "Batch: 22, Loss: 1.1939051151275635, Accuracy: 0.6416015625\n",
      "Batch: 23, Loss: 1.0915769338607788, Accuracy: 0.6396484375\n",
      "Batch: 24, Loss: 1.1345458030700684, Accuracy: 0.640625\n",
      "Batch: 25, Loss: 1.071986198425293, Accuracy: 0.640625\n",
      "Batch: 26, Loss: 0.9850127696990967, Accuracy: 0.6787109375\n",
      "Batch: 27, Loss: 1.038155436515808, Accuracy: 0.646484375\n",
      "Batch: 28, Loss: 1.121036410331726, Accuracy: 0.623046875\n",
      "Batch: 29, Loss: 1.0701571702957153, Accuracy: 0.666015625\n",
      "Batch: 30, Loss: 1.0799472332000732, Accuracy: 0.669921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 31, Loss: 1.0398718118667603, Accuracy: 0.6796875\n",
      "Batch: 32, Loss: 1.0277332067489624, Accuracy: 0.6640625\n",
      "Batch: 33, Loss: 1.211318850517273, Accuracy: 0.6181640625\n",
      "Batch: 34, Loss: 1.2547540664672852, Accuracy: 0.5947265625\n",
      "Batch: 35, Loss: 1.1132655143737793, Accuracy: 0.625\n",
      "Batch: 36, Loss: 1.145747184753418, Accuracy: 0.638671875\n",
      "Batch: 37, Loss: 1.088765025138855, Accuracy: 0.6572265625\n",
      "Batch: 38, Loss: 1.1353691816329956, Accuracy: 0.626953125\n",
      "Batch: 39, Loss: 1.1303298473358154, Accuracy: 0.638671875\n",
      "Batch: 40, Loss: 1.150198221206665, Accuracy: 0.6435546875\n",
      "Batch: 41, Loss: 1.1309514045715332, Accuracy: 0.638671875\n",
      "Batch: 42, Loss: 0.8855272531509399, Accuracy: 0.7158203125\n",
      "Batch: 43, Loss: 1.0692834854125977, Accuracy: 0.6494140625\n",
      "Batch: 44, Loss: 1.1377406120300293, Accuracy: 0.6181640625\n",
      "Batch: 45, Loss: 0.9600785970687866, Accuracy: 0.6865234375\n",
      "Batch: 46, Loss: 1.0599889755249023, Accuracy: 0.6845703125\n",
      "Batch: 47, Loss: 1.0655500888824463, Accuracy: 0.6796875\n",
      "Batch: 48, Loss: 1.0536788702011108, Accuracy: 0.666015625\n",
      "Batch: 49, Loss: 1.2239978313446045, Accuracy: 0.6162109375\n",
      "Batch: 50, Loss: 1.1602377891540527, Accuracy: 0.630859375\n",
      "Batch: 51, Loss: 1.2237579822540283, Accuracy: 0.611328125\n",
      "Batch: 52, Loss: 1.2044963836669922, Accuracy: 0.625\n",
      "Batch: 53, Loss: 1.0098177194595337, Accuracy: 0.6630859375\n",
      "Batch: 54, Loss: 1.073412299156189, Accuracy: 0.658203125\n",
      "Batch: 55, Loss: 1.1530961990356445, Accuracy: 0.634765625\n",
      "Batch: 56, Loss: 1.1626832485198975, Accuracy: 0.6435546875\n",
      "Batch: 57, Loss: 1.0873239040374756, Accuracy: 0.6474609375\n",
      "Batch: 58, Loss: 1.1926146745681763, Accuracy: 0.625\n",
      "Batch: 59, Loss: 1.0512899160385132, Accuracy: 0.673828125\n",
      "Batch: 60, Loss: 0.982158362865448, Accuracy: 0.6904296875\n",
      "Batch: 61, Loss: 1.1313297748565674, Accuracy: 0.6337890625\n",
      "Batch: 62, Loss: 1.0836470127105713, Accuracy: 0.6650390625\n",
      "Batch: 63, Loss: 1.1485637426376343, Accuracy: 0.6416015625\n",
      "Batch: 64, Loss: 1.0863275527954102, Accuracy: 0.6611328125\n",
      "Batch: 65, Loss: 1.1205533742904663, Accuracy: 0.6484375\n",
      "Batch: 66, Loss: 1.047839879989624, Accuracy: 0.6591796875\n",
      "Batch: 67, Loss: 1.231476068496704, Accuracy: 0.6279296875\n",
      "Batch: 68, Loss: 1.1947273015975952, Accuracy: 0.63671875\n",
      "Batch: 69, Loss: 1.1599698066711426, Accuracy: 0.64453125\n",
      "Batch: 70, Loss: 1.1486746072769165, Accuracy: 0.650390625\n",
      "Batch: 71, Loss: 1.098991870880127, Accuracy: 0.650390625\n",
      "Batch: 72, Loss: 0.9874730110168457, Accuracy: 0.6904296875\n",
      "Batch: 73, Loss: 1.062577486038208, Accuracy: 0.6748046875\n",
      "Batch: 74, Loss: 1.0246169567108154, Accuracy: 0.6689453125\n",
      "Batch: 75, Loss: 0.9577970504760742, Accuracy: 0.68359375\n",
      "Batch: 76, Loss: 1.088142991065979, Accuracy: 0.634765625\n",
      "Batch: 77, Loss: 1.0746477842330933, Accuracy: 0.65625\n",
      "Batch: 78, Loss: 1.050804615020752, Accuracy: 0.6904296875\n",
      "Batch: 79, Loss: 1.018681526184082, Accuracy: 0.69140625\n",
      "Batch: 80, Loss: 1.035447597503662, Accuracy: 0.6591796875\n",
      "Batch: 81, Loss: 1.178916335105896, Accuracy: 0.6044921875\n",
      "Batch: 82, Loss: 1.104952335357666, Accuracy: 0.6318359375\n",
      "Batch: 83, Loss: 0.9695556163787842, Accuracy: 0.7041015625\n",
      "Batch: 84, Loss: 1.0628962516784668, Accuracy: 0.666015625\n",
      "Batch: 85, Loss: 1.0137906074523926, Accuracy: 0.681640625\n",
      "Batch: 86, Loss: 1.2115529775619507, Accuracy: 0.6181640625\n",
      "Batch: 87, Loss: 1.0123447179794312, Accuracy: 0.6953125\n",
      "Batch: 88, Loss: 1.1325201988220215, Accuracy: 0.6572265625\n",
      "Batch: 89, Loss: 1.1281788349151611, Accuracy: 0.65234375\n",
      "Batch: 90, Loss: 1.028253436088562, Accuracy: 0.6650390625\n",
      "Batch: 91, Loss: 1.0609239339828491, Accuracy: 0.650390625\n",
      "Batch: 92, Loss: 1.1385291814804077, Accuracy: 0.63671875\n",
      "Batch: 93, Loss: 1.052255630493164, Accuracy: 0.666015625\n",
      "Batch: 94, Loss: 1.0637822151184082, Accuracy: 0.642578125\n",
      "Batch: 95, Loss: 1.1087347269058228, Accuracy: 0.6376953125\n",
      "Batch: 96, Loss: 1.043765664100647, Accuracy: 0.6689453125\n",
      "Batch: 97, Loss: 0.9560948610305786, Accuracy: 0.6845703125\n",
      "Batch: 98, Loss: 1.0236364603042603, Accuracy: 0.6826171875\n",
      "Batch: 99, Loss: 1.000267744064331, Accuracy: 0.6796875\n",
      "Batch: 100, Loss: 1.0454976558685303, Accuracy: 0.669921875\n",
      "Batch: 101, Loss: 1.1384546756744385, Accuracy: 0.6435546875\n",
      "Batch: 102, Loss: 1.064992904663086, Accuracy: 0.6572265625\n",
      "Batch: 103, Loss: 1.144693374633789, Accuracy: 0.650390625\n",
      "Batch: 104, Loss: 1.0249911546707153, Accuracy: 0.6748046875\n",
      "Batch: 105, Loss: 1.1255611181259155, Accuracy: 0.6357421875\n",
      "Batch: 106, Loss: 1.06324303150177, Accuracy: 0.6669921875\n",
      "Batch: 107, Loss: 1.1317164897918701, Accuracy: 0.6416015625\n",
      "Batch: 108, Loss: 1.1010241508483887, Accuracy: 0.634765625\n",
      "Batch: 109, Loss: 1.2199137210845947, Accuracy: 0.6044921875\n",
      "Batch: 110, Loss: 0.9452981352806091, Accuracy: 0.7099609375\n",
      "Batch: 111, Loss: 1.1260758638381958, Accuracy: 0.62890625\n",
      "Batch: 112, Loss: 1.105135202407837, Accuracy: 0.662109375\n",
      "Batch: 113, Loss: 1.1070878505706787, Accuracy: 0.6455078125\n",
      "Batch: 114, Loss: 1.181431770324707, Accuracy: 0.6162109375\n",
      "Batch: 115, Loss: 1.223245620727539, Accuracy: 0.6123046875\n",
      "Batch: 116, Loss: 1.1263771057128906, Accuracy: 0.642578125\n",
      "Batch: 117, Loss: 1.1442054510116577, Accuracy: 0.6513671875\n",
      "Batch: 118, Loss: 0.9779857397079468, Accuracy: 0.6748046875\n",
      "Batch: 119, Loss: 1.0188237428665161, Accuracy: 0.6904296875\n",
      "Batch: 120, Loss: 1.1457055807113647, Accuracy: 0.6337890625\n",
      "Batch: 121, Loss: 1.1526700258255005, Accuracy: 0.6259765625\n",
      "Batch: 122, Loss: 1.050982117652893, Accuracy: 0.6591796875\n",
      "Batch: 123, Loss: 1.073406457901001, Accuracy: 0.6455078125\n",
      "Batch: 124, Loss: 1.1208038330078125, Accuracy: 0.6484375\n",
      "Batch: 125, Loss: 1.154958724975586, Accuracy: 0.63671875\n",
      "Batch: 126, Loss: 1.0943876504898071, Accuracy: 0.646484375\n",
      "Batch: 127, Loss: 0.9997442960739136, Accuracy: 0.7021484375\n",
      "Batch: 128, Loss: 1.2318685054779053, Accuracy: 0.640625\n",
      "Batch: 129, Loss: 1.0446217060089111, Accuracy: 0.6669921875\n",
      "Batch: 130, Loss: 1.2891067266464233, Accuracy: 0.5908203125\n",
      "Batch: 131, Loss: 1.1557447910308838, Accuracy: 0.626953125\n",
      "Batch: 132, Loss: 1.1790030002593994, Accuracy: 0.6396484375\n",
      "Batch: 133, Loss: 1.0479955673217773, Accuracy: 0.6533203125\n",
      "Batch: 134, Loss: 1.126504898071289, Accuracy: 0.6337890625\n",
      "Batch: 135, Loss: 1.0744366645812988, Accuracy: 0.6845703125\n",
      "Batch: 136, Loss: 1.095518946647644, Accuracy: 0.650390625\n",
      "Batch: 137, Loss: 1.0170056819915771, Accuracy: 0.6640625\n",
      "Batch: 138, Loss: 0.9323822259902954, Accuracy: 0.7001953125\n",
      "Batch: 139, Loss: 0.9992489814758301, Accuracy: 0.671875\n",
      "Batch: 140, Loss: 1.0981673002243042, Accuracy: 0.626953125\n",
      "Batch: 141, Loss: 1.1093770265579224, Accuracy: 0.650390625\n",
      "Batch: 142, Loss: 1.1643080711364746, Accuracy: 0.6328125\n",
      "Batch: 143, Loss: 1.1289803981781006, Accuracy: 0.640625\n",
      "Batch: 144, Loss: 1.1070096492767334, Accuracy: 0.658203125\n",
      "Batch: 145, Loss: 1.0572328567504883, Accuracy: 0.634765625\n",
      "Batch: 146, Loss: 1.1794469356536865, Accuracy: 0.6171875\n",
      "Batch: 147, Loss: 1.1227397918701172, Accuracy: 0.6416015625\n",
      "Batch: 148, Loss: 1.2246371507644653, Accuracy: 0.591796875\n",
      "Batch: 149, Loss: 1.0873041152954102, Accuracy: 0.646484375\n",
      "Batch: 150, Loss: 1.0917844772338867, Accuracy: 0.646484375\n",
      "Batch: 151, Loss: 0.982775092124939, Accuracy: 0.6865234375\n",
      "Epoch 19/80\n",
      "Batch: 1, Loss: 1.229889988899231, Accuracy: 0.5888671875\n",
      "Batch: 2, Loss: 1.1182136535644531, Accuracy: 0.6279296875\n",
      "Batch: 3, Loss: 1.0539984703063965, Accuracy: 0.658203125\n",
      "Batch: 4, Loss: 0.9905629754066467, Accuracy: 0.6904296875\n",
      "Batch: 5, Loss: 1.019205093383789, Accuracy: 0.6865234375\n",
      "Batch: 6, Loss: 1.0704712867736816, Accuracy: 0.654296875\n",
      "Batch: 7, Loss: 1.043226957321167, Accuracy: 0.6669921875\n",
      "Batch: 8, Loss: 1.0370855331420898, Accuracy: 0.6552734375\n",
      "Batch: 9, Loss: 0.9958707094192505, Accuracy: 0.6806640625\n",
      "Batch: 10, Loss: 1.0002739429473877, Accuracy: 0.6572265625\n",
      "Batch: 11, Loss: 1.1523786783218384, Accuracy: 0.6259765625\n",
      "Batch: 12, Loss: 1.1352856159210205, Accuracy: 0.62109375\n",
      "Batch: 13, Loss: 0.9355934858322144, Accuracy: 0.7021484375\n",
      "Batch: 14, Loss: 1.181780457496643, Accuracy: 0.607421875\n",
      "Batch: 15, Loss: 1.057887077331543, Accuracy: 0.6728515625\n",
      "Batch: 16, Loss: 1.03043532371521, Accuracy: 0.6865234375\n",
      "Batch: 17, Loss: 1.1156150102615356, Accuracy: 0.6337890625\n",
      "Batch: 18, Loss: 1.123212456703186, Accuracy: 0.6435546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 19, Loss: 1.1427054405212402, Accuracy: 0.6494140625\n",
      "Batch: 20, Loss: 1.059380054473877, Accuracy: 0.6923828125\n",
      "Batch: 21, Loss: 1.0278301239013672, Accuracy: 0.6728515625\n",
      "Batch: 22, Loss: 1.145776629447937, Accuracy: 0.638671875\n",
      "Batch: 23, Loss: 1.0942637920379639, Accuracy: 0.650390625\n",
      "Batch: 24, Loss: 1.1097826957702637, Accuracy: 0.642578125\n",
      "Batch: 25, Loss: 1.0435564517974854, Accuracy: 0.6640625\n",
      "Batch: 26, Loss: 0.9728639125823975, Accuracy: 0.689453125\n",
      "Batch: 27, Loss: 1.0192420482635498, Accuracy: 0.654296875\n",
      "Batch: 28, Loss: 1.1111606359481812, Accuracy: 0.6318359375\n",
      "Batch: 29, Loss: 1.0878994464874268, Accuracy: 0.646484375\n",
      "Batch: 30, Loss: 1.071357011795044, Accuracy: 0.6708984375\n",
      "Batch: 31, Loss: 1.016679048538208, Accuracy: 0.685546875\n",
      "Batch: 32, Loss: 0.9959779977798462, Accuracy: 0.66015625\n",
      "Batch: 33, Loss: 1.2073311805725098, Accuracy: 0.611328125\n",
      "Batch: 34, Loss: 1.2301028966903687, Accuracy: 0.6103515625\n",
      "Batch: 35, Loss: 1.105818748474121, Accuracy: 0.6416015625\n",
      "Batch: 36, Loss: 1.1098759174346924, Accuracy: 0.658203125\n",
      "Batch: 37, Loss: 1.088627576828003, Accuracy: 0.6474609375\n",
      "Batch: 38, Loss: 1.1051909923553467, Accuracy: 0.63671875\n",
      "Batch: 39, Loss: 1.1119329929351807, Accuracy: 0.646484375\n",
      "Batch: 40, Loss: 1.1272876262664795, Accuracy: 0.65625\n",
      "Batch: 41, Loss: 1.0655568838119507, Accuracy: 0.6748046875\n",
      "Batch: 42, Loss: 0.8735131025314331, Accuracy: 0.712890625\n",
      "Batch: 43, Loss: 1.0466843843460083, Accuracy: 0.646484375\n",
      "Batch: 44, Loss: 1.1157234907150269, Accuracy: 0.63671875\n",
      "Batch: 45, Loss: 0.9413707256317139, Accuracy: 0.6923828125\n",
      "Batch: 46, Loss: 1.049363374710083, Accuracy: 0.6904296875\n",
      "Batch: 47, Loss: 1.055311918258667, Accuracy: 0.6708984375\n",
      "Batch: 48, Loss: 1.0156481266021729, Accuracy: 0.6767578125\n",
      "Batch: 49, Loss: 1.1911346912384033, Accuracy: 0.61328125\n",
      "Batch: 50, Loss: 1.156000018119812, Accuracy: 0.6181640625\n",
      "Batch: 51, Loss: 1.2212696075439453, Accuracy: 0.61328125\n",
      "Batch: 52, Loss: 1.1787267923355103, Accuracy: 0.6328125\n",
      "Batch: 53, Loss: 0.9952405691146851, Accuracy: 0.673828125\n",
      "Batch: 54, Loss: 1.060743808746338, Accuracy: 0.6904296875\n",
      "Batch: 55, Loss: 1.140881061553955, Accuracy: 0.619140625\n",
      "Batch: 56, Loss: 1.1207892894744873, Accuracy: 0.6484375\n",
      "Batch: 57, Loss: 1.0726675987243652, Accuracy: 0.6640625\n",
      "Batch: 58, Loss: 1.192246913909912, Accuracy: 0.6279296875\n",
      "Batch: 59, Loss: 1.0147701501846313, Accuracy: 0.681640625\n",
      "Batch: 60, Loss: 0.9759476184844971, Accuracy: 0.6845703125\n",
      "Batch: 61, Loss: 1.1143420934677124, Accuracy: 0.6484375\n",
      "Batch: 62, Loss: 1.0733730792999268, Accuracy: 0.640625\n",
      "Batch: 63, Loss: 1.120345115661621, Accuracy: 0.6484375\n",
      "Batch: 64, Loss: 1.04634428024292, Accuracy: 0.662109375\n",
      "Batch: 65, Loss: 1.0849175453186035, Accuracy: 0.6630859375\n",
      "Batch: 66, Loss: 1.0356192588806152, Accuracy: 0.671875\n",
      "Batch: 67, Loss: 1.184361219406128, Accuracy: 0.62109375\n",
      "Batch: 68, Loss: 1.1783978939056396, Accuracy: 0.63671875\n",
      "Batch: 69, Loss: 1.1229677200317383, Accuracy: 0.66015625\n",
      "Batch: 70, Loss: 1.1221427917480469, Accuracy: 0.65625\n",
      "Batch: 71, Loss: 1.103613257408142, Accuracy: 0.6435546875\n",
      "Batch: 72, Loss: 0.9865717887878418, Accuracy: 0.6845703125\n",
      "Batch: 73, Loss: 1.0239300727844238, Accuracy: 0.6865234375\n",
      "Batch: 74, Loss: 1.017431616783142, Accuracy: 0.681640625\n",
      "Batch: 75, Loss: 0.9454476833343506, Accuracy: 0.6962890625\n",
      "Batch: 76, Loss: 1.0665793418884277, Accuracy: 0.6484375\n",
      "Batch: 77, Loss: 1.0308253765106201, Accuracy: 0.6796875\n",
      "Batch: 78, Loss: 1.0544390678405762, Accuracy: 0.6875\n",
      "Batch: 79, Loss: 0.9869161248207092, Accuracy: 0.701171875\n",
      "Batch: 80, Loss: 0.9835427403450012, Accuracy: 0.6650390625\n",
      "Batch: 81, Loss: 1.1343731880187988, Accuracy: 0.6162109375\n",
      "Batch: 82, Loss: 1.0925207138061523, Accuracy: 0.64453125\n",
      "Batch: 83, Loss: 0.9394397139549255, Accuracy: 0.7197265625\n",
      "Batch: 84, Loss: 1.0522836446762085, Accuracy: 0.6845703125\n",
      "Batch: 85, Loss: 1.0145471096038818, Accuracy: 0.677734375\n",
      "Batch: 86, Loss: 1.212636947631836, Accuracy: 0.62109375\n",
      "Batch: 87, Loss: 0.9845635294914246, Accuracy: 0.7021484375\n",
      "Batch: 88, Loss: 1.1439334154129028, Accuracy: 0.6513671875\n",
      "Batch: 89, Loss: 1.110203504562378, Accuracy: 0.6650390625\n",
      "Batch: 90, Loss: 1.0132715702056885, Accuracy: 0.6767578125\n",
      "Batch: 91, Loss: 1.0692219734191895, Accuracy: 0.66015625\n",
      "Batch: 92, Loss: 1.1077817678451538, Accuracy: 0.640625\n",
      "Batch: 93, Loss: 1.030649185180664, Accuracy: 0.6572265625\n",
      "Batch: 94, Loss: 1.0571773052215576, Accuracy: 0.6591796875\n",
      "Batch: 95, Loss: 1.0585659742355347, Accuracy: 0.6474609375\n",
      "Batch: 96, Loss: 1.0542587041854858, Accuracy: 0.65625\n",
      "Batch: 97, Loss: 0.9153212904930115, Accuracy: 0.6953125\n",
      "Batch: 98, Loss: 0.978884220123291, Accuracy: 0.693359375\n",
      "Batch: 99, Loss: 0.9773342609405518, Accuracy: 0.6923828125\n",
      "Batch: 100, Loss: 1.015026569366455, Accuracy: 0.6640625\n",
      "Batch: 101, Loss: 1.1099634170532227, Accuracy: 0.666015625\n",
      "Batch: 102, Loss: 1.0162020921707153, Accuracy: 0.6748046875\n",
      "Batch: 103, Loss: 1.1251709461212158, Accuracy: 0.658203125\n",
      "Batch: 104, Loss: 1.0159246921539307, Accuracy: 0.6630859375\n",
      "Batch: 105, Loss: 1.1000902652740479, Accuracy: 0.6533203125\n",
      "Batch: 106, Loss: 1.0537055730819702, Accuracy: 0.6630859375\n",
      "Batch: 107, Loss: 1.133872389793396, Accuracy: 0.6396484375\n",
      "Batch: 108, Loss: 1.1126830577850342, Accuracy: 0.626953125\n",
      "Batch: 109, Loss: 1.2004328966140747, Accuracy: 0.619140625\n",
      "Batch: 110, Loss: 0.9326927065849304, Accuracy: 0.697265625\n",
      "Batch: 111, Loss: 1.1125054359436035, Accuracy: 0.6298828125\n",
      "Batch: 112, Loss: 1.0557842254638672, Accuracy: 0.6728515625\n",
      "Batch: 113, Loss: 1.0775370597839355, Accuracy: 0.662109375\n",
      "Batch: 114, Loss: 1.1451568603515625, Accuracy: 0.6259765625\n",
      "Batch: 115, Loss: 1.2316888570785522, Accuracy: 0.625\n",
      "Batch: 116, Loss: 1.1291035413742065, Accuracy: 0.6435546875\n",
      "Batch: 117, Loss: 1.1677329540252686, Accuracy: 0.650390625\n",
      "Batch: 118, Loss: 0.9731189012527466, Accuracy: 0.6923828125\n",
      "Batch: 119, Loss: 0.9823142290115356, Accuracy: 0.7060546875\n",
      "Batch: 120, Loss: 1.1251002550125122, Accuracy: 0.6240234375\n",
      "Batch: 121, Loss: 1.136725902557373, Accuracy: 0.65234375\n",
      "Batch: 122, Loss: 1.0367379188537598, Accuracy: 0.6748046875\n",
      "Batch: 123, Loss: 1.0279537439346313, Accuracy: 0.673828125\n",
      "Batch: 124, Loss: 1.1115243434906006, Accuracy: 0.6337890625\n",
      "Batch: 125, Loss: 1.1352277994155884, Accuracy: 0.6357421875\n",
      "Batch: 126, Loss: 1.0925517082214355, Accuracy: 0.64453125\n",
      "Batch: 127, Loss: 0.979314923286438, Accuracy: 0.6982421875\n",
      "Batch: 128, Loss: 1.2185957431793213, Accuracy: 0.630859375\n",
      "Batch: 129, Loss: 1.0377317667007446, Accuracy: 0.6787109375\n",
      "Batch: 130, Loss: 1.2165707349777222, Accuracy: 0.615234375\n",
      "Batch: 131, Loss: 1.1171151399612427, Accuracy: 0.65234375\n",
      "Batch: 132, Loss: 1.1754841804504395, Accuracy: 0.6357421875\n",
      "Batch: 133, Loss: 1.0240871906280518, Accuracy: 0.66015625\n",
      "Batch: 134, Loss: 1.1092019081115723, Accuracy: 0.6328125\n",
      "Batch: 135, Loss: 1.052884817123413, Accuracy: 0.67578125\n",
      "Batch: 136, Loss: 1.0796047449111938, Accuracy: 0.6669921875\n",
      "Batch: 137, Loss: 1.004565954208374, Accuracy: 0.6640625\n",
      "Batch: 138, Loss: 0.9448426365852356, Accuracy: 0.6806640625\n",
      "Batch: 139, Loss: 0.9606207609176636, Accuracy: 0.6845703125\n",
      "Batch: 140, Loss: 1.084281086921692, Accuracy: 0.65234375\n",
      "Batch: 141, Loss: 1.0611896514892578, Accuracy: 0.6708984375\n",
      "Batch: 142, Loss: 1.1557577848434448, Accuracy: 0.625\n",
      "Batch: 143, Loss: 1.1180297136306763, Accuracy: 0.6513671875\n",
      "Batch: 144, Loss: 1.07265305519104, Accuracy: 0.6630859375\n",
      "Batch: 145, Loss: 1.037829875946045, Accuracy: 0.6494140625\n",
      "Batch: 146, Loss: 1.157690167427063, Accuracy: 0.6201171875\n",
      "Batch: 147, Loss: 1.1027157306671143, Accuracy: 0.6455078125\n",
      "Batch: 148, Loss: 1.2006988525390625, Accuracy: 0.6025390625\n",
      "Batch: 149, Loss: 1.0969746112823486, Accuracy: 0.640625\n",
      "Batch: 150, Loss: 1.047898530960083, Accuracy: 0.6591796875\n",
      "Batch: 151, Loss: 0.9563109874725342, Accuracy: 0.6923828125\n",
      "Epoch 20/80\n",
      "Batch: 1, Loss: 1.2398605346679688, Accuracy: 0.5927734375\n",
      "Batch: 2, Loss: 1.099493384361267, Accuracy: 0.62109375\n",
      "Batch: 3, Loss: 1.0156011581420898, Accuracy: 0.6669921875\n",
      "Batch: 4, Loss: 0.9674200415611267, Accuracy: 0.7001953125\n",
      "Batch: 5, Loss: 1.0109552145004272, Accuracy: 0.6806640625\n",
      "Batch: 6, Loss: 1.0611121654510498, Accuracy: 0.658203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 7, Loss: 1.0210174322128296, Accuracy: 0.6767578125\n",
      "Batch: 8, Loss: 1.0044325590133667, Accuracy: 0.685546875\n",
      "Batch: 9, Loss: 0.9654982686042786, Accuracy: 0.6923828125\n",
      "Batch: 10, Loss: 1.0161315202713013, Accuracy: 0.654296875\n",
      "Batch: 11, Loss: 1.1146657466888428, Accuracy: 0.6162109375\n",
      "Batch: 12, Loss: 1.1257421970367432, Accuracy: 0.63671875\n",
      "Batch: 13, Loss: 0.9113985300064087, Accuracy: 0.7119140625\n",
      "Batch: 14, Loss: 1.1600162982940674, Accuracy: 0.6064453125\n",
      "Batch: 15, Loss: 0.9988839030265808, Accuracy: 0.697265625\n",
      "Batch: 16, Loss: 1.0171210765838623, Accuracy: 0.6728515625\n",
      "Batch: 17, Loss: 1.094366192817688, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.1069207191467285, Accuracy: 0.638671875\n",
      "Batch: 19, Loss: 1.1541693210601807, Accuracy: 0.638671875\n",
      "Batch: 20, Loss: 1.0343652963638306, Accuracy: 0.6943359375\n",
      "Batch: 21, Loss: 0.9825983047485352, Accuracy: 0.6767578125\n",
      "Batch: 22, Loss: 1.1375837326049805, Accuracy: 0.6474609375\n",
      "Batch: 23, Loss: 1.0622586011886597, Accuracy: 0.6533203125\n",
      "Batch: 24, Loss: 1.0936905145645142, Accuracy: 0.65234375\n",
      "Batch: 25, Loss: 1.032896876335144, Accuracy: 0.6611328125\n",
      "Batch: 26, Loss: 0.9374918937683105, Accuracy: 0.697265625\n",
      "Batch: 27, Loss: 1.0048385858535767, Accuracy: 0.6650390625\n",
      "Batch: 28, Loss: 1.0975947380065918, Accuracy: 0.6318359375\n",
      "Batch: 29, Loss: 1.054878830909729, Accuracy: 0.6630859375\n",
      "Batch: 30, Loss: 1.0452830791473389, Accuracy: 0.677734375\n",
      "Batch: 31, Loss: 1.0260356664657593, Accuracy: 0.6767578125\n",
      "Batch: 32, Loss: 0.9833673238754272, Accuracy: 0.6845703125\n",
      "Batch: 33, Loss: 1.1780943870544434, Accuracy: 0.630859375\n",
      "Batch: 34, Loss: 1.207420825958252, Accuracy: 0.61328125\n",
      "Batch: 35, Loss: 1.0953915119171143, Accuracy: 0.6357421875\n",
      "Batch: 36, Loss: 1.112856149673462, Accuracy: 0.6533203125\n",
      "Batch: 37, Loss: 1.0297503471374512, Accuracy: 0.6689453125\n",
      "Batch: 38, Loss: 1.0763578414916992, Accuracy: 0.6484375\n",
      "Batch: 39, Loss: 1.1041972637176514, Accuracy: 0.6552734375\n",
      "Batch: 40, Loss: 1.1113336086273193, Accuracy: 0.6552734375\n",
      "Batch: 41, Loss: 1.0543169975280762, Accuracy: 0.662109375\n",
      "Batch: 42, Loss: 0.8218775987625122, Accuracy: 0.7373046875\n",
      "Batch: 43, Loss: 1.0135118961334229, Accuracy: 0.662109375\n",
      "Batch: 44, Loss: 1.07090163230896, Accuracy: 0.646484375\n",
      "Batch: 45, Loss: 0.9556171298027039, Accuracy: 0.6806640625\n",
      "Batch: 46, Loss: 1.0520128011703491, Accuracy: 0.673828125\n",
      "Batch: 47, Loss: 1.037341833114624, Accuracy: 0.6826171875\n",
      "Batch: 48, Loss: 1.0147472620010376, Accuracy: 0.6650390625\n",
      "Batch: 49, Loss: 1.1925138235092163, Accuracy: 0.6259765625\n",
      "Batch: 50, Loss: 1.1369366645812988, Accuracy: 0.62890625\n",
      "Batch: 51, Loss: 1.2086167335510254, Accuracy: 0.6162109375\n",
      "Batch: 52, Loss: 1.1428371667861938, Accuracy: 0.646484375\n",
      "Batch: 53, Loss: 0.9461738467216492, Accuracy: 0.6875\n",
      "Batch: 54, Loss: 1.0348763465881348, Accuracy: 0.67578125\n",
      "Batch: 55, Loss: 1.1246609687805176, Accuracy: 0.6376953125\n",
      "Batch: 56, Loss: 1.0986088514328003, Accuracy: 0.6640625\n",
      "Batch: 57, Loss: 1.0406893491744995, Accuracy: 0.6806640625\n",
      "Batch: 58, Loss: 1.1285109519958496, Accuracy: 0.6435546875\n",
      "Batch: 59, Loss: 1.0254616737365723, Accuracy: 0.673828125\n",
      "Batch: 60, Loss: 0.952975869178772, Accuracy: 0.697265625\n",
      "Batch: 61, Loss: 1.0916833877563477, Accuracy: 0.638671875\n",
      "Batch: 62, Loss: 1.067999005317688, Accuracy: 0.6591796875\n",
      "Batch: 63, Loss: 1.120632529258728, Accuracy: 0.654296875\n",
      "Batch: 64, Loss: 1.0232517719268799, Accuracy: 0.6669921875\n",
      "Batch: 65, Loss: 1.0669152736663818, Accuracy: 0.6533203125\n",
      "Batch: 66, Loss: 1.0273579359054565, Accuracy: 0.6845703125\n",
      "Batch: 67, Loss: 1.1733566522598267, Accuracy: 0.642578125\n",
      "Batch: 68, Loss: 1.164475440979004, Accuracy: 0.625\n",
      "Batch: 69, Loss: 1.1024761199951172, Accuracy: 0.6552734375\n",
      "Batch: 70, Loss: 1.0732269287109375, Accuracy: 0.671875\n",
      "Batch: 71, Loss: 1.0610154867172241, Accuracy: 0.6640625\n",
      "Batch: 72, Loss: 0.9839069843292236, Accuracy: 0.6826171875\n",
      "Batch: 73, Loss: 1.0299608707427979, Accuracy: 0.67578125\n",
      "Batch: 74, Loss: 0.9934340715408325, Accuracy: 0.7001953125\n",
      "Batch: 75, Loss: 0.9449793100357056, Accuracy: 0.6982421875\n",
      "Batch: 76, Loss: 1.041677474975586, Accuracy: 0.6591796875\n",
      "Batch: 77, Loss: 1.005292534828186, Accuracy: 0.6787109375\n",
      "Batch: 78, Loss: 1.0319900512695312, Accuracy: 0.6806640625\n",
      "Batch: 79, Loss: 0.9709764719009399, Accuracy: 0.7099609375\n",
      "Batch: 80, Loss: 1.008374571800232, Accuracy: 0.6572265625\n",
      "Batch: 81, Loss: 1.1332180500030518, Accuracy: 0.6220703125\n",
      "Batch: 82, Loss: 1.0601062774658203, Accuracy: 0.662109375\n",
      "Batch: 83, Loss: 0.9345301985740662, Accuracy: 0.7236328125\n",
      "Batch: 84, Loss: 1.025599718093872, Accuracy: 0.685546875\n",
      "Batch: 85, Loss: 0.9778633713722229, Accuracy: 0.7041015625\n",
      "Batch: 86, Loss: 1.1709063053131104, Accuracy: 0.625\n",
      "Batch: 87, Loss: 0.9752676486968994, Accuracy: 0.701171875\n",
      "Batch: 88, Loss: 1.110539197921753, Accuracy: 0.6748046875\n",
      "Batch: 89, Loss: 1.0826665163040161, Accuracy: 0.6728515625\n",
      "Batch: 90, Loss: 0.9902030229568481, Accuracy: 0.66796875\n",
      "Batch: 91, Loss: 1.0450570583343506, Accuracy: 0.673828125\n",
      "Batch: 92, Loss: 1.0986340045928955, Accuracy: 0.6474609375\n",
      "Batch: 93, Loss: 1.0214073657989502, Accuracy: 0.6630859375\n",
      "Batch: 94, Loss: 1.0734951496124268, Accuracy: 0.6650390625\n",
      "Batch: 95, Loss: 1.0695043802261353, Accuracy: 0.6513671875\n",
      "Batch: 96, Loss: 1.0204603672027588, Accuracy: 0.6787109375\n",
      "Batch: 97, Loss: 0.8975217342376709, Accuracy: 0.7021484375\n",
      "Batch: 98, Loss: 0.9825764894485474, Accuracy: 0.6826171875\n",
      "Batch: 99, Loss: 0.9864606857299805, Accuracy: 0.6875\n",
      "Batch: 100, Loss: 1.0067716836929321, Accuracy: 0.6904296875\n",
      "Batch: 101, Loss: 1.1018604040145874, Accuracy: 0.634765625\n",
      "Batch: 102, Loss: 1.0406726598739624, Accuracy: 0.6650390625\n",
      "Batch: 103, Loss: 1.1022459268569946, Accuracy: 0.6630859375\n",
      "Batch: 104, Loss: 0.995938777923584, Accuracy: 0.677734375\n",
      "Batch: 105, Loss: 1.0877829790115356, Accuracy: 0.6611328125\n",
      "Batch: 106, Loss: 1.04111909866333, Accuracy: 0.662109375\n",
      "Batch: 107, Loss: 1.1056222915649414, Accuracy: 0.654296875\n",
      "Batch: 108, Loss: 1.0726574659347534, Accuracy: 0.6455078125\n",
      "Batch: 109, Loss: 1.1878011226654053, Accuracy: 0.62109375\n",
      "Batch: 110, Loss: 0.912618100643158, Accuracy: 0.7060546875\n",
      "Batch: 111, Loss: 1.0991601943969727, Accuracy: 0.63671875\n",
      "Batch: 112, Loss: 1.0487329959869385, Accuracy: 0.669921875\n",
      "Batch: 113, Loss: 1.082615852355957, Accuracy: 0.658203125\n",
      "Batch: 114, Loss: 1.134093999862671, Accuracy: 0.6201171875\n",
      "Batch: 115, Loss: 1.178476333618164, Accuracy: 0.6396484375\n",
      "Batch: 116, Loss: 1.1019110679626465, Accuracy: 0.64453125\n",
      "Batch: 117, Loss: 1.1106786727905273, Accuracy: 0.6572265625\n",
      "Batch: 118, Loss: 0.9507398009300232, Accuracy: 0.6953125\n",
      "Batch: 119, Loss: 1.0034462213516235, Accuracy: 0.6748046875\n",
      "Batch: 120, Loss: 1.1107978820800781, Accuracy: 0.640625\n",
      "Batch: 121, Loss: 1.124284267425537, Accuracy: 0.6416015625\n",
      "Batch: 122, Loss: 1.0026676654815674, Accuracy: 0.6845703125\n",
      "Batch: 123, Loss: 1.0403854846954346, Accuracy: 0.669921875\n",
      "Batch: 124, Loss: 1.081710934638977, Accuracy: 0.6494140625\n",
      "Batch: 125, Loss: 1.1209206581115723, Accuracy: 0.662109375\n",
      "Batch: 126, Loss: 1.0765488147735596, Accuracy: 0.65625\n",
      "Batch: 127, Loss: 0.9694909453392029, Accuracy: 0.70703125\n",
      "Batch: 128, Loss: 1.1850121021270752, Accuracy: 0.634765625\n",
      "Batch: 129, Loss: 0.9904228448867798, Accuracy: 0.6845703125\n",
      "Batch: 130, Loss: 1.2125669717788696, Accuracy: 0.619140625\n",
      "Batch: 131, Loss: 1.0932962894439697, Accuracy: 0.654296875\n",
      "Batch: 132, Loss: 1.1407204866409302, Accuracy: 0.64453125\n",
      "Batch: 133, Loss: 1.0075335502624512, Accuracy: 0.666015625\n",
      "Batch: 134, Loss: 1.07305908203125, Accuracy: 0.658203125\n",
      "Batch: 135, Loss: 1.0092978477478027, Accuracy: 0.69921875\n",
      "Batch: 136, Loss: 1.0657987594604492, Accuracy: 0.6689453125\n",
      "Batch: 137, Loss: 0.990479588508606, Accuracy: 0.6650390625\n",
      "Batch: 138, Loss: 0.8963804244995117, Accuracy: 0.7099609375\n",
      "Batch: 139, Loss: 0.9693233966827393, Accuracy: 0.6845703125\n",
      "Batch: 140, Loss: 1.0735795497894287, Accuracy: 0.642578125\n",
      "Batch: 141, Loss: 1.0644181966781616, Accuracy: 0.66796875\n",
      "Batch: 142, Loss: 1.1260586977005005, Accuracy: 0.646484375\n",
      "Batch: 143, Loss: 1.0859746932983398, Accuracy: 0.6533203125\n",
      "Batch: 144, Loss: 1.0318801403045654, Accuracy: 0.6796875\n",
      "Batch: 145, Loss: 0.9903756380081177, Accuracy: 0.6572265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 146, Loss: 1.1073116064071655, Accuracy: 0.6474609375\n",
      "Batch: 147, Loss: 1.075042486190796, Accuracy: 0.6337890625\n",
      "Batch: 148, Loss: 1.1591163873672485, Accuracy: 0.62109375\n",
      "Batch: 149, Loss: 1.047442078590393, Accuracy: 0.650390625\n",
      "Batch: 150, Loss: 1.0145074129104614, Accuracy: 0.6689453125\n",
      "Batch: 151, Loss: 0.9394470453262329, Accuracy: 0.69921875\n",
      "Saved Weights at epoch 20 to file Weights_20.h5\n",
      "Epoch 21/80\n",
      "Batch: 1, Loss: 1.2320955991744995, Accuracy: 0.6005859375\n",
      "Batch: 2, Loss: 1.106887698173523, Accuracy: 0.61328125\n",
      "Batch: 3, Loss: 1.0199909210205078, Accuracy: 0.6552734375\n",
      "Batch: 4, Loss: 0.9378697276115417, Accuracy: 0.7119140625\n",
      "Batch: 5, Loss: 1.0095915794372559, Accuracy: 0.68359375\n",
      "Batch: 6, Loss: 1.0307117700576782, Accuracy: 0.6640625\n",
      "Batch: 7, Loss: 1.0022056102752686, Accuracy: 0.666015625\n",
      "Batch: 8, Loss: 0.9721741676330566, Accuracy: 0.6767578125\n",
      "Batch: 9, Loss: 0.9396407604217529, Accuracy: 0.708984375\n",
      "Batch: 10, Loss: 0.9723166227340698, Accuracy: 0.677734375\n",
      "Batch: 11, Loss: 1.0960791110992432, Accuracy: 0.630859375\n",
      "Batch: 12, Loss: 1.1021695137023926, Accuracy: 0.6494140625\n",
      "Batch: 13, Loss: 0.9168994426727295, Accuracy: 0.7275390625\n",
      "Batch: 14, Loss: 1.1164973974227905, Accuracy: 0.6279296875\n",
      "Batch: 15, Loss: 1.0050278902053833, Accuracy: 0.693359375\n",
      "Batch: 16, Loss: 0.9991854429244995, Accuracy: 0.69140625\n",
      "Batch: 17, Loss: 1.077476978302002, Accuracy: 0.6484375\n",
      "Batch: 18, Loss: 1.0765256881713867, Accuracy: 0.654296875\n",
      "Batch: 19, Loss: 1.1202945709228516, Accuracy: 0.654296875\n",
      "Batch: 20, Loss: 1.0010071992874146, Accuracy: 0.7080078125\n",
      "Batch: 21, Loss: 0.9717423915863037, Accuracy: 0.681640625\n",
      "Batch: 22, Loss: 1.095665693283081, Accuracy: 0.64453125\n",
      "Batch: 23, Loss: 1.021847128868103, Accuracy: 0.662109375\n",
      "Batch: 24, Loss: 1.0675727128982544, Accuracy: 0.65234375\n",
      "Batch: 25, Loss: 1.0123475790023804, Accuracy: 0.669921875\n",
      "Batch: 26, Loss: 0.9292867183685303, Accuracy: 0.7099609375\n",
      "Batch: 27, Loss: 0.9855910539627075, Accuracy: 0.666015625\n",
      "Batch: 28, Loss: 1.0496350526809692, Accuracy: 0.646484375\n",
      "Batch: 29, Loss: 1.0551224946975708, Accuracy: 0.6630859375\n",
      "Batch: 30, Loss: 1.0135974884033203, Accuracy: 0.6943359375\n",
      "Batch: 31, Loss: 0.962225615978241, Accuracy: 0.697265625\n",
      "Batch: 32, Loss: 0.9552352428436279, Accuracy: 0.677734375\n",
      "Batch: 33, Loss: 1.1348838806152344, Accuracy: 0.634765625\n",
      "Batch: 34, Loss: 1.1971369981765747, Accuracy: 0.6162109375\n",
      "Batch: 35, Loss: 1.0749099254608154, Accuracy: 0.64453125\n",
      "Batch: 36, Loss: 1.083442211151123, Accuracy: 0.6640625\n",
      "Batch: 37, Loss: 1.0369340181350708, Accuracy: 0.666015625\n",
      "Batch: 38, Loss: 1.0798487663269043, Accuracy: 0.6435546875\n",
      "Batch: 39, Loss: 1.0858128070831299, Accuracy: 0.640625\n",
      "Batch: 40, Loss: 1.0748848915100098, Accuracy: 0.66796875\n",
      "Batch: 41, Loss: 1.0221943855285645, Accuracy: 0.6748046875\n",
      "Batch: 42, Loss: 0.8478207588195801, Accuracy: 0.734375\n",
      "Batch: 43, Loss: 0.9978572130203247, Accuracy: 0.669921875\n",
      "Batch: 44, Loss: 1.0895787477493286, Accuracy: 0.63671875\n",
      "Batch: 45, Loss: 0.9141845703125, Accuracy: 0.7099609375\n",
      "Batch: 46, Loss: 1.0179499387741089, Accuracy: 0.6875\n",
      "Batch: 47, Loss: 1.03519868850708, Accuracy: 0.6826171875\n",
      "Batch: 48, Loss: 0.9889716506004333, Accuracy: 0.6708984375\n",
      "Batch: 49, Loss: 1.1335341930389404, Accuracy: 0.640625\n",
      "Batch: 50, Loss: 1.1105968952178955, Accuracy: 0.6376953125\n",
      "Batch: 51, Loss: 1.1757677793502808, Accuracy: 0.634765625\n",
      "Batch: 52, Loss: 1.1258097887039185, Accuracy: 0.6484375\n",
      "Batch: 53, Loss: 0.9815467000007629, Accuracy: 0.669921875\n",
      "Batch: 54, Loss: 1.0079715251922607, Accuracy: 0.67578125\n",
      "Batch: 55, Loss: 1.1219016313552856, Accuracy: 0.6435546875\n",
      "Batch: 56, Loss: 1.0900968313217163, Accuracy: 0.658203125\n",
      "Batch: 57, Loss: 1.0507906675338745, Accuracy: 0.6806640625\n",
      "Batch: 58, Loss: 1.1548633575439453, Accuracy: 0.64453125\n",
      "Batch: 59, Loss: 1.0239571332931519, Accuracy: 0.6826171875\n",
      "Batch: 60, Loss: 0.9555766582489014, Accuracy: 0.689453125\n",
      "Batch: 61, Loss: 1.0654144287109375, Accuracy: 0.6591796875\n",
      "Batch: 62, Loss: 1.0390124320983887, Accuracy: 0.6591796875\n",
      "Batch: 63, Loss: 1.0735267400741577, Accuracy: 0.6572265625\n",
      "Batch: 64, Loss: 1.0350735187530518, Accuracy: 0.6611328125\n",
      "Batch: 65, Loss: 1.0762754678726196, Accuracy: 0.65234375\n",
      "Batch: 66, Loss: 1.0056321620941162, Accuracy: 0.6826171875\n",
      "Batch: 67, Loss: 1.1482162475585938, Accuracy: 0.63671875\n",
      "Batch: 68, Loss: 1.1419341564178467, Accuracy: 0.638671875\n",
      "Batch: 69, Loss: 1.0907678604125977, Accuracy: 0.6552734375\n",
      "Batch: 70, Loss: 1.0714665651321411, Accuracy: 0.666015625\n",
      "Batch: 71, Loss: 1.0584256649017334, Accuracy: 0.6689453125\n",
      "Batch: 72, Loss: 0.9278962016105652, Accuracy: 0.70703125\n",
      "Batch: 73, Loss: 1.0099456310272217, Accuracy: 0.68359375\n",
      "Batch: 74, Loss: 0.9696165323257446, Accuracy: 0.689453125\n",
      "Batch: 75, Loss: 0.9168941378593445, Accuracy: 0.703125\n",
      "Batch: 76, Loss: 1.0269745588302612, Accuracy: 0.6689453125\n",
      "Batch: 77, Loss: 1.0137596130371094, Accuracy: 0.6689453125\n",
      "Batch: 78, Loss: 0.9913017153739929, Accuracy: 0.69140625\n",
      "Batch: 79, Loss: 0.9430854916572571, Accuracy: 0.716796875\n",
      "Batch: 80, Loss: 0.9641184210777283, Accuracy: 0.6689453125\n",
      "Batch: 81, Loss: 1.0869057178497314, Accuracy: 0.6201171875\n",
      "Batch: 82, Loss: 1.0493346452713013, Accuracy: 0.6572265625\n",
      "Batch: 83, Loss: 0.9152077436447144, Accuracy: 0.7158203125\n",
      "Batch: 84, Loss: 0.9903709888458252, Accuracy: 0.6923828125\n",
      "Batch: 85, Loss: 0.9472711086273193, Accuracy: 0.7060546875\n",
      "Batch: 86, Loss: 1.1675093173980713, Accuracy: 0.6337890625\n",
      "Batch: 87, Loss: 0.9520230293273926, Accuracy: 0.69140625\n",
      "Batch: 88, Loss: 1.0731030702590942, Accuracy: 0.671875\n",
      "Batch: 89, Loss: 1.0684704780578613, Accuracy: 0.6708984375\n",
      "Batch: 90, Loss: 0.9550681114196777, Accuracy: 0.7001953125\n",
      "Batch: 91, Loss: 1.0330665111541748, Accuracy: 0.671875\n",
      "Batch: 92, Loss: 1.0845863819122314, Accuracy: 0.6591796875\n",
      "Batch: 93, Loss: 1.0121276378631592, Accuracy: 0.673828125\n",
      "Batch: 94, Loss: 1.0227606296539307, Accuracy: 0.6650390625\n",
      "Batch: 95, Loss: 1.0363905429840088, Accuracy: 0.6572265625\n",
      "Batch: 96, Loss: 1.0169545412063599, Accuracy: 0.669921875\n",
      "Batch: 97, Loss: 0.8879378437995911, Accuracy: 0.6982421875\n",
      "Batch: 98, Loss: 0.9591807126998901, Accuracy: 0.703125\n",
      "Batch: 99, Loss: 0.9567375183105469, Accuracy: 0.6962890625\n",
      "Batch: 100, Loss: 1.0175421237945557, Accuracy: 0.6708984375\n",
      "Batch: 101, Loss: 1.0971622467041016, Accuracy: 0.6513671875\n",
      "Batch: 102, Loss: 1.0183665752410889, Accuracy: 0.685546875\n",
      "Batch: 103, Loss: 1.0723962783813477, Accuracy: 0.6748046875\n",
      "Batch: 104, Loss: 0.9973937273025513, Accuracy: 0.6787109375\n",
      "Batch: 105, Loss: 1.0767241716384888, Accuracy: 0.666015625\n",
      "Batch: 106, Loss: 0.9934360980987549, Accuracy: 0.6875\n",
      "Batch: 107, Loss: 1.0795671939849854, Accuracy: 0.654296875\n",
      "Batch: 108, Loss: 1.0591604709625244, Accuracy: 0.6572265625\n",
      "Batch: 109, Loss: 1.169217824935913, Accuracy: 0.607421875\n",
      "Batch: 110, Loss: 0.9058988094329834, Accuracy: 0.70703125\n",
      "Batch: 111, Loss: 1.0687158107757568, Accuracy: 0.638671875\n",
      "Batch: 112, Loss: 1.0286873579025269, Accuracy: 0.6767578125\n",
      "Batch: 113, Loss: 1.0115569829940796, Accuracy: 0.6708984375\n",
      "Batch: 114, Loss: 1.1070668697357178, Accuracy: 0.6435546875\n",
      "Batch: 115, Loss: 1.1679235696792603, Accuracy: 0.62890625\n",
      "Batch: 116, Loss: 1.078392505645752, Accuracy: 0.6416015625\n",
      "Batch: 117, Loss: 1.088629126548767, Accuracy: 0.6611328125\n",
      "Batch: 118, Loss: 0.9345880746841431, Accuracy: 0.7021484375\n",
      "Batch: 119, Loss: 0.9775587320327759, Accuracy: 0.6884765625\n",
      "Batch: 120, Loss: 1.074135422706604, Accuracy: 0.6484375\n",
      "Batch: 121, Loss: 1.0777966976165771, Accuracy: 0.6640625\n",
      "Batch: 122, Loss: 0.9910001754760742, Accuracy: 0.6982421875\n",
      "Batch: 123, Loss: 0.9931750297546387, Accuracy: 0.6884765625\n",
      "Batch: 124, Loss: 1.0697336196899414, Accuracy: 0.662109375\n",
      "Batch: 125, Loss: 1.078757882118225, Accuracy: 0.66015625\n",
      "Batch: 126, Loss: 1.053215742111206, Accuracy: 0.666015625\n",
      "Batch: 127, Loss: 0.9535778760910034, Accuracy: 0.7060546875\n",
      "Batch: 128, Loss: 1.173136830329895, Accuracy: 0.6513671875\n",
      "Batch: 129, Loss: 0.9813445806503296, Accuracy: 0.69140625\n",
      "Batch: 130, Loss: 1.1800380945205688, Accuracy: 0.6279296875\n",
      "Batch: 131, Loss: 1.0905883312225342, Accuracy: 0.6572265625\n",
      "Batch: 132, Loss: 1.1178011894226074, Accuracy: 0.6650390625\n",
      "Batch: 133, Loss: 1.0038414001464844, Accuracy: 0.6591796875\n",
      "Batch: 134, Loss: 1.0655066967010498, Accuracy: 0.640625\n",
      "Batch: 135, Loss: 1.0265976190567017, Accuracy: 0.685546875\n",
      "Batch: 136, Loss: 1.064485788345337, Accuracy: 0.6708984375\n",
      "Batch: 137, Loss: 0.9809439182281494, Accuracy: 0.6591796875\n",
      "Batch: 138, Loss: 0.9125034809112549, Accuracy: 0.701171875\n",
      "Batch: 139, Loss: 0.9402285814285278, Accuracy: 0.697265625\n",
      "Batch: 140, Loss: 1.057145118713379, Accuracy: 0.64453125\n",
      "Batch: 141, Loss: 1.04367196559906, Accuracy: 0.6767578125\n",
      "Batch: 142, Loss: 1.131413221359253, Accuracy: 0.6357421875\n",
      "Batch: 143, Loss: 1.087205171585083, Accuracy: 0.6494140625\n",
      "Batch: 144, Loss: 1.0519498586654663, Accuracy: 0.6552734375\n",
      "Batch: 145, Loss: 0.994349479675293, Accuracy: 0.654296875\n",
      "Batch: 146, Loss: 1.0956083536148071, Accuracy: 0.638671875\n",
      "Batch: 147, Loss: 1.05043363571167, Accuracy: 0.6513671875\n",
      "Batch: 148, Loss: 1.1523828506469727, Accuracy: 0.6142578125\n",
      "Batch: 149, Loss: 1.0276410579681396, Accuracy: 0.6611328125\n",
      "Batch: 150, Loss: 1.0460814237594604, Accuracy: 0.6650390625\n",
      "Batch: 151, Loss: 0.9246666431427002, Accuracy: 0.6982421875\n",
      "Epoch 22/80\n",
      "Batch: 1, Loss: 1.205075979232788, Accuracy: 0.6005859375\n",
      "Batch: 2, Loss: 1.0794014930725098, Accuracy: 0.6240234375\n",
      "Batch: 3, Loss: 0.9784570932388306, Accuracy: 0.6748046875\n",
      "Batch: 4, Loss: 0.9282406568527222, Accuracy: 0.7236328125\n",
      "Batch: 5, Loss: 0.9939748048782349, Accuracy: 0.6962890625\n",
      "Batch: 6, Loss: 1.0613751411437988, Accuracy: 0.6455078125\n",
      "Batch: 7, Loss: 1.0117430686950684, Accuracy: 0.658203125\n",
      "Batch: 8, Loss: 1.0116336345672607, Accuracy: 0.6669921875\n",
      "Batch: 9, Loss: 0.9286426305770874, Accuracy: 0.7158203125\n",
      "Batch: 10, Loss: 0.947883129119873, Accuracy: 0.6943359375\n",
      "Batch: 11, Loss: 1.0936005115509033, Accuracy: 0.62890625\n",
      "Batch: 12, Loss: 1.0766816139221191, Accuracy: 0.65234375\n",
      "Batch: 13, Loss: 0.8754295706748962, Accuracy: 0.7236328125\n",
      "Batch: 14, Loss: 1.1221237182617188, Accuracy: 0.63671875\n",
      "Batch: 15, Loss: 0.9917660355567932, Accuracy: 0.6953125\n",
      "Batch: 16, Loss: 0.9547745585441589, Accuracy: 0.708984375\n",
      "Batch: 17, Loss: 1.078047275543213, Accuracy: 0.6572265625\n",
      "Batch: 18, Loss: 1.0352427959442139, Accuracy: 0.65625\n",
      "Batch: 19, Loss: 1.0704076290130615, Accuracy: 0.673828125\n",
      "Batch: 20, Loss: 0.9986364841461182, Accuracy: 0.705078125\n",
      "Batch: 21, Loss: 0.9692939519882202, Accuracy: 0.6767578125\n",
      "Batch: 22, Loss: 1.0678470134735107, Accuracy: 0.669921875\n",
      "Batch: 23, Loss: 1.036594271659851, Accuracy: 0.6650390625\n",
      "Batch: 24, Loss: 1.0701441764831543, Accuracy: 0.6630859375\n",
      "Batch: 25, Loss: 1.0023362636566162, Accuracy: 0.673828125\n",
      "Batch: 26, Loss: 0.9098343849182129, Accuracy: 0.7138671875\n",
      "Batch: 27, Loss: 0.9734600782394409, Accuracy: 0.6689453125\n",
      "Batch: 28, Loss: 1.086874008178711, Accuracy: 0.62890625\n",
      "Batch: 29, Loss: 1.004235029220581, Accuracy: 0.6748046875\n",
      "Batch: 30, Loss: 1.0172019004821777, Accuracy: 0.6845703125\n",
      "Batch: 31, Loss: 0.9467908143997192, Accuracy: 0.7060546875\n",
      "Batch: 32, Loss: 0.945730984210968, Accuracy: 0.6953125\n",
      "Batch: 33, Loss: 1.131598949432373, Accuracy: 0.6171875\n",
      "Batch: 34, Loss: 1.1693836450576782, Accuracy: 0.62890625\n",
      "Batch: 35, Loss: 1.068949580192566, Accuracy: 0.650390625\n",
      "Batch: 36, Loss: 1.0705772638320923, Accuracy: 0.6630859375\n",
      "Batch: 37, Loss: 1.0197968482971191, Accuracy: 0.6640625\n",
      "Batch: 38, Loss: 1.0726821422576904, Accuracy: 0.6396484375\n",
      "Batch: 39, Loss: 1.0584770441055298, Accuracy: 0.666015625\n",
      "Batch: 40, Loss: 1.0783863067626953, Accuracy: 0.658203125\n",
      "Batch: 41, Loss: 1.0098665952682495, Accuracy: 0.6962890625\n",
      "Batch: 42, Loss: 0.8369590044021606, Accuracy: 0.72265625\n",
      "Batch: 43, Loss: 0.970903754234314, Accuracy: 0.6748046875\n",
      "Batch: 44, Loss: 1.0815436840057373, Accuracy: 0.6494140625\n",
      "Batch: 45, Loss: 0.9109449982643127, Accuracy: 0.6865234375\n",
      "Batch: 46, Loss: 0.978832483291626, Accuracy: 0.69140625\n",
      "Batch: 47, Loss: 1.025935411453247, Accuracy: 0.69140625\n",
      "Batch: 48, Loss: 0.9615771770477295, Accuracy: 0.6845703125\n",
      "Batch: 49, Loss: 1.1306557655334473, Accuracy: 0.638671875\n",
      "Batch: 50, Loss: 1.0687706470489502, Accuracy: 0.650390625\n",
      "Batch: 51, Loss: 1.141988754272461, Accuracy: 0.640625\n",
      "Batch: 52, Loss: 1.1297407150268555, Accuracy: 0.64453125\n",
      "Batch: 53, Loss: 0.943534255027771, Accuracy: 0.6962890625\n",
      "Batch: 54, Loss: 0.9820036888122559, Accuracy: 0.68359375\n",
      "Batch: 55, Loss: 1.085998296737671, Accuracy: 0.64453125\n",
      "Batch: 56, Loss: 1.0836875438690186, Accuracy: 0.6484375\n",
      "Batch: 57, Loss: 1.0074011087417603, Accuracy: 0.6708984375\n",
      "Batch: 58, Loss: 1.1072851419448853, Accuracy: 0.658203125\n",
      "Batch: 59, Loss: 0.9639885425567627, Accuracy: 0.6962890625\n",
      "Batch: 60, Loss: 0.9178684949874878, Accuracy: 0.6982421875\n",
      "Batch: 61, Loss: 1.0592114925384521, Accuracy: 0.66015625\n",
      "Batch: 62, Loss: 1.0056235790252686, Accuracy: 0.685546875\n",
      "Batch: 63, Loss: 1.0648226737976074, Accuracy: 0.66015625\n",
      "Batch: 64, Loss: 1.0266611576080322, Accuracy: 0.669921875\n",
      "Batch: 65, Loss: 1.0279860496520996, Accuracy: 0.681640625\n",
      "Batch: 66, Loss: 1.0033369064331055, Accuracy: 0.689453125\n",
      "Batch: 67, Loss: 1.1309552192687988, Accuracy: 0.6513671875\n",
      "Batch: 68, Loss: 1.1197326183319092, Accuracy: 0.650390625\n",
      "Batch: 69, Loss: 1.0884937047958374, Accuracy: 0.6748046875\n",
      "Batch: 70, Loss: 1.0559172630310059, Accuracy: 0.6748046875\n",
      "Batch: 71, Loss: 1.059765338897705, Accuracy: 0.669921875\n",
      "Batch: 72, Loss: 0.9292083978652954, Accuracy: 0.6953125\n",
      "Batch: 73, Loss: 0.9818304181098938, Accuracy: 0.6953125\n",
      "Batch: 74, Loss: 0.9334125518798828, Accuracy: 0.7099609375\n",
      "Batch: 75, Loss: 0.8786219358444214, Accuracy: 0.71875\n",
      "Batch: 76, Loss: 1.0390092134475708, Accuracy: 0.658203125\n",
      "Batch: 77, Loss: 0.9808933734893799, Accuracy: 0.6904296875\n",
      "Batch: 78, Loss: 0.9947080612182617, Accuracy: 0.6962890625\n",
      "Batch: 79, Loss: 0.9363272190093994, Accuracy: 0.71875\n",
      "Batch: 80, Loss: 0.9511282444000244, Accuracy: 0.6787109375\n",
      "Batch: 81, Loss: 1.0556212663650513, Accuracy: 0.650390625\n",
      "Batch: 82, Loss: 1.0264533758163452, Accuracy: 0.6748046875\n",
      "Batch: 83, Loss: 0.8758865594863892, Accuracy: 0.740234375\n",
      "Batch: 84, Loss: 0.9899405837059021, Accuracy: 0.708984375\n",
      "Batch: 85, Loss: 0.928849995136261, Accuracy: 0.7119140625\n",
      "Batch: 86, Loss: 1.1623541116714478, Accuracy: 0.6357421875\n",
      "Batch: 87, Loss: 0.9349527955055237, Accuracy: 0.7001953125\n",
      "Batch: 88, Loss: 1.0708401203155518, Accuracy: 0.6845703125\n",
      "Batch: 89, Loss: 1.0444140434265137, Accuracy: 0.6728515625\n",
      "Batch: 90, Loss: 0.956434965133667, Accuracy: 0.697265625\n",
      "Batch: 91, Loss: 1.0013582706451416, Accuracy: 0.6796875\n",
      "Batch: 92, Loss: 1.0696065425872803, Accuracy: 0.6611328125\n",
      "Batch: 93, Loss: 0.9700103998184204, Accuracy: 0.67578125\n",
      "Batch: 94, Loss: 1.0099592208862305, Accuracy: 0.6689453125\n",
      "Batch: 95, Loss: 1.0022860765457153, Accuracy: 0.65625\n",
      "Batch: 96, Loss: 0.9896482229232788, Accuracy: 0.685546875\n",
      "Batch: 97, Loss: 0.8793036937713623, Accuracy: 0.7138671875\n",
      "Batch: 98, Loss: 0.9379255771636963, Accuracy: 0.7099609375\n",
      "Batch: 99, Loss: 0.9402111768722534, Accuracy: 0.701171875\n",
      "Batch: 100, Loss: 0.9367865920066833, Accuracy: 0.7041015625\n",
      "Batch: 101, Loss: 1.0543392896652222, Accuracy: 0.6591796875\n",
      "Batch: 102, Loss: 0.9658557772636414, Accuracy: 0.69140625\n",
      "Batch: 103, Loss: 1.051763892173767, Accuracy: 0.68359375\n",
      "Batch: 104, Loss: 0.9663867950439453, Accuracy: 0.677734375\n",
      "Batch: 105, Loss: 1.0439398288726807, Accuracy: 0.673828125\n",
      "Batch: 106, Loss: 0.9843099117279053, Accuracy: 0.6875\n",
      "Batch: 107, Loss: 1.0492002964019775, Accuracy: 0.6640625\n",
      "Batch: 108, Loss: 1.0636935234069824, Accuracy: 0.65234375\n",
      "Batch: 109, Loss: 1.1312892436981201, Accuracy: 0.630859375\n",
      "Batch: 110, Loss: 0.8638636469841003, Accuracy: 0.7216796875\n",
      "Batch: 111, Loss: 1.0457584857940674, Accuracy: 0.654296875\n",
      "Batch: 112, Loss: 1.0251840353012085, Accuracy: 0.6826171875\n",
      "Batch: 113, Loss: 1.0224146842956543, Accuracy: 0.6796875\n",
      "Batch: 114, Loss: 1.0951814651489258, Accuracy: 0.64453125\n",
      "Batch: 115, Loss: 1.1471643447875977, Accuracy: 0.6591796875\n",
      "Batch: 116, Loss: 1.0629887580871582, Accuracy: 0.65625\n",
      "Batch: 117, Loss: 1.0653510093688965, Accuracy: 0.671875\n",
      "Batch: 118, Loss: 0.9226022958755493, Accuracy: 0.712890625\n",
      "Batch: 119, Loss: 0.9529757499694824, Accuracy: 0.6953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 120, Loss: 1.050247311592102, Accuracy: 0.6455078125\n",
      "Batch: 121, Loss: 1.0867347717285156, Accuracy: 0.6630859375\n",
      "Batch: 122, Loss: 0.9922860860824585, Accuracy: 0.68359375\n",
      "Batch: 123, Loss: 0.9775695204734802, Accuracy: 0.6982421875\n",
      "Batch: 124, Loss: 1.0450834035873413, Accuracy: 0.662109375\n",
      "Batch: 125, Loss: 1.057469129562378, Accuracy: 0.6767578125\n",
      "Batch: 126, Loss: 1.047475814819336, Accuracy: 0.65234375\n",
      "Batch: 127, Loss: 0.9254767298698425, Accuracy: 0.7265625\n",
      "Batch: 128, Loss: 1.1357808113098145, Accuracy: 0.6533203125\n",
      "Batch: 129, Loss: 0.97287917137146, Accuracy: 0.6884765625\n",
      "Batch: 130, Loss: 1.1531530618667603, Accuracy: 0.6279296875\n",
      "Batch: 131, Loss: 1.072029948234558, Accuracy: 0.6650390625\n",
      "Batch: 132, Loss: 1.106170415878296, Accuracy: 0.642578125\n",
      "Batch: 133, Loss: 0.9963499307632446, Accuracy: 0.662109375\n",
      "Batch: 134, Loss: 1.0218019485473633, Accuracy: 0.66015625\n",
      "Batch: 135, Loss: 1.0102102756500244, Accuracy: 0.69921875\n",
      "Batch: 136, Loss: 1.0401105880737305, Accuracy: 0.6796875\n",
      "Batch: 137, Loss: 0.9708629846572876, Accuracy: 0.6728515625\n",
      "Batch: 138, Loss: 0.8910314440727234, Accuracy: 0.708984375\n",
      "Batch: 139, Loss: 0.9312623143196106, Accuracy: 0.701171875\n",
      "Batch: 140, Loss: 0.9958975315093994, Accuracy: 0.6708984375\n",
      "Batch: 141, Loss: 1.0499331951141357, Accuracy: 0.67578125\n",
      "Batch: 142, Loss: 1.0737794637680054, Accuracy: 0.65234375\n",
      "Batch: 143, Loss: 1.038896083831787, Accuracy: 0.671875\n",
      "Batch: 144, Loss: 1.0199873447418213, Accuracy: 0.669921875\n",
      "Batch: 145, Loss: 0.9675228595733643, Accuracy: 0.6494140625\n",
      "Batch: 146, Loss: 1.0770541429519653, Accuracy: 0.6513671875\n",
      "Batch: 147, Loss: 1.0418956279754639, Accuracy: 0.654296875\n",
      "Batch: 148, Loss: 1.1200809478759766, Accuracy: 0.615234375\n",
      "Batch: 149, Loss: 0.9955710768699646, Accuracy: 0.6650390625\n",
      "Batch: 150, Loss: 1.0143502950668335, Accuracy: 0.6865234375\n",
      "Batch: 151, Loss: 0.9082446098327637, Accuracy: 0.7138671875\n",
      "Epoch 23/80\n",
      "Batch: 1, Loss: 1.1926522254943848, Accuracy: 0.591796875\n",
      "Batch: 2, Loss: 1.0379037857055664, Accuracy: 0.642578125\n",
      "Batch: 3, Loss: 0.9524591565132141, Accuracy: 0.6826171875\n",
      "Batch: 4, Loss: 0.9152789115905762, Accuracy: 0.701171875\n",
      "Batch: 5, Loss: 0.9570149183273315, Accuracy: 0.6943359375\n",
      "Batch: 6, Loss: 1.019517421722412, Accuracy: 0.6748046875\n",
      "Batch: 7, Loss: 0.9760473966598511, Accuracy: 0.6943359375\n",
      "Batch: 8, Loss: 0.9674925804138184, Accuracy: 0.681640625\n",
      "Batch: 9, Loss: 0.9311936497688293, Accuracy: 0.7060546875\n",
      "Batch: 10, Loss: 0.9329277276992798, Accuracy: 0.68359375\n",
      "Batch: 11, Loss: 1.0763729810714722, Accuracy: 0.6435546875\n",
      "Batch: 12, Loss: 1.086262583732605, Accuracy: 0.6591796875\n",
      "Batch: 13, Loss: 0.8597119450569153, Accuracy: 0.71875\n",
      "Batch: 14, Loss: 1.090531349182129, Accuracy: 0.6484375\n",
      "Batch: 15, Loss: 0.9821197986602783, Accuracy: 0.7001953125\n",
      "Batch: 16, Loss: 0.9604237675666809, Accuracy: 0.693359375\n",
      "Batch: 17, Loss: 1.0325778722763062, Accuracy: 0.6630859375\n",
      "Batch: 18, Loss: 1.053088665008545, Accuracy: 0.662109375\n",
      "Batch: 19, Loss: 1.0886502265930176, Accuracy: 0.65625\n",
      "Batch: 20, Loss: 1.004241704940796, Accuracy: 0.6865234375\n",
      "Batch: 21, Loss: 0.9608350992202759, Accuracy: 0.6728515625\n",
      "Batch: 22, Loss: 1.0865890979766846, Accuracy: 0.65234375\n",
      "Batch: 23, Loss: 1.0189203023910522, Accuracy: 0.6650390625\n",
      "Batch: 24, Loss: 1.0326015949249268, Accuracy: 0.677734375\n",
      "Batch: 25, Loss: 1.0009331703186035, Accuracy: 0.669921875\n",
      "Batch: 26, Loss: 0.8960012197494507, Accuracy: 0.7119140625\n",
      "Batch: 27, Loss: 0.9429434537887573, Accuracy: 0.6865234375\n",
      "Batch: 28, Loss: 1.022312879562378, Accuracy: 0.6533203125\n",
      "Batch: 29, Loss: 1.00392484664917, Accuracy: 0.681640625\n",
      "Batch: 30, Loss: 0.9952226877212524, Accuracy: 0.6904296875\n",
      "Batch: 31, Loss: 0.938731849193573, Accuracy: 0.705078125\n",
      "Batch: 32, Loss: 0.9314874410629272, Accuracy: 0.7021484375\n",
      "Batch: 33, Loss: 1.1230460405349731, Accuracy: 0.64453125\n",
      "Batch: 34, Loss: 1.1643881797790527, Accuracy: 0.6259765625\n",
      "Batch: 35, Loss: 1.0572841167449951, Accuracy: 0.658203125\n",
      "Batch: 36, Loss: 1.0645043849945068, Accuracy: 0.6533203125\n",
      "Batch: 37, Loss: 0.9717060327529907, Accuracy: 0.681640625\n",
      "Batch: 38, Loss: 1.034637689590454, Accuracy: 0.65625\n",
      "Batch: 39, Loss: 1.0364177227020264, Accuracy: 0.666015625\n",
      "Batch: 40, Loss: 1.072121262550354, Accuracy: 0.65625\n",
      "Batch: 41, Loss: 0.977776825428009, Accuracy: 0.69921875\n",
      "Batch: 42, Loss: 0.7902151942253113, Accuracy: 0.7451171875\n",
      "Batch: 43, Loss: 0.9547476768493652, Accuracy: 0.69140625\n",
      "Batch: 44, Loss: 1.036136507987976, Accuracy: 0.658203125\n",
      "Batch: 45, Loss: 0.9114192724227905, Accuracy: 0.697265625\n",
      "Batch: 46, Loss: 0.9841872453689575, Accuracy: 0.69921875\n",
      "Batch: 47, Loss: 0.9816570281982422, Accuracy: 0.6943359375\n",
      "Batch: 48, Loss: 0.9260537624359131, Accuracy: 0.6943359375\n",
      "Batch: 49, Loss: 1.1079612970352173, Accuracy: 0.650390625\n",
      "Batch: 50, Loss: 1.0622315406799316, Accuracy: 0.6650390625\n",
      "Batch: 51, Loss: 1.1477084159851074, Accuracy: 0.6396484375\n",
      "Batch: 52, Loss: 1.0761696100234985, Accuracy: 0.662109375\n",
      "Batch: 53, Loss: 0.919472873210907, Accuracy: 0.69921875\n",
      "Batch: 54, Loss: 0.9684784412384033, Accuracy: 0.6943359375\n",
      "Batch: 55, Loss: 1.081822156906128, Accuracy: 0.6484375\n",
      "Batch: 56, Loss: 1.0639333724975586, Accuracy: 0.6591796875\n",
      "Batch: 57, Loss: 1.0057836771011353, Accuracy: 0.68359375\n",
      "Batch: 58, Loss: 1.1078286170959473, Accuracy: 0.65625\n",
      "Batch: 59, Loss: 0.9728603363037109, Accuracy: 0.7080078125\n",
      "Batch: 60, Loss: 0.9180437326431274, Accuracy: 0.7001953125\n",
      "Batch: 61, Loss: 1.0336610078811646, Accuracy: 0.6630859375\n",
      "Batch: 62, Loss: 1.00789213180542, Accuracy: 0.6787109375\n",
      "Batch: 63, Loss: 1.0587348937988281, Accuracy: 0.6650390625\n",
      "Batch: 64, Loss: 1.009244441986084, Accuracy: 0.681640625\n",
      "Batch: 65, Loss: 1.0220218896865845, Accuracy: 0.69140625\n",
      "Batch: 66, Loss: 0.9852839112281799, Accuracy: 0.6982421875\n",
      "Batch: 67, Loss: 1.0952000617980957, Accuracy: 0.6611328125\n",
      "Batch: 68, Loss: 1.1127233505249023, Accuracy: 0.65625\n",
      "Batch: 69, Loss: 1.0541694164276123, Accuracy: 0.671875\n",
      "Batch: 70, Loss: 1.0304540395736694, Accuracy: 0.681640625\n",
      "Batch: 71, Loss: 1.0376579761505127, Accuracy: 0.6748046875\n",
      "Batch: 72, Loss: 0.9193474054336548, Accuracy: 0.708984375\n",
      "Batch: 73, Loss: 0.9629083871841431, Accuracy: 0.705078125\n",
      "Batch: 74, Loss: 0.9217615723609924, Accuracy: 0.7109375\n",
      "Batch: 75, Loss: 0.9000357985496521, Accuracy: 0.7109375\n",
      "Batch: 76, Loss: 0.98226398229599, Accuracy: 0.677734375\n",
      "Batch: 77, Loss: 0.948413610458374, Accuracy: 0.6884765625\n",
      "Batch: 78, Loss: 0.9748567938804626, Accuracy: 0.7021484375\n",
      "Batch: 79, Loss: 0.9337648749351501, Accuracy: 0.7197265625\n",
      "Batch: 80, Loss: 0.9527926445007324, Accuracy: 0.67578125\n",
      "Batch: 81, Loss: 1.0809855461120605, Accuracy: 0.625\n",
      "Batch: 82, Loss: 1.0235439538955688, Accuracy: 0.66796875\n",
      "Batch: 83, Loss: 0.8814213275909424, Accuracy: 0.736328125\n",
      "Batch: 84, Loss: 0.9684727191925049, Accuracy: 0.7041015625\n",
      "Batch: 85, Loss: 0.9367730021476746, Accuracy: 0.7109375\n",
      "Batch: 86, Loss: 1.1232006549835205, Accuracy: 0.65625\n",
      "Batch: 87, Loss: 0.9149694442749023, Accuracy: 0.703125\n",
      "Batch: 88, Loss: 1.05095636844635, Accuracy: 0.6875\n",
      "Batch: 89, Loss: 1.0347092151641846, Accuracy: 0.6708984375\n",
      "Batch: 90, Loss: 0.9605664014816284, Accuracy: 0.697265625\n",
      "Batch: 91, Loss: 1.0041818618774414, Accuracy: 0.67578125\n",
      "Batch: 92, Loss: 1.0242397785186768, Accuracy: 0.6845703125\n",
      "Batch: 93, Loss: 0.9832577705383301, Accuracy: 0.6728515625\n",
      "Batch: 94, Loss: 1.004737377166748, Accuracy: 0.677734375\n",
      "Batch: 95, Loss: 1.010522484779358, Accuracy: 0.650390625\n",
      "Batch: 96, Loss: 0.9728847742080688, Accuracy: 0.6923828125\n",
      "Batch: 97, Loss: 0.8481943607330322, Accuracy: 0.708984375\n",
      "Batch: 98, Loss: 0.9250820875167847, Accuracy: 0.708984375\n",
      "Batch: 99, Loss: 0.9279848337173462, Accuracy: 0.705078125\n",
      "Batch: 100, Loss: 0.9786032438278198, Accuracy: 0.6796875\n",
      "Batch: 101, Loss: 1.052675485610962, Accuracy: 0.6572265625\n",
      "Batch: 102, Loss: 0.9817392826080322, Accuracy: 0.6796875\n",
      "Batch: 103, Loss: 1.0206221342086792, Accuracy: 0.6796875\n",
      "Batch: 104, Loss: 0.9312135577201843, Accuracy: 0.7041015625\n",
      "Batch: 105, Loss: 1.0122647285461426, Accuracy: 0.662109375\n",
      "Batch: 106, Loss: 0.9731065630912781, Accuracy: 0.6982421875\n",
      "Batch: 107, Loss: 1.051806926727295, Accuracy: 0.6708984375\n",
      "Batch: 108, Loss: 1.011243224143982, Accuracy: 0.6708984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 109, Loss: 1.0879335403442383, Accuracy: 0.65234375\n",
      "Batch: 110, Loss: 0.8780173659324646, Accuracy: 0.72265625\n",
      "Batch: 111, Loss: 1.034928560256958, Accuracy: 0.671875\n",
      "Batch: 112, Loss: 0.9909574389457703, Accuracy: 0.67578125\n",
      "Batch: 113, Loss: 1.0082608461380005, Accuracy: 0.6865234375\n",
      "Batch: 114, Loss: 1.0654923915863037, Accuracy: 0.6533203125\n",
      "Batch: 115, Loss: 1.1215672492980957, Accuracy: 0.64453125\n",
      "Batch: 116, Loss: 1.0601991415023804, Accuracy: 0.6513671875\n",
      "Batch: 117, Loss: 1.0806646347045898, Accuracy: 0.6572265625\n",
      "Batch: 118, Loss: 0.9075382947921753, Accuracy: 0.7109375\n",
      "Batch: 119, Loss: 0.9065350294113159, Accuracy: 0.7333984375\n",
      "Batch: 120, Loss: 1.0359644889831543, Accuracy: 0.669921875\n",
      "Batch: 121, Loss: 1.031389832496643, Accuracy: 0.662109375\n",
      "Batch: 122, Loss: 0.9886113405227661, Accuracy: 0.6884765625\n",
      "Batch: 123, Loss: 0.9704005718231201, Accuracy: 0.6953125\n",
      "Batch: 124, Loss: 1.0169693231582642, Accuracy: 0.6640625\n",
      "Batch: 125, Loss: 1.0488245487213135, Accuracy: 0.671875\n",
      "Batch: 126, Loss: 0.9886907935142517, Accuracy: 0.666015625\n",
      "Batch: 127, Loss: 0.9286152720451355, Accuracy: 0.72265625\n",
      "Batch: 128, Loss: 1.1441280841827393, Accuracy: 0.65625\n",
      "Batch: 129, Loss: 0.9365040063858032, Accuracy: 0.693359375\n",
      "Batch: 130, Loss: 1.1380243301391602, Accuracy: 0.640625\n",
      "Batch: 131, Loss: 1.0383023023605347, Accuracy: 0.666015625\n",
      "Batch: 132, Loss: 1.0838022232055664, Accuracy: 0.6611328125\n",
      "Batch: 133, Loss: 0.9611071348190308, Accuracy: 0.671875\n",
      "Batch: 134, Loss: 1.0458147525787354, Accuracy: 0.6513671875\n",
      "Batch: 135, Loss: 0.977042019367218, Accuracy: 0.7021484375\n",
      "Batch: 136, Loss: 1.0224577188491821, Accuracy: 0.6787109375\n",
      "Batch: 137, Loss: 0.9596942663192749, Accuracy: 0.6806640625\n",
      "Batch: 138, Loss: 0.8526701927185059, Accuracy: 0.7373046875\n",
      "Batch: 139, Loss: 0.8890388607978821, Accuracy: 0.7041015625\n",
      "Batch: 140, Loss: 1.0133607387542725, Accuracy: 0.6826171875\n",
      "Batch: 141, Loss: 0.9948647022247314, Accuracy: 0.6767578125\n",
      "Batch: 142, Loss: 1.077862024307251, Accuracy: 0.6552734375\n",
      "Batch: 143, Loss: 1.018629550933838, Accuracy: 0.68359375\n",
      "Batch: 144, Loss: 0.9820109009742737, Accuracy: 0.697265625\n",
      "Batch: 145, Loss: 0.9298160076141357, Accuracy: 0.6796875\n",
      "Batch: 146, Loss: 1.0578665733337402, Accuracy: 0.65625\n",
      "Batch: 147, Loss: 1.0442488193511963, Accuracy: 0.6474609375\n",
      "Batch: 148, Loss: 1.1146535873413086, Accuracy: 0.6376953125\n",
      "Batch: 149, Loss: 0.9735205769538879, Accuracy: 0.6787109375\n",
      "Batch: 150, Loss: 1.023955225944519, Accuracy: 0.6787109375\n",
      "Batch: 151, Loss: 0.8966989517211914, Accuracy: 0.7236328125\n",
      "Epoch 24/80\n",
      "Batch: 1, Loss: 1.1535149812698364, Accuracy: 0.6162109375\n",
      "Batch: 2, Loss: 1.0512633323669434, Accuracy: 0.6611328125\n",
      "Batch: 3, Loss: 0.9287890195846558, Accuracy: 0.689453125\n",
      "Batch: 4, Loss: 0.8901208639144897, Accuracy: 0.7236328125\n",
      "Batch: 5, Loss: 0.9452835321426392, Accuracy: 0.6982421875\n",
      "Batch: 6, Loss: 0.9824447631835938, Accuracy: 0.673828125\n",
      "Batch: 7, Loss: 0.9403515458106995, Accuracy: 0.69921875\n",
      "Batch: 8, Loss: 0.9502816200256348, Accuracy: 0.6650390625\n",
      "Batch: 9, Loss: 0.9081519842147827, Accuracy: 0.7021484375\n",
      "Batch: 10, Loss: 0.9492137432098389, Accuracy: 0.6943359375\n",
      "Batch: 11, Loss: 1.0389505624771118, Accuracy: 0.6552734375\n",
      "Batch: 12, Loss: 1.0524864196777344, Accuracy: 0.6728515625\n",
      "Batch: 13, Loss: 0.8471308946609497, Accuracy: 0.7255859375\n",
      "Batch: 14, Loss: 1.1091601848602295, Accuracy: 0.623046875\n",
      "Batch: 15, Loss: 0.9302425384521484, Accuracy: 0.7119140625\n",
      "Batch: 16, Loss: 0.9361094832420349, Accuracy: 0.69921875\n",
      "Batch: 17, Loss: 0.995613694190979, Accuracy: 0.6767578125\n",
      "Batch: 18, Loss: 1.0163260698318481, Accuracy: 0.6923828125\n",
      "Batch: 19, Loss: 1.0664218664169312, Accuracy: 0.671875\n",
      "Batch: 20, Loss: 0.958956778049469, Accuracy: 0.716796875\n",
      "Batch: 21, Loss: 0.9440781474113464, Accuracy: 0.6923828125\n",
      "Batch: 22, Loss: 1.070566177368164, Accuracy: 0.6572265625\n",
      "Batch: 23, Loss: 1.0012198686599731, Accuracy: 0.66796875\n",
      "Batch: 24, Loss: 1.022642970085144, Accuracy: 0.6630859375\n",
      "Batch: 25, Loss: 0.9580433964729309, Accuracy: 0.68359375\n",
      "Batch: 26, Loss: 0.9024487137794495, Accuracy: 0.708984375\n",
      "Batch: 27, Loss: 0.9366260766983032, Accuracy: 0.6904296875\n",
      "Batch: 28, Loss: 1.021714448928833, Accuracy: 0.65234375\n",
      "Batch: 29, Loss: 0.9655450582504272, Accuracy: 0.6796875\n",
      "Batch: 30, Loss: 0.961331307888031, Accuracy: 0.705078125\n",
      "Batch: 31, Loss: 0.8997217416763306, Accuracy: 0.7177734375\n",
      "Batch: 32, Loss: 0.9120973348617554, Accuracy: 0.697265625\n",
      "Batch: 33, Loss: 1.091489315032959, Accuracy: 0.640625\n",
      "Batch: 34, Loss: 1.136311411857605, Accuracy: 0.638671875\n",
      "Batch: 35, Loss: 1.0220012664794922, Accuracy: 0.66015625\n",
      "Batch: 36, Loss: 1.0402703285217285, Accuracy: 0.6669921875\n",
      "Batch: 37, Loss: 0.985279381275177, Accuracy: 0.6826171875\n",
      "Batch: 38, Loss: 1.0193963050842285, Accuracy: 0.6533203125\n",
      "Batch: 39, Loss: 1.0059876441955566, Accuracy: 0.681640625\n",
      "Batch: 40, Loss: 1.0300592184066772, Accuracy: 0.6806640625\n",
      "Batch: 41, Loss: 0.9645376205444336, Accuracy: 0.6865234375\n",
      "Batch: 42, Loss: 0.7750056982040405, Accuracy: 0.744140625\n",
      "Batch: 43, Loss: 0.9585025310516357, Accuracy: 0.685546875\n",
      "Batch: 44, Loss: 1.0221307277679443, Accuracy: 0.6533203125\n",
      "Batch: 45, Loss: 0.8655012845993042, Accuracy: 0.708984375\n",
      "Batch: 46, Loss: 0.9709094762802124, Accuracy: 0.7080078125\n",
      "Batch: 47, Loss: 0.985065221786499, Accuracy: 0.697265625\n",
      "Batch: 48, Loss: 0.9163705706596375, Accuracy: 0.7001953125\n",
      "Batch: 49, Loss: 1.0952913761138916, Accuracy: 0.6640625\n",
      "Batch: 50, Loss: 1.0399622917175293, Accuracy: 0.6513671875\n",
      "Batch: 51, Loss: 1.1075741052627563, Accuracy: 0.650390625\n",
      "Batch: 52, Loss: 1.075939416885376, Accuracy: 0.6650390625\n",
      "Batch: 53, Loss: 0.9060239791870117, Accuracy: 0.6943359375\n",
      "Batch: 54, Loss: 0.974532425403595, Accuracy: 0.69140625\n",
      "Batch: 55, Loss: 1.064943790435791, Accuracy: 0.6533203125\n",
      "Batch: 56, Loss: 1.0515720844268799, Accuracy: 0.6640625\n",
      "Batch: 57, Loss: 1.0025787353515625, Accuracy: 0.6796875\n",
      "Batch: 58, Loss: 1.083475112915039, Accuracy: 0.6630859375\n",
      "Batch: 59, Loss: 0.943901002407074, Accuracy: 0.7001953125\n",
      "Batch: 60, Loss: 0.9060249924659729, Accuracy: 0.69140625\n",
      "Batch: 61, Loss: 1.0352389812469482, Accuracy: 0.6650390625\n",
      "Batch: 62, Loss: 0.9751459956169128, Accuracy: 0.673828125\n",
      "Batch: 63, Loss: 1.0086243152618408, Accuracy: 0.6845703125\n",
      "Batch: 64, Loss: 0.9676920771598816, Accuracy: 0.6982421875\n",
      "Batch: 65, Loss: 1.0302808284759521, Accuracy: 0.689453125\n",
      "Batch: 66, Loss: 0.9724663496017456, Accuracy: 0.701171875\n",
      "Batch: 67, Loss: 1.0893096923828125, Accuracy: 0.65234375\n",
      "Batch: 68, Loss: 1.1057519912719727, Accuracy: 0.65625\n",
      "Batch: 69, Loss: 1.041782259941101, Accuracy: 0.6826171875\n",
      "Batch: 70, Loss: 1.0191279649734497, Accuracy: 0.6904296875\n",
      "Batch: 71, Loss: 1.0173945426940918, Accuracy: 0.669921875\n",
      "Batch: 72, Loss: 0.8728939294815063, Accuracy: 0.732421875\n",
      "Batch: 73, Loss: 0.9368736743927002, Accuracy: 0.7119140625\n",
      "Batch: 74, Loss: 0.9023885726928711, Accuracy: 0.712890625\n",
      "Batch: 75, Loss: 0.8707765340805054, Accuracy: 0.7255859375\n",
      "Batch: 76, Loss: 0.9785106778144836, Accuracy: 0.6728515625\n",
      "Batch: 77, Loss: 0.9348185062408447, Accuracy: 0.6953125\n",
      "Batch: 78, Loss: 0.9668270349502563, Accuracy: 0.703125\n",
      "Batch: 79, Loss: 0.9264079928398132, Accuracy: 0.73046875\n",
      "Batch: 80, Loss: 0.9163295030593872, Accuracy: 0.6884765625\n",
      "Batch: 81, Loss: 1.044766902923584, Accuracy: 0.6240234375\n",
      "Batch: 82, Loss: 0.9878775477409363, Accuracy: 0.66796875\n",
      "Batch: 83, Loss: 0.8680603504180908, Accuracy: 0.732421875\n",
      "Batch: 84, Loss: 0.9602258205413818, Accuracy: 0.69921875\n",
      "Batch: 85, Loss: 0.8983126282691956, Accuracy: 0.720703125\n",
      "Batch: 86, Loss: 1.1147518157958984, Accuracy: 0.66015625\n",
      "Batch: 87, Loss: 0.8995906114578247, Accuracy: 0.7060546875\n",
      "Batch: 88, Loss: 1.0516345500946045, Accuracy: 0.68359375\n",
      "Batch: 89, Loss: 1.0136932134628296, Accuracy: 0.69140625\n",
      "Batch: 90, Loss: 0.9348781704902649, Accuracy: 0.703125\n",
      "Batch: 91, Loss: 0.9667551517486572, Accuracy: 0.685546875\n",
      "Batch: 92, Loss: 1.0245493650436401, Accuracy: 0.673828125\n",
      "Batch: 93, Loss: 0.9568684697151184, Accuracy: 0.6884765625\n",
      "Batch: 94, Loss: 0.9800087213516235, Accuracy: 0.6806640625\n",
      "Batch: 95, Loss: 0.9778487682342529, Accuracy: 0.6650390625\n",
      "Batch: 96, Loss: 0.9725604057312012, Accuracy: 0.689453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 97, Loss: 0.8452897667884827, Accuracy: 0.7158203125\n",
      "Batch: 98, Loss: 0.9201657772064209, Accuracy: 0.7080078125\n",
      "Batch: 99, Loss: 0.8997576236724854, Accuracy: 0.703125\n",
      "Batch: 100, Loss: 0.9522759914398193, Accuracy: 0.6865234375\n",
      "Batch: 101, Loss: 1.006611943244934, Accuracy: 0.69140625\n",
      "Batch: 102, Loss: 0.9508626461029053, Accuracy: 0.6953125\n",
      "Batch: 103, Loss: 1.0172388553619385, Accuracy: 0.703125\n",
      "Batch: 104, Loss: 0.919359564781189, Accuracy: 0.6923828125\n",
      "Batch: 105, Loss: 0.9795063734054565, Accuracy: 0.689453125\n",
      "Batch: 106, Loss: 0.9481618404388428, Accuracy: 0.6884765625\n",
      "Batch: 107, Loss: 1.0339547395706177, Accuracy: 0.6728515625\n",
      "Batch: 108, Loss: 0.9905179738998413, Accuracy: 0.6806640625\n",
      "Batch: 109, Loss: 1.082846999168396, Accuracy: 0.64453125\n",
      "Batch: 110, Loss: 0.8595744371414185, Accuracy: 0.7158203125\n",
      "Batch: 111, Loss: 1.0229474306106567, Accuracy: 0.6640625\n",
      "Batch: 112, Loss: 0.9683249592781067, Accuracy: 0.6982421875\n",
      "Batch: 113, Loss: 0.9844796657562256, Accuracy: 0.671875\n",
      "Batch: 114, Loss: 1.036846399307251, Accuracy: 0.6650390625\n",
      "Batch: 115, Loss: 1.1216764450073242, Accuracy: 0.662109375\n",
      "Batch: 116, Loss: 1.010408878326416, Accuracy: 0.6787109375\n",
      "Batch: 117, Loss: 1.0321528911590576, Accuracy: 0.681640625\n",
      "Batch: 118, Loss: 0.865204930305481, Accuracy: 0.7236328125\n",
      "Batch: 119, Loss: 0.9165370464324951, Accuracy: 0.708984375\n",
      "Batch: 120, Loss: 1.012447476387024, Accuracy: 0.6708984375\n",
      "Batch: 121, Loss: 1.0379443168640137, Accuracy: 0.662109375\n",
      "Batch: 122, Loss: 0.9763962030410767, Accuracy: 0.7001953125\n",
      "Batch: 123, Loss: 0.9509772062301636, Accuracy: 0.697265625\n",
      "Batch: 124, Loss: 1.0139431953430176, Accuracy: 0.6689453125\n",
      "Batch: 125, Loss: 1.031585693359375, Accuracy: 0.6611328125\n",
      "Batch: 126, Loss: 1.0021361112594604, Accuracy: 0.68359375\n",
      "Batch: 127, Loss: 0.9117562174797058, Accuracy: 0.71484375\n",
      "Batch: 128, Loss: 1.1036547422409058, Accuracy: 0.669921875\n",
      "Batch: 129, Loss: 0.9370905160903931, Accuracy: 0.7001953125\n",
      "Batch: 130, Loss: 1.1305252313613892, Accuracy: 0.6396484375\n",
      "Batch: 131, Loss: 1.0615111589431763, Accuracy: 0.662109375\n",
      "Batch: 132, Loss: 1.0696561336517334, Accuracy: 0.6748046875\n",
      "Batch: 133, Loss: 0.9551287889480591, Accuracy: 0.6787109375\n",
      "Batch: 134, Loss: 1.0173251628875732, Accuracy: 0.6611328125\n",
      "Batch: 135, Loss: 0.9630441069602966, Accuracy: 0.72265625\n",
      "Batch: 136, Loss: 1.0148119926452637, Accuracy: 0.689453125\n",
      "Batch: 137, Loss: 0.9457588195800781, Accuracy: 0.6884765625\n",
      "Batch: 138, Loss: 0.8616147637367249, Accuracy: 0.7080078125\n",
      "Batch: 139, Loss: 0.8966118693351746, Accuracy: 0.712890625\n",
      "Batch: 140, Loss: 0.9873756170272827, Accuracy: 0.6806640625\n",
      "Batch: 141, Loss: 0.9869654178619385, Accuracy: 0.6953125\n",
      "Batch: 142, Loss: 1.0706595182418823, Accuracy: 0.64453125\n",
      "Batch: 143, Loss: 1.0084562301635742, Accuracy: 0.6650390625\n",
      "Batch: 144, Loss: 0.9481171369552612, Accuracy: 0.6884765625\n",
      "Batch: 145, Loss: 0.9241275787353516, Accuracy: 0.6845703125\n",
      "Batch: 146, Loss: 1.043424367904663, Accuracy: 0.6572265625\n",
      "Batch: 147, Loss: 1.0084724426269531, Accuracy: 0.66796875\n",
      "Batch: 148, Loss: 1.1073403358459473, Accuracy: 0.634765625\n",
      "Batch: 149, Loss: 0.9800643920898438, Accuracy: 0.6845703125\n",
      "Batch: 150, Loss: 0.9661356210708618, Accuracy: 0.69140625\n",
      "Batch: 151, Loss: 0.8659511208534241, Accuracy: 0.7294921875\n",
      "Epoch 25/80\n",
      "Batch: 1, Loss: 1.1546775102615356, Accuracy: 0.6142578125\n",
      "Batch: 2, Loss: 1.0450565814971924, Accuracy: 0.640625\n",
      "Batch: 3, Loss: 0.9373603463172913, Accuracy: 0.6943359375\n",
      "Batch: 4, Loss: 0.8874917030334473, Accuracy: 0.720703125\n",
      "Batch: 5, Loss: 0.9299994111061096, Accuracy: 0.7177734375\n",
      "Batch: 6, Loss: 0.976553201675415, Accuracy: 0.6796875\n",
      "Batch: 7, Loss: 0.9877449870109558, Accuracy: 0.669921875\n",
      "Batch: 8, Loss: 0.9251153469085693, Accuracy: 0.693359375\n",
      "Batch: 9, Loss: 0.9232775568962097, Accuracy: 0.70703125\n",
      "Batch: 10, Loss: 0.9284356832504272, Accuracy: 0.6904296875\n",
      "Batch: 11, Loss: 1.0449209213256836, Accuracy: 0.6435546875\n",
      "Batch: 12, Loss: 0.9958959817886353, Accuracy: 0.701171875\n",
      "Batch: 13, Loss: 0.8286559581756592, Accuracy: 0.7255859375\n",
      "Batch: 14, Loss: 1.0800056457519531, Accuracy: 0.6396484375\n",
      "Batch: 15, Loss: 0.9043963551521301, Accuracy: 0.71875\n",
      "Batch: 16, Loss: 0.904036283493042, Accuracy: 0.7197265625\n",
      "Batch: 17, Loss: 1.0046226978302002, Accuracy: 0.677734375\n",
      "Batch: 18, Loss: 1.0176650285720825, Accuracy: 0.6787109375\n",
      "Batch: 19, Loss: 1.035949468612671, Accuracy: 0.689453125\n",
      "Batch: 20, Loss: 0.9544346928596497, Accuracy: 0.7041015625\n",
      "Batch: 21, Loss: 0.939307451248169, Accuracy: 0.6728515625\n",
      "Batch: 22, Loss: 1.0534937381744385, Accuracy: 0.6513671875\n",
      "Batch: 23, Loss: 0.990257978439331, Accuracy: 0.6904296875\n",
      "Batch: 24, Loss: 1.0170085430145264, Accuracy: 0.6630859375\n",
      "Batch: 25, Loss: 0.972138524055481, Accuracy: 0.6845703125\n",
      "Batch: 26, Loss: 0.8612431883811951, Accuracy: 0.724609375\n",
      "Batch: 27, Loss: 0.9237489700317383, Accuracy: 0.6748046875\n",
      "Batch: 28, Loss: 0.996442437171936, Accuracy: 0.6767578125\n",
      "Batch: 29, Loss: 0.9723833203315735, Accuracy: 0.6904296875\n",
      "Batch: 30, Loss: 0.9815847873687744, Accuracy: 0.6953125\n",
      "Batch: 31, Loss: 0.8699787855148315, Accuracy: 0.73046875\n",
      "Batch: 32, Loss: 0.9278527498245239, Accuracy: 0.6845703125\n",
      "Batch: 33, Loss: 1.1074762344360352, Accuracy: 0.64453125\n",
      "Batch: 34, Loss: 1.1368485689163208, Accuracy: 0.638671875\n",
      "Batch: 35, Loss: 1.0351827144622803, Accuracy: 0.6533203125\n",
      "Batch: 36, Loss: 1.0238826274871826, Accuracy: 0.6884765625\n",
      "Batch: 37, Loss: 0.9793574810028076, Accuracy: 0.6962890625\n",
      "Batch: 38, Loss: 1.010870337486267, Accuracy: 0.67578125\n",
      "Batch: 39, Loss: 0.998862624168396, Accuracy: 0.671875\n",
      "Batch: 40, Loss: 1.0093748569488525, Accuracy: 0.689453125\n",
      "Batch: 41, Loss: 0.9940510392189026, Accuracy: 0.673828125\n",
      "Batch: 42, Loss: 0.77112877368927, Accuracy: 0.7509765625\n",
      "Batch: 43, Loss: 0.9380133748054504, Accuracy: 0.67578125\n",
      "Batch: 44, Loss: 0.9833300113677979, Accuracy: 0.6845703125\n",
      "Batch: 45, Loss: 0.8585559129714966, Accuracy: 0.7177734375\n",
      "Batch: 46, Loss: 0.9334021806716919, Accuracy: 0.71484375\n",
      "Batch: 47, Loss: 0.9698072671890259, Accuracy: 0.693359375\n",
      "Batch: 48, Loss: 0.9322428703308105, Accuracy: 0.693359375\n",
      "Batch: 49, Loss: 1.0958778858184814, Accuracy: 0.6474609375\n",
      "Batch: 50, Loss: 1.0200259685516357, Accuracy: 0.662109375\n",
      "Batch: 51, Loss: 1.0622012615203857, Accuracy: 0.66015625\n",
      "Batch: 52, Loss: 1.0385123491287231, Accuracy: 0.66796875\n",
      "Batch: 53, Loss: 0.901739239692688, Accuracy: 0.7041015625\n",
      "Batch: 54, Loss: 0.9601767063140869, Accuracy: 0.705078125\n",
      "Batch: 55, Loss: 1.0779099464416504, Accuracy: 0.6513671875\n",
      "Batch: 56, Loss: 1.021613597869873, Accuracy: 0.6650390625\n",
      "Batch: 57, Loss: 0.9789189100265503, Accuracy: 0.697265625\n",
      "Batch: 58, Loss: 1.0802414417266846, Accuracy: 0.6611328125\n",
      "Batch: 59, Loss: 0.9612622857093811, Accuracy: 0.6962890625\n",
      "Batch: 60, Loss: 0.9128637313842773, Accuracy: 0.7041015625\n",
      "Batch: 61, Loss: 0.9939981698989868, Accuracy: 0.6689453125\n",
      "Batch: 62, Loss: 0.9359932541847229, Accuracy: 0.7001953125\n",
      "Batch: 63, Loss: 1.0175765752792358, Accuracy: 0.681640625\n",
      "Batch: 64, Loss: 0.9639975428581238, Accuracy: 0.7060546875\n",
      "Batch: 65, Loss: 0.9970512390136719, Accuracy: 0.681640625\n",
      "Batch: 66, Loss: 0.9609043002128601, Accuracy: 0.6982421875\n",
      "Batch: 67, Loss: 1.092201828956604, Accuracy: 0.6435546875\n",
      "Batch: 68, Loss: 1.059567928314209, Accuracy: 0.654296875\n",
      "Batch: 69, Loss: 1.0274081230163574, Accuracy: 0.6806640625\n",
      "Batch: 70, Loss: 1.0068910121917725, Accuracy: 0.703125\n",
      "Batch: 71, Loss: 0.9849073886871338, Accuracy: 0.697265625\n",
      "Batch: 72, Loss: 0.9047235250473022, Accuracy: 0.724609375\n",
      "Batch: 73, Loss: 0.9167882204055786, Accuracy: 0.71484375\n",
      "Batch: 74, Loss: 0.9001469612121582, Accuracy: 0.716796875\n",
      "Batch: 75, Loss: 0.852725625038147, Accuracy: 0.7265625\n",
      "Batch: 76, Loss: 0.9525142908096313, Accuracy: 0.689453125\n",
      "Batch: 77, Loss: 0.9587600231170654, Accuracy: 0.689453125\n",
      "Batch: 78, Loss: 0.9468299150466919, Accuracy: 0.712890625\n",
      "Batch: 79, Loss: 0.8665077686309814, Accuracy: 0.7373046875\n",
      "Batch: 80, Loss: 0.9265828728675842, Accuracy: 0.6884765625\n",
      "Batch: 81, Loss: 1.031313180923462, Accuracy: 0.6484375\n",
      "Batch: 82, Loss: 0.9638025760650635, Accuracy: 0.6748046875\n",
      "Batch: 83, Loss: 0.8502277135848999, Accuracy: 0.7353515625\n",
      "Batch: 84, Loss: 0.9300162196159363, Accuracy: 0.7109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 85, Loss: 0.8862950801849365, Accuracy: 0.72265625\n",
      "Batch: 86, Loss: 1.0796599388122559, Accuracy: 0.650390625\n",
      "Batch: 87, Loss: 0.869384229183197, Accuracy: 0.7294921875\n",
      "Batch: 88, Loss: 1.0285570621490479, Accuracy: 0.6982421875\n",
      "Batch: 89, Loss: 0.9734927415847778, Accuracy: 0.7021484375\n",
      "Batch: 90, Loss: 0.8984807729721069, Accuracy: 0.712890625\n",
      "Batch: 91, Loss: 0.9658443927764893, Accuracy: 0.689453125\n",
      "Batch: 92, Loss: 1.0094326734542847, Accuracy: 0.6787109375\n",
      "Batch: 93, Loss: 0.9473292231559753, Accuracy: 0.69921875\n",
      "Batch: 94, Loss: 0.9645918011665344, Accuracy: 0.689453125\n",
      "Batch: 95, Loss: 0.9808114171028137, Accuracy: 0.6767578125\n",
      "Batch: 96, Loss: 0.9489967823028564, Accuracy: 0.7119140625\n",
      "Batch: 97, Loss: 0.8332123756408691, Accuracy: 0.7080078125\n",
      "Batch: 98, Loss: 0.8962606191635132, Accuracy: 0.7080078125\n",
      "Batch: 99, Loss: 0.9093054533004761, Accuracy: 0.7021484375\n",
      "Batch: 100, Loss: 0.9295132160186768, Accuracy: 0.6962890625\n",
      "Batch: 101, Loss: 1.0190553665161133, Accuracy: 0.671875\n",
      "Batch: 102, Loss: 0.9607391357421875, Accuracy: 0.6904296875\n",
      "Batch: 103, Loss: 1.0211868286132812, Accuracy: 0.6806640625\n",
      "Batch: 104, Loss: 0.9311220645904541, Accuracy: 0.6923828125\n",
      "Batch: 105, Loss: 0.9744945168495178, Accuracy: 0.6953125\n",
      "Batch: 106, Loss: 0.9439788460731506, Accuracy: 0.6923828125\n",
      "Batch: 107, Loss: 1.0026206970214844, Accuracy: 0.689453125\n",
      "Batch: 108, Loss: 1.0083993673324585, Accuracy: 0.6728515625\n",
      "Batch: 109, Loss: 1.0593459606170654, Accuracy: 0.65234375\n",
      "Batch: 110, Loss: 0.852959156036377, Accuracy: 0.7080078125\n",
      "Batch: 111, Loss: 1.001281976699829, Accuracy: 0.65625\n",
      "Batch: 112, Loss: 0.958412766456604, Accuracy: 0.6962890625\n",
      "Batch: 113, Loss: 0.9911760687828064, Accuracy: 0.69140625\n",
      "Batch: 114, Loss: 1.0614945888519287, Accuracy: 0.654296875\n",
      "Batch: 115, Loss: 1.0951333045959473, Accuracy: 0.6611328125\n",
      "Batch: 116, Loss: 1.0217373371124268, Accuracy: 0.6513671875\n",
      "Batch: 117, Loss: 1.0140273571014404, Accuracy: 0.681640625\n",
      "Batch: 118, Loss: 0.8737561106681824, Accuracy: 0.7275390625\n",
      "Batch: 119, Loss: 0.9151313304901123, Accuracy: 0.71875\n",
      "Batch: 120, Loss: 0.9689470529556274, Accuracy: 0.6826171875\n",
      "Batch: 121, Loss: 1.0201692581176758, Accuracy: 0.66796875\n",
      "Batch: 122, Loss: 0.9204940795898438, Accuracy: 0.7099609375\n",
      "Batch: 123, Loss: 0.9330217838287354, Accuracy: 0.7109375\n",
      "Batch: 124, Loss: 0.9874616265296936, Accuracy: 0.6669921875\n",
      "Batch: 125, Loss: 0.9988288879394531, Accuracy: 0.671875\n",
      "Batch: 126, Loss: 0.9661300182342529, Accuracy: 0.669921875\n",
      "Batch: 127, Loss: 0.8953163027763367, Accuracy: 0.7314453125\n",
      "Batch: 128, Loss: 1.115293264389038, Accuracy: 0.666015625\n",
      "Batch: 129, Loss: 0.9245358109474182, Accuracy: 0.7119140625\n",
      "Batch: 130, Loss: 1.122607707977295, Accuracy: 0.642578125\n",
      "Batch: 131, Loss: 1.0094419717788696, Accuracy: 0.6865234375\n",
      "Batch: 132, Loss: 1.069077968597412, Accuracy: 0.671875\n",
      "Batch: 133, Loss: 0.9433109164237976, Accuracy: 0.6826171875\n",
      "Batch: 134, Loss: 0.9966336488723755, Accuracy: 0.6611328125\n",
      "Batch: 135, Loss: 0.9250959157943726, Accuracy: 0.7138671875\n",
      "Batch: 136, Loss: 1.003631353378296, Accuracy: 0.6845703125\n",
      "Batch: 137, Loss: 0.9176256656646729, Accuracy: 0.7001953125\n",
      "Batch: 138, Loss: 0.8420252799987793, Accuracy: 0.7158203125\n",
      "Batch: 139, Loss: 0.871031641960144, Accuracy: 0.7158203125\n",
      "Batch: 140, Loss: 0.9940559267997742, Accuracy: 0.6904296875\n",
      "Batch: 141, Loss: 0.9907448291778564, Accuracy: 0.673828125\n",
      "Batch: 142, Loss: 1.0464682579040527, Accuracy: 0.6611328125\n",
      "Batch: 143, Loss: 1.008714199066162, Accuracy: 0.6826171875\n",
      "Batch: 144, Loss: 0.9444347620010376, Accuracy: 0.701171875\n",
      "Batch: 145, Loss: 0.9092241525650024, Accuracy: 0.6826171875\n",
      "Batch: 146, Loss: 1.0329244136810303, Accuracy: 0.6708984375\n",
      "Batch: 147, Loss: 0.9680174589157104, Accuracy: 0.69140625\n",
      "Batch: 148, Loss: 1.0654771327972412, Accuracy: 0.6396484375\n",
      "Batch: 149, Loss: 0.9249787926673889, Accuracy: 0.70703125\n",
      "Batch: 150, Loss: 0.9423027634620667, Accuracy: 0.7060546875\n",
      "Batch: 151, Loss: 0.8697166442871094, Accuracy: 0.7265625\n",
      "Epoch 26/80\n",
      "Batch: 1, Loss: 1.1306564807891846, Accuracy: 0.63671875\n",
      "Batch: 2, Loss: 1.004715919494629, Accuracy: 0.6494140625\n",
      "Batch: 3, Loss: 0.9033299684524536, Accuracy: 0.7001953125\n",
      "Batch: 4, Loss: 0.8712246417999268, Accuracy: 0.73046875\n",
      "Batch: 5, Loss: 0.923456609249115, Accuracy: 0.708984375\n",
      "Batch: 6, Loss: 0.9774956107139587, Accuracy: 0.673828125\n",
      "Batch: 7, Loss: 0.9519767761230469, Accuracy: 0.681640625\n",
      "Batch: 8, Loss: 0.9326986074447632, Accuracy: 0.69140625\n",
      "Batch: 9, Loss: 0.9054101705551147, Accuracy: 0.712890625\n",
      "Batch: 10, Loss: 0.8824679255485535, Accuracy: 0.69921875\n",
      "Batch: 11, Loss: 1.0307369232177734, Accuracy: 0.6494140625\n",
      "Batch: 12, Loss: 1.012012004852295, Accuracy: 0.67578125\n",
      "Batch: 13, Loss: 0.796287477016449, Accuracy: 0.7412109375\n",
      "Batch: 14, Loss: 1.0476189851760864, Accuracy: 0.65234375\n",
      "Batch: 15, Loss: 0.8970969915390015, Accuracy: 0.7197265625\n",
      "Batch: 16, Loss: 0.9028037786483765, Accuracy: 0.703125\n",
      "Batch: 17, Loss: 0.9729024171829224, Accuracy: 0.6904296875\n",
      "Batch: 18, Loss: 0.9716891050338745, Accuracy: 0.6865234375\n",
      "Batch: 19, Loss: 1.0376209020614624, Accuracy: 0.6875\n",
      "Batch: 20, Loss: 0.9370855093002319, Accuracy: 0.7080078125\n",
      "Batch: 21, Loss: 0.9017229080200195, Accuracy: 0.6884765625\n",
      "Batch: 22, Loss: 1.0383611917495728, Accuracy: 0.68359375\n",
      "Batch: 23, Loss: 1.0116159915924072, Accuracy: 0.677734375\n",
      "Batch: 24, Loss: 1.0045744180679321, Accuracy: 0.6689453125\n",
      "Batch: 25, Loss: 0.9576133489608765, Accuracy: 0.6904296875\n",
      "Batch: 26, Loss: 0.850631594657898, Accuracy: 0.72265625\n",
      "Batch: 27, Loss: 0.9050199389457703, Accuracy: 0.69140625\n",
      "Batch: 28, Loss: 0.9777076244354248, Accuracy: 0.677734375\n",
      "Batch: 29, Loss: 0.9446364045143127, Accuracy: 0.689453125\n",
      "Batch: 30, Loss: 0.9486794471740723, Accuracy: 0.6943359375\n",
      "Batch: 31, Loss: 0.8660176396369934, Accuracy: 0.7314453125\n",
      "Batch: 32, Loss: 0.8922059535980225, Accuracy: 0.712890625\n",
      "Batch: 33, Loss: 1.070052146911621, Accuracy: 0.646484375\n",
      "Batch: 34, Loss: 1.118006944656372, Accuracy: 0.6240234375\n",
      "Batch: 35, Loss: 1.0067849159240723, Accuracy: 0.6611328125\n",
      "Batch: 36, Loss: 1.0201685428619385, Accuracy: 0.6787109375\n",
      "Batch: 37, Loss: 0.9625041484832764, Accuracy: 0.685546875\n",
      "Batch: 38, Loss: 0.9938506484031677, Accuracy: 0.671875\n",
      "Batch: 39, Loss: 0.9972043037414551, Accuracy: 0.6728515625\n",
      "Batch: 40, Loss: 1.0321385860443115, Accuracy: 0.666015625\n",
      "Batch: 41, Loss: 0.9324176907539368, Accuracy: 0.69921875\n",
      "Batch: 42, Loss: 0.7548019886016846, Accuracy: 0.7529296875\n",
      "Batch: 43, Loss: 0.9214440584182739, Accuracy: 0.6728515625\n",
      "Batch: 44, Loss: 0.9856840968132019, Accuracy: 0.67578125\n",
      "Batch: 45, Loss: 0.8757652640342712, Accuracy: 0.712890625\n",
      "Batch: 46, Loss: 0.9224740266799927, Accuracy: 0.7138671875\n",
      "Batch: 47, Loss: 0.9373259544372559, Accuracy: 0.7099609375\n",
      "Batch: 48, Loss: 0.8764862418174744, Accuracy: 0.7158203125\n",
      "Batch: 49, Loss: 1.0538761615753174, Accuracy: 0.66015625\n",
      "Batch: 50, Loss: 1.0049314498901367, Accuracy: 0.6796875\n",
      "Batch: 51, Loss: 1.0713038444519043, Accuracy: 0.6669921875\n",
      "Batch: 52, Loss: 1.039600133895874, Accuracy: 0.6748046875\n",
      "Batch: 53, Loss: 0.8946755528450012, Accuracy: 0.701171875\n",
      "Batch: 54, Loss: 0.9163550138473511, Accuracy: 0.7099609375\n",
      "Batch: 55, Loss: 1.0342278480529785, Accuracy: 0.6708984375\n",
      "Batch: 56, Loss: 1.0565193891525269, Accuracy: 0.66015625\n",
      "Batch: 57, Loss: 0.9520273804664612, Accuracy: 0.6953125\n",
      "Batch: 58, Loss: 1.099234938621521, Accuracy: 0.65625\n",
      "Batch: 59, Loss: 0.9130240678787231, Accuracy: 0.7177734375\n",
      "Batch: 60, Loss: 0.8907335996627808, Accuracy: 0.705078125\n",
      "Batch: 61, Loss: 1.0030243396759033, Accuracy: 0.6728515625\n",
      "Batch: 62, Loss: 0.9641082882881165, Accuracy: 0.6943359375\n",
      "Batch: 63, Loss: 0.9887045621871948, Accuracy: 0.6787109375\n",
      "Batch: 64, Loss: 0.9430424571037292, Accuracy: 0.693359375\n",
      "Batch: 65, Loss: 0.9833973050117493, Accuracy: 0.701171875\n",
      "Batch: 66, Loss: 0.9442434310913086, Accuracy: 0.7021484375\n",
      "Batch: 67, Loss: 1.05671226978302, Accuracy: 0.6591796875\n",
      "Batch: 68, Loss: 1.0383830070495605, Accuracy: 0.6787109375\n",
      "Batch: 69, Loss: 1.0049140453338623, Accuracy: 0.69140625\n",
      "Batch: 70, Loss: 0.9860202074050903, Accuracy: 0.7001953125\n",
      "Batch: 71, Loss: 0.9743625521659851, Accuracy: 0.68359375\n",
      "Batch: 72, Loss: 0.8831937313079834, Accuracy: 0.732421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 73, Loss: 0.9010007381439209, Accuracy: 0.708984375\n",
      "Batch: 74, Loss: 0.8700127601623535, Accuracy: 0.732421875\n",
      "Batch: 75, Loss: 0.8788446187973022, Accuracy: 0.7041015625\n",
      "Batch: 76, Loss: 0.9640972018241882, Accuracy: 0.6796875\n",
      "Batch: 77, Loss: 0.9178855419158936, Accuracy: 0.6953125\n",
      "Batch: 78, Loss: 0.9068175554275513, Accuracy: 0.7314453125\n",
      "Batch: 79, Loss: 0.8773914575576782, Accuracy: 0.7314453125\n",
      "Batch: 80, Loss: 0.8779610395431519, Accuracy: 0.70703125\n",
      "Batch: 81, Loss: 0.9895486235618591, Accuracy: 0.66796875\n",
      "Batch: 82, Loss: 0.9629571437835693, Accuracy: 0.6865234375\n",
      "Batch: 83, Loss: 0.826192319393158, Accuracy: 0.74609375\n",
      "Batch: 84, Loss: 0.9463063478469849, Accuracy: 0.716796875\n",
      "Batch: 85, Loss: 0.8628306984901428, Accuracy: 0.7255859375\n",
      "Batch: 86, Loss: 1.0537114143371582, Accuracy: 0.6748046875\n",
      "Batch: 87, Loss: 0.8686087131500244, Accuracy: 0.7265625\n",
      "Batch: 88, Loss: 1.015150785446167, Accuracy: 0.68359375\n",
      "Batch: 89, Loss: 1.0030142068862915, Accuracy: 0.6884765625\n",
      "Batch: 90, Loss: 0.8969807624816895, Accuracy: 0.708984375\n",
      "Batch: 91, Loss: 0.9523844122886658, Accuracy: 0.6845703125\n",
      "Batch: 92, Loss: 0.9862303733825684, Accuracy: 0.68359375\n",
      "Batch: 93, Loss: 0.9372069239616394, Accuracy: 0.6982421875\n",
      "Batch: 94, Loss: 0.9697459936141968, Accuracy: 0.6708984375\n",
      "Batch: 95, Loss: 0.955988883972168, Accuracy: 0.6767578125\n",
      "Batch: 96, Loss: 0.9384362101554871, Accuracy: 0.6962890625\n",
      "Batch: 97, Loss: 0.802267849445343, Accuracy: 0.732421875\n",
      "Batch: 98, Loss: 0.8791308999061584, Accuracy: 0.724609375\n",
      "Batch: 99, Loss: 0.8977293372154236, Accuracy: 0.7060546875\n",
      "Batch: 100, Loss: 0.926116943359375, Accuracy: 0.7080078125\n",
      "Batch: 101, Loss: 0.9953526854515076, Accuracy: 0.68359375\n",
      "Batch: 102, Loss: 0.9474719166755676, Accuracy: 0.69140625\n",
      "Batch: 103, Loss: 1.0170644521713257, Accuracy: 0.6923828125\n",
      "Batch: 104, Loss: 0.9197114706039429, Accuracy: 0.701171875\n",
      "Batch: 105, Loss: 0.979901909828186, Accuracy: 0.6982421875\n",
      "Batch: 106, Loss: 0.905585527420044, Accuracy: 0.69921875\n",
      "Batch: 107, Loss: 0.9633471965789795, Accuracy: 0.6875\n",
      "Batch: 108, Loss: 0.9733847975730896, Accuracy: 0.6787109375\n",
      "Batch: 109, Loss: 1.0731300115585327, Accuracy: 0.642578125\n",
      "Batch: 110, Loss: 0.8121228814125061, Accuracy: 0.7431640625\n",
      "Batch: 111, Loss: 0.981401801109314, Accuracy: 0.6865234375\n",
      "Batch: 112, Loss: 0.9379457831382751, Accuracy: 0.6982421875\n",
      "Batch: 113, Loss: 0.9437183737754822, Accuracy: 0.7001953125\n",
      "Batch: 114, Loss: 1.0319902896881104, Accuracy: 0.654296875\n",
      "Batch: 115, Loss: 1.0973461866378784, Accuracy: 0.6669921875\n",
      "Batch: 116, Loss: 1.0008018016815186, Accuracy: 0.6796875\n",
      "Batch: 117, Loss: 1.018069863319397, Accuracy: 0.6728515625\n",
      "Batch: 118, Loss: 0.8729407787322998, Accuracy: 0.7119140625\n",
      "Batch: 119, Loss: 0.8820297718048096, Accuracy: 0.7138671875\n",
      "Batch: 120, Loss: 0.9536228775978088, Accuracy: 0.68359375\n",
      "Batch: 121, Loss: 0.9988440275192261, Accuracy: 0.6826171875\n",
      "Batch: 122, Loss: 0.9299948215484619, Accuracy: 0.703125\n",
      "Batch: 123, Loss: 0.914959192276001, Accuracy: 0.7119140625\n",
      "Batch: 124, Loss: 0.9340470433235168, Accuracy: 0.6865234375\n",
      "Batch: 125, Loss: 0.9949676394462585, Accuracy: 0.693359375\n",
      "Batch: 126, Loss: 0.9694361686706543, Accuracy: 0.6875\n",
      "Batch: 127, Loss: 0.8805454969406128, Accuracy: 0.7236328125\n",
      "Batch: 128, Loss: 1.0875236988067627, Accuracy: 0.6708984375\n",
      "Batch: 129, Loss: 0.8971194624900818, Accuracy: 0.7080078125\n",
      "Batch: 130, Loss: 1.0898627042770386, Accuracy: 0.65234375\n",
      "Batch: 131, Loss: 0.9876618981361389, Accuracy: 0.689453125\n",
      "Batch: 132, Loss: 1.058911681175232, Accuracy: 0.6845703125\n",
      "Batch: 133, Loss: 0.9269057512283325, Accuracy: 0.701171875\n",
      "Batch: 134, Loss: 0.9976489543914795, Accuracy: 0.666015625\n",
      "Batch: 135, Loss: 0.9320605397224426, Accuracy: 0.7060546875\n",
      "Batch: 136, Loss: 0.9761947393417358, Accuracy: 0.681640625\n",
      "Batch: 137, Loss: 0.9171411991119385, Accuracy: 0.677734375\n",
      "Batch: 138, Loss: 0.8386267423629761, Accuracy: 0.7265625\n",
      "Batch: 139, Loss: 0.8648742437362671, Accuracy: 0.72265625\n",
      "Batch: 140, Loss: 0.99349445104599, Accuracy: 0.669921875\n",
      "Batch: 141, Loss: 0.9673465490341187, Accuracy: 0.6943359375\n",
      "Batch: 142, Loss: 1.052968144416809, Accuracy: 0.666015625\n",
      "Batch: 143, Loss: 0.965618371963501, Accuracy: 0.6982421875\n",
      "Batch: 144, Loss: 0.951827883720398, Accuracy: 0.6923828125\n",
      "Batch: 145, Loss: 0.9112159609794617, Accuracy: 0.6767578125\n",
      "Batch: 146, Loss: 1.0097694396972656, Accuracy: 0.66015625\n",
      "Batch: 147, Loss: 0.9693176746368408, Accuracy: 0.6943359375\n",
      "Batch: 148, Loss: 1.0810014009475708, Accuracy: 0.63671875\n",
      "Batch: 149, Loss: 0.9383906126022339, Accuracy: 0.705078125\n",
      "Batch: 150, Loss: 0.9831373691558838, Accuracy: 0.6923828125\n",
      "Batch: 151, Loss: 0.8583455085754395, Accuracy: 0.73046875\n",
      "Epoch 27/80\n",
      "Batch: 1, Loss: 1.1355587244033813, Accuracy: 0.6279296875\n",
      "Batch: 2, Loss: 1.021254301071167, Accuracy: 0.658203125\n",
      "Batch: 3, Loss: 0.9228159189224243, Accuracy: 0.69921875\n",
      "Batch: 4, Loss: 0.8737804889678955, Accuracy: 0.72265625\n",
      "Batch: 5, Loss: 0.905378520488739, Accuracy: 0.7119140625\n",
      "Batch: 6, Loss: 0.9645757079124451, Accuracy: 0.685546875\n",
      "Batch: 7, Loss: 0.9429098963737488, Accuracy: 0.6904296875\n",
      "Batch: 8, Loss: 0.9052830934524536, Accuracy: 0.6982421875\n",
      "Batch: 9, Loss: 0.8932355642318726, Accuracy: 0.7158203125\n",
      "Batch: 10, Loss: 0.866167426109314, Accuracy: 0.7197265625\n",
      "Batch: 11, Loss: 1.0164289474487305, Accuracy: 0.6640625\n",
      "Batch: 12, Loss: 0.9819585680961609, Accuracy: 0.6845703125\n",
      "Batch: 13, Loss: 0.7985095977783203, Accuracy: 0.7490234375\n",
      "Batch: 14, Loss: 1.0281566381454468, Accuracy: 0.6669921875\n",
      "Batch: 15, Loss: 0.9000102281570435, Accuracy: 0.7158203125\n",
      "Batch: 16, Loss: 0.8797929286956787, Accuracy: 0.7353515625\n",
      "Batch: 17, Loss: 0.9898709058761597, Accuracy: 0.68359375\n",
      "Batch: 18, Loss: 0.9741849899291992, Accuracy: 0.693359375\n",
      "Batch: 19, Loss: 1.0000367164611816, Accuracy: 0.6962890625\n",
      "Batch: 20, Loss: 0.911596417427063, Accuracy: 0.7177734375\n",
      "Batch: 21, Loss: 0.8992570638656616, Accuracy: 0.7080078125\n",
      "Batch: 22, Loss: 1.044309377670288, Accuracy: 0.66796875\n",
      "Batch: 23, Loss: 0.9447059631347656, Accuracy: 0.697265625\n",
      "Batch: 24, Loss: 0.9837956428527832, Accuracy: 0.69921875\n",
      "Batch: 25, Loss: 0.9030637741088867, Accuracy: 0.716796875\n",
      "Batch: 26, Loss: 0.8316748142242432, Accuracy: 0.7255859375\n",
      "Batch: 27, Loss: 0.9074061512947083, Accuracy: 0.6982421875\n",
      "Batch: 28, Loss: 0.9704828262329102, Accuracy: 0.67578125\n",
      "Batch: 29, Loss: 0.9063729047775269, Accuracy: 0.708984375\n",
      "Batch: 30, Loss: 0.9266266822814941, Accuracy: 0.7138671875\n",
      "Batch: 31, Loss: 0.8777775168418884, Accuracy: 0.7138671875\n",
      "Batch: 32, Loss: 0.8762741684913635, Accuracy: 0.7041015625\n",
      "Batch: 33, Loss: 1.0271451473236084, Accuracy: 0.6728515625\n",
      "Batch: 34, Loss: 1.0662533044815063, Accuracy: 0.654296875\n",
      "Batch: 35, Loss: 0.9751543998718262, Accuracy: 0.681640625\n",
      "Batch: 36, Loss: 1.0116848945617676, Accuracy: 0.6826171875\n",
      "Batch: 37, Loss: 0.9319945573806763, Accuracy: 0.705078125\n",
      "Batch: 38, Loss: 0.9983311295509338, Accuracy: 0.6767578125\n",
      "Batch: 39, Loss: 0.9701325297355652, Accuracy: 0.6962890625\n",
      "Batch: 40, Loss: 0.9719941020011902, Accuracy: 0.693359375\n",
      "Batch: 41, Loss: 0.9299184083938599, Accuracy: 0.69921875\n",
      "Batch: 42, Loss: 0.7579361200332642, Accuracy: 0.75390625\n",
      "Batch: 43, Loss: 0.919556200504303, Accuracy: 0.7021484375\n",
      "Batch: 44, Loss: 0.9713631868362427, Accuracy: 0.6865234375\n",
      "Batch: 45, Loss: 0.8222919702529907, Accuracy: 0.7177734375\n",
      "Batch: 46, Loss: 0.8991276025772095, Accuracy: 0.724609375\n",
      "Batch: 47, Loss: 0.9303820133209229, Accuracy: 0.712890625\n",
      "Batch: 48, Loss: 0.8926496505737305, Accuracy: 0.6982421875\n",
      "Batch: 49, Loss: 1.053536295890808, Accuracy: 0.671875\n",
      "Batch: 50, Loss: 0.9873084425926208, Accuracy: 0.6767578125\n",
      "Batch: 51, Loss: 1.0598201751708984, Accuracy: 0.666015625\n",
      "Batch: 52, Loss: 1.0124763250350952, Accuracy: 0.6767578125\n",
      "Batch: 53, Loss: 0.8659027814865112, Accuracy: 0.7119140625\n",
      "Batch: 54, Loss: 0.9124894738197327, Accuracy: 0.7021484375\n",
      "Batch: 55, Loss: 1.0234496593475342, Accuracy: 0.662109375\n",
      "Batch: 56, Loss: 1.024701476097107, Accuracy: 0.677734375\n",
      "Batch: 57, Loss: 0.9498766660690308, Accuracy: 0.6875\n",
      "Batch: 58, Loss: 1.0633330345153809, Accuracy: 0.66015625\n",
      "Batch: 59, Loss: 0.9130710363388062, Accuracy: 0.7099609375\n",
      "Batch: 60, Loss: 0.8919001817703247, Accuracy: 0.705078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 61, Loss: 0.9543855786323547, Accuracy: 0.6923828125\n",
      "Batch: 62, Loss: 0.9468588829040527, Accuracy: 0.69140625\n",
      "Batch: 63, Loss: 0.981076717376709, Accuracy: 0.6787109375\n",
      "Batch: 64, Loss: 0.9387920498847961, Accuracy: 0.7021484375\n",
      "Batch: 65, Loss: 0.9477752447128296, Accuracy: 0.7109375\n",
      "Batch: 66, Loss: 0.9316629767417908, Accuracy: 0.7177734375\n",
      "Batch: 67, Loss: 1.0709996223449707, Accuracy: 0.6796875\n",
      "Batch: 68, Loss: 1.028350591659546, Accuracy: 0.669921875\n",
      "Batch: 69, Loss: 1.0017871856689453, Accuracy: 0.6796875\n",
      "Batch: 70, Loss: 0.9772500395774841, Accuracy: 0.6962890625\n",
      "Batch: 71, Loss: 0.9477843046188354, Accuracy: 0.6904296875\n",
      "Batch: 72, Loss: 0.861142635345459, Accuracy: 0.71875\n",
      "Batch: 73, Loss: 0.8999859094619751, Accuracy: 0.7177734375\n",
      "Batch: 74, Loss: 0.8782904148101807, Accuracy: 0.724609375\n",
      "Batch: 75, Loss: 0.8359684348106384, Accuracy: 0.716796875\n",
      "Batch: 76, Loss: 0.9250913262367249, Accuracy: 0.6962890625\n",
      "Batch: 77, Loss: 0.8872042894363403, Accuracy: 0.70703125\n",
      "Batch: 78, Loss: 0.9329058527946472, Accuracy: 0.7099609375\n",
      "Batch: 79, Loss: 0.8835409283638, Accuracy: 0.732421875\n",
      "Batch: 80, Loss: 0.8867019414901733, Accuracy: 0.703125\n",
      "Batch: 81, Loss: 1.0200049877166748, Accuracy: 0.6533203125\n",
      "Batch: 82, Loss: 0.9401606321334839, Accuracy: 0.70703125\n",
      "Batch: 83, Loss: 0.8181357979774475, Accuracy: 0.7607421875\n",
      "Batch: 84, Loss: 0.9217584729194641, Accuracy: 0.71484375\n",
      "Batch: 85, Loss: 0.8637528419494629, Accuracy: 0.7392578125\n",
      "Batch: 86, Loss: 1.0275163650512695, Accuracy: 0.6708984375\n",
      "Batch: 87, Loss: 0.8609946370124817, Accuracy: 0.7119140625\n",
      "Batch: 88, Loss: 0.9928914308547974, Accuracy: 0.703125\n",
      "Batch: 89, Loss: 0.9726738929748535, Accuracy: 0.7099609375\n",
      "Batch: 90, Loss: 0.8807259798049927, Accuracy: 0.7109375\n",
      "Batch: 91, Loss: 0.9407562017440796, Accuracy: 0.6943359375\n",
      "Batch: 92, Loss: 0.9719640016555786, Accuracy: 0.6904296875\n",
      "Batch: 93, Loss: 0.9085966348648071, Accuracy: 0.7080078125\n",
      "Batch: 94, Loss: 0.9384018778800964, Accuracy: 0.6884765625\n",
      "Batch: 95, Loss: 0.9444717764854431, Accuracy: 0.6796875\n",
      "Batch: 96, Loss: 0.9221452474594116, Accuracy: 0.708984375\n",
      "Batch: 97, Loss: 0.8079329133033752, Accuracy: 0.7451171875\n",
      "Batch: 98, Loss: 0.8703551888465881, Accuracy: 0.7236328125\n",
      "Batch: 99, Loss: 0.857667088508606, Accuracy: 0.720703125\n",
      "Batch: 100, Loss: 0.9039052724838257, Accuracy: 0.7109375\n",
      "Batch: 101, Loss: 0.9990139007568359, Accuracy: 0.68359375\n",
      "Batch: 102, Loss: 0.9095380306243896, Accuracy: 0.7060546875\n",
      "Batch: 103, Loss: 0.9893486499786377, Accuracy: 0.6845703125\n",
      "Batch: 104, Loss: 0.9034844636917114, Accuracy: 0.70703125\n",
      "Batch: 105, Loss: 0.9631098508834839, Accuracy: 0.68359375\n",
      "Batch: 106, Loss: 0.9095447063446045, Accuracy: 0.7138671875\n",
      "Batch: 107, Loss: 0.9865061044692993, Accuracy: 0.6845703125\n",
      "Batch: 108, Loss: 0.9489129781723022, Accuracy: 0.705078125\n",
      "Batch: 109, Loss: 1.0166903734207153, Accuracy: 0.6533203125\n",
      "Batch: 110, Loss: 0.8137948513031006, Accuracy: 0.734375\n",
      "Batch: 111, Loss: 0.9733954668045044, Accuracy: 0.6865234375\n",
      "Batch: 112, Loss: 0.918595016002655, Accuracy: 0.7119140625\n",
      "Batch: 113, Loss: 0.9300798177719116, Accuracy: 0.6982421875\n",
      "Batch: 114, Loss: 0.9770097732543945, Accuracy: 0.6884765625\n",
      "Batch: 115, Loss: 1.0649924278259277, Accuracy: 0.669921875\n",
      "Batch: 116, Loss: 0.9843955636024475, Accuracy: 0.6806640625\n",
      "Batch: 117, Loss: 1.0119727849960327, Accuracy: 0.671875\n",
      "Batch: 118, Loss: 0.860603928565979, Accuracy: 0.7265625\n",
      "Batch: 119, Loss: 0.8670095801353455, Accuracy: 0.724609375\n",
      "Batch: 120, Loss: 0.9654560089111328, Accuracy: 0.6845703125\n",
      "Batch: 121, Loss: 0.9967823028564453, Accuracy: 0.6767578125\n",
      "Batch: 122, Loss: 0.9260900020599365, Accuracy: 0.7001953125\n",
      "Batch: 123, Loss: 0.902193546295166, Accuracy: 0.71484375\n",
      "Batch: 124, Loss: 0.9412143230438232, Accuracy: 0.6904296875\n",
      "Batch: 125, Loss: 1.0018185377120972, Accuracy: 0.67578125\n",
      "Batch: 126, Loss: 0.9462310075759888, Accuracy: 0.693359375\n",
      "Batch: 127, Loss: 0.8581560850143433, Accuracy: 0.7421875\n",
      "Batch: 128, Loss: 1.0399802923202515, Accuracy: 0.68359375\n",
      "Batch: 129, Loss: 0.8648802638053894, Accuracy: 0.7373046875\n",
      "Batch: 130, Loss: 1.083598256111145, Accuracy: 0.666015625\n",
      "Batch: 131, Loss: 1.000471830368042, Accuracy: 0.685546875\n",
      "Batch: 132, Loss: 1.0306048393249512, Accuracy: 0.677734375\n",
      "Batch: 133, Loss: 0.9138774275779724, Accuracy: 0.7080078125\n",
      "Batch: 134, Loss: 0.9743160009384155, Accuracy: 0.677734375\n",
      "Batch: 135, Loss: 0.9121105670928955, Accuracy: 0.732421875\n",
      "Batch: 136, Loss: 0.9721335172653198, Accuracy: 0.693359375\n",
      "Batch: 137, Loss: 0.9069911241531372, Accuracy: 0.7021484375\n",
      "Batch: 138, Loss: 0.820918083190918, Accuracy: 0.7470703125\n",
      "Batch: 139, Loss: 0.8518958687782288, Accuracy: 0.7275390625\n",
      "Batch: 140, Loss: 0.9767723083496094, Accuracy: 0.6826171875\n",
      "Batch: 141, Loss: 0.9629306793212891, Accuracy: 0.697265625\n",
      "Batch: 142, Loss: 1.040905475616455, Accuracy: 0.669921875\n",
      "Batch: 143, Loss: 0.9800081253051758, Accuracy: 0.6943359375\n",
      "Batch: 144, Loss: 0.924629271030426, Accuracy: 0.7099609375\n",
      "Batch: 145, Loss: 0.8944287896156311, Accuracy: 0.685546875\n",
      "Batch: 146, Loss: 1.011963129043579, Accuracy: 0.6669921875\n",
      "Batch: 147, Loss: 0.9829794764518738, Accuracy: 0.6796875\n",
      "Batch: 148, Loss: 1.0485433340072632, Accuracy: 0.673828125\n",
      "Batch: 149, Loss: 0.9192203283309937, Accuracy: 0.6923828125\n",
      "Batch: 150, Loss: 0.9076818227767944, Accuracy: 0.71484375\n",
      "Batch: 151, Loss: 0.8376373648643494, Accuracy: 0.7314453125\n",
      "Epoch 28/80\n",
      "Batch: 1, Loss: 1.1205213069915771, Accuracy: 0.640625\n",
      "Batch: 2, Loss: 1.002191424369812, Accuracy: 0.654296875\n",
      "Batch: 3, Loss: 0.8926105499267578, Accuracy: 0.703125\n",
      "Batch: 4, Loss: 0.8613978624343872, Accuracy: 0.73828125\n",
      "Batch: 5, Loss: 0.8845539093017578, Accuracy: 0.7333984375\n",
      "Batch: 6, Loss: 0.9424097537994385, Accuracy: 0.6982421875\n",
      "Batch: 7, Loss: 0.9205688834190369, Accuracy: 0.6904296875\n",
      "Batch: 8, Loss: 0.8875958919525146, Accuracy: 0.712890625\n",
      "Batch: 9, Loss: 0.870457112789154, Accuracy: 0.7265625\n",
      "Batch: 10, Loss: 0.8933058381080627, Accuracy: 0.7109375\n",
      "Batch: 11, Loss: 1.000459909439087, Accuracy: 0.6611328125\n",
      "Batch: 12, Loss: 0.9607703685760498, Accuracy: 0.6923828125\n",
      "Batch: 13, Loss: 0.7900084853172302, Accuracy: 0.748046875\n",
      "Batch: 14, Loss: 1.0301307439804077, Accuracy: 0.67578125\n",
      "Batch: 15, Loss: 0.9034810066223145, Accuracy: 0.7158203125\n",
      "Batch: 16, Loss: 0.8885053396224976, Accuracy: 0.724609375\n",
      "Batch: 17, Loss: 0.9342206716537476, Accuracy: 0.701171875\n",
      "Batch: 18, Loss: 0.9650684595108032, Accuracy: 0.6845703125\n",
      "Batch: 19, Loss: 1.0289208889007568, Accuracy: 0.6884765625\n",
      "Batch: 20, Loss: 0.9007148146629333, Accuracy: 0.7265625\n",
      "Batch: 21, Loss: 0.9018352031707764, Accuracy: 0.693359375\n",
      "Batch: 22, Loss: 1.0185482501983643, Accuracy: 0.6826171875\n",
      "Batch: 23, Loss: 0.9838831424713135, Accuracy: 0.673828125\n",
      "Batch: 24, Loss: 0.9992658495903015, Accuracy: 0.6640625\n",
      "Batch: 25, Loss: 0.9259997606277466, Accuracy: 0.6875\n",
      "Batch: 26, Loss: 0.832092821598053, Accuracy: 0.7333984375\n",
      "Batch: 27, Loss: 0.8848127722740173, Accuracy: 0.693359375\n",
      "Batch: 28, Loss: 0.9578341841697693, Accuracy: 0.6806640625\n",
      "Batch: 29, Loss: 0.9204785823822021, Accuracy: 0.705078125\n",
      "Batch: 30, Loss: 0.902121901512146, Accuracy: 0.736328125\n",
      "Batch: 31, Loss: 0.8653755187988281, Accuracy: 0.7216796875\n",
      "Batch: 32, Loss: 0.871202826499939, Accuracy: 0.70703125\n",
      "Batch: 33, Loss: 1.0278555154800415, Accuracy: 0.6865234375\n",
      "Batch: 34, Loss: 1.0429751873016357, Accuracy: 0.6845703125\n",
      "Batch: 35, Loss: 0.980719804763794, Accuracy: 0.669921875\n",
      "Batch: 36, Loss: 0.9868492484092712, Accuracy: 0.697265625\n",
      "Batch: 37, Loss: 0.9246826171875, Accuracy: 0.7041015625\n",
      "Batch: 38, Loss: 0.9667729139328003, Accuracy: 0.6806640625\n",
      "Batch: 39, Loss: 0.947151780128479, Accuracy: 0.6982421875\n",
      "Batch: 40, Loss: 0.9579728245735168, Accuracy: 0.6982421875\n",
      "Batch: 41, Loss: 0.9007008075714111, Accuracy: 0.7001953125\n",
      "Batch: 42, Loss: 0.735508918762207, Accuracy: 0.767578125\n",
      "Batch: 43, Loss: 0.9216305017471313, Accuracy: 0.6943359375\n",
      "Batch: 44, Loss: 0.9671682119369507, Accuracy: 0.6845703125\n",
      "Batch: 45, Loss: 0.826372504234314, Accuracy: 0.7216796875\n",
      "Batch: 46, Loss: 0.886650025844574, Accuracy: 0.7275390625\n",
      "Batch: 47, Loss: 0.9230104684829712, Accuracy: 0.70703125\n",
      "Batch: 48, Loss: 0.8813318014144897, Accuracy: 0.7158203125\n",
      "Batch: 49, Loss: 1.0460903644561768, Accuracy: 0.669921875\n",
      "Batch: 50, Loss: 0.9596027135848999, Accuracy: 0.68359375\n",
      "Batch: 51, Loss: 1.0451991558074951, Accuracy: 0.6767578125\n",
      "Batch: 52, Loss: 0.993715226650238, Accuracy: 0.69140625\n",
      "Batch: 53, Loss: 0.8583835959434509, Accuracy: 0.7060546875\n",
      "Batch: 54, Loss: 0.8908752799034119, Accuracy: 0.70703125\n",
      "Batch: 55, Loss: 1.0221580266952515, Accuracy: 0.6669921875\n",
      "Batch: 56, Loss: 0.9861443042755127, Accuracy: 0.681640625\n",
      "Batch: 57, Loss: 0.9484859704971313, Accuracy: 0.69921875\n",
      "Batch: 58, Loss: 1.0597279071807861, Accuracy: 0.6708984375\n",
      "Batch: 59, Loss: 0.9048277139663696, Accuracy: 0.720703125\n",
      "Batch: 60, Loss: 0.8824730515480042, Accuracy: 0.708984375\n",
      "Batch: 61, Loss: 0.9566907286643982, Accuracy: 0.7001953125\n",
      "Batch: 62, Loss: 0.930842399597168, Accuracy: 0.7138671875\n",
      "Batch: 63, Loss: 0.980462372303009, Accuracy: 0.6826171875\n",
      "Batch: 64, Loss: 0.9075045585632324, Accuracy: 0.7109375\n",
      "Batch: 65, Loss: 0.9562202095985413, Accuracy: 0.701171875\n",
      "Batch: 66, Loss: 0.9105620384216309, Accuracy: 0.7080078125\n",
      "Batch: 67, Loss: 1.025410532951355, Accuracy: 0.6767578125\n",
      "Batch: 68, Loss: 1.0318715572357178, Accuracy: 0.6796875\n",
      "Batch: 69, Loss: 0.9679908752441406, Accuracy: 0.69140625\n",
      "Batch: 70, Loss: 0.9552774429321289, Accuracy: 0.7060546875\n",
      "Batch: 71, Loss: 0.9696177244186401, Accuracy: 0.6962890625\n",
      "Batch: 72, Loss: 0.847138524055481, Accuracy: 0.7392578125\n",
      "Batch: 73, Loss: 0.8580180406570435, Accuracy: 0.73828125\n",
      "Batch: 74, Loss: 0.8464186191558838, Accuracy: 0.7333984375\n",
      "Batch: 75, Loss: 0.8225383758544922, Accuracy: 0.7392578125\n",
      "Batch: 76, Loss: 0.9036559462547302, Accuracy: 0.69921875\n",
      "Batch: 77, Loss: 0.8914766907691956, Accuracy: 0.724609375\n",
      "Batch: 78, Loss: 0.8910497426986694, Accuracy: 0.7294921875\n",
      "Batch: 79, Loss: 0.8689193725585938, Accuracy: 0.728515625\n",
      "Batch: 80, Loss: 0.8692315816879272, Accuracy: 0.72265625\n",
      "Batch: 81, Loss: 0.996792197227478, Accuracy: 0.65234375\n",
      "Batch: 82, Loss: 0.9467271566390991, Accuracy: 0.6875\n",
      "Batch: 83, Loss: 0.7999194860458374, Accuracy: 0.7490234375\n",
      "Batch: 84, Loss: 0.9011752605438232, Accuracy: 0.728515625\n",
      "Batch: 85, Loss: 0.8498974442481995, Accuracy: 0.732421875\n",
      "Batch: 86, Loss: 1.0226552486419678, Accuracy: 0.67578125\n",
      "Batch: 87, Loss: 0.8414586782455444, Accuracy: 0.724609375\n",
      "Batch: 88, Loss: 0.9899356961250305, Accuracy: 0.703125\n",
      "Batch: 89, Loss: 0.9430639743804932, Accuracy: 0.7001953125\n",
      "Batch: 90, Loss: 0.8717836141586304, Accuracy: 0.73046875\n",
      "Batch: 91, Loss: 0.8837668895721436, Accuracy: 0.7041015625\n",
      "Batch: 92, Loss: 0.977555513381958, Accuracy: 0.6953125\n",
      "Batch: 93, Loss: 0.9113302826881409, Accuracy: 0.716796875\n",
      "Batch: 94, Loss: 0.9079987406730652, Accuracy: 0.6923828125\n",
      "Batch: 95, Loss: 0.9356468319892883, Accuracy: 0.6943359375\n",
      "Batch: 96, Loss: 0.907220721244812, Accuracy: 0.705078125\n",
      "Batch: 97, Loss: 0.7932254076004028, Accuracy: 0.736328125\n",
      "Batch: 98, Loss: 0.8500202894210815, Accuracy: 0.7412109375\n",
      "Batch: 99, Loss: 0.8441627025604248, Accuracy: 0.7255859375\n",
      "Batch: 100, Loss: 0.8877800703048706, Accuracy: 0.697265625\n",
      "Batch: 101, Loss: 0.9730715155601501, Accuracy: 0.68359375\n",
      "Batch: 102, Loss: 0.9209736585617065, Accuracy: 0.7021484375\n",
      "Batch: 103, Loss: 0.9598746299743652, Accuracy: 0.7119140625\n",
      "Batch: 104, Loss: 0.8965498208999634, Accuracy: 0.7099609375\n",
      "Batch: 105, Loss: 0.933495819568634, Accuracy: 0.693359375\n",
      "Batch: 106, Loss: 0.8898788690567017, Accuracy: 0.712890625\n",
      "Batch: 107, Loss: 0.9432607889175415, Accuracy: 0.6943359375\n",
      "Batch: 108, Loss: 0.9369492530822754, Accuracy: 0.6943359375\n",
      "Batch: 109, Loss: 0.9831058979034424, Accuracy: 0.6806640625\n",
      "Batch: 110, Loss: 0.8114436268806458, Accuracy: 0.7451171875\n",
      "Batch: 111, Loss: 0.9676687717437744, Accuracy: 0.69140625\n",
      "Batch: 112, Loss: 0.9038656949996948, Accuracy: 0.7138671875\n",
      "Batch: 113, Loss: 0.9518272280693054, Accuracy: 0.6884765625\n",
      "Batch: 114, Loss: 0.9971034526824951, Accuracy: 0.685546875\n",
      "Batch: 115, Loss: 1.046260118484497, Accuracy: 0.67578125\n",
      "Batch: 116, Loss: 1.0080947875976562, Accuracy: 0.6845703125\n",
      "Batch: 117, Loss: 0.9772350192070007, Accuracy: 0.6943359375\n",
      "Batch: 118, Loss: 0.834039032459259, Accuracy: 0.7294921875\n",
      "Batch: 119, Loss: 0.8535147309303284, Accuracy: 0.7314453125\n",
      "Batch: 120, Loss: 0.9511095285415649, Accuracy: 0.6845703125\n",
      "Batch: 121, Loss: 1.001384973526001, Accuracy: 0.6767578125\n",
      "Batch: 122, Loss: 0.9005322456359863, Accuracy: 0.7158203125\n",
      "Batch: 123, Loss: 0.8985012769699097, Accuracy: 0.720703125\n",
      "Batch: 124, Loss: 0.9458128213882446, Accuracy: 0.68359375\n",
      "Batch: 125, Loss: 0.9797958731651306, Accuracy: 0.6875\n",
      "Batch: 126, Loss: 0.9183421730995178, Accuracy: 0.6953125\n",
      "Batch: 127, Loss: 0.8534910678863525, Accuracy: 0.75\n",
      "Batch: 128, Loss: 1.073555827140808, Accuracy: 0.66796875\n",
      "Batch: 129, Loss: 0.8967292308807373, Accuracy: 0.7080078125\n",
      "Batch: 130, Loss: 1.0652740001678467, Accuracy: 0.6572265625\n",
      "Batch: 131, Loss: 0.9900659918785095, Accuracy: 0.681640625\n",
      "Batch: 132, Loss: 1.0334264039993286, Accuracy: 0.6845703125\n",
      "Batch: 133, Loss: 0.9154505729675293, Accuracy: 0.701171875\n",
      "Batch: 134, Loss: 0.9473820924758911, Accuracy: 0.6826171875\n",
      "Batch: 135, Loss: 0.9135572910308838, Accuracy: 0.72265625\n",
      "Batch: 136, Loss: 0.9658905863761902, Accuracy: 0.6904296875\n",
      "Batch: 137, Loss: 0.9072715044021606, Accuracy: 0.6982421875\n",
      "Batch: 138, Loss: 0.8156527280807495, Accuracy: 0.7275390625\n",
      "Batch: 139, Loss: 0.8325914144515991, Accuracy: 0.7275390625\n",
      "Batch: 140, Loss: 0.9534081220626831, Accuracy: 0.685546875\n",
      "Batch: 141, Loss: 0.9438161253929138, Accuracy: 0.7001953125\n",
      "Batch: 142, Loss: 1.0210552215576172, Accuracy: 0.6728515625\n",
      "Batch: 143, Loss: 0.9445317983627319, Accuracy: 0.703125\n",
      "Batch: 144, Loss: 0.9069888591766357, Accuracy: 0.708984375\n",
      "Batch: 145, Loss: 0.8831622004508972, Accuracy: 0.6845703125\n",
      "Batch: 146, Loss: 0.9648883938789368, Accuracy: 0.6875\n",
      "Batch: 147, Loss: 0.9418690204620361, Accuracy: 0.6943359375\n",
      "Batch: 148, Loss: 1.0617849826812744, Accuracy: 0.650390625\n",
      "Batch: 149, Loss: 0.8982337713241577, Accuracy: 0.7119140625\n",
      "Batch: 150, Loss: 0.9109408855438232, Accuracy: 0.7138671875\n",
      "Batch: 151, Loss: 0.8165259957313538, Accuracy: 0.732421875\n",
      "Epoch 29/80\n",
      "Batch: 1, Loss: 1.0843532085418701, Accuracy: 0.6435546875\n",
      "Batch: 2, Loss: 1.0011682510375977, Accuracy: 0.6484375\n",
      "Batch: 3, Loss: 0.8919602632522583, Accuracy: 0.6982421875\n",
      "Batch: 4, Loss: 0.8288395404815674, Accuracy: 0.7470703125\n",
      "Batch: 5, Loss: 0.8902665972709656, Accuracy: 0.7255859375\n",
      "Batch: 6, Loss: 0.9180625081062317, Accuracy: 0.705078125\n",
      "Batch: 7, Loss: 0.9176391959190369, Accuracy: 0.6865234375\n",
      "Batch: 8, Loss: 0.867786169052124, Accuracy: 0.7080078125\n",
      "Batch: 9, Loss: 0.842881441116333, Accuracy: 0.734375\n",
      "Batch: 10, Loss: 0.862608790397644, Accuracy: 0.705078125\n",
      "Batch: 11, Loss: 0.9701018333435059, Accuracy: 0.685546875\n",
      "Batch: 12, Loss: 0.9785271883010864, Accuracy: 0.689453125\n",
      "Batch: 13, Loss: 0.7706553936004639, Accuracy: 0.759765625\n",
      "Batch: 14, Loss: 0.9972587823867798, Accuracy: 0.6767578125\n",
      "Batch: 15, Loss: 0.8847333788871765, Accuracy: 0.7373046875\n",
      "Batch: 16, Loss: 0.846606969833374, Accuracy: 0.7412109375\n",
      "Batch: 17, Loss: 0.9454669952392578, Accuracy: 0.689453125\n",
      "Batch: 18, Loss: 0.940484881401062, Accuracy: 0.701171875\n",
      "Batch: 19, Loss: 0.9832336902618408, Accuracy: 0.703125\n",
      "Batch: 20, Loss: 0.8985990285873413, Accuracy: 0.71484375\n",
      "Batch: 21, Loss: 0.8620122671127319, Accuracy: 0.724609375\n",
      "Batch: 22, Loss: 0.9947928190231323, Accuracy: 0.697265625\n",
      "Batch: 23, Loss: 0.9299119710922241, Accuracy: 0.697265625\n",
      "Batch: 24, Loss: 0.9642552137374878, Accuracy: 0.685546875\n",
      "Batch: 25, Loss: 0.8952881097793579, Accuracy: 0.71875\n",
      "Batch: 26, Loss: 0.7958164215087891, Accuracy: 0.7421875\n",
      "Batch: 27, Loss: 0.8833202123641968, Accuracy: 0.7080078125\n",
      "Batch: 28, Loss: 0.9362316131591797, Accuracy: 0.689453125\n",
      "Batch: 29, Loss: 0.9227160215377808, Accuracy: 0.705078125\n",
      "Batch: 30, Loss: 0.9009572863578796, Accuracy: 0.73046875\n",
      "Batch: 31, Loss: 0.8533551692962646, Accuracy: 0.7255859375\n",
      "Batch: 32, Loss: 0.85414719581604, Accuracy: 0.7216796875\n",
      "Batch: 33, Loss: 1.0167596340179443, Accuracy: 0.6787109375\n",
      "Batch: 34, Loss: 1.065690040588379, Accuracy: 0.6484375\n",
      "Batch: 35, Loss: 0.9404767751693726, Accuracy: 0.6953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 36, Loss: 0.9617893099784851, Accuracy: 0.6962890625\n",
      "Batch: 37, Loss: 0.913299560546875, Accuracy: 0.69921875\n",
      "Batch: 38, Loss: 0.9683160781860352, Accuracy: 0.68359375\n",
      "Batch: 39, Loss: 0.9523054361343384, Accuracy: 0.6923828125\n",
      "Batch: 40, Loss: 0.9515005350112915, Accuracy: 0.7080078125\n",
      "Batch: 41, Loss: 0.8852434158325195, Accuracy: 0.712890625\n",
      "Batch: 42, Loss: 0.7083771228790283, Accuracy: 0.755859375\n",
      "Batch: 43, Loss: 0.8934667110443115, Accuracy: 0.703125\n",
      "Batch: 44, Loss: 0.9320199489593506, Accuracy: 0.7001953125\n",
      "Batch: 45, Loss: 0.7957416772842407, Accuracy: 0.740234375\n",
      "Batch: 46, Loss: 0.866419792175293, Accuracy: 0.7353515625\n",
      "Batch: 47, Loss: 0.9310369491577148, Accuracy: 0.7177734375\n",
      "Batch: 48, Loss: 0.83642578125, Accuracy: 0.73046875\n",
      "Batch: 49, Loss: 1.0257465839385986, Accuracy: 0.6669921875\n",
      "Batch: 50, Loss: 0.9378932118415833, Accuracy: 0.689453125\n",
      "Batch: 51, Loss: 1.0080828666687012, Accuracy: 0.671875\n",
      "Batch: 52, Loss: 0.9659305214881897, Accuracy: 0.6904296875\n",
      "Batch: 53, Loss: 0.8499482274055481, Accuracy: 0.728515625\n",
      "Batch: 54, Loss: 0.8852962255477905, Accuracy: 0.7138671875\n",
      "Batch: 55, Loss: 1.0016071796417236, Accuracy: 0.6708984375\n",
      "Batch: 56, Loss: 0.9821738004684448, Accuracy: 0.673828125\n",
      "Batch: 57, Loss: 0.9178681373596191, Accuracy: 0.705078125\n",
      "Batch: 58, Loss: 1.0344054698944092, Accuracy: 0.6865234375\n",
      "Batch: 59, Loss: 0.89045649766922, Accuracy: 0.7216796875\n",
      "Batch: 60, Loss: 0.8446282744407654, Accuracy: 0.7197265625\n",
      "Batch: 61, Loss: 0.9427388906478882, Accuracy: 0.6962890625\n",
      "Batch: 62, Loss: 0.8967587351799011, Accuracy: 0.705078125\n",
      "Batch: 63, Loss: 0.9204431772232056, Accuracy: 0.7099609375\n",
      "Batch: 64, Loss: 0.8892585635185242, Accuracy: 0.7060546875\n",
      "Batch: 65, Loss: 0.9552969932556152, Accuracy: 0.7041015625\n",
      "Batch: 66, Loss: 0.9056581258773804, Accuracy: 0.7158203125\n",
      "Batch: 67, Loss: 1.012225866317749, Accuracy: 0.6865234375\n",
      "Batch: 68, Loss: 0.9927664399147034, Accuracy: 0.6787109375\n",
      "Batch: 69, Loss: 0.9288135170936584, Accuracy: 0.697265625\n",
      "Batch: 70, Loss: 0.9319639205932617, Accuracy: 0.7099609375\n",
      "Batch: 71, Loss: 0.9318335056304932, Accuracy: 0.69921875\n",
      "Batch: 72, Loss: 0.8257509469985962, Accuracy: 0.73046875\n",
      "Batch: 73, Loss: 0.8547071218490601, Accuracy: 0.724609375\n",
      "Batch: 74, Loss: 0.8535129427909851, Accuracy: 0.7333984375\n",
      "Batch: 75, Loss: 0.8004004955291748, Accuracy: 0.7197265625\n",
      "Batch: 76, Loss: 0.9038119316101074, Accuracy: 0.705078125\n",
      "Batch: 77, Loss: 0.8497979640960693, Accuracy: 0.7236328125\n",
      "Batch: 78, Loss: 0.8577687740325928, Accuracy: 0.740234375\n",
      "Batch: 79, Loss: 0.8322425484657288, Accuracy: 0.7548828125\n",
      "Batch: 80, Loss: 0.8539313673973083, Accuracy: 0.7060546875\n",
      "Batch: 81, Loss: 0.9836820363998413, Accuracy: 0.6474609375\n",
      "Batch: 82, Loss: 0.9247209429740906, Accuracy: 0.689453125\n",
      "Batch: 83, Loss: 0.8025723695755005, Accuracy: 0.7529296875\n",
      "Batch: 84, Loss: 0.9156845808029175, Accuracy: 0.70703125\n",
      "Batch: 85, Loss: 0.8437776565551758, Accuracy: 0.7353515625\n",
      "Batch: 86, Loss: 1.0326625108718872, Accuracy: 0.666015625\n",
      "Batch: 87, Loss: 0.8313048481941223, Accuracy: 0.740234375\n",
      "Batch: 88, Loss: 0.9459002017974854, Accuracy: 0.7099609375\n",
      "Batch: 89, Loss: 0.9209911823272705, Accuracy: 0.7099609375\n",
      "Batch: 90, Loss: 0.8507373929023743, Accuracy: 0.7041015625\n",
      "Batch: 91, Loss: 0.9090963006019592, Accuracy: 0.689453125\n",
      "Batch: 92, Loss: 0.9593977928161621, Accuracy: 0.6943359375\n",
      "Batch: 93, Loss: 0.9072890281677246, Accuracy: 0.697265625\n",
      "Batch: 94, Loss: 0.9094375967979431, Accuracy: 0.703125\n",
      "Batch: 95, Loss: 0.8884047269821167, Accuracy: 0.697265625\n",
      "Batch: 96, Loss: 0.8892388343811035, Accuracy: 0.7021484375\n",
      "Batch: 97, Loss: 0.760359525680542, Accuracy: 0.755859375\n",
      "Batch: 98, Loss: 0.8668005466461182, Accuracy: 0.7275390625\n",
      "Batch: 99, Loss: 0.8464581370353699, Accuracy: 0.712890625\n",
      "Batch: 100, Loss: 0.8755320906639099, Accuracy: 0.7265625\n",
      "Batch: 101, Loss: 0.9562649130821228, Accuracy: 0.6875\n",
      "Batch: 102, Loss: 0.8949945569038391, Accuracy: 0.7275390625\n",
      "Batch: 103, Loss: 0.9543291330337524, Accuracy: 0.7138671875\n",
      "Batch: 104, Loss: 0.8773813247680664, Accuracy: 0.71484375\n",
      "Batch: 105, Loss: 0.951927125453949, Accuracy: 0.6982421875\n",
      "Batch: 106, Loss: 0.8654153347015381, Accuracy: 0.740234375\n",
      "Batch: 107, Loss: 0.9478814601898193, Accuracy: 0.7099609375\n",
      "Batch: 108, Loss: 0.9175886511802673, Accuracy: 0.69921875\n",
      "Batch: 109, Loss: 0.9937112927436829, Accuracy: 0.685546875\n",
      "Batch: 110, Loss: 0.8001933097839355, Accuracy: 0.7412109375\n",
      "Batch: 111, Loss: 0.9375301003456116, Accuracy: 0.6787109375\n",
      "Batch: 112, Loss: 0.9015300273895264, Accuracy: 0.7080078125\n",
      "Batch: 113, Loss: 0.9215238094329834, Accuracy: 0.7021484375\n",
      "Batch: 114, Loss: 0.9626089334487915, Accuracy: 0.6884765625\n",
      "Batch: 115, Loss: 1.0234653949737549, Accuracy: 0.6796875\n",
      "Batch: 116, Loss: 0.9452766180038452, Accuracy: 0.6953125\n",
      "Batch: 117, Loss: 0.9769375324249268, Accuracy: 0.693359375\n",
      "Batch: 118, Loss: 0.8390322923660278, Accuracy: 0.736328125\n",
      "Batch: 119, Loss: 0.8537083268165588, Accuracy: 0.7412109375\n",
      "Batch: 120, Loss: 0.9723227024078369, Accuracy: 0.6875\n",
      "Batch: 121, Loss: 0.9709179401397705, Accuracy: 0.6865234375\n",
      "Batch: 122, Loss: 0.9150747060775757, Accuracy: 0.7060546875\n",
      "Batch: 123, Loss: 0.8997395038604736, Accuracy: 0.71875\n",
      "Batch: 124, Loss: 0.9168477058410645, Accuracy: 0.7001953125\n",
      "Batch: 125, Loss: 0.9731363654136658, Accuracy: 0.7041015625\n",
      "Batch: 126, Loss: 0.9238351583480835, Accuracy: 0.703125\n",
      "Batch: 127, Loss: 0.8365978002548218, Accuracy: 0.7275390625\n",
      "Batch: 128, Loss: 1.0326404571533203, Accuracy: 0.6767578125\n",
      "Batch: 129, Loss: 0.8646408319473267, Accuracy: 0.7119140625\n",
      "Batch: 130, Loss: 1.0452910661697388, Accuracy: 0.66796875\n",
      "Batch: 131, Loss: 0.9847536087036133, Accuracy: 0.6796875\n",
      "Batch: 132, Loss: 0.9904778003692627, Accuracy: 0.6904296875\n",
      "Batch: 133, Loss: 0.8892419934272766, Accuracy: 0.6865234375\n",
      "Batch: 134, Loss: 0.9440324902534485, Accuracy: 0.6884765625\n",
      "Batch: 135, Loss: 0.8939851522445679, Accuracy: 0.724609375\n",
      "Batch: 136, Loss: 0.9193888902664185, Accuracy: 0.7080078125\n",
      "Batch: 137, Loss: 0.8821303844451904, Accuracy: 0.7119140625\n",
      "Batch: 138, Loss: 0.7868285775184631, Accuracy: 0.7294921875\n",
      "Batch: 139, Loss: 0.8527432680130005, Accuracy: 0.7197265625\n",
      "Batch: 140, Loss: 0.9581289291381836, Accuracy: 0.7041015625\n",
      "Batch: 141, Loss: 0.9341267347335815, Accuracy: 0.705078125\n",
      "Batch: 142, Loss: 1.000081181526184, Accuracy: 0.685546875\n",
      "Batch: 143, Loss: 0.9468610286712646, Accuracy: 0.69140625\n",
      "Batch: 144, Loss: 0.8833308219909668, Accuracy: 0.70703125\n",
      "Batch: 145, Loss: 0.8641607165336609, Accuracy: 0.689453125\n",
      "Batch: 146, Loss: 0.92142653465271, Accuracy: 0.69921875\n",
      "Batch: 147, Loss: 0.940388560295105, Accuracy: 0.6904296875\n",
      "Batch: 148, Loss: 1.0092875957489014, Accuracy: 0.6708984375\n",
      "Batch: 149, Loss: 0.8904157876968384, Accuracy: 0.70703125\n",
      "Batch: 150, Loss: 0.9034284353256226, Accuracy: 0.70703125\n",
      "Batch: 151, Loss: 0.8298616409301758, Accuracy: 0.740234375\n",
      "Epoch 30/80\n",
      "Batch: 1, Loss: 1.0588665008544922, Accuracy: 0.65625\n",
      "Batch: 2, Loss: 0.946026086807251, Accuracy: 0.689453125\n",
      "Batch: 3, Loss: 0.886161744594574, Accuracy: 0.7080078125\n",
      "Batch: 4, Loss: 0.8267889022827148, Accuracy: 0.73828125\n",
      "Batch: 5, Loss: 0.8532516956329346, Accuracy: 0.7333984375\n",
      "Batch: 6, Loss: 0.9195874333381653, Accuracy: 0.693359375\n",
      "Batch: 7, Loss: 0.8979214429855347, Accuracy: 0.7021484375\n",
      "Batch: 8, Loss: 0.8662083148956299, Accuracy: 0.71875\n",
      "Batch: 9, Loss: 0.8552622199058533, Accuracy: 0.734375\n",
      "Batch: 10, Loss: 0.8334609270095825, Accuracy: 0.7197265625\n",
      "Batch: 11, Loss: 0.9732863903045654, Accuracy: 0.6669921875\n",
      "Batch: 12, Loss: 0.957179069519043, Accuracy: 0.685546875\n",
      "Batch: 13, Loss: 0.7692283987998962, Accuracy: 0.7578125\n",
      "Batch: 14, Loss: 1.0036985874176025, Accuracy: 0.6669921875\n",
      "Batch: 15, Loss: 0.858065128326416, Accuracy: 0.7353515625\n",
      "Batch: 16, Loss: 0.861223578453064, Accuracy: 0.7509765625\n",
      "Batch: 17, Loss: 0.9485307931900024, Accuracy: 0.69140625\n",
      "Batch: 18, Loss: 0.9359484314918518, Accuracy: 0.703125\n",
      "Batch: 19, Loss: 0.9695613980293274, Accuracy: 0.7099609375\n",
      "Batch: 20, Loss: 0.8749483823776245, Accuracy: 0.7275390625\n",
      "Batch: 21, Loss: 0.8441905975341797, Accuracy: 0.7216796875\n",
      "Batch: 22, Loss: 1.023966670036316, Accuracy: 0.6689453125\n",
      "Batch: 23, Loss: 0.9231484532356262, Accuracy: 0.6982421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 24, Loss: 0.9367574453353882, Accuracy: 0.6923828125\n",
      "Batch: 25, Loss: 0.8945484161376953, Accuracy: 0.7060546875\n",
      "Batch: 26, Loss: 0.8086756467819214, Accuracy: 0.736328125\n",
      "Batch: 27, Loss: 0.8435313105583191, Accuracy: 0.7158203125\n",
      "Batch: 28, Loss: 0.9126133918762207, Accuracy: 0.7001953125\n",
      "Batch: 29, Loss: 0.8962092399597168, Accuracy: 0.70703125\n",
      "Batch: 30, Loss: 0.8616291284561157, Accuracy: 0.7412109375\n",
      "Batch: 31, Loss: 0.8498114347457886, Accuracy: 0.73828125\n",
      "Batch: 32, Loss: 0.8418635129928589, Accuracy: 0.7158203125\n",
      "Batch: 33, Loss: 1.0014984607696533, Accuracy: 0.6787109375\n",
      "Batch: 34, Loss: 1.0042204856872559, Accuracy: 0.6728515625\n",
      "Batch: 35, Loss: 0.9415527582168579, Accuracy: 0.6884765625\n",
      "Batch: 36, Loss: 0.950411319732666, Accuracy: 0.701171875\n",
      "Batch: 37, Loss: 0.894091784954071, Accuracy: 0.7041015625\n",
      "Batch: 38, Loss: 0.9328435063362122, Accuracy: 0.705078125\n",
      "Batch: 39, Loss: 0.931415855884552, Accuracy: 0.7021484375\n",
      "Batch: 40, Loss: 0.9474799036979675, Accuracy: 0.697265625\n",
      "Batch: 41, Loss: 0.8721882700920105, Accuracy: 0.7255859375\n",
      "Batch: 42, Loss: 0.7104735374450684, Accuracy: 0.76953125\n",
      "Batch: 43, Loss: 0.8949876427650452, Accuracy: 0.7060546875\n",
      "Batch: 44, Loss: 0.9000252485275269, Accuracy: 0.7158203125\n",
      "Batch: 45, Loss: 0.800430178642273, Accuracy: 0.7451171875\n",
      "Batch: 46, Loss: 0.8644902110099792, Accuracy: 0.73828125\n",
      "Batch: 47, Loss: 0.8961547613143921, Accuracy: 0.7255859375\n",
      "Batch: 48, Loss: 0.840593159198761, Accuracy: 0.7216796875\n",
      "Batch: 49, Loss: 0.9937920570373535, Accuracy: 0.69921875\n",
      "Batch: 50, Loss: 0.9239112138748169, Accuracy: 0.6923828125\n",
      "Batch: 51, Loss: 0.999638020992279, Accuracy: 0.6806640625\n",
      "Batch: 52, Loss: 0.9621121883392334, Accuracy: 0.6943359375\n",
      "Batch: 53, Loss: 0.8393152952194214, Accuracy: 0.7119140625\n",
      "Batch: 54, Loss: 0.8728027939796448, Accuracy: 0.7177734375\n",
      "Batch: 55, Loss: 0.9573748111724854, Accuracy: 0.6689453125\n",
      "Batch: 56, Loss: 0.9797293543815613, Accuracy: 0.6806640625\n",
      "Batch: 57, Loss: 0.9186784029006958, Accuracy: 0.708984375\n",
      "Batch: 58, Loss: 1.0260368585586548, Accuracy: 0.6748046875\n",
      "Batch: 59, Loss: 0.8725258708000183, Accuracy: 0.716796875\n",
      "Batch: 60, Loss: 0.828458309173584, Accuracy: 0.732421875\n",
      "Batch: 61, Loss: 0.9430148601531982, Accuracy: 0.701171875\n",
      "Batch: 62, Loss: 0.8809226751327515, Accuracy: 0.701171875\n",
      "Batch: 63, Loss: 0.942373514175415, Accuracy: 0.71484375\n",
      "Batch: 64, Loss: 0.8742132782936096, Accuracy: 0.716796875\n",
      "Batch: 65, Loss: 0.9287518262863159, Accuracy: 0.712890625\n",
      "Batch: 66, Loss: 0.8740460872650146, Accuracy: 0.736328125\n",
      "Batch: 67, Loss: 1.0048328638076782, Accuracy: 0.6982421875\n",
      "Batch: 68, Loss: 0.980208158493042, Accuracy: 0.681640625\n",
      "Batch: 69, Loss: 0.9549065828323364, Accuracy: 0.71484375\n",
      "Batch: 70, Loss: 0.8992786407470703, Accuracy: 0.7099609375\n",
      "Batch: 71, Loss: 0.9137176871299744, Accuracy: 0.7001953125\n",
      "Batch: 72, Loss: 0.8359315395355225, Accuracy: 0.72265625\n",
      "Batch: 73, Loss: 0.8462597727775574, Accuracy: 0.7392578125\n",
      "Batch: 74, Loss: 0.832707405090332, Accuracy: 0.748046875\n",
      "Batch: 75, Loss: 0.7821508646011353, Accuracy: 0.744140625\n",
      "Batch: 76, Loss: 0.9023308753967285, Accuracy: 0.701171875\n",
      "Batch: 77, Loss: 0.8571280837059021, Accuracy: 0.7275390625\n",
      "Batch: 78, Loss: 0.836022138595581, Accuracy: 0.7333984375\n",
      "Batch: 79, Loss: 0.8254271149635315, Accuracy: 0.74609375\n",
      "Batch: 80, Loss: 0.8639919757843018, Accuracy: 0.7080078125\n",
      "Batch: 81, Loss: 0.9596934914588928, Accuracy: 0.6748046875\n",
      "Batch: 82, Loss: 0.8953627943992615, Accuracy: 0.712890625\n",
      "Batch: 83, Loss: 0.785692572593689, Accuracy: 0.7470703125\n",
      "Batch: 84, Loss: 0.87273108959198, Accuracy: 0.7197265625\n",
      "Batch: 85, Loss: 0.8269014954566956, Accuracy: 0.7490234375\n",
      "Batch: 86, Loss: 1.0043054819107056, Accuracy: 0.6796875\n",
      "Batch: 87, Loss: 0.8206707239151001, Accuracy: 0.7373046875\n",
      "Batch: 88, Loss: 0.9231806993484497, Accuracy: 0.71875\n",
      "Batch: 89, Loss: 0.9106759428977966, Accuracy: 0.7236328125\n",
      "Batch: 90, Loss: 0.8509179353713989, Accuracy: 0.736328125\n",
      "Batch: 91, Loss: 0.8835949301719666, Accuracy: 0.7119140625\n",
      "Batch: 92, Loss: 0.9085021615028381, Accuracy: 0.7080078125\n",
      "Batch: 93, Loss: 0.89985191822052, Accuracy: 0.7109375\n",
      "Batch: 94, Loss: 0.8824801445007324, Accuracy: 0.708984375\n",
      "Batch: 95, Loss: 0.909866452217102, Accuracy: 0.6884765625\n",
      "Batch: 96, Loss: 0.9027596116065979, Accuracy: 0.716796875\n",
      "Batch: 97, Loss: 0.7512462139129639, Accuracy: 0.7666015625\n",
      "Batch: 98, Loss: 0.8308660984039307, Accuracy: 0.724609375\n",
      "Batch: 99, Loss: 0.8830500841140747, Accuracy: 0.7197265625\n",
      "Batch: 100, Loss: 0.8787896633148193, Accuracy: 0.7255859375\n",
      "Batch: 101, Loss: 0.9728537201881409, Accuracy: 0.6884765625\n",
      "Batch: 102, Loss: 0.8981099724769592, Accuracy: 0.7109375\n",
      "Batch: 103, Loss: 0.9777602553367615, Accuracy: 0.705078125\n",
      "Batch: 104, Loss: 0.8761676549911499, Accuracy: 0.7099609375\n",
      "Batch: 105, Loss: 0.899266242980957, Accuracy: 0.7255859375\n",
      "Batch: 106, Loss: 0.8643158674240112, Accuracy: 0.7109375\n",
      "Batch: 107, Loss: 0.8883626461029053, Accuracy: 0.7265625\n",
      "Batch: 108, Loss: 0.9213559031486511, Accuracy: 0.693359375\n",
      "Batch: 109, Loss: 0.9637926816940308, Accuracy: 0.6806640625\n",
      "Batch: 110, Loss: 0.7656592130661011, Accuracy: 0.7568359375\n",
      "Batch: 111, Loss: 0.9030335545539856, Accuracy: 0.7177734375\n",
      "Batch: 112, Loss: 0.8779367208480835, Accuracy: 0.7138671875\n",
      "Batch: 113, Loss: 0.9147590398788452, Accuracy: 0.708984375\n",
      "Batch: 114, Loss: 0.9715328812599182, Accuracy: 0.685546875\n",
      "Batch: 115, Loss: 1.0236979722976685, Accuracy: 0.666015625\n",
      "Batch: 116, Loss: 0.9542204737663269, Accuracy: 0.69140625\n",
      "Batch: 117, Loss: 0.9473288655281067, Accuracy: 0.7109375\n",
      "Batch: 118, Loss: 0.8038396835327148, Accuracy: 0.7392578125\n",
      "Batch: 119, Loss: 0.8135963082313538, Accuracy: 0.7470703125\n",
      "Batch: 120, Loss: 0.9222416877746582, Accuracy: 0.6904296875\n",
      "Batch: 121, Loss: 0.9519801139831543, Accuracy: 0.7060546875\n",
      "Batch: 122, Loss: 0.898989200592041, Accuracy: 0.7138671875\n",
      "Batch: 123, Loss: 0.8575557470321655, Accuracy: 0.736328125\n",
      "Batch: 124, Loss: 0.9216158390045166, Accuracy: 0.69921875\n",
      "Batch: 125, Loss: 0.9535337686538696, Accuracy: 0.7001953125\n",
      "Batch: 126, Loss: 0.9069702625274658, Accuracy: 0.703125\n",
      "Batch: 127, Loss: 0.8343042731285095, Accuracy: 0.7490234375\n",
      "Batch: 128, Loss: 1.0395381450653076, Accuracy: 0.6845703125\n",
      "Batch: 129, Loss: 0.8721851110458374, Accuracy: 0.720703125\n",
      "Batch: 130, Loss: 1.049217939376831, Accuracy: 0.662109375\n",
      "Batch: 131, Loss: 0.9363051652908325, Accuracy: 0.69140625\n",
      "Batch: 132, Loss: 0.9772859811782837, Accuracy: 0.6884765625\n",
      "Batch: 133, Loss: 0.8648692965507507, Accuracy: 0.7001953125\n",
      "Batch: 134, Loss: 0.9277252554893494, Accuracy: 0.677734375\n",
      "Batch: 135, Loss: 0.8889533877372742, Accuracy: 0.7373046875\n",
      "Batch: 136, Loss: 0.9561752676963806, Accuracy: 0.6884765625\n",
      "Batch: 137, Loss: 0.8803361654281616, Accuracy: 0.6943359375\n",
      "Batch: 138, Loss: 0.7816586494445801, Accuracy: 0.7490234375\n",
      "Batch: 139, Loss: 0.8271543979644775, Accuracy: 0.7216796875\n",
      "Batch: 140, Loss: 0.9168334007263184, Accuracy: 0.7080078125\n",
      "Batch: 141, Loss: 0.923940122127533, Accuracy: 0.7001953125\n",
      "Batch: 142, Loss: 0.9919320344924927, Accuracy: 0.6904296875\n",
      "Batch: 143, Loss: 0.9330382347106934, Accuracy: 0.712890625\n",
      "Batch: 144, Loss: 0.9299749135971069, Accuracy: 0.6923828125\n",
      "Batch: 145, Loss: 0.8593759536743164, Accuracy: 0.6982421875\n",
      "Batch: 146, Loss: 0.9575928449630737, Accuracy: 0.69140625\n",
      "Batch: 147, Loss: 0.9244696497917175, Accuracy: 0.7001953125\n",
      "Batch: 148, Loss: 1.019181728363037, Accuracy: 0.6494140625\n",
      "Batch: 149, Loss: 0.8842145204544067, Accuracy: 0.7236328125\n",
      "Batch: 150, Loss: 0.9021806716918945, Accuracy: 0.70703125\n",
      "Batch: 151, Loss: 0.783542275428772, Accuracy: 0.736328125\n",
      "Saved Weights at epoch 30 to file Weights_30.h5\n",
      "Epoch 31/80\n",
      "Batch: 1, Loss: 1.0436094999313354, Accuracy: 0.6650390625\n",
      "Batch: 2, Loss: 0.9652607440948486, Accuracy: 0.6826171875\n",
      "Batch: 3, Loss: 0.860575258731842, Accuracy: 0.712890625\n",
      "Batch: 4, Loss: 0.82823646068573, Accuracy: 0.7578125\n",
      "Batch: 5, Loss: 0.8413125276565552, Accuracy: 0.732421875\n",
      "Batch: 6, Loss: 0.8975139856338501, Accuracy: 0.7099609375\n",
      "Batch: 7, Loss: 0.8725459575653076, Accuracy: 0.69140625\n",
      "Batch: 8, Loss: 0.849679172039032, Accuracy: 0.7109375\n",
      "Batch: 9, Loss: 0.8134007453918457, Accuracy: 0.7314453125\n",
      "Batch: 10, Loss: 0.8314586281776428, Accuracy: 0.7216796875\n",
      "Batch: 11, Loss: 0.9447871446609497, Accuracy: 0.6904296875\n",
      "Batch: 12, Loss: 0.9673562049865723, Accuracy: 0.6953125\n",
      "Batch: 13, Loss: 0.7913446426391602, Accuracy: 0.7412109375\n",
      "Batch: 14, Loss: 0.9922670125961304, Accuracy: 0.6826171875\n",
      "Batch: 15, Loss: 0.8536970615386963, Accuracy: 0.728515625\n",
      "Batch: 16, Loss: 0.8555105924606323, Accuracy: 0.734375\n",
      "Batch: 17, Loss: 0.9396254420280457, Accuracy: 0.703125\n",
      "Batch: 18, Loss: 0.9180145263671875, Accuracy: 0.70703125\n",
      "Batch: 19, Loss: 0.9343428611755371, Accuracy: 0.7158203125\n",
      "Batch: 20, Loss: 0.8404024839401245, Accuracy: 0.7412109375\n",
      "Batch: 21, Loss: 0.8484194278717041, Accuracy: 0.724609375\n",
      "Batch: 22, Loss: 0.967988908290863, Accuracy: 0.6845703125\n",
      "Batch: 23, Loss: 0.9261601567268372, Accuracy: 0.703125\n",
      "Batch: 24, Loss: 0.94571852684021, Accuracy: 0.6943359375\n",
      "Batch: 25, Loss: 0.8488234281539917, Accuracy: 0.724609375\n",
      "Batch: 26, Loss: 0.7912461161613464, Accuracy: 0.73828125\n",
      "Batch: 27, Loss: 0.8423093557357788, Accuracy: 0.7080078125\n",
      "Batch: 28, Loss: 0.9076284170150757, Accuracy: 0.693359375\n",
      "Batch: 29, Loss: 0.884560763835907, Accuracy: 0.712890625\n",
      "Batch: 30, Loss: 0.8726046085357666, Accuracy: 0.71875\n",
      "Batch: 31, Loss: 0.820244312286377, Accuracy: 0.7412109375\n",
      "Batch: 32, Loss: 0.8336566090583801, Accuracy: 0.7265625\n",
      "Batch: 33, Loss: 0.968449592590332, Accuracy: 0.6962890625\n",
      "Batch: 34, Loss: 1.0038994550704956, Accuracy: 0.673828125\n",
      "Batch: 35, Loss: 0.9228991270065308, Accuracy: 0.6953125\n",
      "Batch: 36, Loss: 0.9487875699996948, Accuracy: 0.69921875\n",
      "Batch: 37, Loss: 0.8995591402053833, Accuracy: 0.7197265625\n",
      "Batch: 38, Loss: 0.9262874126434326, Accuracy: 0.6865234375\n",
      "Batch: 39, Loss: 0.9167414903640747, Accuracy: 0.708984375\n",
      "Batch: 40, Loss: 0.9177115559577942, Accuracy: 0.72265625\n",
      "Batch: 41, Loss: 0.8463410139083862, Accuracy: 0.720703125\n",
      "Batch: 42, Loss: 0.7022556066513062, Accuracy: 0.765625\n",
      "Batch: 43, Loss: 0.8626270294189453, Accuracy: 0.716796875\n",
      "Batch: 44, Loss: 0.9256240129470825, Accuracy: 0.697265625\n",
      "Batch: 45, Loss: 0.778905987739563, Accuracy: 0.7373046875\n",
      "Batch: 46, Loss: 0.8393195867538452, Accuracy: 0.7470703125\n",
      "Batch: 47, Loss: 0.8696226477622986, Accuracy: 0.7353515625\n",
      "Batch: 48, Loss: 0.8144725561141968, Accuracy: 0.7470703125\n",
      "Batch: 49, Loss: 0.9787673950195312, Accuracy: 0.6875\n",
      "Batch: 50, Loss: 0.9057642221450806, Accuracy: 0.69921875\n",
      "Batch: 51, Loss: 0.9906399250030518, Accuracy: 0.685546875\n",
      "Batch: 52, Loss: 0.9427869319915771, Accuracy: 0.7060546875\n",
      "Batch: 53, Loss: 0.8176462650299072, Accuracy: 0.7255859375\n",
      "Batch: 54, Loss: 0.8775458931922913, Accuracy: 0.708984375\n",
      "Batch: 55, Loss: 0.9941969513893127, Accuracy: 0.6748046875\n",
      "Batch: 56, Loss: 0.9406800270080566, Accuracy: 0.69921875\n",
      "Batch: 57, Loss: 0.9060157537460327, Accuracy: 0.7177734375\n",
      "Batch: 58, Loss: 0.9872382283210754, Accuracy: 0.6806640625\n",
      "Batch: 59, Loss: 0.8401426076889038, Accuracy: 0.734375\n",
      "Batch: 60, Loss: 0.8382023572921753, Accuracy: 0.73828125\n",
      "Batch: 61, Loss: 0.9382317066192627, Accuracy: 0.703125\n",
      "Batch: 62, Loss: 0.8886895775794983, Accuracy: 0.71484375\n",
      "Batch: 63, Loss: 0.9295845031738281, Accuracy: 0.705078125\n",
      "Batch: 64, Loss: 0.8862895369529724, Accuracy: 0.7119140625\n",
      "Batch: 65, Loss: 0.9013076424598694, Accuracy: 0.724609375\n",
      "Batch: 66, Loss: 0.8726938366889954, Accuracy: 0.7236328125\n",
      "Batch: 67, Loss: 0.981472373008728, Accuracy: 0.6923828125\n",
      "Batch: 68, Loss: 0.9381946325302124, Accuracy: 0.6943359375\n",
      "Batch: 69, Loss: 0.9409762620925903, Accuracy: 0.7060546875\n",
      "Batch: 70, Loss: 0.8884004354476929, Accuracy: 0.71875\n",
      "Batch: 71, Loss: 0.9252023696899414, Accuracy: 0.6943359375\n",
      "Batch: 72, Loss: 0.8178365230560303, Accuracy: 0.7353515625\n",
      "Batch: 73, Loss: 0.8288969993591309, Accuracy: 0.720703125\n",
      "Batch: 74, Loss: 0.8020512461662292, Accuracy: 0.748046875\n",
      "Batch: 75, Loss: 0.7725088000297546, Accuracy: 0.7314453125\n",
      "Batch: 76, Loss: 0.8894261121749878, Accuracy: 0.7138671875\n",
      "Batch: 77, Loss: 0.8481014966964722, Accuracy: 0.7216796875\n",
      "Batch: 78, Loss: 0.8605591058731079, Accuracy: 0.732421875\n",
      "Batch: 79, Loss: 0.8235000371932983, Accuracy: 0.7529296875\n",
      "Batch: 80, Loss: 0.8178508877754211, Accuracy: 0.7314453125\n",
      "Batch: 81, Loss: 0.9518352746963501, Accuracy: 0.6796875\n",
      "Batch: 82, Loss: 0.922720730304718, Accuracy: 0.7109375\n",
      "Batch: 83, Loss: 0.7563076019287109, Accuracy: 0.779296875\n",
      "Batch: 84, Loss: 0.8613443970680237, Accuracy: 0.734375\n",
      "Batch: 85, Loss: 0.8178977370262146, Accuracy: 0.744140625\n",
      "Batch: 86, Loss: 0.9750999808311462, Accuracy: 0.689453125\n",
      "Batch: 87, Loss: 0.8193740248680115, Accuracy: 0.7373046875\n",
      "Batch: 88, Loss: 0.9265545606613159, Accuracy: 0.7138671875\n",
      "Batch: 89, Loss: 0.9166290163993835, Accuracy: 0.71484375\n",
      "Batch: 90, Loss: 0.8634737730026245, Accuracy: 0.736328125\n",
      "Batch: 91, Loss: 0.8859583139419556, Accuracy: 0.7021484375\n",
      "Batch: 92, Loss: 0.925186812877655, Accuracy: 0.693359375\n",
      "Batch: 93, Loss: 0.873544454574585, Accuracy: 0.72265625\n",
      "Batch: 94, Loss: 0.9043892621994019, Accuracy: 0.701171875\n",
      "Batch: 95, Loss: 0.9121292233467102, Accuracy: 0.6884765625\n",
      "Batch: 96, Loss: 0.8427928686141968, Accuracy: 0.724609375\n",
      "Batch: 97, Loss: 0.7254065275192261, Accuracy: 0.765625\n",
      "Batch: 98, Loss: 0.8123971223831177, Accuracy: 0.7294921875\n",
      "Batch: 99, Loss: 0.8319554328918457, Accuracy: 0.732421875\n",
      "Batch: 100, Loss: 0.8529903292655945, Accuracy: 0.7197265625\n",
      "Batch: 101, Loss: 0.9509427547454834, Accuracy: 0.701171875\n",
      "Batch: 102, Loss: 0.8751257658004761, Accuracy: 0.7177734375\n",
      "Batch: 103, Loss: 0.9464502334594727, Accuracy: 0.7080078125\n",
      "Batch: 104, Loss: 0.8248607516288757, Accuracy: 0.724609375\n",
      "Batch: 105, Loss: 0.8733704686164856, Accuracy: 0.7158203125\n",
      "Batch: 106, Loss: 0.8322048187255859, Accuracy: 0.732421875\n",
      "Batch: 107, Loss: 0.8953945636749268, Accuracy: 0.7138671875\n",
      "Batch: 108, Loss: 0.887315034866333, Accuracy: 0.70703125\n",
      "Batch: 109, Loss: 0.9507979154586792, Accuracy: 0.6923828125\n",
      "Batch: 110, Loss: 0.7781566977500916, Accuracy: 0.7509765625\n",
      "Batch: 111, Loss: 0.8895430564880371, Accuracy: 0.7138671875\n",
      "Batch: 112, Loss: 0.879358172416687, Accuracy: 0.7119140625\n",
      "Batch: 113, Loss: 0.8794863224029541, Accuracy: 0.7119140625\n",
      "Batch: 114, Loss: 0.978874921798706, Accuracy: 0.6669921875\n",
      "Batch: 115, Loss: 1.0257078409194946, Accuracy: 0.697265625\n",
      "Batch: 116, Loss: 0.9333641529083252, Accuracy: 0.7080078125\n",
      "Batch: 117, Loss: 0.9475414156913757, Accuracy: 0.7060546875\n",
      "Batch: 118, Loss: 0.806139349937439, Accuracy: 0.740234375\n",
      "Batch: 119, Loss: 0.8337852358818054, Accuracy: 0.732421875\n",
      "Batch: 120, Loss: 0.8985326290130615, Accuracy: 0.6923828125\n",
      "Batch: 121, Loss: 0.9360594749450684, Accuracy: 0.6962890625\n",
      "Batch: 122, Loss: 0.8704842925071716, Accuracy: 0.720703125\n",
      "Batch: 123, Loss: 0.8556267619132996, Accuracy: 0.7158203125\n",
      "Batch: 124, Loss: 0.9087303876876831, Accuracy: 0.7001953125\n",
      "Batch: 125, Loss: 0.9410155415534973, Accuracy: 0.7041015625\n",
      "Batch: 126, Loss: 0.8750154376029968, Accuracy: 0.71875\n",
      "Batch: 127, Loss: 0.818579912185669, Accuracy: 0.7431640625\n",
      "Batch: 128, Loss: 0.9708656072616577, Accuracy: 0.6904296875\n",
      "Batch: 129, Loss: 0.852344274520874, Accuracy: 0.72265625\n",
      "Batch: 130, Loss: 1.0109825134277344, Accuracy: 0.6650390625\n",
      "Batch: 131, Loss: 0.9359496831893921, Accuracy: 0.703125\n",
      "Batch: 132, Loss: 0.9806408882141113, Accuracy: 0.693359375\n",
      "Batch: 133, Loss: 0.8643696308135986, Accuracy: 0.712890625\n",
      "Batch: 134, Loss: 0.9294297695159912, Accuracy: 0.6796875\n",
      "Batch: 135, Loss: 0.8762142658233643, Accuracy: 0.7236328125\n",
      "Batch: 136, Loss: 0.9133590459823608, Accuracy: 0.703125\n",
      "Batch: 137, Loss: 0.8860673904418945, Accuracy: 0.6962890625\n",
      "Batch: 138, Loss: 0.7909402251243591, Accuracy: 0.740234375\n",
      "Batch: 139, Loss: 0.8141978979110718, Accuracy: 0.7392578125\n",
      "Batch: 140, Loss: 0.895761251449585, Accuracy: 0.7109375\n",
      "Batch: 141, Loss: 0.8996030688285828, Accuracy: 0.73046875\n",
      "Batch: 142, Loss: 0.9600270986557007, Accuracy: 0.69140625\n",
      "Batch: 143, Loss: 0.92423415184021, Accuracy: 0.7001953125\n",
      "Batch: 144, Loss: 0.8968492746353149, Accuracy: 0.7099609375\n",
      "Batch: 145, Loss: 0.8390791416168213, Accuracy: 0.7197265625\n",
      "Batch: 146, Loss: 0.9257215261459351, Accuracy: 0.693359375\n",
      "Batch: 147, Loss: 0.9058918952941895, Accuracy: 0.7041015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 148, Loss: 1.011331558227539, Accuracy: 0.6611328125\n",
      "Batch: 149, Loss: 0.8747854232788086, Accuracy: 0.7216796875\n",
      "Batch: 150, Loss: 0.9180442094802856, Accuracy: 0.697265625\n",
      "Batch: 151, Loss: 0.798166036605835, Accuracy: 0.7421875\n",
      "Epoch 32/80\n",
      "Batch: 1, Loss: 1.0490623712539673, Accuracy: 0.65625\n",
      "Batch: 2, Loss: 0.9538207054138184, Accuracy: 0.677734375\n",
      "Batch: 3, Loss: 0.8643113970756531, Accuracy: 0.716796875\n",
      "Batch: 4, Loss: 0.8077225685119629, Accuracy: 0.7529296875\n",
      "Batch: 5, Loss: 0.8680545687675476, Accuracy: 0.7255859375\n",
      "Batch: 6, Loss: 0.8982332944869995, Accuracy: 0.703125\n",
      "Batch: 7, Loss: 0.9065897464752197, Accuracy: 0.7021484375\n",
      "Batch: 8, Loss: 0.8478982448577881, Accuracy: 0.716796875\n",
      "Batch: 9, Loss: 0.8331065773963928, Accuracy: 0.7255859375\n",
      "Batch: 10, Loss: 0.8286624550819397, Accuracy: 0.732421875\n",
      "Batch: 11, Loss: 0.9406368732452393, Accuracy: 0.689453125\n",
      "Batch: 12, Loss: 0.9320780038833618, Accuracy: 0.6904296875\n",
      "Batch: 13, Loss: 0.7965965270996094, Accuracy: 0.7470703125\n",
      "Batch: 14, Loss: 0.9833889007568359, Accuracy: 0.67578125\n",
      "Batch: 15, Loss: 0.8351964354515076, Accuracy: 0.74609375\n",
      "Batch: 16, Loss: 0.8379001617431641, Accuracy: 0.7470703125\n",
      "Batch: 17, Loss: 0.901474118232727, Accuracy: 0.7099609375\n",
      "Batch: 18, Loss: 0.9063340425491333, Accuracy: 0.703125\n",
      "Batch: 19, Loss: 0.9571099281311035, Accuracy: 0.705078125\n",
      "Batch: 20, Loss: 0.833214521408081, Accuracy: 0.7216796875\n",
      "Batch: 21, Loss: 0.8247475624084473, Accuracy: 0.7177734375\n",
      "Batch: 22, Loss: 0.9748002290725708, Accuracy: 0.6875\n",
      "Batch: 23, Loss: 0.8781030178070068, Accuracy: 0.7216796875\n",
      "Batch: 24, Loss: 0.920737087726593, Accuracy: 0.697265625\n",
      "Batch: 25, Loss: 0.852959394454956, Accuracy: 0.732421875\n",
      "Batch: 26, Loss: 0.7621668577194214, Accuracy: 0.763671875\n",
      "Batch: 27, Loss: 0.8456487655639648, Accuracy: 0.7158203125\n",
      "Batch: 28, Loss: 0.8917073011398315, Accuracy: 0.7021484375\n",
      "Batch: 29, Loss: 0.8530279397964478, Accuracy: 0.73046875\n",
      "Batch: 30, Loss: 0.8521602153778076, Accuracy: 0.736328125\n",
      "Batch: 31, Loss: 0.7858983278274536, Accuracy: 0.748046875\n",
      "Batch: 32, Loss: 0.8378204107284546, Accuracy: 0.7216796875\n",
      "Batch: 33, Loss: 0.9870767593383789, Accuracy: 0.6796875\n",
      "Batch: 34, Loss: 1.0183504819869995, Accuracy: 0.6689453125\n",
      "Batch: 35, Loss: 0.9260377883911133, Accuracy: 0.7080078125\n",
      "Batch: 36, Loss: 0.8908939361572266, Accuracy: 0.7314453125\n",
      "Batch: 37, Loss: 0.8826853036880493, Accuracy: 0.71875\n",
      "Batch: 38, Loss: 0.9174632430076599, Accuracy: 0.6962890625\n",
      "Batch: 39, Loss: 0.9135594964027405, Accuracy: 0.7021484375\n",
      "Batch: 40, Loss: 0.9374173879623413, Accuracy: 0.7001953125\n",
      "Batch: 41, Loss: 0.8087911605834961, Accuracy: 0.7333984375\n",
      "Batch: 42, Loss: 0.7020938396453857, Accuracy: 0.771484375\n",
      "Batch: 43, Loss: 0.871056079864502, Accuracy: 0.7177734375\n",
      "Batch: 44, Loss: 0.8994898796081543, Accuracy: 0.7119140625\n",
      "Batch: 45, Loss: 0.7837843298912048, Accuracy: 0.7421875\n",
      "Batch: 46, Loss: 0.8325620889663696, Accuracy: 0.7451171875\n",
      "Batch: 47, Loss: 0.8776457905769348, Accuracy: 0.7421875\n",
      "Batch: 48, Loss: 0.8068605065345764, Accuracy: 0.740234375\n",
      "Batch: 49, Loss: 0.9911328554153442, Accuracy: 0.68359375\n",
      "Batch: 50, Loss: 0.8799993991851807, Accuracy: 0.712890625\n",
      "Batch: 51, Loss: 0.9806321859359741, Accuracy: 0.6884765625\n",
      "Batch: 52, Loss: 0.9270586967468262, Accuracy: 0.708984375\n",
      "Batch: 53, Loss: 0.816961407661438, Accuracy: 0.740234375\n",
      "Batch: 54, Loss: 0.864019513130188, Accuracy: 0.734375\n",
      "Batch: 55, Loss: 0.958610475063324, Accuracy: 0.6865234375\n",
      "Batch: 56, Loss: 0.9388576149940491, Accuracy: 0.6953125\n",
      "Batch: 57, Loss: 0.8899279236793518, Accuracy: 0.7109375\n",
      "Batch: 58, Loss: 0.9771727323532104, Accuracy: 0.6904296875\n",
      "Batch: 59, Loss: 0.8487746119499207, Accuracy: 0.7255859375\n",
      "Batch: 60, Loss: 0.807118833065033, Accuracy: 0.734375\n",
      "Batch: 61, Loss: 0.9162789583206177, Accuracy: 0.7060546875\n",
      "Batch: 62, Loss: 0.833604633808136, Accuracy: 0.716796875\n",
      "Batch: 63, Loss: 0.8692115545272827, Accuracy: 0.728515625\n",
      "Batch: 64, Loss: 0.8444768190383911, Accuracy: 0.720703125\n",
      "Batch: 65, Loss: 0.9069164991378784, Accuracy: 0.7197265625\n",
      "Batch: 66, Loss: 0.8761463761329651, Accuracy: 0.7314453125\n",
      "Batch: 67, Loss: 0.9699097275733948, Accuracy: 0.701171875\n",
      "Batch: 68, Loss: 0.9375839829444885, Accuracy: 0.7001953125\n",
      "Batch: 69, Loss: 0.9011019468307495, Accuracy: 0.7080078125\n",
      "Batch: 70, Loss: 0.8925282955169678, Accuracy: 0.7373046875\n",
      "Batch: 71, Loss: 0.892964243888855, Accuracy: 0.720703125\n",
      "Batch: 72, Loss: 0.795884907245636, Accuracy: 0.7421875\n",
      "Batch: 73, Loss: 0.8356766700744629, Accuracy: 0.7314453125\n",
      "Batch: 74, Loss: 0.8088393211364746, Accuracy: 0.7431640625\n",
      "Batch: 75, Loss: 0.7835388779640198, Accuracy: 0.7509765625\n",
      "Batch: 76, Loss: 0.8804404735565186, Accuracy: 0.7001953125\n",
      "Batch: 77, Loss: 0.8197340965270996, Accuracy: 0.75\n",
      "Batch: 78, Loss: 0.8301030397415161, Accuracy: 0.7490234375\n",
      "Batch: 79, Loss: 0.8166126012802124, Accuracy: 0.7578125\n",
      "Batch: 80, Loss: 0.8165498971939087, Accuracy: 0.7197265625\n",
      "Batch: 81, Loss: 0.9234452843666077, Accuracy: 0.69140625\n",
      "Batch: 82, Loss: 0.8865065574645996, Accuracy: 0.697265625\n",
      "Batch: 83, Loss: 0.763350248336792, Accuracy: 0.765625\n",
      "Batch: 84, Loss: 0.8405280113220215, Accuracy: 0.734375\n",
      "Batch: 85, Loss: 0.7949913144111633, Accuracy: 0.7646484375\n",
      "Batch: 86, Loss: 0.9873291254043579, Accuracy: 0.7021484375\n",
      "Batch: 87, Loss: 0.8147072196006775, Accuracy: 0.732421875\n",
      "Batch: 88, Loss: 0.9008171558380127, Accuracy: 0.7158203125\n",
      "Batch: 89, Loss: 0.8709901571273804, Accuracy: 0.7431640625\n",
      "Batch: 90, Loss: 0.8389781713485718, Accuracy: 0.73828125\n",
      "Batch: 91, Loss: 0.858978271484375, Accuracy: 0.7216796875\n",
      "Batch: 92, Loss: 0.8759137392044067, Accuracy: 0.72265625\n",
      "Batch: 93, Loss: 0.8692163228988647, Accuracy: 0.7275390625\n",
      "Batch: 94, Loss: 0.8676329851150513, Accuracy: 0.7236328125\n",
      "Batch: 95, Loss: 0.8958791494369507, Accuracy: 0.7109375\n",
      "Batch: 96, Loss: 0.8699140548706055, Accuracy: 0.7216796875\n",
      "Batch: 97, Loss: 0.7280665636062622, Accuracy: 0.7548828125\n",
      "Batch: 98, Loss: 0.8602684140205383, Accuracy: 0.72265625\n",
      "Batch: 99, Loss: 0.8396041989326477, Accuracy: 0.7294921875\n",
      "Batch: 100, Loss: 0.8697631359100342, Accuracy: 0.716796875\n",
      "Batch: 101, Loss: 0.9394159317016602, Accuracy: 0.69921875\n",
      "Batch: 102, Loss: 0.8681576251983643, Accuracy: 0.7275390625\n",
      "Batch: 103, Loss: 0.9013240933418274, Accuracy: 0.7314453125\n",
      "Batch: 104, Loss: 0.8616509437561035, Accuracy: 0.7109375\n",
      "Batch: 105, Loss: 0.8717043995857239, Accuracy: 0.724609375\n",
      "Batch: 106, Loss: 0.8495074510574341, Accuracy: 0.7275390625\n",
      "Batch: 107, Loss: 0.9015793204307556, Accuracy: 0.7099609375\n",
      "Batch: 108, Loss: 0.9106040000915527, Accuracy: 0.705078125\n",
      "Batch: 109, Loss: 0.9557199478149414, Accuracy: 0.68359375\n",
      "Batch: 110, Loss: 0.7731069922447205, Accuracy: 0.7548828125\n",
      "Batch: 111, Loss: 0.9077669382095337, Accuracy: 0.6943359375\n",
      "Batch: 112, Loss: 0.8630720376968384, Accuracy: 0.716796875\n",
      "Batch: 113, Loss: 0.8754647970199585, Accuracy: 0.71484375\n",
      "Batch: 114, Loss: 0.9434332847595215, Accuracy: 0.681640625\n",
      "Batch: 115, Loss: 1.007629156112671, Accuracy: 0.6884765625\n",
      "Batch: 116, Loss: 0.9077466726303101, Accuracy: 0.7060546875\n",
      "Batch: 117, Loss: 0.9334326386451721, Accuracy: 0.6953125\n",
      "Batch: 118, Loss: 0.7891827821731567, Accuracy: 0.7373046875\n",
      "Batch: 119, Loss: 0.8110079765319824, Accuracy: 0.75390625\n",
      "Batch: 120, Loss: 0.8784627914428711, Accuracy: 0.720703125\n",
      "Batch: 121, Loss: 0.939824104309082, Accuracy: 0.6953125\n",
      "Batch: 122, Loss: 0.8604904413223267, Accuracy: 0.73828125\n",
      "Batch: 123, Loss: 0.847631573677063, Accuracy: 0.7373046875\n",
      "Batch: 124, Loss: 0.8857927918434143, Accuracy: 0.7041015625\n",
      "Batch: 125, Loss: 0.9422597885131836, Accuracy: 0.70703125\n",
      "Batch: 126, Loss: 0.8757439851760864, Accuracy: 0.7158203125\n",
      "Batch: 127, Loss: 0.8012229204177856, Accuracy: 0.7490234375\n",
      "Batch: 128, Loss: 0.9918407201766968, Accuracy: 0.6923828125\n",
      "Batch: 129, Loss: 0.829460859298706, Accuracy: 0.724609375\n",
      "Batch: 130, Loss: 1.0125867128372192, Accuracy: 0.671875\n",
      "Batch: 131, Loss: 0.9379100203514099, Accuracy: 0.701171875\n",
      "Batch: 132, Loss: 0.9448943734169006, Accuracy: 0.708984375\n",
      "Batch: 133, Loss: 0.8693991899490356, Accuracy: 0.697265625\n",
      "Batch: 134, Loss: 0.91196608543396, Accuracy: 0.6982421875\n",
      "Batch: 135, Loss: 0.866877555847168, Accuracy: 0.7294921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 136, Loss: 0.9069334268569946, Accuracy: 0.7119140625\n",
      "Batch: 137, Loss: 0.8713752031326294, Accuracy: 0.69921875\n",
      "Batch: 138, Loss: 0.7883439064025879, Accuracy: 0.736328125\n",
      "Batch: 139, Loss: 0.7994595766067505, Accuracy: 0.7431640625\n",
      "Batch: 140, Loss: 0.8928244709968567, Accuracy: 0.716796875\n",
      "Batch: 141, Loss: 0.8931583166122437, Accuracy: 0.6953125\n",
      "Batch: 142, Loss: 0.9465001821517944, Accuracy: 0.7158203125\n",
      "Batch: 143, Loss: 0.897218644618988, Accuracy: 0.7294921875\n",
      "Batch: 144, Loss: 0.8689188957214355, Accuracy: 0.734375\n",
      "Batch: 145, Loss: 0.8409143090248108, Accuracy: 0.7001953125\n",
      "Batch: 146, Loss: 0.930229663848877, Accuracy: 0.693359375\n",
      "Batch: 147, Loss: 0.9127706289291382, Accuracy: 0.701171875\n",
      "Batch: 148, Loss: 0.9576635956764221, Accuracy: 0.6875\n",
      "Batch: 149, Loss: 0.8582836985588074, Accuracy: 0.7236328125\n",
      "Batch: 150, Loss: 0.8844424486160278, Accuracy: 0.7109375\n",
      "Batch: 151, Loss: 0.8024930357933044, Accuracy: 0.74609375\n",
      "Epoch 33/80\n",
      "Batch: 1, Loss: 1.0678799152374268, Accuracy: 0.650390625\n",
      "Batch: 2, Loss: 0.9417370557785034, Accuracy: 0.6767578125\n",
      "Batch: 3, Loss: 0.8198360204696655, Accuracy: 0.7314453125\n",
      "Batch: 4, Loss: 0.7963547706604004, Accuracy: 0.7509765625\n",
      "Batch: 5, Loss: 0.8421143293380737, Accuracy: 0.736328125\n",
      "Batch: 6, Loss: 0.8925801515579224, Accuracy: 0.6953125\n",
      "Batch: 7, Loss: 0.8793125748634338, Accuracy: 0.6943359375\n",
      "Batch: 8, Loss: 0.8371238708496094, Accuracy: 0.7158203125\n",
      "Batch: 9, Loss: 0.8313112258911133, Accuracy: 0.7265625\n",
      "Batch: 10, Loss: 0.8185848593711853, Accuracy: 0.724609375\n",
      "Batch: 11, Loss: 0.9373919367790222, Accuracy: 0.6865234375\n",
      "Batch: 12, Loss: 0.9041265249252319, Accuracy: 0.71484375\n",
      "Batch: 13, Loss: 0.7407748699188232, Accuracy: 0.7607421875\n",
      "Batch: 14, Loss: 0.9661720991134644, Accuracy: 0.6728515625\n",
      "Batch: 15, Loss: 0.8195372819900513, Accuracy: 0.7509765625\n",
      "Batch: 16, Loss: 0.8451387882232666, Accuracy: 0.740234375\n",
      "Batch: 17, Loss: 0.8725041151046753, Accuracy: 0.7138671875\n",
      "Batch: 18, Loss: 0.8852840662002563, Accuracy: 0.7109375\n",
      "Batch: 19, Loss: 0.9220489859580994, Accuracy: 0.712890625\n",
      "Batch: 20, Loss: 0.8535054326057434, Accuracy: 0.748046875\n",
      "Batch: 21, Loss: 0.8390238285064697, Accuracy: 0.7197265625\n",
      "Batch: 22, Loss: 0.9491904973983765, Accuracy: 0.6884765625\n",
      "Batch: 23, Loss: 0.9209080934524536, Accuracy: 0.7021484375\n",
      "Batch: 24, Loss: 0.9209038019180298, Accuracy: 0.6943359375\n",
      "Batch: 25, Loss: 0.8211773633956909, Accuracy: 0.728515625\n",
      "Batch: 26, Loss: 0.7667481303215027, Accuracy: 0.75\n",
      "Batch: 27, Loss: 0.8249586820602417, Accuracy: 0.712890625\n",
      "Batch: 28, Loss: 0.8870708346366882, Accuracy: 0.712890625\n",
      "Batch: 29, Loss: 0.8437519073486328, Accuracy: 0.72265625\n",
      "Batch: 30, Loss: 0.8309083580970764, Accuracy: 0.7412109375\n",
      "Batch: 31, Loss: 0.7820889949798584, Accuracy: 0.7607421875\n",
      "Batch: 32, Loss: 0.8203773498535156, Accuracy: 0.7138671875\n",
      "Batch: 33, Loss: 0.939269483089447, Accuracy: 0.708984375\n",
      "Batch: 34, Loss: 0.9916185140609741, Accuracy: 0.6787109375\n",
      "Batch: 35, Loss: 0.9073734283447266, Accuracy: 0.693359375\n",
      "Batch: 36, Loss: 0.9293899536132812, Accuracy: 0.7197265625\n",
      "Batch: 37, Loss: 0.8676095008850098, Accuracy: 0.71484375\n",
      "Batch: 38, Loss: 0.8943766355514526, Accuracy: 0.7138671875\n",
      "Batch: 39, Loss: 0.8796422481536865, Accuracy: 0.72265625\n",
      "Batch: 40, Loss: 0.9044793248176575, Accuracy: 0.7021484375\n",
      "Batch: 41, Loss: 0.8110212087631226, Accuracy: 0.7392578125\n",
      "Batch: 42, Loss: 0.683527946472168, Accuracy: 0.7900390625\n",
      "Batch: 43, Loss: 0.8456347584724426, Accuracy: 0.7255859375\n",
      "Batch: 44, Loss: 0.9050014019012451, Accuracy: 0.7041015625\n",
      "Batch: 45, Loss: 0.7875277996063232, Accuracy: 0.744140625\n",
      "Batch: 46, Loss: 0.8465090990066528, Accuracy: 0.7431640625\n",
      "Batch: 47, Loss: 0.8425837755203247, Accuracy: 0.748046875\n",
      "Batch: 48, Loss: 0.7981698513031006, Accuracy: 0.7421875\n",
      "Batch: 49, Loss: 0.9688296318054199, Accuracy: 0.7099609375\n",
      "Batch: 50, Loss: 0.8799943923950195, Accuracy: 0.728515625\n",
      "Batch: 51, Loss: 0.9724780321121216, Accuracy: 0.7060546875\n",
      "Batch: 52, Loss: 0.8997462391853333, Accuracy: 0.7080078125\n",
      "Batch: 53, Loss: 0.7740365266799927, Accuracy: 0.7490234375\n",
      "Batch: 54, Loss: 0.8284298181533813, Accuracy: 0.728515625\n",
      "Batch: 55, Loss: 0.9350103139877319, Accuracy: 0.6875\n",
      "Batch: 56, Loss: 0.9447407722473145, Accuracy: 0.6904296875\n",
      "Batch: 57, Loss: 0.8578119277954102, Accuracy: 0.7236328125\n",
      "Batch: 58, Loss: 1.0035603046417236, Accuracy: 0.6943359375\n",
      "Batch: 59, Loss: 0.8433459997177124, Accuracy: 0.7265625\n",
      "Batch: 60, Loss: 0.8050829172134399, Accuracy: 0.744140625\n",
      "Batch: 61, Loss: 0.8766129016876221, Accuracy: 0.7265625\n",
      "Batch: 62, Loss: 0.83458012342453, Accuracy: 0.7392578125\n",
      "Batch: 63, Loss: 0.8859875202178955, Accuracy: 0.71484375\n",
      "Batch: 64, Loss: 0.8359092473983765, Accuracy: 0.7353515625\n",
      "Batch: 65, Loss: 0.8903688788414001, Accuracy: 0.728515625\n",
      "Batch: 66, Loss: 0.8736520409584045, Accuracy: 0.732421875\n",
      "Batch: 67, Loss: 0.9343825578689575, Accuracy: 0.705078125\n",
      "Batch: 68, Loss: 0.9493269920349121, Accuracy: 0.7021484375\n",
      "Batch: 69, Loss: 0.903127133846283, Accuracy: 0.7001953125\n",
      "Batch: 70, Loss: 0.9024354219436646, Accuracy: 0.7255859375\n",
      "Batch: 71, Loss: 0.89253830909729, Accuracy: 0.7197265625\n",
      "Batch: 72, Loss: 0.7819342613220215, Accuracy: 0.740234375\n",
      "Batch: 73, Loss: 0.8316542506217957, Accuracy: 0.740234375\n",
      "Batch: 74, Loss: 0.7783214449882507, Accuracy: 0.7568359375\n",
      "Batch: 75, Loss: 0.7587302923202515, Accuracy: 0.7607421875\n",
      "Batch: 76, Loss: 0.8338513374328613, Accuracy: 0.7255859375\n",
      "Batch: 77, Loss: 0.8189042806625366, Accuracy: 0.73046875\n",
      "Batch: 78, Loss: 0.8004692792892456, Accuracy: 0.7587890625\n",
      "Batch: 79, Loss: 0.8094992637634277, Accuracy: 0.7470703125\n",
      "Batch: 80, Loss: 0.800122857093811, Accuracy: 0.7373046875\n",
      "Batch: 81, Loss: 0.8951005935668945, Accuracy: 0.70703125\n",
      "Batch: 82, Loss: 0.8694496154785156, Accuracy: 0.72265625\n",
      "Batch: 83, Loss: 0.7407926917076111, Accuracy: 0.78125\n",
      "Batch: 84, Loss: 0.871086835861206, Accuracy: 0.7294921875\n",
      "Batch: 85, Loss: 0.7987149357795715, Accuracy: 0.759765625\n",
      "Batch: 86, Loss: 0.9692955017089844, Accuracy: 0.7001953125\n",
      "Batch: 87, Loss: 0.7979071140289307, Accuracy: 0.75\n",
      "Batch: 88, Loss: 0.889110267162323, Accuracy: 0.7275390625\n",
      "Batch: 89, Loss: 0.9118702411651611, Accuracy: 0.716796875\n",
      "Batch: 90, Loss: 0.8198807239532471, Accuracy: 0.7431640625\n",
      "Batch: 91, Loss: 0.8473615050315857, Accuracy: 0.7099609375\n",
      "Batch: 92, Loss: 0.8877370953559875, Accuracy: 0.7197265625\n",
      "Batch: 93, Loss: 0.8497037887573242, Accuracy: 0.7275390625\n",
      "Batch: 94, Loss: 0.881378173828125, Accuracy: 0.712890625\n",
      "Batch: 95, Loss: 0.874680757522583, Accuracy: 0.7099609375\n",
      "Batch: 96, Loss: 0.8487130999565125, Accuracy: 0.736328125\n",
      "Batch: 97, Loss: 0.7218818664550781, Accuracy: 0.76171875\n",
      "Batch: 98, Loss: 0.8184564113616943, Accuracy: 0.736328125\n",
      "Batch: 99, Loss: 0.8223159313201904, Accuracy: 0.7333984375\n",
      "Batch: 100, Loss: 0.8466947674751282, Accuracy: 0.720703125\n",
      "Batch: 101, Loss: 0.8978468179702759, Accuracy: 0.705078125\n",
      "Batch: 102, Loss: 0.8716813325881958, Accuracy: 0.7294921875\n",
      "Batch: 103, Loss: 0.9216931462287903, Accuracy: 0.7158203125\n",
      "Batch: 104, Loss: 0.8298420906066895, Accuracy: 0.736328125\n",
      "Batch: 105, Loss: 0.858169436454773, Accuracy: 0.72265625\n",
      "Batch: 106, Loss: 0.8256679773330688, Accuracy: 0.7353515625\n",
      "Batch: 107, Loss: 0.882172703742981, Accuracy: 0.7255859375\n",
      "Batch: 108, Loss: 0.8731109499931335, Accuracy: 0.7109375\n",
      "Batch: 109, Loss: 0.9389250874519348, Accuracy: 0.685546875\n",
      "Batch: 110, Loss: 0.7744714021682739, Accuracy: 0.7578125\n",
      "Batch: 111, Loss: 0.9105706214904785, Accuracy: 0.703125\n",
      "Batch: 112, Loss: 0.8718984127044678, Accuracy: 0.71875\n",
      "Batch: 113, Loss: 0.8448846936225891, Accuracy: 0.73046875\n",
      "Batch: 114, Loss: 0.935921311378479, Accuracy: 0.70703125\n",
      "Batch: 115, Loss: 0.9763168096542358, Accuracy: 0.677734375\n",
      "Batch: 116, Loss: 0.8790896534919739, Accuracy: 0.7333984375\n",
      "Batch: 117, Loss: 0.9408886432647705, Accuracy: 0.7041015625\n",
      "Batch: 118, Loss: 0.8204693794250488, Accuracy: 0.7373046875\n",
      "Batch: 119, Loss: 0.7891303300857544, Accuracy: 0.7666015625\n",
      "Batch: 120, Loss: 0.8681782484054565, Accuracy: 0.72265625\n",
      "Batch: 121, Loss: 0.8967821598052979, Accuracy: 0.7177734375\n",
      "Batch: 122, Loss: 0.8508486151695251, Accuracy: 0.734375\n",
      "Batch: 123, Loss: 0.8268903493881226, Accuracy: 0.7255859375\n",
      "Batch: 124, Loss: 0.9024218320846558, Accuracy: 0.7255859375\n",
      "Batch: 125, Loss: 0.9302846789360046, Accuracy: 0.7041015625\n",
      "Batch: 126, Loss: 0.8877084851264954, Accuracy: 0.7158203125\n",
      "Batch: 127, Loss: 0.7916488647460938, Accuracy: 0.7490234375\n",
      "Batch: 128, Loss: 1.000333547592163, Accuracy: 0.6943359375\n",
      "Batch: 129, Loss: 0.8140458464622498, Accuracy: 0.72265625\n",
      "Batch: 130, Loss: 0.9702714085578918, Accuracy: 0.6875\n",
      "Batch: 131, Loss: 0.9180775284767151, Accuracy: 0.6982421875\n",
      "Batch: 132, Loss: 0.9329694509506226, Accuracy: 0.703125\n",
      "Batch: 133, Loss: 0.8483124375343323, Accuracy: 0.7138671875\n",
      "Batch: 134, Loss: 0.8892350196838379, Accuracy: 0.697265625\n",
      "Batch: 135, Loss: 0.8147398233413696, Accuracy: 0.7431640625\n",
      "Batch: 136, Loss: 0.8843551278114319, Accuracy: 0.7158203125\n",
      "Batch: 137, Loss: 0.8643691539764404, Accuracy: 0.6982421875\n",
      "Batch: 138, Loss: 0.7877697944641113, Accuracy: 0.7373046875\n",
      "Batch: 139, Loss: 0.7917808890342712, Accuracy: 0.7421875\n",
      "Batch: 140, Loss: 0.8938209414482117, Accuracy: 0.705078125\n",
      "Batch: 141, Loss: 0.8937263488769531, Accuracy: 0.7294921875\n",
      "Batch: 142, Loss: 0.9164332151412964, Accuracy: 0.71484375\n",
      "Batch: 143, Loss: 0.8783307671546936, Accuracy: 0.705078125\n",
      "Batch: 144, Loss: 0.8312284350395203, Accuracy: 0.734375\n",
      "Batch: 145, Loss: 0.8374300599098206, Accuracy: 0.716796875\n",
      "Batch: 146, Loss: 0.9123398065567017, Accuracy: 0.6923828125\n",
      "Batch: 147, Loss: 0.9019356369972229, Accuracy: 0.69921875\n",
      "Batch: 148, Loss: 0.977306604385376, Accuracy: 0.6806640625\n",
      "Batch: 149, Loss: 0.8585256338119507, Accuracy: 0.720703125\n",
      "Batch: 150, Loss: 0.8789814710617065, Accuracy: 0.708984375\n",
      "Batch: 151, Loss: 0.7540808916091919, Accuracy: 0.759765625\n",
      "Epoch 34/80\n",
      "Batch: 1, Loss: 1.0278549194335938, Accuracy: 0.6767578125\n",
      "Batch: 2, Loss: 0.9461779594421387, Accuracy: 0.6728515625\n",
      "Batch: 3, Loss: 0.8498678207397461, Accuracy: 0.7197265625\n",
      "Batch: 4, Loss: 0.8004266619682312, Accuracy: 0.734375\n",
      "Batch: 5, Loss: 0.8129919171333313, Accuracy: 0.7373046875\n",
      "Batch: 6, Loss: 0.8597662448883057, Accuracy: 0.7119140625\n",
      "Batch: 7, Loss: 0.8398517370223999, Accuracy: 0.728515625\n",
      "Batch: 8, Loss: 0.8064653873443604, Accuracy: 0.7275390625\n",
      "Batch: 9, Loss: 0.781234860420227, Accuracy: 0.7490234375\n",
      "Batch: 10, Loss: 0.8055461049079895, Accuracy: 0.7314453125\n",
      "Batch: 11, Loss: 0.8867805600166321, Accuracy: 0.712890625\n",
      "Batch: 12, Loss: 0.9087421298027039, Accuracy: 0.697265625\n",
      "Batch: 13, Loss: 0.7228876352310181, Accuracy: 0.765625\n",
      "Batch: 14, Loss: 0.9542710185050964, Accuracy: 0.689453125\n",
      "Batch: 15, Loss: 0.8097927570343018, Accuracy: 0.744140625\n",
      "Batch: 16, Loss: 0.838430643081665, Accuracy: 0.736328125\n",
      "Batch: 17, Loss: 0.8889110088348389, Accuracy: 0.724609375\n",
      "Batch: 18, Loss: 0.8629042506217957, Accuracy: 0.73046875\n",
      "Batch: 19, Loss: 0.9128641486167908, Accuracy: 0.7099609375\n",
      "Batch: 20, Loss: 0.828053891658783, Accuracy: 0.74609375\n",
      "Batch: 21, Loss: 0.8059229850769043, Accuracy: 0.7353515625\n",
      "Batch: 22, Loss: 0.9420662522315979, Accuracy: 0.6796875\n",
      "Batch: 23, Loss: 0.8525497913360596, Accuracy: 0.7109375\n",
      "Batch: 24, Loss: 0.8962592482566833, Accuracy: 0.697265625\n",
      "Batch: 25, Loss: 0.8408463001251221, Accuracy: 0.7197265625\n",
      "Batch: 26, Loss: 0.7421286702156067, Accuracy: 0.75390625\n",
      "Batch: 27, Loss: 0.8178593516349792, Accuracy: 0.7392578125\n",
      "Batch: 28, Loss: 0.876656711101532, Accuracy: 0.7041015625\n",
      "Batch: 29, Loss: 0.8189178705215454, Accuracy: 0.7392578125\n",
      "Batch: 30, Loss: 0.8039141893386841, Accuracy: 0.744140625\n",
      "Batch: 31, Loss: 0.7828214168548584, Accuracy: 0.75390625\n",
      "Batch: 32, Loss: 0.7958816289901733, Accuracy: 0.724609375\n",
      "Batch: 33, Loss: 0.9427052140235901, Accuracy: 0.703125\n",
      "Batch: 34, Loss: 0.9823766946792603, Accuracy: 0.6865234375\n",
      "Batch: 35, Loss: 0.8829890489578247, Accuracy: 0.70703125\n",
      "Batch: 36, Loss: 0.8682624101638794, Accuracy: 0.7314453125\n",
      "Batch: 37, Loss: 0.8521796464920044, Accuracy: 0.7255859375\n",
      "Batch: 38, Loss: 0.8982576131820679, Accuracy: 0.7138671875\n",
      "Batch: 39, Loss: 0.8633057475090027, Accuracy: 0.724609375\n",
      "Batch: 40, Loss: 0.880657434463501, Accuracy: 0.7333984375\n",
      "Batch: 41, Loss: 0.8107619285583496, Accuracy: 0.73828125\n",
      "Batch: 42, Loss: 0.6624751687049866, Accuracy: 0.7724609375\n",
      "Batch: 43, Loss: 0.8242642283439636, Accuracy: 0.724609375\n",
      "Batch: 44, Loss: 0.8729808330535889, Accuracy: 0.716796875\n",
      "Batch: 45, Loss: 0.760682225227356, Accuracy: 0.75390625\n",
      "Batch: 46, Loss: 0.8357882499694824, Accuracy: 0.74609375\n",
      "Batch: 47, Loss: 0.8334356546401978, Accuracy: 0.7529296875\n",
      "Batch: 48, Loss: 0.8015842437744141, Accuracy: 0.7451171875\n",
      "Batch: 49, Loss: 0.9422746896743774, Accuracy: 0.6943359375\n",
      "Batch: 50, Loss: 0.8405197858810425, Accuracy: 0.7353515625\n",
      "Batch: 51, Loss: 0.9299641847610474, Accuracy: 0.7119140625\n",
      "Batch: 52, Loss: 0.8840510845184326, Accuracy: 0.7158203125\n",
      "Batch: 53, Loss: 0.7565455436706543, Accuracy: 0.7548828125\n",
      "Batch: 54, Loss: 0.8145115375518799, Accuracy: 0.7412109375\n",
      "Batch: 55, Loss: 0.943487823009491, Accuracy: 0.693359375\n",
      "Batch: 56, Loss: 0.9436282515525818, Accuracy: 0.6953125\n",
      "Batch: 57, Loss: 0.8630006313323975, Accuracy: 0.7255859375\n",
      "Batch: 58, Loss: 0.9411482214927673, Accuracy: 0.7119140625\n",
      "Batch: 59, Loss: 0.8389480113983154, Accuracy: 0.728515625\n",
      "Batch: 60, Loss: 0.8071502447128296, Accuracy: 0.7392578125\n",
      "Batch: 61, Loss: 0.8914976716041565, Accuracy: 0.71484375\n",
      "Batch: 62, Loss: 0.8392629623413086, Accuracy: 0.72265625\n",
      "Batch: 63, Loss: 0.8908880949020386, Accuracy: 0.71484375\n",
      "Batch: 64, Loss: 0.8477941155433655, Accuracy: 0.7294921875\n",
      "Batch: 65, Loss: 0.9036523103713989, Accuracy: 0.71875\n",
      "Batch: 66, Loss: 0.8418303728103638, Accuracy: 0.72265625\n",
      "Batch: 67, Loss: 0.9329786896705627, Accuracy: 0.7158203125\n",
      "Batch: 68, Loss: 0.9163785576820374, Accuracy: 0.7109375\n",
      "Batch: 69, Loss: 0.8970931172370911, Accuracy: 0.708984375\n",
      "Batch: 70, Loss: 0.8989183902740479, Accuracy: 0.7265625\n",
      "Batch: 71, Loss: 0.8807492852210999, Accuracy: 0.7060546875\n",
      "Batch: 72, Loss: 0.804162859916687, Accuracy: 0.734375\n",
      "Batch: 73, Loss: 0.7670503854751587, Accuracy: 0.765625\n",
      "Batch: 74, Loss: 0.7798023223876953, Accuracy: 0.7529296875\n",
      "Batch: 75, Loss: 0.7689875960350037, Accuracy: 0.7529296875\n",
      "Batch: 76, Loss: 0.8334304690361023, Accuracy: 0.7255859375\n",
      "Batch: 77, Loss: 0.7906233072280884, Accuracy: 0.7529296875\n",
      "Batch: 78, Loss: 0.7970950603485107, Accuracy: 0.7626953125\n",
      "Batch: 79, Loss: 0.7949346303939819, Accuracy: 0.75390625\n",
      "Batch: 80, Loss: 0.8014355897903442, Accuracy: 0.736328125\n",
      "Batch: 81, Loss: 0.8983861207962036, Accuracy: 0.6943359375\n",
      "Batch: 82, Loss: 0.86620032787323, Accuracy: 0.728515625\n",
      "Batch: 83, Loss: 0.7392246723175049, Accuracy: 0.7626953125\n",
      "Batch: 84, Loss: 0.8120523691177368, Accuracy: 0.744140625\n",
      "Batch: 85, Loss: 0.7984045743942261, Accuracy: 0.75390625\n",
      "Batch: 86, Loss: 0.9535219669342041, Accuracy: 0.6923828125\n",
      "Batch: 87, Loss: 0.7650855779647827, Accuracy: 0.7587890625\n",
      "Batch: 88, Loss: 0.895256757736206, Accuracy: 0.7265625\n",
      "Batch: 89, Loss: 0.8663915395736694, Accuracy: 0.7470703125\n",
      "Batch: 90, Loss: 0.8166192173957825, Accuracy: 0.7392578125\n",
      "Batch: 91, Loss: 0.8440995216369629, Accuracy: 0.720703125\n",
      "Batch: 92, Loss: 0.8993720412254333, Accuracy: 0.7138671875\n",
      "Batch: 93, Loss: 0.8639582395553589, Accuracy: 0.712890625\n",
      "Batch: 94, Loss: 0.8615388870239258, Accuracy: 0.71484375\n",
      "Batch: 95, Loss: 0.882945716381073, Accuracy: 0.7021484375\n",
      "Batch: 96, Loss: 0.8597123622894287, Accuracy: 0.71484375\n",
      "Batch: 97, Loss: 0.6993716955184937, Accuracy: 0.7734375\n",
      "Batch: 98, Loss: 0.8073025345802307, Accuracy: 0.7373046875\n",
      "Batch: 99, Loss: 0.8138174414634705, Accuracy: 0.73046875\n",
      "Batch: 100, Loss: 0.8431328535079956, Accuracy: 0.72265625\n",
      "Batch: 101, Loss: 0.9046337604522705, Accuracy: 0.701171875\n",
      "Batch: 102, Loss: 0.8322021961212158, Accuracy: 0.732421875\n",
      "Batch: 103, Loss: 0.8897668123245239, Accuracy: 0.72265625\n",
      "Batch: 104, Loss: 0.822810173034668, Accuracy: 0.732421875\n",
      "Batch: 105, Loss: 0.8602153658866882, Accuracy: 0.7216796875\n",
      "Batch: 106, Loss: 0.7987862825393677, Accuracy: 0.74609375\n",
      "Batch: 107, Loss: 0.8556697368621826, Accuracy: 0.7275390625\n",
      "Batch: 108, Loss: 0.8731719255447388, Accuracy: 0.716796875\n",
      "Batch: 109, Loss: 0.9261958599090576, Accuracy: 0.712890625\n",
      "Batch: 110, Loss: 0.7585139274597168, Accuracy: 0.75390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 111, Loss: 0.8720688223838806, Accuracy: 0.72265625\n",
      "Batch: 112, Loss: 0.8664950132369995, Accuracy: 0.720703125\n",
      "Batch: 113, Loss: 0.8623948693275452, Accuracy: 0.71875\n",
      "Batch: 114, Loss: 0.9087412357330322, Accuracy: 0.7099609375\n",
      "Batch: 115, Loss: 0.9914865493774414, Accuracy: 0.6943359375\n",
      "Batch: 116, Loss: 0.8705379962921143, Accuracy: 0.7080078125\n",
      "Batch: 117, Loss: 0.9099970459938049, Accuracy: 0.71484375\n",
      "Batch: 118, Loss: 0.7626806497573853, Accuracy: 0.76171875\n",
      "Batch: 119, Loss: 0.8003889322280884, Accuracy: 0.7509765625\n",
      "Batch: 120, Loss: 0.8497337102890015, Accuracy: 0.7275390625\n",
      "Batch: 121, Loss: 0.9345769882202148, Accuracy: 0.701171875\n",
      "Batch: 122, Loss: 0.8481169939041138, Accuracy: 0.7314453125\n",
      "Batch: 123, Loss: 0.8231586217880249, Accuracy: 0.740234375\n",
      "Batch: 124, Loss: 0.8687376976013184, Accuracy: 0.7080078125\n",
      "Batch: 125, Loss: 0.9315948486328125, Accuracy: 0.705078125\n",
      "Batch: 126, Loss: 0.8758628368377686, Accuracy: 0.7216796875\n",
      "Batch: 127, Loss: 0.7884677648544312, Accuracy: 0.7607421875\n",
      "Batch: 128, Loss: 0.9591282606124878, Accuracy: 0.7041015625\n",
      "Batch: 129, Loss: 0.8192517757415771, Accuracy: 0.7470703125\n",
      "Batch: 130, Loss: 0.9940329790115356, Accuracy: 0.68359375\n",
      "Batch: 131, Loss: 0.9239973425865173, Accuracy: 0.7021484375\n",
      "Batch: 132, Loss: 0.9158110618591309, Accuracy: 0.7099609375\n",
      "Batch: 133, Loss: 0.8372831344604492, Accuracy: 0.7158203125\n",
      "Batch: 134, Loss: 0.8764117360115051, Accuracy: 0.7060546875\n",
      "Batch: 135, Loss: 0.838982343673706, Accuracy: 0.7373046875\n",
      "Batch: 136, Loss: 0.905143141746521, Accuracy: 0.71875\n",
      "Batch: 137, Loss: 0.8134266138076782, Accuracy: 0.697265625\n",
      "Batch: 138, Loss: 0.7666349411010742, Accuracy: 0.7470703125\n",
      "Batch: 139, Loss: 0.7956877946853638, Accuracy: 0.740234375\n",
      "Batch: 140, Loss: 0.8937350511550903, Accuracy: 0.705078125\n",
      "Batch: 141, Loss: 0.8607510328292847, Accuracy: 0.7373046875\n",
      "Batch: 142, Loss: 0.955054759979248, Accuracy: 0.689453125\n",
      "Batch: 143, Loss: 0.8799259662628174, Accuracy: 0.7177734375\n",
      "Batch: 144, Loss: 0.8521732687950134, Accuracy: 0.732421875\n",
      "Batch: 145, Loss: 0.8178330063819885, Accuracy: 0.712890625\n",
      "Batch: 146, Loss: 0.8691312074661255, Accuracy: 0.7177734375\n",
      "Batch: 147, Loss: 0.8867166042327881, Accuracy: 0.71484375\n",
      "Batch: 148, Loss: 0.9536780118942261, Accuracy: 0.6953125\n",
      "Batch: 149, Loss: 0.84755939245224, Accuracy: 0.716796875\n",
      "Batch: 150, Loss: 0.8306613564491272, Accuracy: 0.7353515625\n",
      "Batch: 151, Loss: 0.7544128894805908, Accuracy: 0.7412109375\n",
      "Epoch 35/80\n",
      "Batch: 1, Loss: 1.0174775123596191, Accuracy: 0.6630859375\n",
      "Batch: 2, Loss: 0.9328790903091431, Accuracy: 0.677734375\n",
      "Batch: 3, Loss: 0.8123681545257568, Accuracy: 0.7294921875\n",
      "Batch: 4, Loss: 0.7903443574905396, Accuracy: 0.759765625\n",
      "Batch: 5, Loss: 0.8189525604248047, Accuracy: 0.7392578125\n",
      "Batch: 6, Loss: 0.8638303279876709, Accuracy: 0.705078125\n",
      "Batch: 7, Loss: 0.8600420951843262, Accuracy: 0.712890625\n",
      "Batch: 8, Loss: 0.7950314283370972, Accuracy: 0.73828125\n",
      "Batch: 9, Loss: 0.8000415563583374, Accuracy: 0.73828125\n",
      "Batch: 10, Loss: 0.794729471206665, Accuracy: 0.7294921875\n",
      "Batch: 11, Loss: 0.9074759483337402, Accuracy: 0.6826171875\n",
      "Batch: 12, Loss: 0.8930994272232056, Accuracy: 0.7158203125\n",
      "Batch: 13, Loss: 0.718880832195282, Accuracy: 0.759765625\n",
      "Batch: 14, Loss: 0.9243517518043518, Accuracy: 0.7021484375\n",
      "Batch: 15, Loss: 0.7864071130752563, Accuracy: 0.755859375\n",
      "Batch: 16, Loss: 0.7985512018203735, Accuracy: 0.7490234375\n",
      "Batch: 17, Loss: 0.8696743249893188, Accuracy: 0.7197265625\n",
      "Batch: 18, Loss: 0.8789825439453125, Accuracy: 0.720703125\n",
      "Batch: 19, Loss: 0.9195219874382019, Accuracy: 0.712890625\n",
      "Batch: 20, Loss: 0.8061836361885071, Accuracy: 0.755859375\n",
      "Batch: 21, Loss: 0.8022899031639099, Accuracy: 0.7392578125\n",
      "Batch: 22, Loss: 0.9170681238174438, Accuracy: 0.703125\n",
      "Batch: 23, Loss: 0.8743400573730469, Accuracy: 0.720703125\n",
      "Batch: 24, Loss: 0.8942239284515381, Accuracy: 0.70703125\n",
      "Batch: 25, Loss: 0.830578088760376, Accuracy: 0.7412109375\n",
      "Batch: 26, Loss: 0.7264682054519653, Accuracy: 0.763671875\n",
      "Batch: 27, Loss: 0.8168133497238159, Accuracy: 0.7109375\n",
      "Batch: 28, Loss: 0.8516412973403931, Accuracy: 0.71875\n",
      "Batch: 29, Loss: 0.8377548456192017, Accuracy: 0.736328125\n",
      "Batch: 30, Loss: 0.7905136346817017, Accuracy: 0.7470703125\n",
      "Batch: 31, Loss: 0.76903235912323, Accuracy: 0.7548828125\n",
      "Batch: 32, Loss: 0.7643860578536987, Accuracy: 0.7353515625\n",
      "Batch: 33, Loss: 0.9510018825531006, Accuracy: 0.705078125\n",
      "Batch: 34, Loss: 0.9485867619514465, Accuracy: 0.6845703125\n",
      "Batch: 35, Loss: 0.8619265556335449, Accuracy: 0.7177734375\n",
      "Batch: 36, Loss: 0.886121392250061, Accuracy: 0.740234375\n",
      "Batch: 37, Loss: 0.8556930422782898, Accuracy: 0.74609375\n",
      "Batch: 38, Loss: 0.877882719039917, Accuracy: 0.69921875\n",
      "Batch: 39, Loss: 0.8661234378814697, Accuracy: 0.7333984375\n",
      "Batch: 40, Loss: 0.8446871638298035, Accuracy: 0.7451171875\n",
      "Batch: 41, Loss: 0.7727032899856567, Accuracy: 0.7490234375\n",
      "Batch: 42, Loss: 0.6552388668060303, Accuracy: 0.7919921875\n",
      "Batch: 43, Loss: 0.8377128839492798, Accuracy: 0.7255859375\n",
      "Batch: 44, Loss: 0.8814698457717896, Accuracy: 0.7041015625\n",
      "Batch: 45, Loss: 0.7529900074005127, Accuracy: 0.7451171875\n",
      "Batch: 46, Loss: 0.802362859249115, Accuracy: 0.7412109375\n",
      "Batch: 47, Loss: 0.8375340700149536, Accuracy: 0.748046875\n",
      "Batch: 48, Loss: 0.7855236530303955, Accuracy: 0.748046875\n",
      "Batch: 49, Loss: 0.9187193512916565, Accuracy: 0.705078125\n",
      "Batch: 50, Loss: 0.8523647785186768, Accuracy: 0.7265625\n",
      "Batch: 51, Loss: 0.9265302419662476, Accuracy: 0.69921875\n",
      "Batch: 52, Loss: 0.8828991055488586, Accuracy: 0.7275390625\n",
      "Batch: 53, Loss: 0.7741976976394653, Accuracy: 0.7509765625\n",
      "Batch: 54, Loss: 0.8452194929122925, Accuracy: 0.7265625\n",
      "Batch: 55, Loss: 0.9254939556121826, Accuracy: 0.6845703125\n",
      "Batch: 56, Loss: 0.9021399617195129, Accuracy: 0.705078125\n",
      "Batch: 57, Loss: 0.8459758162498474, Accuracy: 0.72265625\n",
      "Batch: 58, Loss: 0.948533296585083, Accuracy: 0.7041015625\n",
      "Batch: 59, Loss: 0.8296022415161133, Accuracy: 0.7392578125\n",
      "Batch: 60, Loss: 0.7723622918128967, Accuracy: 0.74609375\n",
      "Batch: 61, Loss: 0.8763240575790405, Accuracy: 0.71875\n",
      "Batch: 62, Loss: 0.7966960668563843, Accuracy: 0.7490234375\n",
      "Batch: 63, Loss: 0.8841413259506226, Accuracy: 0.7275390625\n",
      "Batch: 64, Loss: 0.8173365592956543, Accuracy: 0.732421875\n",
      "Batch: 65, Loss: 0.8675302267074585, Accuracy: 0.7255859375\n",
      "Batch: 66, Loss: 0.8312034606933594, Accuracy: 0.7333984375\n",
      "Batch: 67, Loss: 0.930624783039093, Accuracy: 0.7060546875\n",
      "Batch: 68, Loss: 0.9222475290298462, Accuracy: 0.7119140625\n",
      "Batch: 69, Loss: 0.8809643983840942, Accuracy: 0.7216796875\n",
      "Batch: 70, Loss: 0.8599847555160522, Accuracy: 0.734375\n",
      "Batch: 71, Loss: 0.8788648843765259, Accuracy: 0.7099609375\n",
      "Batch: 72, Loss: 0.7528447508811951, Accuracy: 0.7490234375\n",
      "Batch: 73, Loss: 0.7908288240432739, Accuracy: 0.7529296875\n",
      "Batch: 74, Loss: 0.7717539668083191, Accuracy: 0.7578125\n",
      "Batch: 75, Loss: 0.7390174865722656, Accuracy: 0.7529296875\n",
      "Batch: 76, Loss: 0.8063326478004456, Accuracy: 0.72265625\n",
      "Batch: 77, Loss: 0.7838340401649475, Accuracy: 0.7509765625\n",
      "Batch: 78, Loss: 0.7940893769264221, Accuracy: 0.7587890625\n",
      "Batch: 79, Loss: 0.8036104440689087, Accuracy: 0.76171875\n",
      "Batch: 80, Loss: 0.7767407894134521, Accuracy: 0.7412109375\n",
      "Batch: 81, Loss: 0.9035266041755676, Accuracy: 0.6904296875\n",
      "Batch: 82, Loss: 0.8562443256378174, Accuracy: 0.7158203125\n",
      "Batch: 83, Loss: 0.7142420411109924, Accuracy: 0.783203125\n",
      "Batch: 84, Loss: 0.8182805180549622, Accuracy: 0.7421875\n",
      "Batch: 85, Loss: 0.756711483001709, Accuracy: 0.7587890625\n",
      "Batch: 86, Loss: 0.9771113991737366, Accuracy: 0.68359375\n",
      "Batch: 87, Loss: 0.780239462852478, Accuracy: 0.7529296875\n",
      "Batch: 88, Loss: 0.9109330177307129, Accuracy: 0.7236328125\n",
      "Batch: 89, Loss: 0.8591880798339844, Accuracy: 0.732421875\n",
      "Batch: 90, Loss: 0.8046464323997498, Accuracy: 0.7548828125\n",
      "Batch: 91, Loss: 0.8255054354667664, Accuracy: 0.7275390625\n",
      "Batch: 92, Loss: 0.879433810710907, Accuracy: 0.7158203125\n",
      "Batch: 93, Loss: 0.8245813250541687, Accuracy: 0.7451171875\n",
      "Batch: 94, Loss: 0.8632960915565491, Accuracy: 0.71875\n",
      "Batch: 95, Loss: 0.8489800691604614, Accuracy: 0.72265625\n",
      "Batch: 96, Loss: 0.8222317695617676, Accuracy: 0.7275390625\n",
      "Batch: 97, Loss: 0.7169079780578613, Accuracy: 0.7666015625\n",
      "Batch: 98, Loss: 0.825394868850708, Accuracy: 0.734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 99, Loss: 0.8019484281539917, Accuracy: 0.7412109375\n",
      "Batch: 100, Loss: 0.8115597367286682, Accuracy: 0.732421875\n",
      "Batch: 101, Loss: 0.9116989374160767, Accuracy: 0.7119140625\n",
      "Batch: 102, Loss: 0.8340395092964172, Accuracy: 0.73828125\n",
      "Batch: 103, Loss: 0.876661479473114, Accuracy: 0.732421875\n",
      "Batch: 104, Loss: 0.8066467046737671, Accuracy: 0.7265625\n",
      "Batch: 105, Loss: 0.8428342342376709, Accuracy: 0.7275390625\n",
      "Batch: 106, Loss: 0.8211246728897095, Accuracy: 0.7265625\n",
      "Batch: 107, Loss: 0.8001028299331665, Accuracy: 0.7607421875\n",
      "Batch: 108, Loss: 0.8387786149978638, Accuracy: 0.724609375\n",
      "Batch: 109, Loss: 0.9015616774559021, Accuracy: 0.693359375\n",
      "Batch: 110, Loss: 0.7536075711250305, Accuracy: 0.751953125\n",
      "Batch: 111, Loss: 0.8520256876945496, Accuracy: 0.7138671875\n",
      "Batch: 112, Loss: 0.823411762714386, Accuracy: 0.724609375\n",
      "Batch: 113, Loss: 0.8417283296585083, Accuracy: 0.734375\n",
      "Batch: 114, Loss: 0.907883882522583, Accuracy: 0.708984375\n",
      "Batch: 115, Loss: 0.9473668336868286, Accuracy: 0.703125\n",
      "Batch: 116, Loss: 0.8738608360290527, Accuracy: 0.71875\n",
      "Batch: 117, Loss: 0.9039937257766724, Accuracy: 0.7197265625\n",
      "Batch: 118, Loss: 0.7554011940956116, Accuracy: 0.751953125\n",
      "Batch: 119, Loss: 0.763826847076416, Accuracy: 0.751953125\n",
      "Batch: 120, Loss: 0.8409230709075928, Accuracy: 0.7021484375\n",
      "Batch: 121, Loss: 0.8981841206550598, Accuracy: 0.7177734375\n",
      "Batch: 122, Loss: 0.8278837203979492, Accuracy: 0.75390625\n",
      "Batch: 123, Loss: 0.7908514738082886, Accuracy: 0.7490234375\n",
      "Batch: 124, Loss: 0.8501490354537964, Accuracy: 0.7158203125\n",
      "Batch: 125, Loss: 0.908147394657135, Accuracy: 0.7265625\n",
      "Batch: 126, Loss: 0.8589315414428711, Accuracy: 0.720703125\n",
      "Batch: 127, Loss: 0.7819255590438843, Accuracy: 0.75390625\n",
      "Batch: 128, Loss: 0.970501720905304, Accuracy: 0.701171875\n",
      "Batch: 129, Loss: 0.7966086268424988, Accuracy: 0.7353515625\n",
      "Batch: 130, Loss: 0.9812671542167664, Accuracy: 0.6796875\n",
      "Batch: 131, Loss: 0.8626866936683655, Accuracy: 0.7099609375\n",
      "Batch: 132, Loss: 0.8854566812515259, Accuracy: 0.71875\n",
      "Batch: 133, Loss: 0.8337799906730652, Accuracy: 0.71875\n",
      "Batch: 134, Loss: 0.8709709644317627, Accuracy: 0.6982421875\n",
      "Batch: 135, Loss: 0.7927659153938293, Accuracy: 0.7470703125\n",
      "Batch: 136, Loss: 0.8827446103096008, Accuracy: 0.708984375\n",
      "Batch: 137, Loss: 0.8109608888626099, Accuracy: 0.716796875\n",
      "Batch: 138, Loss: 0.7514063119888306, Accuracy: 0.74609375\n",
      "Batch: 139, Loss: 0.7726539969444275, Accuracy: 0.748046875\n",
      "Batch: 140, Loss: 0.8482785224914551, Accuracy: 0.7255859375\n",
      "Batch: 141, Loss: 0.8725637793540955, Accuracy: 0.71875\n",
      "Batch: 142, Loss: 0.937400221824646, Accuracy: 0.701171875\n",
      "Batch: 143, Loss: 0.8533092737197876, Accuracy: 0.7265625\n",
      "Batch: 144, Loss: 0.8795444965362549, Accuracy: 0.72265625\n",
      "Batch: 145, Loss: 0.7959972620010376, Accuracy: 0.7099609375\n",
      "Batch: 146, Loss: 0.8877213597297668, Accuracy: 0.703125\n",
      "Batch: 147, Loss: 0.8517169952392578, Accuracy: 0.7138671875\n",
      "Batch: 148, Loss: 0.9368722438812256, Accuracy: 0.6884765625\n",
      "Batch: 149, Loss: 0.825036883354187, Accuracy: 0.7216796875\n",
      "Batch: 150, Loss: 0.8361779451370239, Accuracy: 0.73046875\n",
      "Batch: 151, Loss: 0.762148380279541, Accuracy: 0.7705078125\n",
      "Epoch 36/80\n",
      "Batch: 1, Loss: 0.9915879964828491, Accuracy: 0.6748046875\n",
      "Batch: 2, Loss: 0.9005411863327026, Accuracy: 0.685546875\n",
      "Batch: 3, Loss: 0.8123539686203003, Accuracy: 0.7392578125\n",
      "Batch: 4, Loss: 0.7895800471305847, Accuracy: 0.7646484375\n",
      "Batch: 5, Loss: 0.7850878834724426, Accuracy: 0.7548828125\n",
      "Batch: 6, Loss: 0.8732818961143494, Accuracy: 0.70703125\n",
      "Batch: 7, Loss: 0.8475674390792847, Accuracy: 0.7001953125\n",
      "Batch: 8, Loss: 0.793879508972168, Accuracy: 0.734375\n",
      "Batch: 9, Loss: 0.7903802394866943, Accuracy: 0.7431640625\n",
      "Batch: 10, Loss: 0.7888333797454834, Accuracy: 0.7255859375\n",
      "Batch: 11, Loss: 0.8758342266082764, Accuracy: 0.708984375\n",
      "Batch: 12, Loss: 0.8914306163787842, Accuracy: 0.7080078125\n",
      "Batch: 13, Loss: 0.7300623655319214, Accuracy: 0.7646484375\n",
      "Batch: 14, Loss: 0.9099459648132324, Accuracy: 0.6943359375\n",
      "Batch: 15, Loss: 0.8037430047988892, Accuracy: 0.755859375\n",
      "Batch: 16, Loss: 0.7826884388923645, Accuracy: 0.7578125\n",
      "Batch: 17, Loss: 0.8496812582015991, Accuracy: 0.7138671875\n",
      "Batch: 18, Loss: 0.8454155921936035, Accuracy: 0.7216796875\n",
      "Batch: 19, Loss: 0.8813979029655457, Accuracy: 0.73046875\n",
      "Batch: 20, Loss: 0.7764503955841064, Accuracy: 0.7568359375\n",
      "Batch: 21, Loss: 0.7621277570724487, Accuracy: 0.7578125\n",
      "Batch: 22, Loss: 0.9242561459541321, Accuracy: 0.6982421875\n",
      "Batch: 23, Loss: 0.8547357320785522, Accuracy: 0.712890625\n",
      "Batch: 24, Loss: 0.8682622313499451, Accuracy: 0.70703125\n",
      "Batch: 25, Loss: 0.7926516532897949, Accuracy: 0.73828125\n",
      "Batch: 26, Loss: 0.7428150177001953, Accuracy: 0.759765625\n",
      "Batch: 27, Loss: 0.7907967567443848, Accuracy: 0.720703125\n",
      "Batch: 28, Loss: 0.8265460729598999, Accuracy: 0.728515625\n",
      "Batch: 29, Loss: 0.7857643365859985, Accuracy: 0.7451171875\n",
      "Batch: 30, Loss: 0.7901201248168945, Accuracy: 0.7587890625\n",
      "Batch: 31, Loss: 0.7441564798355103, Accuracy: 0.765625\n",
      "Batch: 32, Loss: 0.7616859078407288, Accuracy: 0.744140625\n",
      "Batch: 33, Loss: 0.8854851722717285, Accuracy: 0.73046875\n",
      "Batch: 34, Loss: 0.9497154951095581, Accuracy: 0.68359375\n",
      "Batch: 35, Loss: 0.8658443689346313, Accuracy: 0.720703125\n",
      "Batch: 36, Loss: 0.8778308629989624, Accuracy: 0.7265625\n",
      "Batch: 37, Loss: 0.8304578065872192, Accuracy: 0.7431640625\n",
      "Batch: 38, Loss: 0.9008277654647827, Accuracy: 0.7119140625\n",
      "Batch: 39, Loss: 0.8617592453956604, Accuracy: 0.7177734375\n",
      "Batch: 40, Loss: 0.8516826033592224, Accuracy: 0.7216796875\n",
      "Batch: 41, Loss: 0.8007882833480835, Accuracy: 0.7431640625\n",
      "Batch: 42, Loss: 0.6694435477256775, Accuracy: 0.7763671875\n",
      "Batch: 43, Loss: 0.7816593647003174, Accuracy: 0.7490234375\n",
      "Batch: 44, Loss: 0.8488805294036865, Accuracy: 0.7373046875\n",
      "Batch: 45, Loss: 0.7348731160163879, Accuracy: 0.7626953125\n",
      "Batch: 46, Loss: 0.7703374624252319, Accuracy: 0.7646484375\n",
      "Batch: 47, Loss: 0.8372952938079834, Accuracy: 0.7431640625\n",
      "Batch: 48, Loss: 0.8010691404342651, Accuracy: 0.7509765625\n",
      "Batch: 49, Loss: 0.9481930732727051, Accuracy: 0.701171875\n",
      "Batch: 50, Loss: 0.8480148911476135, Accuracy: 0.724609375\n",
      "Batch: 51, Loss: 0.9413037896156311, Accuracy: 0.6884765625\n",
      "Batch: 52, Loss: 0.8530282974243164, Accuracy: 0.73046875\n",
      "Batch: 53, Loss: 0.7651533484458923, Accuracy: 0.7470703125\n",
      "Batch: 54, Loss: 0.8030346632003784, Accuracy: 0.7451171875\n",
      "Batch: 55, Loss: 0.8985574245452881, Accuracy: 0.7060546875\n",
      "Batch: 56, Loss: 0.9098259210586548, Accuracy: 0.708984375\n",
      "Batch: 57, Loss: 0.8576980829238892, Accuracy: 0.71875\n",
      "Batch: 58, Loss: 0.9479398727416992, Accuracy: 0.7001953125\n",
      "Batch: 59, Loss: 0.7978029847145081, Accuracy: 0.7568359375\n",
      "Batch: 60, Loss: 0.7593528032302856, Accuracy: 0.744140625\n",
      "Batch: 61, Loss: 0.8657440543174744, Accuracy: 0.7255859375\n",
      "Batch: 62, Loss: 0.8304970860481262, Accuracy: 0.7255859375\n",
      "Batch: 63, Loss: 0.847940981388092, Accuracy: 0.7255859375\n",
      "Batch: 64, Loss: 0.8001776337623596, Accuracy: 0.74609375\n",
      "Batch: 65, Loss: 0.8424452543258667, Accuracy: 0.7314453125\n",
      "Batch: 66, Loss: 0.8248202204704285, Accuracy: 0.7392578125\n",
      "Batch: 67, Loss: 0.9370647072792053, Accuracy: 0.7001953125\n",
      "Batch: 68, Loss: 0.8888370394706726, Accuracy: 0.7109375\n",
      "Batch: 69, Loss: 0.8761019110679626, Accuracy: 0.7119140625\n",
      "Batch: 70, Loss: 0.876934289932251, Accuracy: 0.736328125\n",
      "Batch: 71, Loss: 0.8290481567382812, Accuracy: 0.736328125\n",
      "Batch: 72, Loss: 0.7549529075622559, Accuracy: 0.7412109375\n",
      "Batch: 73, Loss: 0.7997457981109619, Accuracy: 0.7568359375\n",
      "Batch: 74, Loss: 0.7485888004302979, Accuracy: 0.7734375\n",
      "Batch: 75, Loss: 0.7347788214683533, Accuracy: 0.76171875\n",
      "Batch: 76, Loss: 0.8210006356239319, Accuracy: 0.7431640625\n",
      "Batch: 77, Loss: 0.7884005308151245, Accuracy: 0.74609375\n",
      "Batch: 78, Loss: 0.7665011286735535, Accuracy: 0.7607421875\n",
      "Batch: 79, Loss: 0.7633998990058899, Accuracy: 0.76171875\n",
      "Batch: 80, Loss: 0.7474863529205322, Accuracy: 0.7587890625\n",
      "Batch: 81, Loss: 0.8752446174621582, Accuracy: 0.708984375\n",
      "Batch: 82, Loss: 0.8447308540344238, Accuracy: 0.7119140625\n",
      "Batch: 83, Loss: 0.7142589092254639, Accuracy: 0.7822265625\n",
      "Batch: 84, Loss: 0.8526530265808105, Accuracy: 0.736328125\n",
      "Batch: 85, Loss: 0.7623465061187744, Accuracy: 0.75390625\n",
      "Batch: 86, Loss: 0.9507613778114319, Accuracy: 0.7041015625\n",
      "Batch: 87, Loss: 0.7573115825653076, Accuracy: 0.7548828125\n",
      "Batch: 88, Loss: 0.8563965559005737, Accuracy: 0.72265625\n",
      "Batch: 89, Loss: 0.8391174077987671, Accuracy: 0.7294921875\n",
      "Batch: 90, Loss: 0.7600631713867188, Accuracy: 0.751953125\n",
      "Batch: 91, Loss: 0.7928333878517151, Accuracy: 0.7265625\n",
      "Batch: 92, Loss: 0.8317394256591797, Accuracy: 0.75\n",
      "Batch: 93, Loss: 0.8407461643218994, Accuracy: 0.7275390625\n",
      "Batch: 94, Loss: 0.8438782095909119, Accuracy: 0.7275390625\n",
      "Batch: 95, Loss: 0.8257808685302734, Accuracy: 0.716796875\n",
      "Batch: 96, Loss: 0.8071485161781311, Accuracy: 0.740234375\n",
      "Batch: 97, Loss: 0.6908771991729736, Accuracy: 0.7685546875\n",
      "Batch: 98, Loss: 0.8073956966400146, Accuracy: 0.740234375\n",
      "Batch: 99, Loss: 0.8029184341430664, Accuracy: 0.728515625\n",
      "Batch: 100, Loss: 0.835507869720459, Accuracy: 0.7236328125\n",
      "Batch: 101, Loss: 0.9034390449523926, Accuracy: 0.6982421875\n",
      "Batch: 102, Loss: 0.8055599927902222, Accuracy: 0.748046875\n",
      "Batch: 103, Loss: 0.8506419658660889, Accuracy: 0.7177734375\n",
      "Batch: 104, Loss: 0.7787011861801147, Accuracy: 0.7421875\n",
      "Batch: 105, Loss: 0.8132818341255188, Accuracy: 0.7333984375\n",
      "Batch: 106, Loss: 0.7875043153762817, Accuracy: 0.751953125\n",
      "Batch: 107, Loss: 0.8407318592071533, Accuracy: 0.75\n",
      "Batch: 108, Loss: 0.8355313539505005, Accuracy: 0.7265625\n",
      "Batch: 109, Loss: 0.9018457531929016, Accuracy: 0.69921875\n",
      "Batch: 110, Loss: 0.755219042301178, Accuracy: 0.76171875\n",
      "Batch: 111, Loss: 0.8416985869407654, Accuracy: 0.71875\n",
      "Batch: 112, Loss: 0.7972643375396729, Accuracy: 0.736328125\n",
      "Batch: 113, Loss: 0.8428264856338501, Accuracy: 0.7177734375\n",
      "Batch: 114, Loss: 0.9083907604217529, Accuracy: 0.7080078125\n",
      "Batch: 115, Loss: 0.9710985422134399, Accuracy: 0.689453125\n",
      "Batch: 116, Loss: 0.8831484913825989, Accuracy: 0.6953125\n",
      "Batch: 117, Loss: 0.9075907468795776, Accuracy: 0.7080078125\n",
      "Batch: 118, Loss: 0.7609033584594727, Accuracy: 0.748046875\n",
      "Batch: 119, Loss: 0.7530549764633179, Accuracy: 0.7646484375\n",
      "Batch: 120, Loss: 0.8301798105239868, Accuracy: 0.732421875\n",
      "Batch: 121, Loss: 0.8992320895195007, Accuracy: 0.69921875\n",
      "Batch: 122, Loss: 0.8425499796867371, Accuracy: 0.7314453125\n",
      "Batch: 123, Loss: 0.7869076728820801, Accuracy: 0.744140625\n",
      "Batch: 124, Loss: 0.8211061954498291, Accuracy: 0.7333984375\n",
      "Batch: 125, Loss: 0.879095733165741, Accuracy: 0.7197265625\n",
      "Batch: 126, Loss: 0.8422396183013916, Accuracy: 0.7177734375\n",
      "Batch: 127, Loss: 0.7403031587600708, Accuracy: 0.7626953125\n",
      "Batch: 128, Loss: 0.9202353954315186, Accuracy: 0.7177734375\n",
      "Batch: 129, Loss: 0.7735224366188049, Accuracy: 0.75\n",
      "Batch: 130, Loss: 0.97348552942276, Accuracy: 0.685546875\n",
      "Batch: 131, Loss: 0.8685255646705627, Accuracy: 0.7353515625\n",
      "Batch: 132, Loss: 0.9083194732666016, Accuracy: 0.712890625\n",
      "Batch: 133, Loss: 0.8090448379516602, Accuracy: 0.7255859375\n",
      "Batch: 134, Loss: 0.8573724031448364, Accuracy: 0.71484375\n",
      "Batch: 135, Loss: 0.8099703788757324, Accuracy: 0.734375\n",
      "Batch: 136, Loss: 0.8504222631454468, Accuracy: 0.732421875\n",
      "Batch: 137, Loss: 0.8457596898078918, Accuracy: 0.7119140625\n",
      "Batch: 138, Loss: 0.7502474784851074, Accuracy: 0.7490234375\n",
      "Batch: 139, Loss: 0.7413169145584106, Accuracy: 0.7626953125\n",
      "Batch: 140, Loss: 0.8456674814224243, Accuracy: 0.7275390625\n",
      "Batch: 141, Loss: 0.8620507717132568, Accuracy: 0.7177734375\n",
      "Batch: 142, Loss: 0.9143213629722595, Accuracy: 0.712890625\n",
      "Batch: 143, Loss: 0.8747597336769104, Accuracy: 0.7119140625\n",
      "Batch: 144, Loss: 0.8348817825317383, Accuracy: 0.7421875\n",
      "Batch: 145, Loss: 0.8178260326385498, Accuracy: 0.70703125\n",
      "Batch: 146, Loss: 0.9061848521232605, Accuracy: 0.701171875\n",
      "Batch: 147, Loss: 0.8449664115905762, Accuracy: 0.71484375\n",
      "Batch: 148, Loss: 0.9556297063827515, Accuracy: 0.6875\n",
      "Batch: 149, Loss: 0.8023605942726135, Accuracy: 0.716796875\n",
      "Batch: 150, Loss: 0.8487991094589233, Accuracy: 0.736328125\n",
      "Batch: 151, Loss: 0.7425841689109802, Accuracy: 0.759765625\n",
      "Epoch 37/80\n",
      "Batch: 1, Loss: 1.0003188848495483, Accuracy: 0.685546875\n",
      "Batch: 2, Loss: 0.8692910075187683, Accuracy: 0.7109375\n",
      "Batch: 3, Loss: 0.8092315196990967, Accuracy: 0.72265625\n",
      "Batch: 4, Loss: 0.7561633586883545, Accuracy: 0.77734375\n",
      "Batch: 5, Loss: 0.8018615245819092, Accuracy: 0.744140625\n",
      "Batch: 6, Loss: 0.851715087890625, Accuracy: 0.716796875\n",
      "Batch: 7, Loss: 0.8134293556213379, Accuracy: 0.7216796875\n",
      "Batch: 8, Loss: 0.7758796811103821, Accuracy: 0.732421875\n",
      "Batch: 9, Loss: 0.7523590326309204, Accuracy: 0.7646484375\n",
      "Batch: 10, Loss: 0.7786293625831604, Accuracy: 0.7353515625\n",
      "Batch: 11, Loss: 0.9102237224578857, Accuracy: 0.697265625\n",
      "Batch: 12, Loss: 0.8540804386138916, Accuracy: 0.7412109375\n",
      "Batch: 13, Loss: 0.6961443424224854, Accuracy: 0.771484375\n",
      "Batch: 14, Loss: 0.8902652263641357, Accuracy: 0.69921875\n",
      "Batch: 15, Loss: 0.7544367909431458, Accuracy: 0.7685546875\n",
      "Batch: 16, Loss: 0.7954425811767578, Accuracy: 0.77734375\n",
      "Batch: 17, Loss: 0.8515762090682983, Accuracy: 0.7216796875\n",
      "Batch: 18, Loss: 0.8480443954467773, Accuracy: 0.7392578125\n",
      "Batch: 19, Loss: 0.8839422464370728, Accuracy: 0.7275390625\n",
      "Batch: 20, Loss: 0.7852823138237, Accuracy: 0.7626953125\n",
      "Batch: 21, Loss: 0.7754481434822083, Accuracy: 0.75\n",
      "Batch: 22, Loss: 0.9055206775665283, Accuracy: 0.708984375\n",
      "Batch: 23, Loss: 0.8835594654083252, Accuracy: 0.7109375\n",
      "Batch: 24, Loss: 0.8593432307243347, Accuracy: 0.71484375\n",
      "Batch: 25, Loss: 0.8028607368469238, Accuracy: 0.732421875\n",
      "Batch: 26, Loss: 0.7266572713851929, Accuracy: 0.759765625\n",
      "Batch: 27, Loss: 0.7984314560890198, Accuracy: 0.7275390625\n",
      "Batch: 28, Loss: 0.8334737420082092, Accuracy: 0.7216796875\n",
      "Batch: 29, Loss: 0.7723175287246704, Accuracy: 0.748046875\n",
      "Batch: 30, Loss: 0.752812922000885, Accuracy: 0.76171875\n",
      "Batch: 31, Loss: 0.7397541999816895, Accuracy: 0.767578125\n",
      "Batch: 32, Loss: 0.7686209678649902, Accuracy: 0.7431640625\n",
      "Batch: 33, Loss: 0.8961828947067261, Accuracy: 0.7138671875\n",
      "Batch: 34, Loss: 0.9333599209785461, Accuracy: 0.6904296875\n",
      "Batch: 35, Loss: 0.8559814691543579, Accuracy: 0.7080078125\n",
      "Batch: 36, Loss: 0.8658933043479919, Accuracy: 0.73046875\n",
      "Batch: 37, Loss: 0.8074594140052795, Accuracy: 0.736328125\n",
      "Batch: 38, Loss: 0.8396643400192261, Accuracy: 0.732421875\n",
      "Batch: 39, Loss: 0.8198779821395874, Accuracy: 0.7294921875\n",
      "Batch: 40, Loss: 0.848098635673523, Accuracy: 0.71875\n",
      "Batch: 41, Loss: 0.7869175672531128, Accuracy: 0.7421875\n",
      "Batch: 42, Loss: 0.6471166014671326, Accuracy: 0.791015625\n",
      "Batch: 43, Loss: 0.8128494024276733, Accuracy: 0.7255859375\n",
      "Batch: 44, Loss: 0.8345731496810913, Accuracy: 0.7236328125\n",
      "Batch: 45, Loss: 0.7324421405792236, Accuracy: 0.7607421875\n",
      "Batch: 46, Loss: 0.7655584812164307, Accuracy: 0.767578125\n",
      "Batch: 47, Loss: 0.8231080770492554, Accuracy: 0.7509765625\n",
      "Batch: 48, Loss: 0.7830315232276917, Accuracy: 0.7373046875\n",
      "Batch: 49, Loss: 0.9168224334716797, Accuracy: 0.705078125\n",
      "Batch: 50, Loss: 0.8209973573684692, Accuracy: 0.7451171875\n",
      "Batch: 51, Loss: 0.9058774709701538, Accuracy: 0.7060546875\n",
      "Batch: 52, Loss: 0.8575305938720703, Accuracy: 0.72265625\n",
      "Batch: 53, Loss: 0.7298274636268616, Accuracy: 0.7568359375\n",
      "Batch: 54, Loss: 0.8059532642364502, Accuracy: 0.748046875\n",
      "Batch: 55, Loss: 0.8866760730743408, Accuracy: 0.703125\n",
      "Batch: 56, Loss: 0.8793061971664429, Accuracy: 0.71875\n",
      "Batch: 57, Loss: 0.838058352470398, Accuracy: 0.7412109375\n",
      "Batch: 58, Loss: 0.9111088514328003, Accuracy: 0.70703125\n",
      "Batch: 59, Loss: 0.8302086591720581, Accuracy: 0.734375\n",
      "Batch: 60, Loss: 0.7961733341217041, Accuracy: 0.7470703125\n",
      "Batch: 61, Loss: 0.8599860668182373, Accuracy: 0.7255859375\n",
      "Batch: 62, Loss: 0.7715274095535278, Accuracy: 0.7548828125\n",
      "Batch: 63, Loss: 0.8421180844306946, Accuracy: 0.7314453125\n",
      "Batch: 64, Loss: 0.7967178821563721, Accuracy: 0.734375\n",
      "Batch: 65, Loss: 0.8630329370498657, Accuracy: 0.728515625\n",
      "Batch: 66, Loss: 0.8294558525085449, Accuracy: 0.7333984375\n",
      "Batch: 67, Loss: 0.902040421962738, Accuracy: 0.705078125\n",
      "Batch: 68, Loss: 0.8750218152999878, Accuracy: 0.6962890625\n",
      "Batch: 69, Loss: 0.8559224605560303, Accuracy: 0.71875\n",
      "Batch: 70, Loss: 0.8520029783248901, Accuracy: 0.740234375\n",
      "Batch: 71, Loss: 0.8396987915039062, Accuracy: 0.71484375\n",
      "Batch: 72, Loss: 0.7589442133903503, Accuracy: 0.7587890625\n",
      "Batch: 73, Loss: 0.7579336166381836, Accuracy: 0.7578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 74, Loss: 0.738568902015686, Accuracy: 0.7685546875\n",
      "Batch: 75, Loss: 0.723450779914856, Accuracy: 0.767578125\n",
      "Batch: 76, Loss: 0.8184963464736938, Accuracy: 0.7392578125\n",
      "Batch: 77, Loss: 0.7877694964408875, Accuracy: 0.744140625\n",
      "Batch: 78, Loss: 0.7804056406021118, Accuracy: 0.767578125\n",
      "Batch: 79, Loss: 0.7565180063247681, Accuracy: 0.76953125\n",
      "Batch: 80, Loss: 0.7848246097564697, Accuracy: 0.7470703125\n",
      "Batch: 81, Loss: 0.8799886703491211, Accuracy: 0.701171875\n",
      "Batch: 82, Loss: 0.8089316487312317, Accuracy: 0.740234375\n",
      "Batch: 83, Loss: 0.7201305627822876, Accuracy: 0.7802734375\n",
      "Batch: 84, Loss: 0.8581106066703796, Accuracy: 0.732421875\n",
      "Batch: 85, Loss: 0.7855535745620728, Accuracy: 0.7666015625\n",
      "Batch: 86, Loss: 0.9234822988510132, Accuracy: 0.7080078125\n",
      "Batch: 87, Loss: 0.7495947480201721, Accuracy: 0.7578125\n",
      "Batch: 88, Loss: 0.8645283579826355, Accuracy: 0.7392578125\n",
      "Batch: 89, Loss: 0.8222931623458862, Accuracy: 0.73828125\n",
      "Batch: 90, Loss: 0.7650695443153381, Accuracy: 0.7587890625\n",
      "Batch: 91, Loss: 0.7889521718025208, Accuracy: 0.7255859375\n",
      "Batch: 92, Loss: 0.8627721071243286, Accuracy: 0.72265625\n",
      "Batch: 93, Loss: 0.8099925518035889, Accuracy: 0.7431640625\n",
      "Batch: 94, Loss: 0.8368734121322632, Accuracy: 0.7109375\n",
      "Batch: 95, Loss: 0.8058297634124756, Accuracy: 0.7373046875\n",
      "Batch: 96, Loss: 0.8234912753105164, Accuracy: 0.7353515625\n",
      "Batch: 97, Loss: 0.6918514370918274, Accuracy: 0.7763671875\n",
      "Batch: 98, Loss: 0.8154691457748413, Accuracy: 0.7353515625\n",
      "Batch: 99, Loss: 0.7650023698806763, Accuracy: 0.763671875\n",
      "Batch: 100, Loss: 0.7915126085281372, Accuracy: 0.7412109375\n",
      "Batch: 101, Loss: 0.8735260367393494, Accuracy: 0.7216796875\n",
      "Batch: 102, Loss: 0.7958420515060425, Accuracy: 0.7490234375\n",
      "Batch: 103, Loss: 0.8807579874992371, Accuracy: 0.720703125\n",
      "Batch: 104, Loss: 0.7914282083511353, Accuracy: 0.7421875\n",
      "Batch: 105, Loss: 0.8426246047019958, Accuracy: 0.7294921875\n",
      "Batch: 106, Loss: 0.7530383467674255, Accuracy: 0.7568359375\n",
      "Batch: 107, Loss: 0.8506943583488464, Accuracy: 0.7216796875\n",
      "Batch: 108, Loss: 0.7991777062416077, Accuracy: 0.7412109375\n",
      "Batch: 109, Loss: 0.8898768424987793, Accuracy: 0.7041015625\n",
      "Batch: 110, Loss: 0.7225645780563354, Accuracy: 0.7724609375\n",
      "Batch: 111, Loss: 0.8207575082778931, Accuracy: 0.73046875\n",
      "Batch: 112, Loss: 0.8416445255279541, Accuracy: 0.7275390625\n",
      "Batch: 113, Loss: 0.857640266418457, Accuracy: 0.728515625\n",
      "Batch: 114, Loss: 0.9039649963378906, Accuracy: 0.7109375\n",
      "Batch: 115, Loss: 0.9506519436836243, Accuracy: 0.705078125\n",
      "Batch: 116, Loss: 0.8499236702919006, Accuracy: 0.732421875\n",
      "Batch: 117, Loss: 0.874298095703125, Accuracy: 0.7177734375\n",
      "Batch: 118, Loss: 0.748170793056488, Accuracy: 0.775390625\n",
      "Batch: 119, Loss: 0.7352837324142456, Accuracy: 0.771484375\n",
      "Batch: 120, Loss: 0.8385884761810303, Accuracy: 0.72265625\n",
      "Batch: 121, Loss: 0.8701868057250977, Accuracy: 0.724609375\n",
      "Batch: 122, Loss: 0.8359870910644531, Accuracy: 0.736328125\n",
      "Batch: 123, Loss: 0.7816238403320312, Accuracy: 0.736328125\n",
      "Batch: 124, Loss: 0.8252094388008118, Accuracy: 0.732421875\n",
      "Batch: 125, Loss: 0.8791788816452026, Accuracy: 0.7080078125\n",
      "Batch: 126, Loss: 0.8454850912094116, Accuracy: 0.71484375\n",
      "Batch: 127, Loss: 0.7334169149398804, Accuracy: 0.7802734375\n",
      "Batch: 128, Loss: 0.9042273759841919, Accuracy: 0.71484375\n",
      "Batch: 129, Loss: 0.7739871740341187, Accuracy: 0.7568359375\n",
      "Batch: 130, Loss: 0.9239013195037842, Accuracy: 0.701171875\n",
      "Batch: 131, Loss: 0.8506844639778137, Accuracy: 0.724609375\n",
      "Batch: 132, Loss: 0.8793721795082092, Accuracy: 0.7236328125\n",
      "Batch: 133, Loss: 0.8099392056465149, Accuracy: 0.71484375\n",
      "Batch: 134, Loss: 0.8605431318283081, Accuracy: 0.708984375\n",
      "Batch: 135, Loss: 0.7948760986328125, Accuracy: 0.765625\n",
      "Batch: 136, Loss: 0.8184126615524292, Accuracy: 0.73828125\n",
      "Batch: 137, Loss: 0.7920792102813721, Accuracy: 0.734375\n",
      "Batch: 138, Loss: 0.7365866899490356, Accuracy: 0.74609375\n",
      "Batch: 139, Loss: 0.7465263605117798, Accuracy: 0.7734375\n",
      "Batch: 140, Loss: 0.8302129507064819, Accuracy: 0.7412109375\n",
      "Batch: 141, Loss: 0.8659172058105469, Accuracy: 0.724609375\n",
      "Batch: 142, Loss: 0.9181778430938721, Accuracy: 0.7001953125\n",
      "Batch: 143, Loss: 0.8731175661087036, Accuracy: 0.72265625\n",
      "Batch: 144, Loss: 0.8024824857711792, Accuracy: 0.7333984375\n",
      "Batch: 145, Loss: 0.7635385394096375, Accuracy: 0.734375\n",
      "Batch: 146, Loss: 0.8820928335189819, Accuracy: 0.708984375\n",
      "Batch: 147, Loss: 0.8520056009292603, Accuracy: 0.7158203125\n",
      "Batch: 148, Loss: 0.934122622013092, Accuracy: 0.701171875\n",
      "Batch: 149, Loss: 0.7887446284294128, Accuracy: 0.7314453125\n",
      "Batch: 150, Loss: 0.8616258502006531, Accuracy: 0.724609375\n",
      "Batch: 151, Loss: 0.7179387211799622, Accuracy: 0.767578125\n",
      "Epoch 38/80\n",
      "Batch: 1, Loss: 1.005028247833252, Accuracy: 0.68359375\n",
      "Batch: 2, Loss: 0.8913771510124207, Accuracy: 0.689453125\n",
      "Batch: 3, Loss: 0.7953405380249023, Accuracy: 0.7490234375\n",
      "Batch: 4, Loss: 0.7471377849578857, Accuracy: 0.7607421875\n",
      "Batch: 5, Loss: 0.7893067002296448, Accuracy: 0.7578125\n",
      "Batch: 6, Loss: 0.8290511965751648, Accuracy: 0.71875\n",
      "Batch: 7, Loss: 0.8155573010444641, Accuracy: 0.7138671875\n",
      "Batch: 8, Loss: 0.778311014175415, Accuracy: 0.7353515625\n",
      "Batch: 9, Loss: 0.7729854583740234, Accuracy: 0.744140625\n",
      "Batch: 10, Loss: 0.7457977533340454, Accuracy: 0.7509765625\n",
      "Batch: 11, Loss: 0.8997234106063843, Accuracy: 0.7001953125\n",
      "Batch: 12, Loss: 0.849570095539093, Accuracy: 0.7373046875\n",
      "Batch: 13, Loss: 0.6905866861343384, Accuracy: 0.7724609375\n",
      "Batch: 14, Loss: 0.8822060823440552, Accuracy: 0.7119140625\n",
      "Batch: 15, Loss: 0.7528425455093384, Accuracy: 0.7841796875\n",
      "Batch: 16, Loss: 0.7715287208557129, Accuracy: 0.76171875\n",
      "Batch: 17, Loss: 0.8257721662521362, Accuracy: 0.7275390625\n",
      "Batch: 18, Loss: 0.8689620494842529, Accuracy: 0.720703125\n",
      "Batch: 19, Loss: 0.8575564622879028, Accuracy: 0.736328125\n",
      "Batch: 20, Loss: 0.7657185792922974, Accuracy: 0.763671875\n",
      "Batch: 21, Loss: 0.7507792711257935, Accuracy: 0.75\n",
      "Batch: 22, Loss: 0.8675817251205444, Accuracy: 0.7294921875\n",
      "Batch: 23, Loss: 0.8328971862792969, Accuracy: 0.73046875\n",
      "Batch: 24, Loss: 0.8394094705581665, Accuracy: 0.70703125\n",
      "Batch: 25, Loss: 0.8009318113327026, Accuracy: 0.755859375\n",
      "Batch: 26, Loss: 0.7062557935714722, Accuracy: 0.76953125\n",
      "Batch: 27, Loss: 0.7688926458358765, Accuracy: 0.7509765625\n",
      "Batch: 28, Loss: 0.802071213722229, Accuracy: 0.73828125\n",
      "Batch: 29, Loss: 0.7774530649185181, Accuracy: 0.7626953125\n",
      "Batch: 30, Loss: 0.757163405418396, Accuracy: 0.748046875\n",
      "Batch: 31, Loss: 0.7552106976509094, Accuracy: 0.7587890625\n",
      "Batch: 32, Loss: 0.7308648824691772, Accuracy: 0.7509765625\n",
      "Batch: 33, Loss: 0.8759894967079163, Accuracy: 0.71484375\n",
      "Batch: 34, Loss: 0.925309956073761, Accuracy: 0.703125\n",
      "Batch: 35, Loss: 0.8191481828689575, Accuracy: 0.724609375\n",
      "Batch: 36, Loss: 0.877558708190918, Accuracy: 0.7275390625\n",
      "Batch: 37, Loss: 0.8265330791473389, Accuracy: 0.728515625\n",
      "Batch: 38, Loss: 0.843222975730896, Accuracy: 0.7138671875\n",
      "Batch: 39, Loss: 0.8258719444274902, Accuracy: 0.7451171875\n",
      "Batch: 40, Loss: 0.8769603967666626, Accuracy: 0.7177734375\n",
      "Batch: 41, Loss: 0.7343573570251465, Accuracy: 0.7587890625\n",
      "Batch: 42, Loss: 0.6280434131622314, Accuracy: 0.78515625\n",
      "Batch: 43, Loss: 0.7904220223426819, Accuracy: 0.744140625\n",
      "Batch: 44, Loss: 0.8504537343978882, Accuracy: 0.71484375\n",
      "Batch: 45, Loss: 0.6961005926132202, Accuracy: 0.763671875\n",
      "Batch: 46, Loss: 0.7752890586853027, Accuracy: 0.755859375\n",
      "Batch: 47, Loss: 0.7897306680679321, Accuracy: 0.75\n",
      "Batch: 48, Loss: 0.7434442043304443, Accuracy: 0.7607421875\n",
      "Batch: 49, Loss: 0.9101784229278564, Accuracy: 0.716796875\n",
      "Batch: 50, Loss: 0.8110649585723877, Accuracy: 0.732421875\n",
      "Batch: 51, Loss: 0.9235889911651611, Accuracy: 0.703125\n",
      "Batch: 52, Loss: 0.8268699645996094, Accuracy: 0.7314453125\n",
      "Batch: 53, Loss: 0.7386372685432434, Accuracy: 0.7568359375\n",
      "Batch: 54, Loss: 0.814153254032135, Accuracy: 0.759765625\n",
      "Batch: 55, Loss: 0.8901665210723877, Accuracy: 0.697265625\n",
      "Batch: 56, Loss: 0.8864279985427856, Accuracy: 0.7001953125\n",
      "Batch: 57, Loss: 0.8086981773376465, Accuracy: 0.74609375\n",
      "Batch: 58, Loss: 0.9172853231430054, Accuracy: 0.7158203125\n",
      "Batch: 59, Loss: 0.7743701338768005, Accuracy: 0.751953125\n",
      "Batch: 60, Loss: 0.7311176061630249, Accuracy: 0.74609375\n",
      "Batch: 61, Loss: 0.817646861076355, Accuracy: 0.7392578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 62, Loss: 0.7918705940246582, Accuracy: 0.7373046875\n",
      "Batch: 63, Loss: 0.849541425704956, Accuracy: 0.7236328125\n",
      "Batch: 64, Loss: 0.8017226457595825, Accuracy: 0.7392578125\n",
      "Batch: 65, Loss: 0.8309379816055298, Accuracy: 0.7470703125\n",
      "Batch: 66, Loss: 0.7992258071899414, Accuracy: 0.7509765625\n",
      "Batch: 67, Loss: 0.8911662697792053, Accuracy: 0.720703125\n",
      "Batch: 68, Loss: 0.8835924863815308, Accuracy: 0.708984375\n",
      "Batch: 69, Loss: 0.8526981472969055, Accuracy: 0.73046875\n",
      "Batch: 70, Loss: 0.8397197127342224, Accuracy: 0.7314453125\n",
      "Batch: 71, Loss: 0.8274033665657043, Accuracy: 0.748046875\n",
      "Batch: 72, Loss: 0.7677304744720459, Accuracy: 0.7470703125\n",
      "Batch: 73, Loss: 0.757592499256134, Accuracy: 0.7509765625\n",
      "Batch: 74, Loss: 0.7086331248283386, Accuracy: 0.7822265625\n",
      "Batch: 75, Loss: 0.7258232831954956, Accuracy: 0.7734375\n",
      "Batch: 76, Loss: 0.8022968769073486, Accuracy: 0.744140625\n",
      "Batch: 77, Loss: 0.7640527486801147, Accuracy: 0.759765625\n",
      "Batch: 78, Loss: 0.7261813879013062, Accuracy: 0.763671875\n",
      "Batch: 79, Loss: 0.7550954818725586, Accuracy: 0.7705078125\n",
      "Batch: 80, Loss: 0.7592055797576904, Accuracy: 0.740234375\n",
      "Batch: 81, Loss: 0.8624716997146606, Accuracy: 0.701171875\n",
      "Batch: 82, Loss: 0.8307830691337585, Accuracy: 0.740234375\n",
      "Batch: 83, Loss: 0.7256859540939331, Accuracy: 0.7841796875\n",
      "Batch: 84, Loss: 0.7891700863838196, Accuracy: 0.7568359375\n",
      "Batch: 85, Loss: 0.7450624108314514, Accuracy: 0.7626953125\n",
      "Batch: 86, Loss: 0.9037445783615112, Accuracy: 0.716796875\n",
      "Batch: 87, Loss: 0.722899854183197, Accuracy: 0.7744140625\n",
      "Batch: 88, Loss: 0.8497925996780396, Accuracy: 0.728515625\n",
      "Batch: 89, Loss: 0.8205766677856445, Accuracy: 0.7451171875\n",
      "Batch: 90, Loss: 0.7534366846084595, Accuracy: 0.7646484375\n",
      "Batch: 91, Loss: 0.7775412797927856, Accuracy: 0.740234375\n",
      "Batch: 92, Loss: 0.8273367881774902, Accuracy: 0.7451171875\n",
      "Batch: 93, Loss: 0.8238576650619507, Accuracy: 0.7314453125\n",
      "Batch: 94, Loss: 0.835680365562439, Accuracy: 0.732421875\n",
      "Batch: 95, Loss: 0.8164496421813965, Accuracy: 0.7177734375\n",
      "Batch: 96, Loss: 0.8328751921653748, Accuracy: 0.7275390625\n",
      "Batch: 97, Loss: 0.6811283230781555, Accuracy: 0.78515625\n",
      "Batch: 98, Loss: 0.7981626987457275, Accuracy: 0.732421875\n",
      "Batch: 99, Loss: 0.7977736592292786, Accuracy: 0.7373046875\n",
      "Batch: 100, Loss: 0.7702680230140686, Accuracy: 0.740234375\n",
      "Batch: 101, Loss: 0.8628823757171631, Accuracy: 0.7197265625\n",
      "Batch: 102, Loss: 0.8089234828948975, Accuracy: 0.734375\n",
      "Batch: 103, Loss: 0.8464658260345459, Accuracy: 0.73828125\n",
      "Batch: 104, Loss: 0.7812751531600952, Accuracy: 0.7568359375\n",
      "Batch: 105, Loss: 0.8065751791000366, Accuracy: 0.7451171875\n",
      "Batch: 106, Loss: 0.7571625709533691, Accuracy: 0.748046875\n",
      "Batch: 107, Loss: 0.8237380981445312, Accuracy: 0.7431640625\n",
      "Batch: 108, Loss: 0.8112795352935791, Accuracy: 0.732421875\n",
      "Batch: 109, Loss: 0.8606629371643066, Accuracy: 0.7197265625\n",
      "Batch: 110, Loss: 0.72966068983078, Accuracy: 0.76171875\n",
      "Batch: 111, Loss: 0.8215968608856201, Accuracy: 0.73046875\n",
      "Batch: 112, Loss: 0.8370389342308044, Accuracy: 0.7373046875\n",
      "Batch: 113, Loss: 0.8068081140518188, Accuracy: 0.7373046875\n",
      "Batch: 114, Loss: 0.8719155788421631, Accuracy: 0.72265625\n",
      "Batch: 115, Loss: 0.9197845458984375, Accuracy: 0.708984375\n",
      "Batch: 116, Loss: 0.8652557134628296, Accuracy: 0.7255859375\n",
      "Batch: 117, Loss: 0.8784089684486389, Accuracy: 0.7216796875\n",
      "Batch: 118, Loss: 0.7376474738121033, Accuracy: 0.759765625\n",
      "Batch: 119, Loss: 0.7524533271789551, Accuracy: 0.7734375\n",
      "Batch: 120, Loss: 0.8054243326187134, Accuracy: 0.7333984375\n",
      "Batch: 121, Loss: 0.8597326278686523, Accuracy: 0.736328125\n",
      "Batch: 122, Loss: 0.7912750840187073, Accuracy: 0.748046875\n",
      "Batch: 123, Loss: 0.7917394638061523, Accuracy: 0.75\n",
      "Batch: 124, Loss: 0.8049235939979553, Accuracy: 0.7265625\n",
      "Batch: 125, Loss: 0.8862419128417969, Accuracy: 0.7236328125\n",
      "Batch: 126, Loss: 0.8438051342964172, Accuracy: 0.7158203125\n",
      "Batch: 127, Loss: 0.7409600019454956, Accuracy: 0.7607421875\n",
      "Batch: 128, Loss: 0.9058465957641602, Accuracy: 0.7158203125\n",
      "Batch: 129, Loss: 0.7796229124069214, Accuracy: 0.744140625\n",
      "Batch: 130, Loss: 0.9563202857971191, Accuracy: 0.685546875\n",
      "Batch: 131, Loss: 0.8772556781768799, Accuracy: 0.7197265625\n",
      "Batch: 132, Loss: 0.8613803386688232, Accuracy: 0.7138671875\n",
      "Batch: 133, Loss: 0.7644202709197998, Accuracy: 0.7421875\n",
      "Batch: 134, Loss: 0.7947611808776855, Accuracy: 0.7119140625\n",
      "Batch: 135, Loss: 0.785266637802124, Accuracy: 0.7470703125\n",
      "Batch: 136, Loss: 0.829410195350647, Accuracy: 0.734375\n",
      "Batch: 137, Loss: 0.8096354007720947, Accuracy: 0.71875\n",
      "Batch: 138, Loss: 0.7390788197517395, Accuracy: 0.7509765625\n",
      "Batch: 139, Loss: 0.7691646814346313, Accuracy: 0.7587890625\n",
      "Batch: 140, Loss: 0.8690981268882751, Accuracy: 0.716796875\n",
      "Batch: 141, Loss: 0.8547559976577759, Accuracy: 0.7197265625\n",
      "Batch: 142, Loss: 0.9116238355636597, Accuracy: 0.7080078125\n",
      "Batch: 143, Loss: 0.8336852788925171, Accuracy: 0.734375\n",
      "Batch: 144, Loss: 0.8200868964195251, Accuracy: 0.744140625\n",
      "Batch: 145, Loss: 0.784486711025238, Accuracy: 0.73046875\n",
      "Batch: 146, Loss: 0.8457629084587097, Accuracy: 0.724609375\n",
      "Batch: 147, Loss: 0.8131778836250305, Accuracy: 0.7275390625\n",
      "Batch: 148, Loss: 0.9486000537872314, Accuracy: 0.6826171875\n",
      "Batch: 149, Loss: 0.8057953715324402, Accuracy: 0.7294921875\n",
      "Batch: 150, Loss: 0.8084307312965393, Accuracy: 0.7451171875\n",
      "Batch: 151, Loss: 0.7496824264526367, Accuracy: 0.7587890625\n",
      "Epoch 39/80\n",
      "Batch: 1, Loss: 1.0016374588012695, Accuracy: 0.685546875\n",
      "Batch: 2, Loss: 0.8849972486495972, Accuracy: 0.6953125\n",
      "Batch: 3, Loss: 0.7862539291381836, Accuracy: 0.74609375\n",
      "Batch: 4, Loss: 0.7344759702682495, Accuracy: 0.76171875\n",
      "Batch: 5, Loss: 0.77510005235672, Accuracy: 0.759765625\n",
      "Batch: 6, Loss: 0.8027023077011108, Accuracy: 0.7412109375\n",
      "Batch: 7, Loss: 0.7802654504776001, Accuracy: 0.734375\n",
      "Batch: 8, Loss: 0.7721912264823914, Accuracy: 0.73828125\n",
      "Batch: 9, Loss: 0.7692645192146301, Accuracy: 0.7392578125\n",
      "Batch: 10, Loss: 0.7398642301559448, Accuracy: 0.7470703125\n",
      "Batch: 11, Loss: 0.8432528376579285, Accuracy: 0.7236328125\n",
      "Batch: 12, Loss: 0.8591470718383789, Accuracy: 0.7431640625\n",
      "Batch: 13, Loss: 0.6689125299453735, Accuracy: 0.791015625\n",
      "Batch: 14, Loss: 0.8904368281364441, Accuracy: 0.708984375\n",
      "Batch: 15, Loss: 0.7742974758148193, Accuracy: 0.76953125\n",
      "Batch: 16, Loss: 0.7359669208526611, Accuracy: 0.76953125\n",
      "Batch: 17, Loss: 0.8143457174301147, Accuracy: 0.7412109375\n",
      "Batch: 18, Loss: 0.8386802673339844, Accuracy: 0.73828125\n",
      "Batch: 19, Loss: 0.8388160467147827, Accuracy: 0.7392578125\n",
      "Batch: 20, Loss: 0.7541396617889404, Accuracy: 0.7734375\n",
      "Batch: 21, Loss: 0.7478626370429993, Accuracy: 0.7490234375\n",
      "Batch: 22, Loss: 0.8860554099082947, Accuracy: 0.7265625\n",
      "Batch: 23, Loss: 0.8457504510879517, Accuracy: 0.7109375\n",
      "Batch: 24, Loss: 0.8302340507507324, Accuracy: 0.732421875\n",
      "Batch: 25, Loss: 0.7850370407104492, Accuracy: 0.7529296875\n",
      "Batch: 26, Loss: 0.7173588275909424, Accuracy: 0.779296875\n",
      "Batch: 27, Loss: 0.7512817978858948, Accuracy: 0.73828125\n",
      "Batch: 28, Loss: 0.8121995329856873, Accuracy: 0.724609375\n",
      "Batch: 29, Loss: 0.7619307041168213, Accuracy: 0.7587890625\n",
      "Batch: 30, Loss: 0.7260742783546448, Accuracy: 0.7646484375\n",
      "Batch: 31, Loss: 0.7180078625679016, Accuracy: 0.7646484375\n",
      "Batch: 32, Loss: 0.7391853928565979, Accuracy: 0.7529296875\n",
      "Batch: 33, Loss: 0.8884390592575073, Accuracy: 0.7197265625\n",
      "Batch: 34, Loss: 0.8848921060562134, Accuracy: 0.71484375\n",
      "Batch: 35, Loss: 0.8112150430679321, Accuracy: 0.748046875\n",
      "Batch: 36, Loss: 0.8292289972305298, Accuracy: 0.7314453125\n",
      "Batch: 37, Loss: 0.7996735572814941, Accuracy: 0.7373046875\n",
      "Batch: 38, Loss: 0.8360726833343506, Accuracy: 0.72265625\n",
      "Batch: 39, Loss: 0.8174636363983154, Accuracy: 0.748046875\n",
      "Batch: 40, Loss: 0.8313292264938354, Accuracy: 0.734375\n",
      "Batch: 41, Loss: 0.7646579146385193, Accuracy: 0.7548828125\n",
      "Batch: 42, Loss: 0.6125556230545044, Accuracy: 0.7998046875\n",
      "Batch: 43, Loss: 0.7586286664009094, Accuracy: 0.748046875\n",
      "Batch: 44, Loss: 0.8165056109428406, Accuracy: 0.7373046875\n",
      "Batch: 45, Loss: 0.7118141055107117, Accuracy: 0.76171875\n",
      "Batch: 46, Loss: 0.7461153268814087, Accuracy: 0.76953125\n",
      "Batch: 47, Loss: 0.7966874837875366, Accuracy: 0.7646484375\n",
      "Batch: 48, Loss: 0.7757024765014648, Accuracy: 0.7431640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 49, Loss: 0.8853654861450195, Accuracy: 0.716796875\n",
      "Batch: 50, Loss: 0.8023261427879333, Accuracy: 0.744140625\n",
      "Batch: 51, Loss: 0.8745993971824646, Accuracy: 0.7197265625\n",
      "Batch: 52, Loss: 0.844097375869751, Accuracy: 0.7333984375\n",
      "Batch: 53, Loss: 0.7177146673202515, Accuracy: 0.7646484375\n",
      "Batch: 54, Loss: 0.7618101239204407, Accuracy: 0.7578125\n",
      "Batch: 55, Loss: 0.8949141502380371, Accuracy: 0.712890625\n",
      "Batch: 56, Loss: 0.8612829446792603, Accuracy: 0.7216796875\n",
      "Batch: 57, Loss: 0.7943791151046753, Accuracy: 0.7451171875\n",
      "Batch: 58, Loss: 0.8963742256164551, Accuracy: 0.7333984375\n",
      "Batch: 59, Loss: 0.7804745435714722, Accuracy: 0.765625\n",
      "Batch: 60, Loss: 0.7376040816307068, Accuracy: 0.76953125\n",
      "Batch: 61, Loss: 0.8359239101409912, Accuracy: 0.72265625\n",
      "Batch: 62, Loss: 0.7583739757537842, Accuracy: 0.740234375\n",
      "Batch: 63, Loss: 0.8260402679443359, Accuracy: 0.7470703125\n",
      "Batch: 64, Loss: 0.7713786363601685, Accuracy: 0.7392578125\n",
      "Batch: 65, Loss: 0.8298256993293762, Accuracy: 0.740234375\n",
      "Batch: 66, Loss: 0.8056022524833679, Accuracy: 0.7451171875\n",
      "Batch: 67, Loss: 0.8538114428520203, Accuracy: 0.7353515625\n",
      "Batch: 68, Loss: 0.8474897146224976, Accuracy: 0.7275390625\n",
      "Batch: 69, Loss: 0.7989013195037842, Accuracy: 0.7431640625\n",
      "Batch: 70, Loss: 0.829714298248291, Accuracy: 0.75\n",
      "Batch: 71, Loss: 0.8177529573440552, Accuracy: 0.7255859375\n",
      "Batch: 72, Loss: 0.7397637963294983, Accuracy: 0.75\n",
      "Batch: 73, Loss: 0.7115965485572815, Accuracy: 0.7724609375\n",
      "Batch: 74, Loss: 0.6971640586853027, Accuracy: 0.7763671875\n",
      "Batch: 75, Loss: 0.7194509506225586, Accuracy: 0.7685546875\n",
      "Batch: 76, Loss: 0.8052784204483032, Accuracy: 0.7412109375\n",
      "Batch: 77, Loss: 0.7387604713439941, Accuracy: 0.763671875\n",
      "Batch: 78, Loss: 0.7333486080169678, Accuracy: 0.7666015625\n",
      "Batch: 79, Loss: 0.7521791458129883, Accuracy: 0.7734375\n",
      "Batch: 80, Loss: 0.7553399801254272, Accuracy: 0.755859375\n",
      "Batch: 81, Loss: 0.848598837852478, Accuracy: 0.708984375\n",
      "Batch: 82, Loss: 0.8057922124862671, Accuracy: 0.7392578125\n",
      "Batch: 83, Loss: 0.7082120180130005, Accuracy: 0.79296875\n",
      "Batch: 84, Loss: 0.8027963638305664, Accuracy: 0.7451171875\n",
      "Batch: 85, Loss: 0.7469171285629272, Accuracy: 0.755859375\n",
      "Batch: 86, Loss: 0.9038118720054626, Accuracy: 0.7119140625\n",
      "Batch: 87, Loss: 0.7166472673416138, Accuracy: 0.7822265625\n",
      "Batch: 88, Loss: 0.8595060110092163, Accuracy: 0.734375\n",
      "Batch: 89, Loss: 0.8174372315406799, Accuracy: 0.7451171875\n",
      "Batch: 90, Loss: 0.753890335559845, Accuracy: 0.7568359375\n",
      "Batch: 91, Loss: 0.7806829214096069, Accuracy: 0.744140625\n",
      "Batch: 92, Loss: 0.834161639213562, Accuracy: 0.7412109375\n",
      "Batch: 93, Loss: 0.8088113069534302, Accuracy: 0.734375\n",
      "Batch: 94, Loss: 0.8022173047065735, Accuracy: 0.7333984375\n",
      "Batch: 95, Loss: 0.8173395991325378, Accuracy: 0.7216796875\n",
      "Batch: 96, Loss: 0.8142170906066895, Accuracy: 0.7421875\n",
      "Batch: 97, Loss: 0.6833493113517761, Accuracy: 0.7802734375\n",
      "Batch: 98, Loss: 0.775912880897522, Accuracy: 0.744140625\n",
      "Batch: 99, Loss: 0.7726925611495972, Accuracy: 0.744140625\n",
      "Batch: 100, Loss: 0.7771120071411133, Accuracy: 0.7578125\n",
      "Batch: 101, Loss: 0.8694392442703247, Accuracy: 0.7177734375\n",
      "Batch: 102, Loss: 0.8277286291122437, Accuracy: 0.7236328125\n",
      "Batch: 103, Loss: 0.838718056678772, Accuracy: 0.7412109375\n",
      "Batch: 104, Loss: 0.7791719436645508, Accuracy: 0.7568359375\n",
      "Batch: 105, Loss: 0.8188036680221558, Accuracy: 0.7333984375\n",
      "Batch: 106, Loss: 0.7734024524688721, Accuracy: 0.7470703125\n",
      "Batch: 107, Loss: 0.8144581317901611, Accuracy: 0.7490234375\n",
      "Batch: 108, Loss: 0.8077782392501831, Accuracy: 0.7412109375\n",
      "Batch: 109, Loss: 0.8737422227859497, Accuracy: 0.70703125\n",
      "Batch: 110, Loss: 0.7279344797134399, Accuracy: 0.7568359375\n",
      "Batch: 111, Loss: 0.7749738097190857, Accuracy: 0.7509765625\n",
      "Batch: 112, Loss: 0.8034268021583557, Accuracy: 0.75\n",
      "Batch: 113, Loss: 0.8142142295837402, Accuracy: 0.7373046875\n",
      "Batch: 114, Loss: 0.8597633838653564, Accuracy: 0.72265625\n",
      "Batch: 115, Loss: 0.8897382020950317, Accuracy: 0.728515625\n",
      "Batch: 116, Loss: 0.8244449496269226, Accuracy: 0.736328125\n",
      "Batch: 117, Loss: 0.8529742360115051, Accuracy: 0.728515625\n",
      "Batch: 118, Loss: 0.7295427322387695, Accuracy: 0.75390625\n",
      "Batch: 119, Loss: 0.7183637619018555, Accuracy: 0.7900390625\n",
      "Batch: 120, Loss: 0.8061951994895935, Accuracy: 0.736328125\n",
      "Batch: 121, Loss: 0.8896105289459229, Accuracy: 0.734375\n",
      "Batch: 122, Loss: 0.7819401621818542, Accuracy: 0.75\n",
      "Batch: 123, Loss: 0.7595295906066895, Accuracy: 0.755859375\n",
      "Batch: 124, Loss: 0.8251656293869019, Accuracy: 0.73046875\n",
      "Batch: 125, Loss: 0.8267077803611755, Accuracy: 0.7373046875\n",
      "Batch: 126, Loss: 0.8059316277503967, Accuracy: 0.759765625\n",
      "Batch: 127, Loss: 0.7253668904304504, Accuracy: 0.7587890625\n",
      "Batch: 128, Loss: 0.8721063137054443, Accuracy: 0.7412109375\n",
      "Batch: 129, Loss: 0.7548623085021973, Accuracy: 0.755859375\n",
      "Batch: 130, Loss: 0.896482527256012, Accuracy: 0.705078125\n",
      "Batch: 131, Loss: 0.8491828441619873, Accuracy: 0.728515625\n",
      "Batch: 132, Loss: 0.8592076301574707, Accuracy: 0.728515625\n",
      "Batch: 133, Loss: 0.7867411971092224, Accuracy: 0.7353515625\n",
      "Batch: 134, Loss: 0.8244693279266357, Accuracy: 0.7236328125\n",
      "Batch: 135, Loss: 0.7825636863708496, Accuracy: 0.7490234375\n",
      "Batch: 136, Loss: 0.8068631887435913, Accuracy: 0.744140625\n",
      "Batch: 137, Loss: 0.7873921394348145, Accuracy: 0.734375\n",
      "Batch: 138, Loss: 0.7430073618888855, Accuracy: 0.748046875\n",
      "Batch: 139, Loss: 0.7438254356384277, Accuracy: 0.759765625\n",
      "Batch: 140, Loss: 0.8305888175964355, Accuracy: 0.728515625\n",
      "Batch: 141, Loss: 0.8249530792236328, Accuracy: 0.736328125\n",
      "Batch: 142, Loss: 0.9139552712440491, Accuracy: 0.716796875\n",
      "Batch: 143, Loss: 0.8130665421485901, Accuracy: 0.7275390625\n",
      "Batch: 144, Loss: 0.7857256531715393, Accuracy: 0.7373046875\n",
      "Batch: 145, Loss: 0.751168966293335, Accuracy: 0.73828125\n",
      "Batch: 146, Loss: 0.8543522953987122, Accuracy: 0.7236328125\n",
      "Batch: 147, Loss: 0.8048819303512573, Accuracy: 0.7353515625\n",
      "Batch: 148, Loss: 0.8831918239593506, Accuracy: 0.7119140625\n",
      "Batch: 149, Loss: 0.7632365822792053, Accuracy: 0.7529296875\n",
      "Batch: 150, Loss: 0.8114680647850037, Accuracy: 0.73046875\n",
      "Batch: 151, Loss: 0.7090602517127991, Accuracy: 0.77734375\n",
      "Epoch 40/80\n",
      "Batch: 1, Loss: 0.9865810871124268, Accuracy: 0.6826171875\n",
      "Batch: 2, Loss: 0.8768908381462097, Accuracy: 0.70703125\n",
      "Batch: 3, Loss: 0.7757499814033508, Accuracy: 0.7333984375\n",
      "Batch: 4, Loss: 0.7516592144966125, Accuracy: 0.76171875\n",
      "Batch: 5, Loss: 0.7647888660430908, Accuracy: 0.759765625\n",
      "Batch: 6, Loss: 0.7999735474586487, Accuracy: 0.7587890625\n",
      "Batch: 7, Loss: 0.7807574272155762, Accuracy: 0.7265625\n",
      "Batch: 8, Loss: 0.753167986869812, Accuracy: 0.7607421875\n",
      "Batch: 9, Loss: 0.7580890655517578, Accuracy: 0.75\n",
      "Batch: 10, Loss: 0.7319785356521606, Accuracy: 0.7470703125\n",
      "Batch: 11, Loss: 0.8725636005401611, Accuracy: 0.69140625\n",
      "Batch: 12, Loss: 0.8403198719024658, Accuracy: 0.73046875\n",
      "Batch: 13, Loss: 0.6578701138496399, Accuracy: 0.7822265625\n",
      "Batch: 14, Loss: 0.8600625395774841, Accuracy: 0.7158203125\n",
      "Batch: 15, Loss: 0.7562881708145142, Accuracy: 0.767578125\n",
      "Batch: 16, Loss: 0.7598983645439148, Accuracy: 0.7744140625\n",
      "Batch: 17, Loss: 0.8069664239883423, Accuracy: 0.751953125\n",
      "Batch: 18, Loss: 0.820111095905304, Accuracy: 0.744140625\n",
      "Batch: 19, Loss: 0.8367125988006592, Accuracy: 0.732421875\n",
      "Batch: 20, Loss: 0.7626481652259827, Accuracy: 0.77734375\n",
      "Batch: 21, Loss: 0.7304062843322754, Accuracy: 0.765625\n",
      "Batch: 22, Loss: 0.8855347633361816, Accuracy: 0.720703125\n",
      "Batch: 23, Loss: 0.8122795820236206, Accuracy: 0.7275390625\n",
      "Batch: 24, Loss: 0.8266527652740479, Accuracy: 0.724609375\n",
      "Batch: 25, Loss: 0.7886927127838135, Accuracy: 0.7529296875\n",
      "Batch: 26, Loss: 0.7034721374511719, Accuracy: 0.775390625\n",
      "Batch: 27, Loss: 0.7422716617584229, Accuracy: 0.7392578125\n",
      "Batch: 28, Loss: 0.7891747951507568, Accuracy: 0.7294921875\n",
      "Batch: 29, Loss: 0.7858585715293884, Accuracy: 0.7431640625\n",
      "Batch: 30, Loss: 0.7328704595565796, Accuracy: 0.7548828125\n",
      "Batch: 31, Loss: 0.7101507782936096, Accuracy: 0.779296875\n",
      "Batch: 32, Loss: 0.7250490784645081, Accuracy: 0.765625\n",
      "Batch: 33, Loss: 0.8615149259567261, Accuracy: 0.732421875\n",
      "Batch: 34, Loss: 0.8908816576004028, Accuracy: 0.703125\n",
      "Batch: 35, Loss: 0.8209295272827148, Accuracy: 0.7314453125\n",
      "Batch: 36, Loss: 0.7898855805397034, Accuracy: 0.7587890625\n",
      "Batch: 37, Loss: 0.8012800216674805, Accuracy: 0.7275390625\n",
      "Batch: 38, Loss: 0.8191395401954651, Accuracy: 0.720703125\n",
      "Batch: 39, Loss: 0.8076010346412659, Accuracy: 0.75\n",
      "Batch: 40, Loss: 0.8071578741073608, Accuracy: 0.7265625\n",
      "Batch: 41, Loss: 0.7144302129745483, Accuracy: 0.7734375\n",
      "Batch: 42, Loss: 0.6252245306968689, Accuracy: 0.7998046875\n",
      "Batch: 43, Loss: 0.7488734722137451, Accuracy: 0.7548828125\n",
      "Batch: 44, Loss: 0.8145415186882019, Accuracy: 0.7314453125\n",
      "Batch: 45, Loss: 0.6857931613922119, Accuracy: 0.7763671875\n",
      "Batch: 46, Loss: 0.7819144129753113, Accuracy: 0.75\n",
      "Batch: 47, Loss: 0.802272379398346, Accuracy: 0.751953125\n",
      "Batch: 48, Loss: 0.7750723361968994, Accuracy: 0.7529296875\n",
      "Batch: 49, Loss: 0.8855804204940796, Accuracy: 0.7216796875\n",
      "Batch: 50, Loss: 0.7816107273101807, Accuracy: 0.73046875\n",
      "Batch: 51, Loss: 0.8822091817855835, Accuracy: 0.7158203125\n",
      "Batch: 52, Loss: 0.8300203084945679, Accuracy: 0.7353515625\n",
      "Batch: 53, Loss: 0.7265613675117493, Accuracy: 0.7734375\n",
      "Batch: 54, Loss: 0.7327766418457031, Accuracy: 0.76953125\n",
      "Batch: 55, Loss: 0.8927801847457886, Accuracy: 0.71875\n",
      "Batch: 56, Loss: 0.8471089601516724, Accuracy: 0.724609375\n",
      "Batch: 57, Loss: 0.7979494333267212, Accuracy: 0.75390625\n",
      "Batch: 58, Loss: 0.9048664569854736, Accuracy: 0.7216796875\n",
      "Batch: 59, Loss: 0.7748578786849976, Accuracy: 0.7431640625\n",
      "Batch: 60, Loss: 0.7377608418464661, Accuracy: 0.7587890625\n",
      "Batch: 61, Loss: 0.8335088491439819, Accuracy: 0.7236328125\n",
      "Batch: 62, Loss: 0.7372932434082031, Accuracy: 0.759765625\n",
      "Batch: 63, Loss: 0.7989957332611084, Accuracy: 0.7451171875\n",
      "Batch: 64, Loss: 0.746321976184845, Accuracy: 0.759765625\n",
      "Batch: 65, Loss: 0.8250027894973755, Accuracy: 0.75\n",
      "Batch: 66, Loss: 0.7990132570266724, Accuracy: 0.74609375\n",
      "Batch: 67, Loss: 0.8484991192817688, Accuracy: 0.732421875\n",
      "Batch: 68, Loss: 0.8604368567466736, Accuracy: 0.7158203125\n",
      "Batch: 69, Loss: 0.8045445084571838, Accuracy: 0.7333984375\n",
      "Batch: 70, Loss: 0.7762318253517151, Accuracy: 0.7578125\n",
      "Batch: 71, Loss: 0.8242686986923218, Accuracy: 0.7177734375\n",
      "Batch: 72, Loss: 0.7335431575775146, Accuracy: 0.759765625\n",
      "Batch: 73, Loss: 0.7735269069671631, Accuracy: 0.7548828125\n",
      "Batch: 74, Loss: 0.7292714715003967, Accuracy: 0.775390625\n",
      "Batch: 75, Loss: 0.7017459273338318, Accuracy: 0.775390625\n",
      "Batch: 76, Loss: 0.8153913021087646, Accuracy: 0.7373046875\n",
      "Batch: 77, Loss: 0.7490512132644653, Accuracy: 0.75390625\n",
      "Batch: 78, Loss: 0.7002443075180054, Accuracy: 0.7734375\n",
      "Batch: 79, Loss: 0.7306197881698608, Accuracy: 0.775390625\n",
      "Batch: 80, Loss: 0.7149432897567749, Accuracy: 0.771484375\n",
      "Batch: 81, Loss: 0.8684419989585876, Accuracy: 0.6962890625\n",
      "Batch: 82, Loss: 0.7977299094200134, Accuracy: 0.74609375\n",
      "Batch: 83, Loss: 0.6819337606430054, Accuracy: 0.7900390625\n",
      "Batch: 84, Loss: 0.7536238431930542, Accuracy: 0.7705078125\n",
      "Batch: 85, Loss: 0.7673473358154297, Accuracy: 0.7607421875\n",
      "Batch: 86, Loss: 0.8929449319839478, Accuracy: 0.716796875\n",
      "Batch: 87, Loss: 0.7417370676994324, Accuracy: 0.7666015625\n",
      "Batch: 88, Loss: 0.8183904886245728, Accuracy: 0.7490234375\n",
      "Batch: 89, Loss: 0.8171983957290649, Accuracy: 0.7431640625\n",
      "Batch: 90, Loss: 0.761088490486145, Accuracy: 0.7490234375\n",
      "Batch: 91, Loss: 0.7694525122642517, Accuracy: 0.7490234375\n",
      "Batch: 92, Loss: 0.8060241341590881, Accuracy: 0.7353515625\n",
      "Batch: 93, Loss: 0.7666654586791992, Accuracy: 0.751953125\n",
      "Batch: 94, Loss: 0.8005505204200745, Accuracy: 0.7451171875\n",
      "Batch: 95, Loss: 0.8093940019607544, Accuracy: 0.728515625\n",
      "Batch: 96, Loss: 0.76923006772995, Accuracy: 0.7451171875\n",
      "Batch: 97, Loss: 0.6751514673233032, Accuracy: 0.7861328125\n",
      "Batch: 98, Loss: 0.793246328830719, Accuracy: 0.7431640625\n",
      "Batch: 99, Loss: 0.7344251871109009, Accuracy: 0.7578125\n",
      "Batch: 100, Loss: 0.7910398244857788, Accuracy: 0.73828125\n",
      "Batch: 101, Loss: 0.830938458442688, Accuracy: 0.73828125\n",
      "Batch: 102, Loss: 0.7892202138900757, Accuracy: 0.7529296875\n",
      "Batch: 103, Loss: 0.8305600881576538, Accuracy: 0.736328125\n",
      "Batch: 104, Loss: 0.7477133274078369, Accuracy: 0.76171875\n",
      "Batch: 105, Loss: 0.7970247864723206, Accuracy: 0.73828125\n",
      "Batch: 106, Loss: 0.7485194206237793, Accuracy: 0.751953125\n",
      "Batch: 107, Loss: 0.7962878942489624, Accuracy: 0.7509765625\n",
      "Batch: 108, Loss: 0.7914834022521973, Accuracy: 0.7431640625\n",
      "Batch: 109, Loss: 0.8205279111862183, Accuracy: 0.712890625\n",
      "Batch: 110, Loss: 0.7176198959350586, Accuracy: 0.7626953125\n",
      "Batch: 111, Loss: 0.794256865978241, Accuracy: 0.7373046875\n",
      "Batch: 112, Loss: 0.8019380569458008, Accuracy: 0.73828125\n",
      "Batch: 113, Loss: 0.8187994956970215, Accuracy: 0.7314453125\n",
      "Batch: 114, Loss: 0.8341749310493469, Accuracy: 0.728515625\n",
      "Batch: 115, Loss: 0.8921511769294739, Accuracy: 0.72265625\n",
      "Batch: 116, Loss: 0.8361496329307556, Accuracy: 0.7412109375\n",
      "Batch: 117, Loss: 0.8585798740386963, Accuracy: 0.7353515625\n",
      "Batch: 118, Loss: 0.7334657907485962, Accuracy: 0.767578125\n",
      "Batch: 119, Loss: 0.7216365337371826, Accuracy: 0.7744140625\n",
      "Batch: 120, Loss: 0.7624980211257935, Accuracy: 0.751953125\n",
      "Batch: 121, Loss: 0.8847901821136475, Accuracy: 0.7099609375\n",
      "Batch: 122, Loss: 0.7829375267028809, Accuracy: 0.76171875\n",
      "Batch: 123, Loss: 0.7571355700492859, Accuracy: 0.76171875\n",
      "Batch: 124, Loss: 0.8074730038642883, Accuracy: 0.7470703125\n",
      "Batch: 125, Loss: 0.8686214685440063, Accuracy: 0.7236328125\n",
      "Batch: 126, Loss: 0.8105292320251465, Accuracy: 0.7294921875\n",
      "Batch: 127, Loss: 0.7264790534973145, Accuracy: 0.7744140625\n",
      "Batch: 128, Loss: 0.9072214961051941, Accuracy: 0.7138671875\n",
      "Batch: 129, Loss: 0.7582902908325195, Accuracy: 0.751953125\n",
      "Batch: 130, Loss: 0.884056031703949, Accuracy: 0.7021484375\n",
      "Batch: 131, Loss: 0.8302698135375977, Accuracy: 0.7216796875\n",
      "Batch: 132, Loss: 0.8272619247436523, Accuracy: 0.7412109375\n",
      "Batch: 133, Loss: 0.7625176906585693, Accuracy: 0.7490234375\n",
      "Batch: 134, Loss: 0.8327013254165649, Accuracy: 0.7158203125\n",
      "Batch: 135, Loss: 0.7617847919464111, Accuracy: 0.7578125\n",
      "Batch: 136, Loss: 0.7930527925491333, Accuracy: 0.76171875\n",
      "Batch: 137, Loss: 0.7993642091751099, Accuracy: 0.734375\n",
      "Batch: 138, Loss: 0.7111598253250122, Accuracy: 0.7666015625\n",
      "Batch: 139, Loss: 0.7112122178077698, Accuracy: 0.7685546875\n",
      "Batch: 140, Loss: 0.8170796632766724, Accuracy: 0.71484375\n",
      "Batch: 141, Loss: 0.8276584148406982, Accuracy: 0.7392578125\n",
      "Batch: 142, Loss: 0.867595374584198, Accuracy: 0.7353515625\n",
      "Batch: 143, Loss: 0.7908987998962402, Accuracy: 0.7392578125\n",
      "Batch: 144, Loss: 0.8017492294311523, Accuracy: 0.744140625\n",
      "Batch: 145, Loss: 0.7697290182113647, Accuracy: 0.724609375\n",
      "Batch: 146, Loss: 0.8348103761672974, Accuracy: 0.736328125\n",
      "Batch: 147, Loss: 0.7912565469741821, Accuracy: 0.755859375\n",
      "Batch: 148, Loss: 0.8964332342147827, Accuracy: 0.7158203125\n",
      "Batch: 149, Loss: 0.7847877740859985, Accuracy: 0.7265625\n",
      "Batch: 150, Loss: 0.8065855503082275, Accuracy: 0.736328125\n",
      "Batch: 151, Loss: 0.685908317565918, Accuracy: 0.767578125\n",
      "Saved Weights at epoch 40 to file Weights_40.h5\n",
      "Epoch 41/80\n",
      "Batch: 1, Loss: 0.9805715084075928, Accuracy: 0.6923828125\n",
      "Batch: 2, Loss: 0.8653245568275452, Accuracy: 0.716796875\n",
      "Batch: 3, Loss: 0.7546309232711792, Accuracy: 0.75390625\n",
      "Batch: 4, Loss: 0.7348928451538086, Accuracy: 0.7734375\n",
      "Batch: 5, Loss: 0.7523651123046875, Accuracy: 0.7587890625\n",
      "Batch: 6, Loss: 0.7825273275375366, Accuracy: 0.7412109375\n",
      "Batch: 7, Loss: 0.7732285857200623, Accuracy: 0.740234375\n",
      "Batch: 8, Loss: 0.7693051695823669, Accuracy: 0.7509765625\n",
      "Batch: 9, Loss: 0.7288802862167358, Accuracy: 0.755859375\n",
      "Batch: 10, Loss: 0.7335633635520935, Accuracy: 0.7529296875\n",
      "Batch: 11, Loss: 0.8317742347717285, Accuracy: 0.720703125\n",
      "Batch: 12, Loss: 0.830304741859436, Accuracy: 0.734375\n",
      "Batch: 13, Loss: 0.6476508378982544, Accuracy: 0.787109375\n",
      "Batch: 14, Loss: 0.8651207089424133, Accuracy: 0.7138671875\n",
      "Batch: 15, Loss: 0.7194066047668457, Accuracy: 0.78515625\n",
      "Batch: 16, Loss: 0.7415211200714111, Accuracy: 0.7744140625\n",
      "Batch: 17, Loss: 0.7852044701576233, Accuracy: 0.7470703125\n",
      "Batch: 18, Loss: 0.7920801043510437, Accuracy: 0.744140625\n",
      "Batch: 19, Loss: 0.8254377841949463, Accuracy: 0.7294921875\n",
      "Batch: 20, Loss: 0.7327360510826111, Accuracy: 0.7822265625\n",
      "Batch: 21, Loss: 0.7394654750823975, Accuracy: 0.7578125\n",
      "Batch: 22, Loss: 0.895675778388977, Accuracy: 0.71484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 23, Loss: 0.8230544328689575, Accuracy: 0.724609375\n",
      "Batch: 24, Loss: 0.8083958625793457, Accuracy: 0.7373046875\n",
      "Batch: 25, Loss: 0.7682199478149414, Accuracy: 0.7587890625\n",
      "Batch: 26, Loss: 0.6953794360160828, Accuracy: 0.7802734375\n",
      "Batch: 27, Loss: 0.7351630926132202, Accuracy: 0.7431640625\n",
      "Batch: 28, Loss: 0.795397162437439, Accuracy: 0.728515625\n",
      "Batch: 29, Loss: 0.7436177730560303, Accuracy: 0.771484375\n",
      "Batch: 30, Loss: 0.7354395389556885, Accuracy: 0.779296875\n",
      "Batch: 31, Loss: 0.7030628323554993, Accuracy: 0.7724609375\n",
      "Batch: 32, Loss: 0.7241981029510498, Accuracy: 0.7685546875\n",
      "Batch: 33, Loss: 0.8308779001235962, Accuracy: 0.7314453125\n",
      "Batch: 34, Loss: 0.849022626876831, Accuracy: 0.732421875\n",
      "Batch: 35, Loss: 0.7987716197967529, Accuracy: 0.734375\n",
      "Batch: 36, Loss: 0.7875551581382751, Accuracy: 0.75\n",
      "Batch: 37, Loss: 0.7789270877838135, Accuracy: 0.7392578125\n",
      "Batch: 38, Loss: 0.8240100145339966, Accuracy: 0.716796875\n",
      "Batch: 39, Loss: 0.8075757622718811, Accuracy: 0.73828125\n",
      "Batch: 40, Loss: 0.8293485641479492, Accuracy: 0.73828125\n",
      "Batch: 41, Loss: 0.7320231199264526, Accuracy: 0.7607421875\n",
      "Batch: 42, Loss: 0.6045503616333008, Accuracy: 0.802734375\n",
      "Batch: 43, Loss: 0.7548739910125732, Accuracy: 0.7509765625\n",
      "Batch: 44, Loss: 0.7786728143692017, Accuracy: 0.744140625\n",
      "Batch: 45, Loss: 0.6597298383712769, Accuracy: 0.7783203125\n",
      "Batch: 46, Loss: 0.7482289671897888, Accuracy: 0.7734375\n",
      "Batch: 47, Loss: 0.7649993300437927, Accuracy: 0.767578125\n",
      "Batch: 48, Loss: 0.7425095438957214, Accuracy: 0.7587890625\n",
      "Batch: 49, Loss: 0.854676365852356, Accuracy: 0.734375\n",
      "Batch: 50, Loss: 0.7958269715309143, Accuracy: 0.73828125\n",
      "Batch: 51, Loss: 0.8768039345741272, Accuracy: 0.72265625\n",
      "Batch: 52, Loss: 0.8183691501617432, Accuracy: 0.7373046875\n",
      "Batch: 53, Loss: 0.7164496779441833, Accuracy: 0.76171875\n",
      "Batch: 54, Loss: 0.7614244222640991, Accuracy: 0.7451171875\n",
      "Batch: 55, Loss: 0.8445284366607666, Accuracy: 0.71875\n",
      "Batch: 56, Loss: 0.8383055925369263, Accuracy: 0.7119140625\n",
      "Batch: 57, Loss: 0.8151525855064392, Accuracy: 0.734375\n",
      "Batch: 58, Loss: 0.8852252960205078, Accuracy: 0.7158203125\n",
      "Batch: 59, Loss: 0.7944141626358032, Accuracy: 0.744140625\n",
      "Batch: 60, Loss: 0.7368139624595642, Accuracy: 0.7568359375\n",
      "Batch: 61, Loss: 0.8323520421981812, Accuracy: 0.7353515625\n",
      "Batch: 62, Loss: 0.7515760064125061, Accuracy: 0.7529296875\n",
      "Batch: 63, Loss: 0.8090458512306213, Accuracy: 0.751953125\n",
      "Batch: 64, Loss: 0.7470892667770386, Accuracy: 0.7529296875\n",
      "Batch: 65, Loss: 0.7712560892105103, Accuracy: 0.7685546875\n",
      "Batch: 66, Loss: 0.7808125615119934, Accuracy: 0.7490234375\n",
      "Batch: 67, Loss: 0.8505688309669495, Accuracy: 0.7451171875\n",
      "Batch: 68, Loss: 0.8438941240310669, Accuracy: 0.7275390625\n",
      "Batch: 69, Loss: 0.7846444845199585, Accuracy: 0.7451171875\n",
      "Batch: 70, Loss: 0.7960092425346375, Accuracy: 0.7626953125\n",
      "Batch: 71, Loss: 0.8052768707275391, Accuracy: 0.7431640625\n",
      "Batch: 72, Loss: 0.7175531387329102, Accuracy: 0.7626953125\n",
      "Batch: 73, Loss: 0.7588263750076294, Accuracy: 0.7578125\n",
      "Batch: 74, Loss: 0.6996585130691528, Accuracy: 0.7919921875\n",
      "Batch: 75, Loss: 0.7077118158340454, Accuracy: 0.7607421875\n",
      "Batch: 76, Loss: 0.7835623025894165, Accuracy: 0.7529296875\n",
      "Batch: 77, Loss: 0.7085571885108948, Accuracy: 0.76953125\n",
      "Batch: 78, Loss: 0.7145384550094604, Accuracy: 0.767578125\n",
      "Batch: 79, Loss: 0.7412619590759277, Accuracy: 0.7783203125\n",
      "Batch: 80, Loss: 0.7001287341117859, Accuracy: 0.7607421875\n",
      "Batch: 81, Loss: 0.8107486367225647, Accuracy: 0.7236328125\n",
      "Batch: 82, Loss: 0.7860730886459351, Accuracy: 0.7451171875\n",
      "Batch: 83, Loss: 0.6946533918380737, Accuracy: 0.7919921875\n",
      "Batch: 84, Loss: 0.8010377883911133, Accuracy: 0.7548828125\n",
      "Batch: 85, Loss: 0.7192367315292358, Accuracy: 0.765625\n",
      "Batch: 86, Loss: 0.8662074208259583, Accuracy: 0.7216796875\n",
      "Batch: 87, Loss: 0.7120276093482971, Accuracy: 0.7666015625\n",
      "Batch: 88, Loss: 0.8198648691177368, Accuracy: 0.748046875\n",
      "Batch: 89, Loss: 0.7921623587608337, Accuracy: 0.7421875\n",
      "Batch: 90, Loss: 0.7329080104827881, Accuracy: 0.7578125\n",
      "Batch: 91, Loss: 0.7302024364471436, Accuracy: 0.751953125\n",
      "Batch: 92, Loss: 0.7944846749305725, Accuracy: 0.7421875\n",
      "Batch: 93, Loss: 0.7643170356750488, Accuracy: 0.7548828125\n",
      "Batch: 94, Loss: 0.7988194227218628, Accuracy: 0.734375\n",
      "Batch: 95, Loss: 0.7641566395759583, Accuracy: 0.734375\n",
      "Batch: 96, Loss: 0.7503821849822998, Accuracy: 0.7548828125\n",
      "Batch: 97, Loss: 0.6512792110443115, Accuracy: 0.787109375\n",
      "Batch: 98, Loss: 0.7663886547088623, Accuracy: 0.73828125\n",
      "Batch: 99, Loss: 0.747804582118988, Accuracy: 0.7568359375\n",
      "Batch: 100, Loss: 0.7447962760925293, Accuracy: 0.755859375\n",
      "Batch: 101, Loss: 0.8236434459686279, Accuracy: 0.7412109375\n",
      "Batch: 102, Loss: 0.7871787548065186, Accuracy: 0.7412109375\n",
      "Batch: 103, Loss: 0.8431532382965088, Accuracy: 0.744140625\n",
      "Batch: 104, Loss: 0.7295977473258972, Accuracy: 0.76953125\n",
      "Batch: 105, Loss: 0.7830231189727783, Accuracy: 0.74609375\n",
      "Batch: 106, Loss: 0.7267844676971436, Accuracy: 0.7666015625\n",
      "Batch: 107, Loss: 0.7842928767204285, Accuracy: 0.7578125\n",
      "Batch: 108, Loss: 0.78026282787323, Accuracy: 0.7451171875\n",
      "Batch: 109, Loss: 0.8027346730232239, Accuracy: 0.71484375\n",
      "Batch: 110, Loss: 0.6995500326156616, Accuracy: 0.76953125\n",
      "Batch: 111, Loss: 0.8068118095397949, Accuracy: 0.7392578125\n",
      "Batch: 112, Loss: 0.7827696800231934, Accuracy: 0.74609375\n",
      "Batch: 113, Loss: 0.8155668377876282, Accuracy: 0.7431640625\n",
      "Batch: 114, Loss: 0.8436597585678101, Accuracy: 0.7275390625\n",
      "Batch: 115, Loss: 0.8770346641540527, Accuracy: 0.724609375\n",
      "Batch: 116, Loss: 0.8063856363296509, Accuracy: 0.734375\n",
      "Batch: 117, Loss: 0.8576651215553284, Accuracy: 0.734375\n",
      "Batch: 118, Loss: 0.7218448519706726, Accuracy: 0.7587890625\n",
      "Batch: 119, Loss: 0.7252472639083862, Accuracy: 0.7646484375\n",
      "Batch: 120, Loss: 0.7691844701766968, Accuracy: 0.73828125\n",
      "Batch: 121, Loss: 0.8185354471206665, Accuracy: 0.7421875\n",
      "Batch: 122, Loss: 0.7580647468566895, Accuracy: 0.76171875\n",
      "Batch: 123, Loss: 0.763637125492096, Accuracy: 0.7626953125\n",
      "Batch: 124, Loss: 0.7943326234817505, Accuracy: 0.7421875\n",
      "Batch: 125, Loss: 0.8094107508659363, Accuracy: 0.7451171875\n",
      "Batch: 126, Loss: 0.7858710289001465, Accuracy: 0.751953125\n",
      "Batch: 127, Loss: 0.7170604467391968, Accuracy: 0.7783203125\n",
      "Batch: 128, Loss: 0.8922438621520996, Accuracy: 0.7255859375\n",
      "Batch: 129, Loss: 0.7436249256134033, Accuracy: 0.76171875\n",
      "Batch: 130, Loss: 0.8811600208282471, Accuracy: 0.7158203125\n",
      "Batch: 131, Loss: 0.8212943077087402, Accuracy: 0.740234375\n",
      "Batch: 132, Loss: 0.8530272245407104, Accuracy: 0.7431640625\n",
      "Batch: 133, Loss: 0.7677651643753052, Accuracy: 0.744140625\n",
      "Batch: 134, Loss: 0.7939242124557495, Accuracy: 0.73046875\n",
      "Batch: 135, Loss: 0.7579405903816223, Accuracy: 0.7568359375\n",
      "Batch: 136, Loss: 0.8217678070068359, Accuracy: 0.7353515625\n",
      "Batch: 137, Loss: 0.7755774259567261, Accuracy: 0.7470703125\n",
      "Batch: 138, Loss: 0.7098493576049805, Accuracy: 0.7724609375\n",
      "Batch: 139, Loss: 0.715704619884491, Accuracy: 0.7724609375\n",
      "Batch: 140, Loss: 0.8236191272735596, Accuracy: 0.716796875\n",
      "Batch: 141, Loss: 0.816614031791687, Accuracy: 0.734375\n",
      "Batch: 142, Loss: 0.8686827421188354, Accuracy: 0.7275390625\n",
      "Batch: 143, Loss: 0.7762681245803833, Accuracy: 0.7431640625\n",
      "Batch: 144, Loss: 0.8206148147583008, Accuracy: 0.73828125\n",
      "Batch: 145, Loss: 0.7338854074478149, Accuracy: 0.7392578125\n",
      "Batch: 146, Loss: 0.8090019822120667, Accuracy: 0.724609375\n",
      "Batch: 147, Loss: 0.780920147895813, Accuracy: 0.7412109375\n",
      "Batch: 148, Loss: 0.8655229806900024, Accuracy: 0.7080078125\n",
      "Batch: 149, Loss: 0.7858337163925171, Accuracy: 0.748046875\n",
      "Batch: 150, Loss: 0.787407398223877, Accuracy: 0.7412109375\n",
      "Batch: 151, Loss: 0.679063618183136, Accuracy: 0.78125\n",
      "Epoch 42/80\n",
      "Batch: 1, Loss: 0.9836761951446533, Accuracy: 0.6923828125\n",
      "Batch: 2, Loss: 0.8669668436050415, Accuracy: 0.7021484375\n",
      "Batch: 3, Loss: 0.7721991539001465, Accuracy: 0.7412109375\n",
      "Batch: 4, Loss: 0.7011166214942932, Accuracy: 0.787109375\n",
      "Batch: 5, Loss: 0.7468826174736023, Accuracy: 0.76171875\n",
      "Batch: 6, Loss: 0.7832474112510681, Accuracy: 0.748046875\n",
      "Batch: 7, Loss: 0.7902198433876038, Accuracy: 0.7333984375\n",
      "Batch: 8, Loss: 0.7336705923080444, Accuracy: 0.7509765625\n",
      "Batch: 9, Loss: 0.7513364553451538, Accuracy: 0.751953125\n",
      "Batch: 10, Loss: 0.7143552303314209, Accuracy: 0.7626953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 11, Loss: 0.8232657313346863, Accuracy: 0.724609375\n",
      "Batch: 12, Loss: 0.8285232782363892, Accuracy: 0.7353515625\n",
      "Batch: 13, Loss: 0.677183985710144, Accuracy: 0.7783203125\n",
      "Batch: 14, Loss: 0.8731361627578735, Accuracy: 0.71875\n",
      "Batch: 15, Loss: 0.6966842412948608, Accuracy: 0.7861328125\n",
      "Batch: 16, Loss: 0.7457690834999084, Accuracy: 0.7685546875\n",
      "Batch: 17, Loss: 0.8008259534835815, Accuracy: 0.76171875\n",
      "Batch: 18, Loss: 0.7934103012084961, Accuracy: 0.75390625\n",
      "Batch: 19, Loss: 0.8532602190971375, Accuracy: 0.7158203125\n",
      "Batch: 20, Loss: 0.7163413763046265, Accuracy: 0.7763671875\n",
      "Batch: 21, Loss: 0.7224346399307251, Accuracy: 0.7578125\n",
      "Batch: 22, Loss: 0.863149881362915, Accuracy: 0.7158203125\n",
      "Batch: 23, Loss: 0.8003641963005066, Accuracy: 0.7353515625\n",
      "Batch: 24, Loss: 0.8015692234039307, Accuracy: 0.7412109375\n",
      "Batch: 25, Loss: 0.7553473114967346, Accuracy: 0.7490234375\n",
      "Batch: 26, Loss: 0.6883836984634399, Accuracy: 0.77734375\n",
      "Batch: 27, Loss: 0.7316904664039612, Accuracy: 0.7509765625\n",
      "Batch: 28, Loss: 0.7885570526123047, Accuracy: 0.744140625\n",
      "Batch: 29, Loss: 0.72600919008255, Accuracy: 0.767578125\n",
      "Batch: 30, Loss: 0.7174036502838135, Accuracy: 0.759765625\n",
      "Batch: 31, Loss: 0.6807632446289062, Accuracy: 0.7900390625\n",
      "Batch: 32, Loss: 0.707204282283783, Accuracy: 0.7646484375\n",
      "Batch: 33, Loss: 0.8535665273666382, Accuracy: 0.7275390625\n",
      "Batch: 34, Loss: 0.8636578321456909, Accuracy: 0.7001953125\n",
      "Batch: 35, Loss: 0.8138328790664673, Accuracy: 0.7431640625\n",
      "Batch: 36, Loss: 0.7911466360092163, Accuracy: 0.74609375\n",
      "Batch: 37, Loss: 0.760562539100647, Accuracy: 0.7509765625\n",
      "Batch: 38, Loss: 0.8145508170127869, Accuracy: 0.7275390625\n",
      "Batch: 39, Loss: 0.7545256614685059, Accuracy: 0.7509765625\n",
      "Batch: 40, Loss: 0.7739641666412354, Accuracy: 0.7568359375\n",
      "Batch: 41, Loss: 0.7010707259178162, Accuracy: 0.779296875\n",
      "Batch: 42, Loss: 0.5942776203155518, Accuracy: 0.7978515625\n",
      "Batch: 43, Loss: 0.7484667301177979, Accuracy: 0.751953125\n",
      "Batch: 44, Loss: 0.815927267074585, Accuracy: 0.73046875\n",
      "Batch: 45, Loss: 0.6763915419578552, Accuracy: 0.7783203125\n",
      "Batch: 46, Loss: 0.7232381105422974, Accuracy: 0.7861328125\n",
      "Batch: 47, Loss: 0.7644912004470825, Accuracy: 0.7587890625\n",
      "Batch: 48, Loss: 0.7469816207885742, Accuracy: 0.75\n",
      "Batch: 49, Loss: 0.8322038054466248, Accuracy: 0.736328125\n",
      "Batch: 50, Loss: 0.7394282817840576, Accuracy: 0.7607421875\n",
      "Batch: 51, Loss: 0.8279544115066528, Accuracy: 0.7314453125\n",
      "Batch: 52, Loss: 0.7953820824623108, Accuracy: 0.740234375\n",
      "Batch: 53, Loss: 0.7152502536773682, Accuracy: 0.76171875\n",
      "Batch: 54, Loss: 0.7458741068840027, Accuracy: 0.76171875\n",
      "Batch: 55, Loss: 0.8488863706588745, Accuracy: 0.7158203125\n",
      "Batch: 56, Loss: 0.8503873944282532, Accuracy: 0.7138671875\n",
      "Batch: 57, Loss: 0.804442286491394, Accuracy: 0.73828125\n",
      "Batch: 58, Loss: 0.8818665146827698, Accuracy: 0.71875\n",
      "Batch: 59, Loss: 0.7527174353599548, Accuracy: 0.7607421875\n",
      "Batch: 60, Loss: 0.7301992177963257, Accuracy: 0.7685546875\n",
      "Batch: 61, Loss: 0.7927110195159912, Accuracy: 0.736328125\n",
      "Batch: 62, Loss: 0.7440899610519409, Accuracy: 0.7509765625\n",
      "Batch: 63, Loss: 0.7771315574645996, Accuracy: 0.755859375\n",
      "Batch: 64, Loss: 0.7493957281112671, Accuracy: 0.748046875\n",
      "Batch: 65, Loss: 0.8082846403121948, Accuracy: 0.7548828125\n",
      "Batch: 66, Loss: 0.7945717573165894, Accuracy: 0.7431640625\n",
      "Batch: 67, Loss: 0.8550605773925781, Accuracy: 0.744140625\n",
      "Batch: 68, Loss: 0.8506553173065186, Accuracy: 0.7275390625\n",
      "Batch: 69, Loss: 0.7821492552757263, Accuracy: 0.755859375\n",
      "Batch: 70, Loss: 0.8029664754867554, Accuracy: 0.7451171875\n",
      "Batch: 71, Loss: 0.7910780906677246, Accuracy: 0.732421875\n",
      "Batch: 72, Loss: 0.715627133846283, Accuracy: 0.7685546875\n",
      "Batch: 73, Loss: 0.7131706476211548, Accuracy: 0.7861328125\n",
      "Batch: 74, Loss: 0.685453474521637, Accuracy: 0.7958984375\n",
      "Batch: 75, Loss: 0.6901021003723145, Accuracy: 0.77734375\n",
      "Batch: 76, Loss: 0.7762368321418762, Accuracy: 0.7470703125\n",
      "Batch: 77, Loss: 0.7151459455490112, Accuracy: 0.771484375\n",
      "Batch: 78, Loss: 0.7117928266525269, Accuracy: 0.775390625\n",
      "Batch: 79, Loss: 0.6961219310760498, Accuracy: 0.7783203125\n",
      "Batch: 80, Loss: 0.6960877180099487, Accuracy: 0.7587890625\n",
      "Batch: 81, Loss: 0.8103580474853516, Accuracy: 0.7431640625\n",
      "Batch: 82, Loss: 0.775825560092926, Accuracy: 0.751953125\n",
      "Batch: 83, Loss: 0.6697381734848022, Accuracy: 0.7919921875\n",
      "Batch: 84, Loss: 0.7788977026939392, Accuracy: 0.75390625\n",
      "Batch: 85, Loss: 0.7459207773208618, Accuracy: 0.7705078125\n",
      "Batch: 86, Loss: 0.8679189682006836, Accuracy: 0.720703125\n",
      "Batch: 87, Loss: 0.7155091762542725, Accuracy: 0.767578125\n",
      "Batch: 88, Loss: 0.8118559122085571, Accuracy: 0.740234375\n",
      "Batch: 89, Loss: 0.818845272064209, Accuracy: 0.7529296875\n",
      "Batch: 90, Loss: 0.7298956513404846, Accuracy: 0.759765625\n",
      "Batch: 91, Loss: 0.7290697693824768, Accuracy: 0.7568359375\n",
      "Batch: 92, Loss: 0.8103430867195129, Accuracy: 0.7294921875\n",
      "Batch: 93, Loss: 0.7409923076629639, Accuracy: 0.7568359375\n",
      "Batch: 94, Loss: 0.7848535776138306, Accuracy: 0.7412109375\n",
      "Batch: 95, Loss: 0.7806333303451538, Accuracy: 0.732421875\n",
      "Batch: 96, Loss: 0.7453511357307434, Accuracy: 0.7666015625\n",
      "Batch: 97, Loss: 0.658444881439209, Accuracy: 0.783203125\n",
      "Batch: 98, Loss: 0.7425273060798645, Accuracy: 0.7607421875\n",
      "Batch: 99, Loss: 0.7584087252616882, Accuracy: 0.7568359375\n",
      "Batch: 100, Loss: 0.7723715901374817, Accuracy: 0.7333984375\n",
      "Batch: 101, Loss: 0.8219641447067261, Accuracy: 0.732421875\n",
      "Batch: 102, Loss: 0.8070372939109802, Accuracy: 0.7373046875\n",
      "Batch: 103, Loss: 0.8122507929801941, Accuracy: 0.74609375\n",
      "Batch: 104, Loss: 0.710822582244873, Accuracy: 0.7646484375\n",
      "Batch: 105, Loss: 0.782741129398346, Accuracy: 0.74609375\n",
      "Batch: 106, Loss: 0.7217902541160583, Accuracy: 0.7666015625\n",
      "Batch: 107, Loss: 0.7622767090797424, Accuracy: 0.76953125\n",
      "Batch: 108, Loss: 0.7892410755157471, Accuracy: 0.7412109375\n",
      "Batch: 109, Loss: 0.8166686296463013, Accuracy: 0.72265625\n",
      "Batch: 110, Loss: 0.7009358406066895, Accuracy: 0.775390625\n",
      "Batch: 111, Loss: 0.7712610960006714, Accuracy: 0.7509765625\n",
      "Batch: 112, Loss: 0.7903491258621216, Accuracy: 0.7431640625\n",
      "Batch: 113, Loss: 0.8022041916847229, Accuracy: 0.7451171875\n",
      "Batch: 114, Loss: 0.8512492179870605, Accuracy: 0.73046875\n",
      "Batch: 115, Loss: 0.8944872617721558, Accuracy: 0.7158203125\n",
      "Batch: 116, Loss: 0.8021033406257629, Accuracy: 0.7431640625\n",
      "Batch: 117, Loss: 0.8299351930618286, Accuracy: 0.7333984375\n",
      "Batch: 118, Loss: 0.6927783489227295, Accuracy: 0.7734375\n",
      "Batch: 119, Loss: 0.7081706523895264, Accuracy: 0.765625\n",
      "Batch: 120, Loss: 0.7896572947502136, Accuracy: 0.728515625\n",
      "Batch: 121, Loss: 0.8503388166427612, Accuracy: 0.7119140625\n",
      "Batch: 122, Loss: 0.7418854236602783, Accuracy: 0.7568359375\n",
      "Batch: 123, Loss: 0.7212433815002441, Accuracy: 0.7666015625\n",
      "Batch: 124, Loss: 0.7625377774238586, Accuracy: 0.7548828125\n",
      "Batch: 125, Loss: 0.8268627524375916, Accuracy: 0.732421875\n",
      "Batch: 126, Loss: 0.783502459526062, Accuracy: 0.7412109375\n",
      "Batch: 127, Loss: 0.6986556649208069, Accuracy: 0.79296875\n",
      "Batch: 128, Loss: 0.8774541616439819, Accuracy: 0.7216796875\n",
      "Batch: 129, Loss: 0.7351824641227722, Accuracy: 0.7646484375\n",
      "Batch: 130, Loss: 0.8510397672653198, Accuracy: 0.7333984375\n",
      "Batch: 131, Loss: 0.8184118270874023, Accuracy: 0.732421875\n",
      "Batch: 132, Loss: 0.8173682689666748, Accuracy: 0.755859375\n",
      "Batch: 133, Loss: 0.7458733320236206, Accuracy: 0.755859375\n",
      "Batch: 134, Loss: 0.82110196352005, Accuracy: 0.7265625\n",
      "Batch: 135, Loss: 0.7452449202537537, Accuracy: 0.7705078125\n",
      "Batch: 136, Loss: 0.7755542397499084, Accuracy: 0.7451171875\n",
      "Batch: 137, Loss: 0.7396429777145386, Accuracy: 0.7509765625\n",
      "Batch: 138, Loss: 0.7016622424125671, Accuracy: 0.751953125\n",
      "Batch: 139, Loss: 0.7060799598693848, Accuracy: 0.7646484375\n",
      "Batch: 140, Loss: 0.804728627204895, Accuracy: 0.748046875\n",
      "Batch: 141, Loss: 0.827092707157135, Accuracy: 0.7373046875\n",
      "Batch: 142, Loss: 0.8851490020751953, Accuracy: 0.71484375\n",
      "Batch: 143, Loss: 0.8233343362808228, Accuracy: 0.7451171875\n",
      "Batch: 144, Loss: 0.7790316343307495, Accuracy: 0.73046875\n",
      "Batch: 145, Loss: 0.7210894823074341, Accuracy: 0.7421875\n",
      "Batch: 146, Loss: 0.8297548294067383, Accuracy: 0.7138671875\n",
      "Batch: 147, Loss: 0.7632343769073486, Accuracy: 0.7529296875\n",
      "Batch: 148, Loss: 0.8659459948539734, Accuracy: 0.7080078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 149, Loss: 0.7555989027023315, Accuracy: 0.75390625\n",
      "Batch: 150, Loss: 0.7897249460220337, Accuracy: 0.755859375\n",
      "Batch: 151, Loss: 0.6576260924339294, Accuracy: 0.7900390625\n",
      "Epoch 43/80\n",
      "Batch: 1, Loss: 0.9311332702636719, Accuracy: 0.7021484375\n",
      "Batch: 2, Loss: 0.8171963691711426, Accuracy: 0.7236328125\n",
      "Batch: 3, Loss: 0.7242735624313354, Accuracy: 0.7548828125\n",
      "Batch: 4, Loss: 0.6876676082611084, Accuracy: 0.7890625\n",
      "Batch: 5, Loss: 0.7680680751800537, Accuracy: 0.7646484375\n",
      "Batch: 6, Loss: 0.7780661582946777, Accuracy: 0.74609375\n",
      "Batch: 7, Loss: 0.7375540137290955, Accuracy: 0.748046875\n",
      "Batch: 8, Loss: 0.722385823726654, Accuracy: 0.765625\n",
      "Batch: 9, Loss: 0.7539635896682739, Accuracy: 0.748046875\n",
      "Batch: 10, Loss: 0.7092480659484863, Accuracy: 0.767578125\n",
      "Batch: 11, Loss: 0.8147733807563782, Accuracy: 0.724609375\n",
      "Batch: 12, Loss: 0.7992362976074219, Accuracy: 0.7607421875\n",
      "Batch: 13, Loss: 0.6751111149787903, Accuracy: 0.7705078125\n",
      "Batch: 14, Loss: 0.8676374554634094, Accuracy: 0.7255859375\n",
      "Batch: 15, Loss: 0.7219798564910889, Accuracy: 0.78125\n",
      "Batch: 16, Loss: 0.7362004518508911, Accuracy: 0.7744140625\n",
      "Batch: 17, Loss: 0.7651549577713013, Accuracy: 0.7470703125\n",
      "Batch: 18, Loss: 0.7820492386817932, Accuracy: 0.7333984375\n",
      "Batch: 19, Loss: 0.7888445854187012, Accuracy: 0.7568359375\n",
      "Batch: 20, Loss: 0.7091615200042725, Accuracy: 0.7763671875\n",
      "Batch: 21, Loss: 0.7231021523475647, Accuracy: 0.767578125\n",
      "Batch: 22, Loss: 0.8448472619056702, Accuracy: 0.724609375\n",
      "Batch: 23, Loss: 0.8098644614219666, Accuracy: 0.7353515625\n",
      "Batch: 24, Loss: 0.7771430015563965, Accuracy: 0.7373046875\n",
      "Batch: 25, Loss: 0.7470219135284424, Accuracy: 0.759765625\n",
      "Batch: 26, Loss: 0.6540780663490295, Accuracy: 0.7880859375\n",
      "Batch: 27, Loss: 0.7015054225921631, Accuracy: 0.771484375\n",
      "Batch: 28, Loss: 0.7864412665367126, Accuracy: 0.7353515625\n",
      "Batch: 29, Loss: 0.7226176857948303, Accuracy: 0.7705078125\n",
      "Batch: 30, Loss: 0.7183222770690918, Accuracy: 0.755859375\n",
      "Batch: 31, Loss: 0.6995468735694885, Accuracy: 0.763671875\n",
      "Batch: 32, Loss: 0.6824581027030945, Accuracy: 0.7646484375\n",
      "Batch: 33, Loss: 0.7983216047286987, Accuracy: 0.732421875\n",
      "Batch: 34, Loss: 0.8566072583198547, Accuracy: 0.7236328125\n",
      "Batch: 35, Loss: 0.8169007897377014, Accuracy: 0.7294921875\n",
      "Batch: 36, Loss: 0.8005756139755249, Accuracy: 0.7490234375\n",
      "Batch: 37, Loss: 0.7636109590530396, Accuracy: 0.7421875\n",
      "Batch: 38, Loss: 0.8036633729934692, Accuracy: 0.7275390625\n",
      "Batch: 39, Loss: 0.7984825968742371, Accuracy: 0.7470703125\n",
      "Batch: 40, Loss: 0.8079088926315308, Accuracy: 0.7392578125\n",
      "Batch: 41, Loss: 0.6957659125328064, Accuracy: 0.7705078125\n",
      "Batch: 42, Loss: 0.5976821780204773, Accuracy: 0.7958984375\n",
      "Batch: 43, Loss: 0.7572528719902039, Accuracy: 0.7626953125\n",
      "Batch: 44, Loss: 0.7947420477867126, Accuracy: 0.7509765625\n",
      "Batch: 45, Loss: 0.6964914798736572, Accuracy: 0.76953125\n",
      "Batch: 46, Loss: 0.7462142705917358, Accuracy: 0.7705078125\n",
      "Batch: 47, Loss: 0.7693154811859131, Accuracy: 0.7607421875\n",
      "Batch: 48, Loss: 0.7106823921203613, Accuracy: 0.77734375\n",
      "Batch: 49, Loss: 0.8152689933776855, Accuracy: 0.7451171875\n",
      "Batch: 50, Loss: 0.7394516468048096, Accuracy: 0.7587890625\n",
      "Batch: 51, Loss: 0.8346388339996338, Accuracy: 0.728515625\n",
      "Batch: 52, Loss: 0.7975279092788696, Accuracy: 0.7353515625\n",
      "Batch: 53, Loss: 0.6855205297470093, Accuracy: 0.765625\n",
      "Batch: 54, Loss: 0.7408743500709534, Accuracy: 0.759765625\n",
      "Batch: 55, Loss: 0.8600180745124817, Accuracy: 0.7158203125\n",
      "Batch: 56, Loss: 0.8084396123886108, Accuracy: 0.720703125\n",
      "Batch: 57, Loss: 0.802331805229187, Accuracy: 0.7451171875\n",
      "Batch: 58, Loss: 0.8907208442687988, Accuracy: 0.72265625\n",
      "Batch: 59, Loss: 0.7629377245903015, Accuracy: 0.748046875\n",
      "Batch: 60, Loss: 0.710250973701477, Accuracy: 0.7607421875\n",
      "Batch: 61, Loss: 0.8190491199493408, Accuracy: 0.740234375\n",
      "Batch: 62, Loss: 0.7299982309341431, Accuracy: 0.759765625\n",
      "Batch: 63, Loss: 0.7625635862350464, Accuracy: 0.744140625\n",
      "Batch: 64, Loss: 0.7650802135467529, Accuracy: 0.75390625\n",
      "Batch: 65, Loss: 0.7868603467941284, Accuracy: 0.7529296875\n",
      "Batch: 66, Loss: 0.7935765385627747, Accuracy: 0.75390625\n",
      "Batch: 67, Loss: 0.8020554780960083, Accuracy: 0.7333984375\n",
      "Batch: 68, Loss: 0.8327610492706299, Accuracy: 0.73046875\n",
      "Batch: 69, Loss: 0.7792688012123108, Accuracy: 0.7529296875\n",
      "Batch: 70, Loss: 0.8239665031433105, Accuracy: 0.7421875\n",
      "Batch: 71, Loss: 0.7753776907920837, Accuracy: 0.751953125\n",
      "Batch: 72, Loss: 0.7081347703933716, Accuracy: 0.76171875\n",
      "Batch: 73, Loss: 0.7064680457115173, Accuracy: 0.7802734375\n",
      "Batch: 74, Loss: 0.6785070896148682, Accuracy: 0.7890625\n",
      "Batch: 75, Loss: 0.6870347857475281, Accuracy: 0.7763671875\n",
      "Batch: 76, Loss: 0.7818946838378906, Accuracy: 0.7509765625\n",
      "Batch: 77, Loss: 0.7031331062316895, Accuracy: 0.765625\n",
      "Batch: 78, Loss: 0.7134689688682556, Accuracy: 0.77734375\n",
      "Batch: 79, Loss: 0.7230479121208191, Accuracy: 0.78125\n",
      "Batch: 80, Loss: 0.7180732488632202, Accuracy: 0.7578125\n",
      "Batch: 81, Loss: 0.8094971179962158, Accuracy: 0.7314453125\n",
      "Batch: 82, Loss: 0.7667281627655029, Accuracy: 0.7578125\n",
      "Batch: 83, Loss: 0.6953414082527161, Accuracy: 0.783203125\n",
      "Batch: 84, Loss: 0.7643662691116333, Accuracy: 0.77734375\n",
      "Batch: 85, Loss: 0.7365628480911255, Accuracy: 0.7666015625\n",
      "Batch: 86, Loss: 0.837731122970581, Accuracy: 0.73046875\n",
      "Batch: 87, Loss: 0.7180660963058472, Accuracy: 0.7734375\n",
      "Batch: 88, Loss: 0.8053426742553711, Accuracy: 0.7509765625\n",
      "Batch: 89, Loss: 0.7760552167892456, Accuracy: 0.7607421875\n",
      "Batch: 90, Loss: 0.7344065308570862, Accuracy: 0.7646484375\n",
      "Batch: 91, Loss: 0.7138968706130981, Accuracy: 0.7646484375\n",
      "Batch: 92, Loss: 0.8002749085426331, Accuracy: 0.748046875\n",
      "Batch: 93, Loss: 0.7508615851402283, Accuracy: 0.7529296875\n",
      "Batch: 94, Loss: 0.7802107334136963, Accuracy: 0.740234375\n",
      "Batch: 95, Loss: 0.7668225765228271, Accuracy: 0.748046875\n",
      "Batch: 96, Loss: 0.764661431312561, Accuracy: 0.7529296875\n",
      "Batch: 97, Loss: 0.6067042350769043, Accuracy: 0.798828125\n",
      "Batch: 98, Loss: 0.7562856674194336, Accuracy: 0.759765625\n",
      "Batch: 99, Loss: 0.7298171520233154, Accuracy: 0.755859375\n",
      "Batch: 100, Loss: 0.7377606630325317, Accuracy: 0.7421875\n",
      "Batch: 101, Loss: 0.8336145877838135, Accuracy: 0.7431640625\n",
      "Batch: 102, Loss: 0.7666481733322144, Accuracy: 0.751953125\n",
      "Batch: 103, Loss: 0.8073318004608154, Accuracy: 0.74609375\n",
      "Batch: 104, Loss: 0.7224574089050293, Accuracy: 0.763671875\n",
      "Batch: 105, Loss: 0.7650507688522339, Accuracy: 0.7451171875\n",
      "Batch: 106, Loss: 0.7243119478225708, Accuracy: 0.7626953125\n",
      "Batch: 107, Loss: 0.7397897243499756, Accuracy: 0.78125\n",
      "Batch: 108, Loss: 0.7503151893615723, Accuracy: 0.7666015625\n",
      "Batch: 109, Loss: 0.7824966311454773, Accuracy: 0.7451171875\n",
      "Batch: 110, Loss: 0.7081475257873535, Accuracy: 0.7724609375\n",
      "Batch: 111, Loss: 0.7641904354095459, Accuracy: 0.7490234375\n",
      "Batch: 112, Loss: 0.7696216106414795, Accuracy: 0.7529296875\n",
      "Batch: 113, Loss: 0.8118191957473755, Accuracy: 0.7373046875\n",
      "Batch: 114, Loss: 0.8250038623809814, Accuracy: 0.734375\n",
      "Batch: 115, Loss: 0.8669365644454956, Accuracy: 0.7265625\n",
      "Batch: 116, Loss: 0.7920809388160706, Accuracy: 0.7509765625\n",
      "Batch: 117, Loss: 0.8396596312522888, Accuracy: 0.7314453125\n",
      "Batch: 118, Loss: 0.7025315761566162, Accuracy: 0.77734375\n",
      "Batch: 119, Loss: 0.6972756385803223, Accuracy: 0.7783203125\n",
      "Batch: 120, Loss: 0.7621753215789795, Accuracy: 0.7431640625\n",
      "Batch: 121, Loss: 0.8172698020935059, Accuracy: 0.736328125\n",
      "Batch: 122, Loss: 0.7730439901351929, Accuracy: 0.7529296875\n",
      "Batch: 123, Loss: 0.7047040462493896, Accuracy: 0.7705078125\n",
      "Batch: 124, Loss: 0.7812143564224243, Accuracy: 0.75\n",
      "Batch: 125, Loss: 0.8342112302780151, Accuracy: 0.734375\n",
      "Batch: 126, Loss: 0.7766122221946716, Accuracy: 0.7431640625\n",
      "Batch: 127, Loss: 0.7046761512756348, Accuracy: 0.7763671875\n",
      "Batch: 128, Loss: 0.8353099822998047, Accuracy: 0.7421875\n",
      "Batch: 129, Loss: 0.6999306678771973, Accuracy: 0.767578125\n",
      "Batch: 130, Loss: 0.831756591796875, Accuracy: 0.734375\n",
      "Batch: 131, Loss: 0.8244286775588989, Accuracy: 0.728515625\n",
      "Batch: 132, Loss: 0.8180114030838013, Accuracy: 0.7451171875\n",
      "Batch: 133, Loss: 0.7585580348968506, Accuracy: 0.751953125\n",
      "Batch: 134, Loss: 0.7948328256607056, Accuracy: 0.736328125\n",
      "Batch: 135, Loss: 0.7658752799034119, Accuracy: 0.7587890625\n",
      "Batch: 136, Loss: 0.7605137825012207, Accuracy: 0.7470703125\n",
      "Batch: 137, Loss: 0.760266125202179, Accuracy: 0.7373046875\n",
      "Batch: 138, Loss: 0.6756371855735779, Accuracy: 0.771484375\n",
      "Batch: 139, Loss: 0.7061799168586731, Accuracy: 0.775390625\n",
      "Batch: 140, Loss: 0.7832672595977783, Accuracy: 0.7490234375\n",
      "Batch: 141, Loss: 0.797544002532959, Accuracy: 0.7490234375\n",
      "Batch: 142, Loss: 0.8361043930053711, Accuracy: 0.740234375\n",
      "Batch: 143, Loss: 0.7771991491317749, Accuracy: 0.7392578125\n",
      "Batch: 144, Loss: 0.7977402806282043, Accuracy: 0.7373046875\n",
      "Batch: 145, Loss: 0.7180969715118408, Accuracy: 0.767578125\n",
      "Batch: 146, Loss: 0.8078979253768921, Accuracy: 0.72265625\n",
      "Batch: 147, Loss: 0.7519651651382446, Accuracy: 0.7490234375\n",
      "Batch: 148, Loss: 0.8576780557632446, Accuracy: 0.724609375\n",
      "Batch: 149, Loss: 0.7302438020706177, Accuracy: 0.759765625\n",
      "Batch: 150, Loss: 0.7685447335243225, Accuracy: 0.748046875\n",
      "Batch: 151, Loss: 0.6664849519729614, Accuracy: 0.7822265625\n",
      "Epoch 44/80\n",
      "Batch: 1, Loss: 0.9555570483207703, Accuracy: 0.7021484375\n",
      "Batch: 2, Loss: 0.8501758575439453, Accuracy: 0.7060546875\n",
      "Batch: 3, Loss: 0.7209122180938721, Accuracy: 0.7607421875\n",
      "Batch: 4, Loss: 0.6830304861068726, Accuracy: 0.7861328125\n",
      "Batch: 5, Loss: 0.7307530641555786, Accuracy: 0.763671875\n",
      "Batch: 6, Loss: 0.7612850069999695, Accuracy: 0.7392578125\n",
      "Batch: 7, Loss: 0.7648143768310547, Accuracy: 0.7236328125\n",
      "Batch: 8, Loss: 0.7198716998100281, Accuracy: 0.7705078125\n",
      "Batch: 9, Loss: 0.7066718935966492, Accuracy: 0.763671875\n",
      "Batch: 10, Loss: 0.7118860483169556, Accuracy: 0.771484375\n",
      "Batch: 11, Loss: 0.7950850129127502, Accuracy: 0.7412109375\n",
      "Batch: 12, Loss: 0.7815308570861816, Accuracy: 0.7509765625\n",
      "Batch: 13, Loss: 0.6637856960296631, Accuracy: 0.767578125\n",
      "Batch: 14, Loss: 0.8201060891151428, Accuracy: 0.72265625\n",
      "Batch: 15, Loss: 0.713421642780304, Accuracy: 0.7763671875\n",
      "Batch: 16, Loss: 0.7144711017608643, Accuracy: 0.7724609375\n",
      "Batch: 17, Loss: 0.7193487286567688, Accuracy: 0.7646484375\n",
      "Batch: 18, Loss: 0.7767566442489624, Accuracy: 0.7470703125\n",
      "Batch: 19, Loss: 0.7692674398422241, Accuracy: 0.7626953125\n",
      "Batch: 20, Loss: 0.7200894355773926, Accuracy: 0.787109375\n",
      "Batch: 21, Loss: 0.7032003402709961, Accuracy: 0.78125\n",
      "Batch: 22, Loss: 0.8333575129508972, Accuracy: 0.728515625\n",
      "Batch: 23, Loss: 0.792776346206665, Accuracy: 0.744140625\n",
      "Batch: 24, Loss: 0.7701270580291748, Accuracy: 0.74609375\n",
      "Batch: 25, Loss: 0.7629009485244751, Accuracy: 0.7587890625\n",
      "Batch: 26, Loss: 0.6683118343353271, Accuracy: 0.78125\n",
      "Batch: 27, Loss: 0.7153518199920654, Accuracy: 0.7607421875\n",
      "Batch: 28, Loss: 0.7540045976638794, Accuracy: 0.7529296875\n",
      "Batch: 29, Loss: 0.7017574906349182, Accuracy: 0.7822265625\n",
      "Batch: 30, Loss: 0.7013859152793884, Accuracy: 0.7724609375\n",
      "Batch: 31, Loss: 0.6645094156265259, Accuracy: 0.7978515625\n",
      "Batch: 32, Loss: 0.7024949789047241, Accuracy: 0.783203125\n",
      "Batch: 33, Loss: 0.7981834411621094, Accuracy: 0.740234375\n",
      "Batch: 34, Loss: 0.8128661513328552, Accuracy: 0.7373046875\n",
      "Batch: 35, Loss: 0.7747661471366882, Accuracy: 0.7373046875\n",
      "Batch: 36, Loss: 0.7426068782806396, Accuracy: 0.76953125\n",
      "Batch: 37, Loss: 0.7774150371551514, Accuracy: 0.751953125\n",
      "Batch: 38, Loss: 0.798761785030365, Accuracy: 0.74609375\n",
      "Batch: 39, Loss: 0.7532259225845337, Accuracy: 0.7568359375\n",
      "Batch: 40, Loss: 0.7226406335830688, Accuracy: 0.7734375\n",
      "Batch: 41, Loss: 0.6776033043861389, Accuracy: 0.7744140625\n",
      "Batch: 42, Loss: 0.5742311477661133, Accuracy: 0.818359375\n",
      "Batch: 43, Loss: 0.7187452912330627, Accuracy: 0.7685546875\n",
      "Batch: 44, Loss: 0.7757084369659424, Accuracy: 0.740234375\n",
      "Batch: 45, Loss: 0.6289225816726685, Accuracy: 0.798828125\n",
      "Batch: 46, Loss: 0.6911157369613647, Accuracy: 0.78125\n",
      "Batch: 47, Loss: 0.7313492298126221, Accuracy: 0.78125\n",
      "Batch: 48, Loss: 0.6998317241668701, Accuracy: 0.7744140625\n",
      "Batch: 49, Loss: 0.8224924802780151, Accuracy: 0.7490234375\n",
      "Batch: 50, Loss: 0.7521995306015015, Accuracy: 0.74609375\n",
      "Batch: 51, Loss: 0.8137478232383728, Accuracy: 0.7294921875\n",
      "Batch: 52, Loss: 0.7663475275039673, Accuracy: 0.748046875\n",
      "Batch: 53, Loss: 0.6728367209434509, Accuracy: 0.78125\n",
      "Batch: 54, Loss: 0.7159996032714844, Accuracy: 0.7666015625\n",
      "Batch: 55, Loss: 0.8289721012115479, Accuracy: 0.7197265625\n",
      "Batch: 56, Loss: 0.8498246669769287, Accuracy: 0.7080078125\n",
      "Batch: 57, Loss: 0.7588080167770386, Accuracy: 0.7470703125\n",
      "Batch: 58, Loss: 0.8788539171218872, Accuracy: 0.728515625\n",
      "Batch: 59, Loss: 0.7626932859420776, Accuracy: 0.76171875\n",
      "Batch: 60, Loss: 0.6901267766952515, Accuracy: 0.771484375\n",
      "Batch: 61, Loss: 0.784762442111969, Accuracy: 0.7392578125\n",
      "Batch: 62, Loss: 0.7344652414321899, Accuracy: 0.7626953125\n",
      "Batch: 63, Loss: 0.7668410539627075, Accuracy: 0.7587890625\n",
      "Batch: 64, Loss: 0.7298639416694641, Accuracy: 0.767578125\n",
      "Batch: 65, Loss: 0.775536060333252, Accuracy: 0.7626953125\n",
      "Batch: 66, Loss: 0.7752389907836914, Accuracy: 0.7548828125\n",
      "Batch: 67, Loss: 0.8044440746307373, Accuracy: 0.7451171875\n",
      "Batch: 68, Loss: 0.8275600671768188, Accuracy: 0.7373046875\n",
      "Batch: 69, Loss: 0.7885837554931641, Accuracy: 0.7470703125\n",
      "Batch: 70, Loss: 0.8064863681793213, Accuracy: 0.755859375\n",
      "Batch: 71, Loss: 0.7897659540176392, Accuracy: 0.7431640625\n",
      "Batch: 72, Loss: 0.7169208526611328, Accuracy: 0.75390625\n",
      "Batch: 73, Loss: 0.6900981664657593, Accuracy: 0.7763671875\n",
      "Batch: 74, Loss: 0.6685706973075867, Accuracy: 0.798828125\n",
      "Batch: 75, Loss: 0.6325383186340332, Accuracy: 0.8046875\n",
      "Batch: 76, Loss: 0.7606310844421387, Accuracy: 0.763671875\n",
      "Batch: 77, Loss: 0.6768531799316406, Accuracy: 0.7763671875\n",
      "Batch: 78, Loss: 0.6897289752960205, Accuracy: 0.779296875\n",
      "Batch: 79, Loss: 0.6966278553009033, Accuracy: 0.7900390625\n",
      "Batch: 80, Loss: 0.7042338848114014, Accuracy: 0.7705078125\n",
      "Batch: 81, Loss: 0.790926992893219, Accuracy: 0.734375\n",
      "Batch: 82, Loss: 0.7495614290237427, Accuracy: 0.7568359375\n",
      "Batch: 83, Loss: 0.6553477048873901, Accuracy: 0.7998046875\n",
      "Batch: 84, Loss: 0.7671778202056885, Accuracy: 0.755859375\n",
      "Batch: 85, Loss: 0.7469379901885986, Accuracy: 0.7724609375\n",
      "Batch: 86, Loss: 0.8525575399398804, Accuracy: 0.728515625\n",
      "Batch: 87, Loss: 0.7030726671218872, Accuracy: 0.775390625\n",
      "Batch: 88, Loss: 0.7756203413009644, Accuracy: 0.7705078125\n",
      "Batch: 89, Loss: 0.7918319702148438, Accuracy: 0.7529296875\n",
      "Batch: 90, Loss: 0.7236101031303406, Accuracy: 0.7705078125\n",
      "Batch: 91, Loss: 0.7333120107650757, Accuracy: 0.755859375\n",
      "Batch: 92, Loss: 0.7486338019371033, Accuracy: 0.7548828125\n",
      "Batch: 93, Loss: 0.7446027994155884, Accuracy: 0.7568359375\n",
      "Batch: 94, Loss: 0.7552273273468018, Accuracy: 0.7451171875\n",
      "Batch: 95, Loss: 0.7741279006004333, Accuracy: 0.7392578125\n",
      "Batch: 96, Loss: 0.7597051858901978, Accuracy: 0.7548828125\n",
      "Batch: 97, Loss: 0.6195111274719238, Accuracy: 0.8017578125\n",
      "Batch: 98, Loss: 0.7662313580513, Accuracy: 0.7431640625\n",
      "Batch: 99, Loss: 0.7031387090682983, Accuracy: 0.767578125\n",
      "Batch: 100, Loss: 0.7474755644798279, Accuracy: 0.755859375\n",
      "Batch: 101, Loss: 0.8122504353523254, Accuracy: 0.7373046875\n",
      "Batch: 102, Loss: 0.7655194401741028, Accuracy: 0.75390625\n",
      "Batch: 103, Loss: 0.7923750877380371, Accuracy: 0.74609375\n",
      "Batch: 104, Loss: 0.7155306339263916, Accuracy: 0.771484375\n",
      "Batch: 105, Loss: 0.7425858974456787, Accuracy: 0.76953125\n",
      "Batch: 106, Loss: 0.675242006778717, Accuracy: 0.76953125\n",
      "Batch: 107, Loss: 0.7460829019546509, Accuracy: 0.7626953125\n",
      "Batch: 108, Loss: 0.754630446434021, Accuracy: 0.751953125\n",
      "Batch: 109, Loss: 0.7923502326011658, Accuracy: 0.7333984375\n",
      "Batch: 110, Loss: 0.6947498917579651, Accuracy: 0.7666015625\n",
      "Batch: 111, Loss: 0.7396386861801147, Accuracy: 0.7470703125\n",
      "Batch: 112, Loss: 0.7675836086273193, Accuracy: 0.7421875\n",
      "Batch: 113, Loss: 0.733788013458252, Accuracy: 0.759765625\n",
      "Batch: 114, Loss: 0.7796836495399475, Accuracy: 0.7451171875\n",
      "Batch: 115, Loss: 0.8576662540435791, Accuracy: 0.732421875\n",
      "Batch: 116, Loss: 0.7951078414916992, Accuracy: 0.732421875\n",
      "Batch: 117, Loss: 0.806674599647522, Accuracy: 0.744140625\n",
      "Batch: 118, Loss: 0.691243052482605, Accuracy: 0.783203125\n",
      "Batch: 119, Loss: 0.7063066959381104, Accuracy: 0.779296875\n",
      "Batch: 120, Loss: 0.7751394510269165, Accuracy: 0.7421875\n",
      "Batch: 121, Loss: 0.8176854848861694, Accuracy: 0.73828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 122, Loss: 0.7460545301437378, Accuracy: 0.7509765625\n",
      "Batch: 123, Loss: 0.6975882649421692, Accuracy: 0.78125\n",
      "Batch: 124, Loss: 0.7624057531356812, Accuracy: 0.7578125\n",
      "Batch: 125, Loss: 0.7923790812492371, Accuracy: 0.7529296875\n",
      "Batch: 126, Loss: 0.7585983276367188, Accuracy: 0.755859375\n",
      "Batch: 127, Loss: 0.664199948310852, Accuracy: 0.787109375\n",
      "Batch: 128, Loss: 0.8174360990524292, Accuracy: 0.7421875\n",
      "Batch: 129, Loss: 0.6937795877456665, Accuracy: 0.783203125\n",
      "Batch: 130, Loss: 0.8494927883148193, Accuracy: 0.712890625\n",
      "Batch: 131, Loss: 0.7625738382339478, Accuracy: 0.751953125\n",
      "Batch: 132, Loss: 0.7649322152137756, Accuracy: 0.76953125\n",
      "Batch: 133, Loss: 0.7126677632331848, Accuracy: 0.763671875\n",
      "Batch: 134, Loss: 0.7665073871612549, Accuracy: 0.751953125\n",
      "Batch: 135, Loss: 0.727972686290741, Accuracy: 0.7578125\n",
      "Batch: 136, Loss: 0.7736035585403442, Accuracy: 0.7451171875\n",
      "Batch: 137, Loss: 0.7583874464035034, Accuracy: 0.7333984375\n",
      "Batch: 138, Loss: 0.6984778642654419, Accuracy: 0.7685546875\n",
      "Batch: 139, Loss: 0.6884891986846924, Accuracy: 0.7724609375\n",
      "Batch: 140, Loss: 0.7607585787773132, Accuracy: 0.7490234375\n",
      "Batch: 141, Loss: 0.7968660593032837, Accuracy: 0.7470703125\n",
      "Batch: 142, Loss: 0.8662445545196533, Accuracy: 0.7314453125\n",
      "Batch: 143, Loss: 0.7705689668655396, Accuracy: 0.75390625\n",
      "Batch: 144, Loss: 0.752921462059021, Accuracy: 0.7490234375\n",
      "Batch: 145, Loss: 0.7090911269187927, Accuracy: 0.75\n",
      "Batch: 146, Loss: 0.7779860496520996, Accuracy: 0.7275390625\n",
      "Batch: 147, Loss: 0.7246748805046082, Accuracy: 0.7626953125\n",
      "Batch: 148, Loss: 0.8339881896972656, Accuracy: 0.7255859375\n",
      "Batch: 149, Loss: 0.7464578151702881, Accuracy: 0.7412109375\n",
      "Batch: 150, Loss: 0.7935936450958252, Accuracy: 0.740234375\n",
      "Batch: 151, Loss: 0.6657824516296387, Accuracy: 0.7734375\n",
      "Epoch 45/80\n",
      "Batch: 1, Loss: 0.9351176023483276, Accuracy: 0.689453125\n",
      "Batch: 2, Loss: 0.8017799854278564, Accuracy: 0.732421875\n",
      "Batch: 3, Loss: 0.7215865850448608, Accuracy: 0.759765625\n",
      "Batch: 4, Loss: 0.691032886505127, Accuracy: 0.7734375\n",
      "Batch: 5, Loss: 0.7535649538040161, Accuracy: 0.78125\n",
      "Batch: 6, Loss: 0.7565510272979736, Accuracy: 0.7587890625\n",
      "Batch: 7, Loss: 0.7262592315673828, Accuracy: 0.748046875\n",
      "Batch: 8, Loss: 0.6848163604736328, Accuracy: 0.787109375\n",
      "Batch: 9, Loss: 0.6957825422286987, Accuracy: 0.779296875\n",
      "Batch: 10, Loss: 0.6888564229011536, Accuracy: 0.7666015625\n",
      "Batch: 11, Loss: 0.8103700280189514, Accuracy: 0.7412109375\n",
      "Batch: 12, Loss: 0.7853982448577881, Accuracy: 0.751953125\n",
      "Batch: 13, Loss: 0.637259304523468, Accuracy: 0.7978515625\n",
      "Batch: 14, Loss: 0.8133740425109863, Accuracy: 0.734375\n",
      "Batch: 15, Loss: 0.6954131126403809, Accuracy: 0.7978515625\n",
      "Batch: 16, Loss: 0.712469220161438, Accuracy: 0.7744140625\n",
      "Batch: 17, Loss: 0.7637726068496704, Accuracy: 0.7568359375\n",
      "Batch: 18, Loss: 0.7997440099716187, Accuracy: 0.7509765625\n",
      "Batch: 19, Loss: 0.8137880563735962, Accuracy: 0.740234375\n",
      "Batch: 20, Loss: 0.6997621655464172, Accuracy: 0.765625\n",
      "Batch: 21, Loss: 0.7049497365951538, Accuracy: 0.7626953125\n",
      "Batch: 22, Loss: 0.863631546497345, Accuracy: 0.7197265625\n",
      "Batch: 23, Loss: 0.7861571311950684, Accuracy: 0.734375\n",
      "Batch: 24, Loss: 0.7906991243362427, Accuracy: 0.751953125\n",
      "Batch: 25, Loss: 0.7428075671195984, Accuracy: 0.7509765625\n",
      "Batch: 26, Loss: 0.6457655429840088, Accuracy: 0.7939453125\n",
      "Batch: 27, Loss: 0.7036136388778687, Accuracy: 0.755859375\n",
      "Batch: 28, Loss: 0.7532467246055603, Accuracy: 0.759765625\n",
      "Batch: 29, Loss: 0.7314325571060181, Accuracy: 0.7607421875\n",
      "Batch: 30, Loss: 0.6830825805664062, Accuracy: 0.771484375\n",
      "Batch: 31, Loss: 0.6559466123580933, Accuracy: 0.7890625\n",
      "Batch: 32, Loss: 0.6683518886566162, Accuracy: 0.7783203125\n",
      "Batch: 33, Loss: 0.7873425483703613, Accuracy: 0.7529296875\n",
      "Batch: 34, Loss: 0.8368549346923828, Accuracy: 0.728515625\n",
      "Batch: 35, Loss: 0.7491539716720581, Accuracy: 0.759765625\n",
      "Batch: 36, Loss: 0.762762725353241, Accuracy: 0.76171875\n",
      "Batch: 37, Loss: 0.77061527967453, Accuracy: 0.755859375\n",
      "Batch: 38, Loss: 0.8026068806648254, Accuracy: 0.72265625\n",
      "Batch: 39, Loss: 0.7657269239425659, Accuracy: 0.7578125\n",
      "Batch: 40, Loss: 0.7758998274803162, Accuracy: 0.740234375\n",
      "Batch: 41, Loss: 0.7076582908630371, Accuracy: 0.7685546875\n",
      "Batch: 42, Loss: 0.568342924118042, Accuracy: 0.81640625\n",
      "Batch: 43, Loss: 0.7232258915901184, Accuracy: 0.755859375\n",
      "Batch: 44, Loss: 0.7718421220779419, Accuracy: 0.7509765625\n",
      "Batch: 45, Loss: 0.6748724579811096, Accuracy: 0.77734375\n",
      "Batch: 46, Loss: 0.7071902751922607, Accuracy: 0.7822265625\n",
      "Batch: 47, Loss: 0.7386064529418945, Accuracy: 0.7568359375\n",
      "Batch: 48, Loss: 0.7279638648033142, Accuracy: 0.7578125\n",
      "Batch: 49, Loss: 0.7897782325744629, Accuracy: 0.755859375\n",
      "Batch: 50, Loss: 0.7406581044197083, Accuracy: 0.7490234375\n",
      "Batch: 51, Loss: 0.808851957321167, Accuracy: 0.7294921875\n",
      "Batch: 52, Loss: 0.7471815347671509, Accuracy: 0.759765625\n",
      "Batch: 53, Loss: 0.6800460815429688, Accuracy: 0.78125\n",
      "Batch: 54, Loss: 0.7073190212249756, Accuracy: 0.7744140625\n",
      "Batch: 55, Loss: 0.8297073841094971, Accuracy: 0.7255859375\n",
      "Batch: 56, Loss: 0.795018196105957, Accuracy: 0.7353515625\n",
      "Batch: 57, Loss: 0.7569664716720581, Accuracy: 0.7646484375\n",
      "Batch: 58, Loss: 0.8539078831672668, Accuracy: 0.736328125\n",
      "Batch: 59, Loss: 0.7518299221992493, Accuracy: 0.7626953125\n",
      "Batch: 60, Loss: 0.705208957195282, Accuracy: 0.7626953125\n",
      "Batch: 61, Loss: 0.7765469551086426, Accuracy: 0.74609375\n",
      "Batch: 62, Loss: 0.7287929654121399, Accuracy: 0.75390625\n",
      "Batch: 63, Loss: 0.7611733675003052, Accuracy: 0.7607421875\n",
      "Batch: 64, Loss: 0.7196434736251831, Accuracy: 0.7587890625\n",
      "Batch: 65, Loss: 0.7955892086029053, Accuracy: 0.7470703125\n",
      "Batch: 66, Loss: 0.7854207754135132, Accuracy: 0.7568359375\n",
      "Batch: 67, Loss: 0.827163815498352, Accuracy: 0.740234375\n",
      "Batch: 68, Loss: 0.8026577234268188, Accuracy: 0.7392578125\n",
      "Batch: 69, Loss: 0.7788142561912537, Accuracy: 0.7548828125\n",
      "Batch: 70, Loss: 0.7900413274765015, Accuracy: 0.76171875\n",
      "Batch: 71, Loss: 0.7847789525985718, Accuracy: 0.748046875\n",
      "Batch: 72, Loss: 0.7097494602203369, Accuracy: 0.7646484375\n",
      "Batch: 73, Loss: 0.6826424598693848, Accuracy: 0.79296875\n",
      "Batch: 74, Loss: 0.6621652245521545, Accuracy: 0.80078125\n",
      "Batch: 75, Loss: 0.643844723701477, Accuracy: 0.7861328125\n",
      "Batch: 76, Loss: 0.7368805408477783, Accuracy: 0.767578125\n",
      "Batch: 77, Loss: 0.7132412195205688, Accuracy: 0.7734375\n",
      "Batch: 78, Loss: 0.677053689956665, Accuracy: 0.7841796875\n",
      "Batch: 79, Loss: 0.7016370892524719, Accuracy: 0.7880859375\n",
      "Batch: 80, Loss: 0.6892876029014587, Accuracy: 0.779296875\n",
      "Batch: 81, Loss: 0.7715435028076172, Accuracy: 0.73828125\n",
      "Batch: 82, Loss: 0.7576053142547607, Accuracy: 0.7548828125\n",
      "Batch: 83, Loss: 0.6308804750442505, Accuracy: 0.810546875\n",
      "Batch: 84, Loss: 0.7393358945846558, Accuracy: 0.775390625\n",
      "Batch: 85, Loss: 0.7054203748703003, Accuracy: 0.7802734375\n",
      "Batch: 86, Loss: 0.8668289184570312, Accuracy: 0.732421875\n",
      "Batch: 87, Loss: 0.6643427014350891, Accuracy: 0.7822265625\n",
      "Batch: 88, Loss: 0.7622860670089722, Accuracy: 0.7646484375\n",
      "Batch: 89, Loss: 0.7620011568069458, Accuracy: 0.7607421875\n",
      "Batch: 90, Loss: 0.6827085614204407, Accuracy: 0.78125\n",
      "Batch: 91, Loss: 0.7272368669509888, Accuracy: 0.7607421875\n",
      "Batch: 92, Loss: 0.7385778427124023, Accuracy: 0.763671875\n",
      "Batch: 93, Loss: 0.7481282353401184, Accuracy: 0.7587890625\n",
      "Batch: 94, Loss: 0.7580128908157349, Accuracy: 0.7607421875\n",
      "Batch: 95, Loss: 0.7470126748085022, Accuracy: 0.7626953125\n",
      "Batch: 96, Loss: 0.7411887645721436, Accuracy: 0.7587890625\n",
      "Batch: 97, Loss: 0.6250158548355103, Accuracy: 0.794921875\n",
      "Batch: 98, Loss: 0.7324355840682983, Accuracy: 0.74609375\n",
      "Batch: 99, Loss: 0.7286864519119263, Accuracy: 0.755859375\n",
      "Batch: 100, Loss: 0.7336438894271851, Accuracy: 0.755859375\n",
      "Batch: 101, Loss: 0.796450138092041, Accuracy: 0.7353515625\n",
      "Batch: 102, Loss: 0.7531009912490845, Accuracy: 0.7529296875\n",
      "Batch: 103, Loss: 0.776236891746521, Accuracy: 0.7578125\n",
      "Batch: 104, Loss: 0.7046442627906799, Accuracy: 0.7666015625\n",
      "Batch: 105, Loss: 0.7479462027549744, Accuracy: 0.748046875\n",
      "Batch: 106, Loss: 0.7055889368057251, Accuracy: 0.771484375\n",
      "Batch: 107, Loss: 0.7200922966003418, Accuracy: 0.7744140625\n",
      "Batch: 108, Loss: 0.7362041473388672, Accuracy: 0.7578125\n",
      "Batch: 109, Loss: 0.7962172031402588, Accuracy: 0.7392578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 110, Loss: 0.6832022666931152, Accuracy: 0.7607421875\n",
      "Batch: 111, Loss: 0.752267599105835, Accuracy: 0.75390625\n",
      "Batch: 112, Loss: 0.7422038316726685, Accuracy: 0.7451171875\n",
      "Batch: 113, Loss: 0.7411324977874756, Accuracy: 0.755859375\n",
      "Batch: 114, Loss: 0.8089735507965088, Accuracy: 0.75\n",
      "Batch: 115, Loss: 0.8725932240486145, Accuracy: 0.7275390625\n",
      "Batch: 116, Loss: 0.7796124219894409, Accuracy: 0.7412109375\n",
      "Batch: 117, Loss: 0.7972645163536072, Accuracy: 0.7431640625\n",
      "Batch: 118, Loss: 0.6943056583404541, Accuracy: 0.78515625\n",
      "Batch: 119, Loss: 0.6902481913566589, Accuracy: 0.7822265625\n",
      "Batch: 120, Loss: 0.7530797719955444, Accuracy: 0.75\n",
      "Batch: 121, Loss: 0.7806097269058228, Accuracy: 0.7470703125\n",
      "Batch: 122, Loss: 0.7294224500656128, Accuracy: 0.763671875\n",
      "Batch: 123, Loss: 0.7178785800933838, Accuracy: 0.779296875\n",
      "Batch: 124, Loss: 0.7489707469940186, Accuracy: 0.7607421875\n",
      "Batch: 125, Loss: 0.7842612266540527, Accuracy: 0.7451171875\n",
      "Batch: 126, Loss: 0.7532914876937866, Accuracy: 0.759765625\n",
      "Batch: 127, Loss: 0.6677314043045044, Accuracy: 0.7919921875\n",
      "Batch: 128, Loss: 0.8373602032661438, Accuracy: 0.732421875\n",
      "Batch: 129, Loss: 0.7103803753852844, Accuracy: 0.7724609375\n",
      "Batch: 130, Loss: 0.8619683980941772, Accuracy: 0.7177734375\n",
      "Batch: 131, Loss: 0.761063814163208, Accuracy: 0.7568359375\n",
      "Batch: 132, Loss: 0.7892147898674011, Accuracy: 0.7568359375\n",
      "Batch: 133, Loss: 0.7295396327972412, Accuracy: 0.7568359375\n",
      "Batch: 134, Loss: 0.7789241671562195, Accuracy: 0.734375\n",
      "Batch: 135, Loss: 0.7196075916290283, Accuracy: 0.7666015625\n",
      "Batch: 136, Loss: 0.7838865518569946, Accuracy: 0.7529296875\n",
      "Batch: 137, Loss: 0.7541735172271729, Accuracy: 0.7451171875\n",
      "Batch: 138, Loss: 0.6798427700996399, Accuracy: 0.7783203125\n",
      "Batch: 139, Loss: 0.6738722920417786, Accuracy: 0.7822265625\n",
      "Batch: 140, Loss: 0.7519360780715942, Accuracy: 0.751953125\n",
      "Batch: 141, Loss: 0.761150598526001, Accuracy: 0.751953125\n",
      "Batch: 142, Loss: 0.8387861251831055, Accuracy: 0.740234375\n",
      "Batch: 143, Loss: 0.7574580907821655, Accuracy: 0.7646484375\n",
      "Batch: 144, Loss: 0.781805157661438, Accuracy: 0.7470703125\n",
      "Batch: 145, Loss: 0.6967476606369019, Accuracy: 0.767578125\n",
      "Batch: 146, Loss: 0.754940390586853, Accuracy: 0.748046875\n",
      "Batch: 147, Loss: 0.7380168437957764, Accuracy: 0.76171875\n",
      "Batch: 148, Loss: 0.8138519525527954, Accuracy: 0.73046875\n",
      "Batch: 149, Loss: 0.7178330421447754, Accuracy: 0.759765625\n",
      "Batch: 150, Loss: 0.7584010362625122, Accuracy: 0.7587890625\n",
      "Batch: 151, Loss: 0.6645156145095825, Accuracy: 0.7978515625\n",
      "Epoch 46/80\n",
      "Batch: 1, Loss: 0.8996009826660156, Accuracy: 0.7080078125\n",
      "Batch: 2, Loss: 0.8014002442359924, Accuracy: 0.7333984375\n",
      "Batch: 3, Loss: 0.7190344333648682, Accuracy: 0.7705078125\n",
      "Batch: 4, Loss: 0.6585237979888916, Accuracy: 0.8115234375\n",
      "Batch: 5, Loss: 0.7077754735946655, Accuracy: 0.771484375\n",
      "Batch: 6, Loss: 0.7605941295623779, Accuracy: 0.7578125\n",
      "Batch: 7, Loss: 0.7377947568893433, Accuracy: 0.7529296875\n",
      "Batch: 8, Loss: 0.6934219002723694, Accuracy: 0.7724609375\n",
      "Batch: 9, Loss: 0.6990063190460205, Accuracy: 0.7685546875\n",
      "Batch: 10, Loss: 0.6698183417320251, Accuracy: 0.7763671875\n",
      "Batch: 11, Loss: 0.7852001190185547, Accuracy: 0.7412109375\n",
      "Batch: 12, Loss: 0.7614331245422363, Accuracy: 0.7490234375\n",
      "Batch: 13, Loss: 0.620741605758667, Accuracy: 0.7880859375\n",
      "Batch: 14, Loss: 0.8131482601165771, Accuracy: 0.732421875\n",
      "Batch: 15, Loss: 0.7073111534118652, Accuracy: 0.7734375\n",
      "Batch: 16, Loss: 0.6658788919448853, Accuracy: 0.80859375\n",
      "Batch: 17, Loss: 0.7368026375770569, Accuracy: 0.7734375\n",
      "Batch: 18, Loss: 0.7609964609146118, Accuracy: 0.7490234375\n",
      "Batch: 19, Loss: 0.7781766057014465, Accuracy: 0.7685546875\n",
      "Batch: 20, Loss: 0.7124541401863098, Accuracy: 0.7763671875\n",
      "Batch: 21, Loss: 0.7272869348526001, Accuracy: 0.7568359375\n",
      "Batch: 22, Loss: 0.8497062921524048, Accuracy: 0.7353515625\n",
      "Batch: 23, Loss: 0.7952620983123779, Accuracy: 0.748046875\n",
      "Batch: 24, Loss: 0.7812881469726562, Accuracy: 0.7373046875\n",
      "Batch: 25, Loss: 0.7172456979751587, Accuracy: 0.763671875\n",
      "Batch: 26, Loss: 0.625200092792511, Accuracy: 0.791015625\n",
      "Batch: 27, Loss: 0.702436089515686, Accuracy: 0.765625\n",
      "Batch: 28, Loss: 0.7219144105911255, Accuracy: 0.74609375\n",
      "Batch: 29, Loss: 0.707761287689209, Accuracy: 0.78125\n",
      "Batch: 30, Loss: 0.6840267181396484, Accuracy: 0.7763671875\n",
      "Batch: 31, Loss: 0.6795045733451843, Accuracy: 0.7880859375\n",
      "Batch: 32, Loss: 0.6900007724761963, Accuracy: 0.7744140625\n",
      "Batch: 33, Loss: 0.7884967923164368, Accuracy: 0.74609375\n",
      "Batch: 34, Loss: 0.7881818413734436, Accuracy: 0.7421875\n",
      "Batch: 35, Loss: 0.7804521918296814, Accuracy: 0.7529296875\n",
      "Batch: 36, Loss: 0.767000138759613, Accuracy: 0.751953125\n",
      "Batch: 37, Loss: 0.7619857788085938, Accuracy: 0.736328125\n",
      "Batch: 38, Loss: 0.7547568082809448, Accuracy: 0.7509765625\n",
      "Batch: 39, Loss: 0.7429395914077759, Accuracy: 0.763671875\n",
      "Batch: 40, Loss: 0.7510265111923218, Accuracy: 0.755859375\n",
      "Batch: 41, Loss: 0.6531269550323486, Accuracy: 0.779296875\n",
      "Batch: 42, Loss: 0.5637258291244507, Accuracy: 0.814453125\n",
      "Batch: 43, Loss: 0.7137374877929688, Accuracy: 0.771484375\n",
      "Batch: 44, Loss: 0.7598224878311157, Accuracy: 0.763671875\n",
      "Batch: 45, Loss: 0.6480346918106079, Accuracy: 0.8017578125\n",
      "Batch: 46, Loss: 0.6881346702575684, Accuracy: 0.79296875\n",
      "Batch: 47, Loss: 0.7215519547462463, Accuracy: 0.77734375\n",
      "Batch: 48, Loss: 0.6961039304733276, Accuracy: 0.7724609375\n",
      "Batch: 49, Loss: 0.8087784051895142, Accuracy: 0.751953125\n",
      "Batch: 50, Loss: 0.7193187475204468, Accuracy: 0.76953125\n",
      "Batch: 51, Loss: 0.7879912853240967, Accuracy: 0.7333984375\n",
      "Batch: 52, Loss: 0.753605306148529, Accuracy: 0.7548828125\n",
      "Batch: 53, Loss: 0.6795904040336609, Accuracy: 0.7802734375\n",
      "Batch: 54, Loss: 0.7198848128318787, Accuracy: 0.7607421875\n",
      "Batch: 55, Loss: 0.8001458048820496, Accuracy: 0.7421875\n",
      "Batch: 56, Loss: 0.8057466149330139, Accuracy: 0.734375\n",
      "Batch: 57, Loss: 0.7665596008300781, Accuracy: 0.75\n",
      "Batch: 58, Loss: 0.8379160165786743, Accuracy: 0.7353515625\n",
      "Batch: 59, Loss: 0.711693286895752, Accuracy: 0.7744140625\n",
      "Batch: 60, Loss: 0.6821909546852112, Accuracy: 0.7685546875\n",
      "Batch: 61, Loss: 0.8040198087692261, Accuracy: 0.736328125\n",
      "Batch: 62, Loss: 0.6962160468101501, Accuracy: 0.7724609375\n",
      "Batch: 63, Loss: 0.7710224390029907, Accuracy: 0.74609375\n",
      "Batch: 64, Loss: 0.70995032787323, Accuracy: 0.7548828125\n",
      "Batch: 65, Loss: 0.7767834067344666, Accuracy: 0.751953125\n",
      "Batch: 66, Loss: 0.7360836267471313, Accuracy: 0.7666015625\n",
      "Batch: 67, Loss: 0.7870781421661377, Accuracy: 0.7548828125\n",
      "Batch: 68, Loss: 0.8215477466583252, Accuracy: 0.7392578125\n",
      "Batch: 69, Loss: 0.7740514874458313, Accuracy: 0.7490234375\n",
      "Batch: 70, Loss: 0.762005090713501, Accuracy: 0.763671875\n",
      "Batch: 71, Loss: 0.7924052476882935, Accuracy: 0.75\n",
      "Batch: 72, Loss: 0.7034603357315063, Accuracy: 0.771484375\n",
      "Batch: 73, Loss: 0.6963428854942322, Accuracy: 0.7880859375\n",
      "Batch: 74, Loss: 0.6602990627288818, Accuracy: 0.806640625\n",
      "Batch: 75, Loss: 0.6550371050834656, Accuracy: 0.78515625\n",
      "Batch: 76, Loss: 0.7582005262374878, Accuracy: 0.755859375\n",
      "Batch: 77, Loss: 0.7032043933868408, Accuracy: 0.7705078125\n",
      "Batch: 78, Loss: 0.6834122538566589, Accuracy: 0.7880859375\n",
      "Batch: 79, Loss: 0.7021631002426147, Accuracy: 0.7763671875\n",
      "Batch: 80, Loss: 0.6872197389602661, Accuracy: 0.7783203125\n",
      "Batch: 81, Loss: 0.7912200689315796, Accuracy: 0.7294921875\n",
      "Batch: 82, Loss: 0.7488797307014465, Accuracy: 0.7578125\n",
      "Batch: 83, Loss: 0.6396108865737915, Accuracy: 0.8076171875\n",
      "Batch: 84, Loss: 0.7173799276351929, Accuracy: 0.7685546875\n",
      "Batch: 85, Loss: 0.7035845518112183, Accuracy: 0.7763671875\n",
      "Batch: 86, Loss: 0.8358931541442871, Accuracy: 0.74609375\n",
      "Batch: 87, Loss: 0.6694720983505249, Accuracy: 0.775390625\n",
      "Batch: 88, Loss: 0.7830920219421387, Accuracy: 0.759765625\n",
      "Batch: 89, Loss: 0.7654352188110352, Accuracy: 0.763671875\n",
      "Batch: 90, Loss: 0.7241806983947754, Accuracy: 0.7734375\n",
      "Batch: 91, Loss: 0.7012155055999756, Accuracy: 0.765625\n",
      "Batch: 92, Loss: 0.7633587718009949, Accuracy: 0.75390625\n",
      "Batch: 93, Loss: 0.7269860506057739, Accuracy: 0.7578125\n",
      "Batch: 94, Loss: 0.7529392838478088, Accuracy: 0.744140625\n",
      "Batch: 95, Loss: 0.7290441989898682, Accuracy: 0.744140625\n",
      "Batch: 96, Loss: 0.7100546360015869, Accuracy: 0.767578125\n",
      "Batch: 97, Loss: 0.6122230291366577, Accuracy: 0.802734375\n",
      "Batch: 98, Loss: 0.7367687821388245, Accuracy: 0.765625\n",
      "Batch: 99, Loss: 0.7191658616065979, Accuracy: 0.7578125\n",
      "Batch: 100, Loss: 0.7335696816444397, Accuracy: 0.7607421875\n",
      "Batch: 101, Loss: 0.7727999687194824, Accuracy: 0.751953125\n",
      "Batch: 102, Loss: 0.7427676916122437, Accuracy: 0.763671875\n",
      "Batch: 103, Loss: 0.7800700664520264, Accuracy: 0.74609375\n",
      "Batch: 104, Loss: 0.6836940050125122, Accuracy: 0.7724609375\n",
      "Batch: 105, Loss: 0.7296496629714966, Accuracy: 0.7734375\n",
      "Batch: 106, Loss: 0.6745877265930176, Accuracy: 0.7861328125\n",
      "Batch: 107, Loss: 0.7485498785972595, Accuracy: 0.76953125\n",
      "Batch: 108, Loss: 0.7282842993736267, Accuracy: 0.7587890625\n",
      "Batch: 109, Loss: 0.7582941055297852, Accuracy: 0.7353515625\n",
      "Batch: 110, Loss: 0.6634267568588257, Accuracy: 0.7744140625\n",
      "Batch: 111, Loss: 0.7214458584785461, Accuracy: 0.759765625\n",
      "Batch: 112, Loss: 0.7282636761665344, Accuracy: 0.759765625\n",
      "Batch: 113, Loss: 0.7503652572631836, Accuracy: 0.7587890625\n",
      "Batch: 114, Loss: 0.8024780750274658, Accuracy: 0.736328125\n",
      "Batch: 115, Loss: 0.855217695236206, Accuracy: 0.728515625\n",
      "Batch: 116, Loss: 0.7522707581520081, Accuracy: 0.7548828125\n",
      "Batch: 117, Loss: 0.7783626914024353, Accuracy: 0.7451171875\n",
      "Batch: 118, Loss: 0.6654888391494751, Accuracy: 0.7724609375\n",
      "Batch: 119, Loss: 0.6591159701347351, Accuracy: 0.7802734375\n",
      "Batch: 120, Loss: 0.7439262866973877, Accuracy: 0.7490234375\n",
      "Batch: 121, Loss: 0.7851992845535278, Accuracy: 0.732421875\n",
      "Batch: 122, Loss: 0.7232829332351685, Accuracy: 0.771484375\n",
      "Batch: 123, Loss: 0.6936593651771545, Accuracy: 0.7802734375\n",
      "Batch: 124, Loss: 0.7500566244125366, Accuracy: 0.7548828125\n",
      "Batch: 125, Loss: 0.8060222864151001, Accuracy: 0.7451171875\n",
      "Batch: 126, Loss: 0.7494715452194214, Accuracy: 0.76171875\n",
      "Batch: 127, Loss: 0.6865128874778748, Accuracy: 0.783203125\n",
      "Batch: 128, Loss: 0.8544417023658752, Accuracy: 0.744140625\n",
      "Batch: 129, Loss: 0.6899343729019165, Accuracy: 0.7744140625\n",
      "Batch: 130, Loss: 0.852672815322876, Accuracy: 0.7236328125\n",
      "Batch: 131, Loss: 0.7607994079589844, Accuracy: 0.751953125\n",
      "Batch: 132, Loss: 0.785117506980896, Accuracy: 0.75\n",
      "Batch: 133, Loss: 0.7370601892471313, Accuracy: 0.7568359375\n",
      "Batch: 134, Loss: 0.7744183540344238, Accuracy: 0.732421875\n",
      "Batch: 135, Loss: 0.7203064560890198, Accuracy: 0.7734375\n",
      "Batch: 136, Loss: 0.7740797996520996, Accuracy: 0.740234375\n",
      "Batch: 137, Loss: 0.7621162533760071, Accuracy: 0.7392578125\n",
      "Batch: 138, Loss: 0.6806086897850037, Accuracy: 0.7666015625\n",
      "Batch: 139, Loss: 0.6735693216323853, Accuracy: 0.7724609375\n",
      "Batch: 140, Loss: 0.7660025358200073, Accuracy: 0.7373046875\n",
      "Batch: 141, Loss: 0.7451975345611572, Accuracy: 0.7451171875\n",
      "Batch: 142, Loss: 0.8460769057273865, Accuracy: 0.734375\n",
      "Batch: 143, Loss: 0.7525956630706787, Accuracy: 0.7529296875\n",
      "Batch: 144, Loss: 0.7513443827629089, Accuracy: 0.7666015625\n",
      "Batch: 145, Loss: 0.6906225085258484, Accuracy: 0.7646484375\n",
      "Batch: 146, Loss: 0.7711845636367798, Accuracy: 0.75\n",
      "Batch: 147, Loss: 0.7227908968925476, Accuracy: 0.7685546875\n",
      "Batch: 148, Loss: 0.8045394420623779, Accuracy: 0.732421875\n",
      "Batch: 149, Loss: 0.7174661755561829, Accuracy: 0.7529296875\n",
      "Batch: 150, Loss: 0.7612919807434082, Accuracy: 0.763671875\n",
      "Batch: 151, Loss: 0.6359862089157104, Accuracy: 0.7939453125\n",
      "Epoch 47/80\n",
      "Batch: 1, Loss: 0.9245206117630005, Accuracy: 0.7060546875\n",
      "Batch: 2, Loss: 0.78053879737854, Accuracy: 0.7412109375\n",
      "Batch: 3, Loss: 0.7016262412071228, Accuracy: 0.76171875\n",
      "Batch: 4, Loss: 0.6678599715232849, Accuracy: 0.783203125\n",
      "Batch: 5, Loss: 0.7051100730895996, Accuracy: 0.7734375\n",
      "Batch: 6, Loss: 0.7513548135757446, Accuracy: 0.7421875\n",
      "Batch: 7, Loss: 0.7031598091125488, Accuracy: 0.7666015625\n",
      "Batch: 8, Loss: 0.6698194742202759, Accuracy: 0.7822265625\n",
      "Batch: 9, Loss: 0.6791290640830994, Accuracy: 0.783203125\n",
      "Batch: 10, Loss: 0.6640242338180542, Accuracy: 0.7890625\n",
      "Batch: 11, Loss: 0.789280891418457, Accuracy: 0.7353515625\n",
      "Batch: 12, Loss: 0.7748795747756958, Accuracy: 0.7568359375\n",
      "Batch: 13, Loss: 0.6039283871650696, Accuracy: 0.791015625\n",
      "Batch: 14, Loss: 0.7902922630310059, Accuracy: 0.7412109375\n",
      "Batch: 15, Loss: 0.6915954351425171, Accuracy: 0.7763671875\n",
      "Batch: 16, Loss: 0.6801607012748718, Accuracy: 0.7900390625\n",
      "Batch: 17, Loss: 0.7267683744430542, Accuracy: 0.7626953125\n",
      "Batch: 18, Loss: 0.7917972803115845, Accuracy: 0.744140625\n",
      "Batch: 19, Loss: 0.7717552185058594, Accuracy: 0.755859375\n",
      "Batch: 20, Loss: 0.6827854514122009, Accuracy: 0.787109375\n",
      "Batch: 21, Loss: 0.6831387281417847, Accuracy: 0.767578125\n",
      "Batch: 22, Loss: 0.8316858410835266, Accuracy: 0.7236328125\n",
      "Batch: 23, Loss: 0.7651116251945496, Accuracy: 0.7490234375\n",
      "Batch: 24, Loss: 0.747628390789032, Accuracy: 0.7470703125\n",
      "Batch: 25, Loss: 0.7334656119346619, Accuracy: 0.76171875\n",
      "Batch: 26, Loss: 0.6488528251647949, Accuracy: 0.7880859375\n",
      "Batch: 27, Loss: 0.7201669812202454, Accuracy: 0.75\n",
      "Batch: 28, Loss: 0.7464665770530701, Accuracy: 0.75\n",
      "Batch: 29, Loss: 0.6853084564208984, Accuracy: 0.765625\n",
      "Batch: 30, Loss: 0.7234461307525635, Accuracy: 0.76953125\n",
      "Batch: 31, Loss: 0.6466013193130493, Accuracy: 0.7890625\n",
      "Batch: 32, Loss: 0.6630059480667114, Accuracy: 0.7919921875\n",
      "Batch: 33, Loss: 0.756729781627655, Accuracy: 0.748046875\n",
      "Batch: 34, Loss: 0.8222675323486328, Accuracy: 0.7216796875\n",
      "Batch: 35, Loss: 0.7453715801239014, Accuracy: 0.7578125\n",
      "Batch: 36, Loss: 0.7447930574417114, Accuracy: 0.765625\n",
      "Batch: 37, Loss: 0.7397124171257019, Accuracy: 0.7587890625\n",
      "Batch: 38, Loss: 0.752231240272522, Accuracy: 0.75\n",
      "Batch: 39, Loss: 0.7508917450904846, Accuracy: 0.7529296875\n",
      "Batch: 40, Loss: 0.7065492272377014, Accuracy: 0.76953125\n",
      "Batch: 41, Loss: 0.661896824836731, Accuracy: 0.767578125\n",
      "Batch: 42, Loss: 0.5449494123458862, Accuracy: 0.828125\n",
      "Batch: 43, Loss: 0.6948673129081726, Accuracy: 0.767578125\n",
      "Batch: 44, Loss: 0.7423045635223389, Accuracy: 0.7607421875\n",
      "Batch: 45, Loss: 0.6455985307693481, Accuracy: 0.7802734375\n",
      "Batch: 46, Loss: 0.6736510992050171, Accuracy: 0.7900390625\n",
      "Batch: 47, Loss: 0.7324896454811096, Accuracy: 0.78515625\n",
      "Batch: 48, Loss: 0.6949432492256165, Accuracy: 0.7763671875\n",
      "Batch: 49, Loss: 0.7979058027267456, Accuracy: 0.748046875\n",
      "Batch: 50, Loss: 0.7277590036392212, Accuracy: 0.7646484375\n",
      "Batch: 51, Loss: 0.8174651265144348, Accuracy: 0.7392578125\n",
      "Batch: 52, Loss: 0.7523884177207947, Accuracy: 0.7548828125\n",
      "Batch: 53, Loss: 0.6510924100875854, Accuracy: 0.798828125\n",
      "Batch: 54, Loss: 0.6778498888015747, Accuracy: 0.7705078125\n",
      "Batch: 55, Loss: 0.7782747745513916, Accuracy: 0.744140625\n",
      "Batch: 56, Loss: 0.7649259567260742, Accuracy: 0.7392578125\n",
      "Batch: 57, Loss: 0.7382009625434875, Accuracy: 0.748046875\n",
      "Batch: 58, Loss: 0.8485259413719177, Accuracy: 0.7314453125\n",
      "Batch: 59, Loss: 0.7270596027374268, Accuracy: 0.765625\n",
      "Batch: 60, Loss: 0.6764026880264282, Accuracy: 0.76953125\n",
      "Batch: 61, Loss: 0.7598142623901367, Accuracy: 0.759765625\n",
      "Batch: 62, Loss: 0.6984272003173828, Accuracy: 0.7763671875\n",
      "Batch: 63, Loss: 0.744619607925415, Accuracy: 0.755859375\n",
      "Batch: 64, Loss: 0.7187545299530029, Accuracy: 0.767578125\n",
      "Batch: 65, Loss: 0.7322696447372437, Accuracy: 0.765625\n",
      "Batch: 66, Loss: 0.7497841715812683, Accuracy: 0.7646484375\n",
      "Batch: 67, Loss: 0.8198361396789551, Accuracy: 0.7451171875\n",
      "Batch: 68, Loss: 0.823228120803833, Accuracy: 0.734375\n",
      "Batch: 69, Loss: 0.769503116607666, Accuracy: 0.7451171875\n",
      "Batch: 70, Loss: 0.7807872891426086, Accuracy: 0.76171875\n",
      "Batch: 71, Loss: 0.7778812646865845, Accuracy: 0.751953125\n",
      "Batch: 72, Loss: 0.686682939529419, Accuracy: 0.7666015625\n",
      "Batch: 73, Loss: 0.69147789478302, Accuracy: 0.7802734375\n",
      "Batch: 74, Loss: 0.6348079442977905, Accuracy: 0.80859375\n",
      "Batch: 75, Loss: 0.637582540512085, Accuracy: 0.7998046875\n",
      "Batch: 76, Loss: 0.7172993421554565, Accuracy: 0.7685546875\n",
      "Batch: 77, Loss: 0.6620494723320007, Accuracy: 0.779296875\n",
      "Batch: 78, Loss: 0.6459370255470276, Accuracy: 0.794921875\n",
      "Batch: 79, Loss: 0.699468731880188, Accuracy: 0.7919921875\n",
      "Batch: 80, Loss: 0.674508273601532, Accuracy: 0.798828125\n",
      "Batch: 81, Loss: 0.7774006128311157, Accuracy: 0.7412109375\n",
      "Batch: 82, Loss: 0.7492383122444153, Accuracy: 0.763671875\n",
      "Batch: 83, Loss: 0.637561559677124, Accuracy: 0.80859375\n",
      "Batch: 84, Loss: 0.7435394525527954, Accuracy: 0.7587890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 85, Loss: 0.7078523635864258, Accuracy: 0.7783203125\n",
      "Batch: 86, Loss: 0.847377598285675, Accuracy: 0.7333984375\n",
      "Batch: 87, Loss: 0.6719344854354858, Accuracy: 0.794921875\n",
      "Batch: 88, Loss: 0.7700664401054382, Accuracy: 0.76171875\n",
      "Batch: 89, Loss: 0.7535456418991089, Accuracy: 0.7568359375\n",
      "Batch: 90, Loss: 0.6764028072357178, Accuracy: 0.7861328125\n",
      "Batch: 91, Loss: 0.6934124231338501, Accuracy: 0.7705078125\n",
      "Batch: 92, Loss: 0.7394678592681885, Accuracy: 0.76953125\n",
      "Batch: 93, Loss: 0.7273836135864258, Accuracy: 0.7529296875\n",
      "Batch: 94, Loss: 0.7469278573989868, Accuracy: 0.7646484375\n",
      "Batch: 95, Loss: 0.744174599647522, Accuracy: 0.744140625\n",
      "Batch: 96, Loss: 0.7035735845565796, Accuracy: 0.7705078125\n",
      "Batch: 97, Loss: 0.5981330871582031, Accuracy: 0.8056640625\n",
      "Batch: 98, Loss: 0.7253941297531128, Accuracy: 0.763671875\n",
      "Batch: 99, Loss: 0.7001774907112122, Accuracy: 0.755859375\n",
      "Batch: 100, Loss: 0.7251651883125305, Accuracy: 0.759765625\n",
      "Batch: 101, Loss: 0.7778232097625732, Accuracy: 0.7451171875\n",
      "Batch: 102, Loss: 0.7470951676368713, Accuracy: 0.75\n",
      "Batch: 103, Loss: 0.7422794103622437, Accuracy: 0.7646484375\n",
      "Batch: 104, Loss: 0.67353355884552, Accuracy: 0.77734375\n",
      "Batch: 105, Loss: 0.7028031349182129, Accuracy: 0.771484375\n",
      "Batch: 106, Loss: 0.6574935913085938, Accuracy: 0.794921875\n",
      "Batch: 107, Loss: 0.712016224861145, Accuracy: 0.7763671875\n",
      "Batch: 108, Loss: 0.7320095896720886, Accuracy: 0.7685546875\n",
      "Batch: 109, Loss: 0.7844120264053345, Accuracy: 0.7333984375\n",
      "Batch: 110, Loss: 0.6513994932174683, Accuracy: 0.79296875\n",
      "Batch: 111, Loss: 0.7418482303619385, Accuracy: 0.7578125\n",
      "Batch: 112, Loss: 0.7079468965530396, Accuracy: 0.7626953125\n",
      "Batch: 113, Loss: 0.7247380018234253, Accuracy: 0.7578125\n",
      "Batch: 114, Loss: 0.7686077356338501, Accuracy: 0.7626953125\n",
      "Batch: 115, Loss: 0.8390747308731079, Accuracy: 0.7275390625\n",
      "Batch: 116, Loss: 0.7430007457733154, Accuracy: 0.7666015625\n",
      "Batch: 117, Loss: 0.8108232021331787, Accuracy: 0.74609375\n",
      "Batch: 118, Loss: 0.6713793277740479, Accuracy: 0.7822265625\n",
      "Batch: 119, Loss: 0.6543574333190918, Accuracy: 0.787109375\n",
      "Batch: 120, Loss: 0.7508184909820557, Accuracy: 0.75\n",
      "Batch: 121, Loss: 0.7746621370315552, Accuracy: 0.7490234375\n",
      "Batch: 122, Loss: 0.7245213389396667, Accuracy: 0.7666015625\n",
      "Batch: 123, Loss: 0.693541407585144, Accuracy: 0.7744140625\n",
      "Batch: 124, Loss: 0.7679699659347534, Accuracy: 0.740234375\n",
      "Batch: 125, Loss: 0.7997247576713562, Accuracy: 0.7451171875\n",
      "Batch: 126, Loss: 0.7547323703765869, Accuracy: 0.75390625\n",
      "Batch: 127, Loss: 0.6460829973220825, Accuracy: 0.7822265625\n",
      "Batch: 128, Loss: 0.8123522996902466, Accuracy: 0.7578125\n",
      "Batch: 129, Loss: 0.687576174736023, Accuracy: 0.783203125\n",
      "Batch: 130, Loss: 0.7994988560676575, Accuracy: 0.7431640625\n",
      "Batch: 131, Loss: 0.7411566972732544, Accuracy: 0.755859375\n",
      "Batch: 132, Loss: 0.780410647392273, Accuracy: 0.76171875\n",
      "Batch: 133, Loss: 0.7421426773071289, Accuracy: 0.7626953125\n",
      "Batch: 134, Loss: 0.7653787732124329, Accuracy: 0.748046875\n",
      "Batch: 135, Loss: 0.7087864875793457, Accuracy: 0.7705078125\n",
      "Batch: 136, Loss: 0.7614858150482178, Accuracy: 0.763671875\n",
      "Batch: 137, Loss: 0.7132052779197693, Accuracy: 0.7587890625\n",
      "Batch: 138, Loss: 0.662506103515625, Accuracy: 0.7666015625\n",
      "Batch: 139, Loss: 0.671574592590332, Accuracy: 0.783203125\n",
      "Batch: 140, Loss: 0.7264856100082397, Accuracy: 0.755859375\n",
      "Batch: 141, Loss: 0.7509434223175049, Accuracy: 0.767578125\n",
      "Batch: 142, Loss: 0.8049747347831726, Accuracy: 0.74609375\n",
      "Batch: 143, Loss: 0.7120837569236755, Accuracy: 0.767578125\n",
      "Batch: 144, Loss: 0.7519180774688721, Accuracy: 0.7587890625\n",
      "Batch: 145, Loss: 0.692581057548523, Accuracy: 0.751953125\n",
      "Batch: 146, Loss: 0.7478481531143188, Accuracy: 0.7451171875\n",
      "Batch: 147, Loss: 0.741118311882019, Accuracy: 0.76953125\n",
      "Batch: 148, Loss: 0.7726876735687256, Accuracy: 0.7568359375\n",
      "Batch: 149, Loss: 0.7213121056556702, Accuracy: 0.7509765625\n",
      "Batch: 150, Loss: 0.7735241651535034, Accuracy: 0.744140625\n",
      "Batch: 151, Loss: 0.6246245503425598, Accuracy: 0.7919921875\n",
      "Epoch 48/80\n",
      "Batch: 1, Loss: 0.9044857621192932, Accuracy: 0.71484375\n",
      "Batch: 2, Loss: 0.8022264242172241, Accuracy: 0.7294921875\n",
      "Batch: 3, Loss: 0.6787672638893127, Accuracy: 0.783203125\n",
      "Batch: 4, Loss: 0.671493649482727, Accuracy: 0.779296875\n",
      "Batch: 5, Loss: 0.7141846418380737, Accuracy: 0.765625\n",
      "Batch: 6, Loss: 0.7472963929176331, Accuracy: 0.7587890625\n",
      "Batch: 7, Loss: 0.7409608960151672, Accuracy: 0.7470703125\n",
      "Batch: 8, Loss: 0.6874442100524902, Accuracy: 0.7744140625\n",
      "Batch: 9, Loss: 0.683573305606842, Accuracy: 0.767578125\n",
      "Batch: 10, Loss: 0.6899502277374268, Accuracy: 0.7802734375\n",
      "Batch: 11, Loss: 0.7438089847564697, Accuracy: 0.75390625\n",
      "Batch: 12, Loss: 0.7876293063163757, Accuracy: 0.7373046875\n",
      "Batch: 13, Loss: 0.6147924065589905, Accuracy: 0.7783203125\n",
      "Batch: 14, Loss: 0.8061661720275879, Accuracy: 0.751953125\n",
      "Batch: 15, Loss: 0.6713606119155884, Accuracy: 0.7890625\n",
      "Batch: 16, Loss: 0.6532720327377319, Accuracy: 0.7978515625\n",
      "Batch: 17, Loss: 0.710159182548523, Accuracy: 0.76953125\n",
      "Batch: 18, Loss: 0.7676640152931213, Accuracy: 0.7626953125\n",
      "Batch: 19, Loss: 0.7649017572402954, Accuracy: 0.7587890625\n",
      "Batch: 20, Loss: 0.6819765567779541, Accuracy: 0.7841796875\n",
      "Batch: 21, Loss: 0.6922745108604431, Accuracy: 0.76953125\n",
      "Batch: 22, Loss: 0.810249388217926, Accuracy: 0.7265625\n",
      "Batch: 23, Loss: 0.7673411965370178, Accuracy: 0.73828125\n",
      "Batch: 24, Loss: 0.7756754159927368, Accuracy: 0.7509765625\n",
      "Batch: 25, Loss: 0.7353194952011108, Accuracy: 0.76171875\n",
      "Batch: 26, Loss: 0.6239759922027588, Accuracy: 0.7978515625\n",
      "Batch: 27, Loss: 0.6879069209098816, Accuracy: 0.7724609375\n",
      "Batch: 28, Loss: 0.7124024629592896, Accuracy: 0.7607421875\n",
      "Batch: 29, Loss: 0.7086246013641357, Accuracy: 0.765625\n",
      "Batch: 30, Loss: 0.6528281569480896, Accuracy: 0.79296875\n",
      "Batch: 31, Loss: 0.6331084966659546, Accuracy: 0.8017578125\n",
      "Batch: 32, Loss: 0.6541780829429626, Accuracy: 0.7685546875\n",
      "Batch: 33, Loss: 0.7733248472213745, Accuracy: 0.7587890625\n",
      "Batch: 34, Loss: 0.774725615978241, Accuracy: 0.748046875\n",
      "Batch: 35, Loss: 0.7430271506309509, Accuracy: 0.763671875\n",
      "Batch: 36, Loss: 0.7533477544784546, Accuracy: 0.76171875\n",
      "Batch: 37, Loss: 0.7337994575500488, Accuracy: 0.751953125\n",
      "Batch: 38, Loss: 0.7471977472305298, Accuracy: 0.74609375\n",
      "Batch: 39, Loss: 0.7317020893096924, Accuracy: 0.759765625\n",
      "Batch: 40, Loss: 0.7212553024291992, Accuracy: 0.7509765625\n",
      "Batch: 41, Loss: 0.655210018157959, Accuracy: 0.7822265625\n",
      "Batch: 42, Loss: 0.5600098371505737, Accuracy: 0.8115234375\n",
      "Batch: 43, Loss: 0.6929047107696533, Accuracy: 0.7626953125\n",
      "Batch: 44, Loss: 0.748012363910675, Accuracy: 0.75390625\n",
      "Batch: 45, Loss: 0.6516991853713989, Accuracy: 0.78125\n",
      "Batch: 46, Loss: 0.6815708875656128, Accuracy: 0.7900390625\n",
      "Batch: 47, Loss: 0.7166551351547241, Accuracy: 0.7861328125\n",
      "Batch: 48, Loss: 0.6989337205886841, Accuracy: 0.765625\n",
      "Batch: 49, Loss: 0.7484032511711121, Accuracy: 0.75\n",
      "Batch: 50, Loss: 0.6939830183982849, Accuracy: 0.7705078125\n",
      "Batch: 51, Loss: 0.7347642183303833, Accuracy: 0.767578125\n",
      "Batch: 52, Loss: 0.7214406132698059, Accuracy: 0.7724609375\n",
      "Batch: 53, Loss: 0.6472667455673218, Accuracy: 0.791015625\n",
      "Batch: 54, Loss: 0.6866893768310547, Accuracy: 0.7841796875\n",
      "Batch: 55, Loss: 0.7886898517608643, Accuracy: 0.7353515625\n",
      "Batch: 56, Loss: 0.7836471199989319, Accuracy: 0.7392578125\n",
      "Batch: 57, Loss: 0.7594725489616394, Accuracy: 0.75\n",
      "Batch: 58, Loss: 0.8094643950462341, Accuracy: 0.755859375\n",
      "Batch: 59, Loss: 0.7176157832145691, Accuracy: 0.77734375\n",
      "Batch: 60, Loss: 0.7052006721496582, Accuracy: 0.7607421875\n",
      "Batch: 61, Loss: 0.761410117149353, Accuracy: 0.75\n",
      "Batch: 62, Loss: 0.697599470615387, Accuracy: 0.7724609375\n",
      "Batch: 63, Loss: 0.7294310331344604, Accuracy: 0.7587890625\n",
      "Batch: 64, Loss: 0.722348153591156, Accuracy: 0.767578125\n",
      "Batch: 65, Loss: 0.7183300256729126, Accuracy: 0.7822265625\n",
      "Batch: 66, Loss: 0.7344404458999634, Accuracy: 0.767578125\n",
      "Batch: 67, Loss: 0.7973871231079102, Accuracy: 0.76171875\n",
      "Batch: 68, Loss: 0.7919921875, Accuracy: 0.7451171875\n",
      "Batch: 69, Loss: 0.7520031332969666, Accuracy: 0.751953125\n",
      "Batch: 70, Loss: 0.756688117980957, Accuracy: 0.78125\n",
      "Batch: 71, Loss: 0.7730586528778076, Accuracy: 0.755859375\n",
      "Batch: 72, Loss: 0.6802680492401123, Accuracy: 0.7763671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 73, Loss: 0.6618608236312866, Accuracy: 0.783203125\n",
      "Batch: 74, Loss: 0.6777040362358093, Accuracy: 0.78515625\n",
      "Batch: 75, Loss: 0.6540809273719788, Accuracy: 0.7978515625\n",
      "Batch: 76, Loss: 0.7203405499458313, Accuracy: 0.76953125\n",
      "Batch: 77, Loss: 0.677881121635437, Accuracy: 0.779296875\n",
      "Batch: 78, Loss: 0.6478934288024902, Accuracy: 0.796875\n",
      "Batch: 79, Loss: 0.6772875785827637, Accuracy: 0.7802734375\n",
      "Batch: 80, Loss: 0.6619237065315247, Accuracy: 0.775390625\n",
      "Batch: 81, Loss: 0.7683258056640625, Accuracy: 0.7421875\n",
      "Batch: 82, Loss: 0.7237099409103394, Accuracy: 0.7705078125\n",
      "Batch: 83, Loss: 0.6406629681587219, Accuracy: 0.806640625\n",
      "Batch: 84, Loss: 0.7139871120452881, Accuracy: 0.7705078125\n",
      "Batch: 85, Loss: 0.7028597593307495, Accuracy: 0.78125\n",
      "Batch: 86, Loss: 0.8077192902565002, Accuracy: 0.755859375\n",
      "Batch: 87, Loss: 0.6759381294250488, Accuracy: 0.78515625\n",
      "Batch: 88, Loss: 0.7624778747558594, Accuracy: 0.7802734375\n",
      "Batch: 89, Loss: 0.7243346571922302, Accuracy: 0.7763671875\n",
      "Batch: 90, Loss: 0.7244960069656372, Accuracy: 0.7666015625\n",
      "Batch: 91, Loss: 0.6767038702964783, Accuracy: 0.7646484375\n",
      "Batch: 92, Loss: 0.7378603219985962, Accuracy: 0.763671875\n",
      "Batch: 93, Loss: 0.7299681901931763, Accuracy: 0.7626953125\n",
      "Batch: 94, Loss: 0.7168167233467102, Accuracy: 0.7685546875\n",
      "Batch: 95, Loss: 0.745329737663269, Accuracy: 0.744140625\n",
      "Batch: 96, Loss: 0.7122641205787659, Accuracy: 0.7705078125\n",
      "Batch: 97, Loss: 0.6049160957336426, Accuracy: 0.802734375\n",
      "Batch: 98, Loss: 0.7281644344329834, Accuracy: 0.763671875\n",
      "Batch: 99, Loss: 0.6987082958221436, Accuracy: 0.763671875\n",
      "Batch: 100, Loss: 0.6961091756820679, Accuracy: 0.7685546875\n",
      "Batch: 101, Loss: 0.7697483897209167, Accuracy: 0.7509765625\n",
      "Batch: 102, Loss: 0.7308305501937866, Accuracy: 0.763671875\n",
      "Batch: 103, Loss: 0.7652926445007324, Accuracy: 0.767578125\n",
      "Batch: 104, Loss: 0.6958103775978088, Accuracy: 0.76953125\n",
      "Batch: 105, Loss: 0.7542258501052856, Accuracy: 0.751953125\n",
      "Batch: 106, Loss: 0.6353148221969604, Accuracy: 0.7890625\n",
      "Batch: 107, Loss: 0.6965636610984802, Accuracy: 0.779296875\n",
      "Batch: 108, Loss: 0.7042574882507324, Accuracy: 0.7734375\n",
      "Batch: 109, Loss: 0.7643687129020691, Accuracy: 0.7353515625\n",
      "Batch: 110, Loss: 0.6665245294570923, Accuracy: 0.7802734375\n",
      "Batch: 111, Loss: 0.7118870615959167, Accuracy: 0.7666015625\n",
      "Batch: 112, Loss: 0.6965583562850952, Accuracy: 0.7763671875\n",
      "Batch: 113, Loss: 0.7802646160125732, Accuracy: 0.7587890625\n",
      "Batch: 114, Loss: 0.7623937726020813, Accuracy: 0.7490234375\n",
      "Batch: 115, Loss: 0.8151507377624512, Accuracy: 0.7451171875\n",
      "Batch: 116, Loss: 0.7501290440559387, Accuracy: 0.771484375\n",
      "Batch: 117, Loss: 0.7910935878753662, Accuracy: 0.7529296875\n",
      "Batch: 118, Loss: 0.6700535416603088, Accuracy: 0.775390625\n",
      "Batch: 119, Loss: 0.6275852918624878, Accuracy: 0.7978515625\n",
      "Batch: 120, Loss: 0.7124982476234436, Accuracy: 0.7578125\n",
      "Batch: 121, Loss: 0.7717472314834595, Accuracy: 0.7578125\n",
      "Batch: 122, Loss: 0.7139196395874023, Accuracy: 0.765625\n",
      "Batch: 123, Loss: 0.6839789748191833, Accuracy: 0.7861328125\n",
      "Batch: 124, Loss: 0.715573787689209, Accuracy: 0.7734375\n",
      "Batch: 125, Loss: 0.767498254776001, Accuracy: 0.748046875\n",
      "Batch: 126, Loss: 0.7296417355537415, Accuracy: 0.755859375\n",
      "Batch: 127, Loss: 0.6476590633392334, Accuracy: 0.7822265625\n",
      "Batch: 128, Loss: 0.7954868078231812, Accuracy: 0.7451171875\n",
      "Batch: 129, Loss: 0.6611117720603943, Accuracy: 0.7802734375\n",
      "Batch: 130, Loss: 0.7908141613006592, Accuracy: 0.744140625\n",
      "Batch: 131, Loss: 0.7378401756286621, Accuracy: 0.755859375\n",
      "Batch: 132, Loss: 0.7609679102897644, Accuracy: 0.76171875\n",
      "Batch: 133, Loss: 0.7045989036560059, Accuracy: 0.7685546875\n",
      "Batch: 134, Loss: 0.749001145362854, Accuracy: 0.74609375\n",
      "Batch: 135, Loss: 0.685386598110199, Accuracy: 0.7841796875\n",
      "Batch: 136, Loss: 0.7295659780502319, Accuracy: 0.767578125\n",
      "Batch: 137, Loss: 0.7128523588180542, Accuracy: 0.7587890625\n",
      "Batch: 138, Loss: 0.6779264211654663, Accuracy: 0.7763671875\n",
      "Batch: 139, Loss: 0.6712198257446289, Accuracy: 0.7724609375\n",
      "Batch: 140, Loss: 0.7295769453048706, Accuracy: 0.7646484375\n",
      "Batch: 141, Loss: 0.758033037185669, Accuracy: 0.763671875\n",
      "Batch: 142, Loss: 0.8121921420097351, Accuracy: 0.73828125\n",
      "Batch: 143, Loss: 0.7323552966117859, Accuracy: 0.76953125\n",
      "Batch: 144, Loss: 0.725616455078125, Accuracy: 0.7734375\n",
      "Batch: 145, Loss: 0.6774784326553345, Accuracy: 0.7587890625\n",
      "Batch: 146, Loss: 0.7487995028495789, Accuracy: 0.7646484375\n",
      "Batch: 147, Loss: 0.7307210564613342, Accuracy: 0.767578125\n",
      "Batch: 148, Loss: 0.7936821579933167, Accuracy: 0.7216796875\n",
      "Batch: 149, Loss: 0.7078988552093506, Accuracy: 0.7529296875\n",
      "Batch: 150, Loss: 0.7573188543319702, Accuracy: 0.763671875\n",
      "Batch: 151, Loss: 0.6382725238800049, Accuracy: 0.79296875\n",
      "Epoch 49/80\n",
      "Batch: 1, Loss: 0.9024477005004883, Accuracy: 0.6962890625\n",
      "Batch: 2, Loss: 0.7785436511039734, Accuracy: 0.7451171875\n",
      "Batch: 3, Loss: 0.6805986166000366, Accuracy: 0.7705078125\n",
      "Batch: 4, Loss: 0.6602618098258972, Accuracy: 0.7939453125\n",
      "Batch: 5, Loss: 0.6897253394126892, Accuracy: 0.78125\n",
      "Batch: 6, Loss: 0.7237937450408936, Accuracy: 0.7626953125\n",
      "Batch: 7, Loss: 0.7112094759941101, Accuracy: 0.7724609375\n",
      "Batch: 8, Loss: 0.6858921051025391, Accuracy: 0.7734375\n",
      "Batch: 9, Loss: 0.6807151436805725, Accuracy: 0.7744140625\n",
      "Batch: 10, Loss: 0.6843849420547485, Accuracy: 0.7763671875\n",
      "Batch: 11, Loss: 0.7563065886497498, Accuracy: 0.751953125\n",
      "Batch: 12, Loss: 0.7681655883789062, Accuracy: 0.7490234375\n",
      "Batch: 13, Loss: 0.6311099529266357, Accuracy: 0.7919921875\n",
      "Batch: 14, Loss: 0.7670842409133911, Accuracy: 0.7548828125\n",
      "Batch: 15, Loss: 0.6545948386192322, Accuracy: 0.7998046875\n",
      "Batch: 16, Loss: 0.6348997950553894, Accuracy: 0.8037109375\n",
      "Batch: 17, Loss: 0.7105695009231567, Accuracy: 0.775390625\n",
      "Batch: 18, Loss: 0.7455956935882568, Accuracy: 0.7578125\n",
      "Batch: 19, Loss: 0.7622252702713013, Accuracy: 0.7568359375\n",
      "Batch: 20, Loss: 0.6929231286048889, Accuracy: 0.7861328125\n",
      "Batch: 21, Loss: 0.6832355260848999, Accuracy: 0.7587890625\n",
      "Batch: 22, Loss: 0.795272946357727, Accuracy: 0.7421875\n",
      "Batch: 23, Loss: 0.7637174129486084, Accuracy: 0.7470703125\n",
      "Batch: 24, Loss: 0.7473232746124268, Accuracy: 0.7470703125\n",
      "Batch: 25, Loss: 0.6761932373046875, Accuracy: 0.779296875\n",
      "Batch: 26, Loss: 0.5939218997955322, Accuracy: 0.8037109375\n",
      "Batch: 27, Loss: 0.6744990944862366, Accuracy: 0.7705078125\n",
      "Batch: 28, Loss: 0.7202445864677429, Accuracy: 0.7509765625\n",
      "Batch: 29, Loss: 0.6972302198410034, Accuracy: 0.779296875\n",
      "Batch: 30, Loss: 0.6625975370407104, Accuracy: 0.787109375\n",
      "Batch: 31, Loss: 0.6423653364181519, Accuracy: 0.8046875\n",
      "Batch: 32, Loss: 0.6775141358375549, Accuracy: 0.76953125\n",
      "Batch: 33, Loss: 0.744084894657135, Accuracy: 0.7646484375\n",
      "Batch: 34, Loss: 0.7649195790290833, Accuracy: 0.7529296875\n",
      "Batch: 35, Loss: 0.7607744932174683, Accuracy: 0.7490234375\n",
      "Batch: 36, Loss: 0.7144818305969238, Accuracy: 0.7724609375\n",
      "Batch: 37, Loss: 0.7509889602661133, Accuracy: 0.75390625\n",
      "Batch: 38, Loss: 0.7446283102035522, Accuracy: 0.75\n",
      "Batch: 39, Loss: 0.6987907886505127, Accuracy: 0.78125\n",
      "Batch: 40, Loss: 0.7085095643997192, Accuracy: 0.763671875\n",
      "Batch: 41, Loss: 0.6414185166358948, Accuracy: 0.7880859375\n",
      "Batch: 42, Loss: 0.5307833552360535, Accuracy: 0.818359375\n",
      "Batch: 43, Loss: 0.7007385492324829, Accuracy: 0.7724609375\n",
      "Batch: 44, Loss: 0.7316015362739563, Accuracy: 0.7666015625\n",
      "Batch: 45, Loss: 0.6197947859764099, Accuracy: 0.8076171875\n",
      "Batch: 46, Loss: 0.6829931735992432, Accuracy: 0.791015625\n",
      "Batch: 47, Loss: 0.7037447690963745, Accuracy: 0.78125\n",
      "Batch: 48, Loss: 0.6693277359008789, Accuracy: 0.7734375\n",
      "Batch: 49, Loss: 0.778289794921875, Accuracy: 0.744140625\n",
      "Batch: 50, Loss: 0.7110754251480103, Accuracy: 0.7744140625\n",
      "Batch: 51, Loss: 0.7658463716506958, Accuracy: 0.7490234375\n",
      "Batch: 52, Loss: 0.7132391929626465, Accuracy: 0.7763671875\n",
      "Batch: 53, Loss: 0.6272406578063965, Accuracy: 0.8017578125\n",
      "Batch: 54, Loss: 0.673315167427063, Accuracy: 0.7841796875\n",
      "Batch: 55, Loss: 0.7570955753326416, Accuracy: 0.7509765625\n",
      "Batch: 56, Loss: 0.7911624908447266, Accuracy: 0.7353515625\n",
      "Batch: 57, Loss: 0.709275484085083, Accuracy: 0.779296875\n",
      "Batch: 58, Loss: 0.8046950101852417, Accuracy: 0.755859375\n",
      "Batch: 59, Loss: 0.7067676782608032, Accuracy: 0.7626953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 60, Loss: 0.6680538058280945, Accuracy: 0.7734375\n",
      "Batch: 61, Loss: 0.7497115135192871, Accuracy: 0.75390625\n",
      "Batch: 62, Loss: 0.6797741651535034, Accuracy: 0.7763671875\n",
      "Batch: 63, Loss: 0.733514666557312, Accuracy: 0.7607421875\n",
      "Batch: 64, Loss: 0.6968221068382263, Accuracy: 0.7783203125\n",
      "Batch: 65, Loss: 0.7432052493095398, Accuracy: 0.763671875\n",
      "Batch: 66, Loss: 0.715305745601654, Accuracy: 0.767578125\n",
      "Batch: 67, Loss: 0.8052575588226318, Accuracy: 0.74609375\n",
      "Batch: 68, Loss: 0.7795919179916382, Accuracy: 0.7529296875\n",
      "Batch: 69, Loss: 0.7284549474716187, Accuracy: 0.7578125\n",
      "Batch: 70, Loss: 0.7573659420013428, Accuracy: 0.7607421875\n",
      "Batch: 71, Loss: 0.7651214003562927, Accuracy: 0.7353515625\n",
      "Batch: 72, Loss: 0.700141429901123, Accuracy: 0.76953125\n",
      "Batch: 73, Loss: 0.6474324464797974, Accuracy: 0.7939453125\n",
      "Batch: 74, Loss: 0.638716459274292, Accuracy: 0.8046875\n",
      "Batch: 75, Loss: 0.6241754293441772, Accuracy: 0.8212890625\n",
      "Batch: 76, Loss: 0.7285955548286438, Accuracy: 0.7705078125\n",
      "Batch: 77, Loss: 0.6536769866943359, Accuracy: 0.7890625\n",
      "Batch: 78, Loss: 0.6646667718887329, Accuracy: 0.80078125\n",
      "Batch: 79, Loss: 0.6428974866867065, Accuracy: 0.8095703125\n",
      "Batch: 80, Loss: 0.6343419551849365, Accuracy: 0.80078125\n",
      "Batch: 81, Loss: 0.740649402141571, Accuracy: 0.7646484375\n",
      "Batch: 82, Loss: 0.7146746516227722, Accuracy: 0.7685546875\n",
      "Batch: 83, Loss: 0.6474530100822449, Accuracy: 0.8017578125\n",
      "Batch: 84, Loss: 0.6955229043960571, Accuracy: 0.7783203125\n",
      "Batch: 85, Loss: 0.6998512744903564, Accuracy: 0.7734375\n",
      "Batch: 86, Loss: 0.822708249092102, Accuracy: 0.7333984375\n",
      "Batch: 87, Loss: 0.6556955575942993, Accuracy: 0.7802734375\n",
      "Batch: 88, Loss: 0.7459777593612671, Accuracy: 0.7763671875\n",
      "Batch: 89, Loss: 0.733135461807251, Accuracy: 0.7685546875\n",
      "Batch: 90, Loss: 0.6999295353889465, Accuracy: 0.779296875\n",
      "Batch: 91, Loss: 0.6804829835891724, Accuracy: 0.7705078125\n",
      "Batch: 92, Loss: 0.7247868776321411, Accuracy: 0.779296875\n",
      "Batch: 93, Loss: 0.7431777119636536, Accuracy: 0.7578125\n",
      "Batch: 94, Loss: 0.7337749004364014, Accuracy: 0.7626953125\n",
      "Batch: 95, Loss: 0.7483004331588745, Accuracy: 0.7548828125\n",
      "Batch: 96, Loss: 0.7056396007537842, Accuracy: 0.767578125\n",
      "Batch: 97, Loss: 0.6120431423187256, Accuracy: 0.802734375\n",
      "Batch: 98, Loss: 0.7347347736358643, Accuracy: 0.7646484375\n",
      "Batch: 99, Loss: 0.7024599313735962, Accuracy: 0.7666015625\n",
      "Batch: 100, Loss: 0.6847707033157349, Accuracy: 0.7734375\n",
      "Batch: 101, Loss: 0.7587035298347473, Accuracy: 0.7578125\n",
      "Batch: 102, Loss: 0.7030430436134338, Accuracy: 0.7734375\n",
      "Batch: 103, Loss: 0.7104740142822266, Accuracy: 0.77734375\n",
      "Batch: 104, Loss: 0.6507846713066101, Accuracy: 0.80078125\n",
      "Batch: 105, Loss: 0.714296281337738, Accuracy: 0.76953125\n",
      "Batch: 106, Loss: 0.6735966801643372, Accuracy: 0.787109375\n",
      "Batch: 107, Loss: 0.705528736114502, Accuracy: 0.7783203125\n",
      "Batch: 108, Loss: 0.719590425491333, Accuracy: 0.77734375\n",
      "Batch: 109, Loss: 0.761157214641571, Accuracy: 0.7451171875\n",
      "Batch: 110, Loss: 0.6504656672477722, Accuracy: 0.7958984375\n",
      "Batch: 111, Loss: 0.7387984395027161, Accuracy: 0.75\n",
      "Batch: 112, Loss: 0.7039371132850647, Accuracy: 0.77734375\n",
      "Batch: 113, Loss: 0.715582549571991, Accuracy: 0.77734375\n",
      "Batch: 114, Loss: 0.7755459547042847, Accuracy: 0.7587890625\n",
      "Batch: 115, Loss: 0.8225142955780029, Accuracy: 0.7294921875\n",
      "Batch: 116, Loss: 0.7455939650535583, Accuracy: 0.7587890625\n",
      "Batch: 117, Loss: 0.7543311715126038, Accuracy: 0.7578125\n",
      "Batch: 118, Loss: 0.6467275023460388, Accuracy: 0.791015625\n",
      "Batch: 119, Loss: 0.6397815346717834, Accuracy: 0.7880859375\n",
      "Batch: 120, Loss: 0.7247664928436279, Accuracy: 0.748046875\n",
      "Batch: 121, Loss: 0.7804502248764038, Accuracy: 0.7392578125\n",
      "Batch: 122, Loss: 0.7088597416877747, Accuracy: 0.76953125\n",
      "Batch: 123, Loss: 0.6955845952033997, Accuracy: 0.7685546875\n",
      "Batch: 124, Loss: 0.7383489608764648, Accuracy: 0.759765625\n",
      "Batch: 125, Loss: 0.7721368074417114, Accuracy: 0.7529296875\n",
      "Batch: 126, Loss: 0.7488970756530762, Accuracy: 0.76171875\n",
      "Batch: 127, Loss: 0.6325681209564209, Accuracy: 0.8017578125\n",
      "Batch: 128, Loss: 0.8034447431564331, Accuracy: 0.7412109375\n",
      "Batch: 129, Loss: 0.6909160614013672, Accuracy: 0.7744140625\n",
      "Batch: 130, Loss: 0.8106266260147095, Accuracy: 0.7353515625\n",
      "Batch: 131, Loss: 0.7393661737442017, Accuracy: 0.75\n",
      "Batch: 132, Loss: 0.7649234533309937, Accuracy: 0.7607421875\n",
      "Batch: 133, Loss: 0.7056450843811035, Accuracy: 0.7724609375\n",
      "Batch: 134, Loss: 0.744134783744812, Accuracy: 0.73828125\n",
      "Batch: 135, Loss: 0.6897261142730713, Accuracy: 0.7783203125\n",
      "Batch: 136, Loss: 0.7366195917129517, Accuracy: 0.763671875\n",
      "Batch: 137, Loss: 0.7279312610626221, Accuracy: 0.7529296875\n",
      "Batch: 138, Loss: 0.6531420946121216, Accuracy: 0.7822265625\n",
      "Batch: 139, Loss: 0.6703349947929382, Accuracy: 0.7587890625\n",
      "Batch: 140, Loss: 0.7253941297531128, Accuracy: 0.765625\n",
      "Batch: 141, Loss: 0.7580646276473999, Accuracy: 0.755859375\n",
      "Batch: 142, Loss: 0.8165930509567261, Accuracy: 0.7314453125\n",
      "Batch: 143, Loss: 0.696134626865387, Accuracy: 0.78515625\n",
      "Batch: 144, Loss: 0.7226212024688721, Accuracy: 0.775390625\n",
      "Batch: 145, Loss: 0.6534227132797241, Accuracy: 0.7705078125\n",
      "Batch: 146, Loss: 0.7426633238792419, Accuracy: 0.748046875\n",
      "Batch: 147, Loss: 0.6956865191459656, Accuracy: 0.7744140625\n",
      "Batch: 148, Loss: 0.7725425958633423, Accuracy: 0.740234375\n",
      "Batch: 149, Loss: 0.6958214640617371, Accuracy: 0.7626953125\n",
      "Batch: 150, Loss: 0.7442532777786255, Accuracy: 0.7587890625\n",
      "Batch: 151, Loss: 0.6157695055007935, Accuracy: 0.7958984375\n",
      "Epoch 50/80\n",
      "Batch: 1, Loss: 0.8906285166740417, Accuracy: 0.7236328125\n",
      "Batch: 2, Loss: 0.784611165523529, Accuracy: 0.724609375\n",
      "Batch: 3, Loss: 0.6595242619514465, Accuracy: 0.7939453125\n",
      "Batch: 4, Loss: 0.6650819778442383, Accuracy: 0.810546875\n",
      "Batch: 5, Loss: 0.6523301601409912, Accuracy: 0.791015625\n",
      "Batch: 6, Loss: 0.7195971012115479, Accuracy: 0.7587890625\n",
      "Batch: 7, Loss: 0.6813592910766602, Accuracy: 0.779296875\n",
      "Batch: 8, Loss: 0.6676269173622131, Accuracy: 0.7880859375\n",
      "Batch: 9, Loss: 0.6838019490242004, Accuracy: 0.7783203125\n",
      "Batch: 10, Loss: 0.6683881282806396, Accuracy: 0.7744140625\n",
      "Batch: 11, Loss: 0.7438592314720154, Accuracy: 0.748046875\n",
      "Batch: 12, Loss: 0.733867347240448, Accuracy: 0.765625\n",
      "Batch: 13, Loss: 0.600786030292511, Accuracy: 0.80078125\n",
      "Batch: 14, Loss: 0.7366451025009155, Accuracy: 0.75390625\n",
      "Batch: 15, Loss: 0.6457149982452393, Accuracy: 0.8095703125\n",
      "Batch: 16, Loss: 0.6314163208007812, Accuracy: 0.8056640625\n",
      "Batch: 17, Loss: 0.7093416452407837, Accuracy: 0.7763671875\n",
      "Batch: 18, Loss: 0.7377294301986694, Accuracy: 0.759765625\n",
      "Batch: 19, Loss: 0.7338083386421204, Accuracy: 0.765625\n",
      "Batch: 20, Loss: 0.6686984300613403, Accuracy: 0.783203125\n",
      "Batch: 21, Loss: 0.6631515026092529, Accuracy: 0.7841796875\n",
      "Batch: 22, Loss: 0.7752613425254822, Accuracy: 0.75\n",
      "Batch: 23, Loss: 0.7613949775695801, Accuracy: 0.751953125\n",
      "Batch: 24, Loss: 0.7429162263870239, Accuracy: 0.759765625\n",
      "Batch: 25, Loss: 0.6922190189361572, Accuracy: 0.7763671875\n",
      "Batch: 26, Loss: 0.6027413010597229, Accuracy: 0.8095703125\n",
      "Batch: 27, Loss: 0.6814442276954651, Accuracy: 0.7685546875\n",
      "Batch: 28, Loss: 0.6802040934562683, Accuracy: 0.7744140625\n",
      "Batch: 29, Loss: 0.6956342458724976, Accuracy: 0.7724609375\n",
      "Batch: 30, Loss: 0.6555497646331787, Accuracy: 0.80078125\n",
      "Batch: 31, Loss: 0.6202182769775391, Accuracy: 0.7890625\n",
      "Batch: 32, Loss: 0.6410000324249268, Accuracy: 0.79296875\n",
      "Batch: 33, Loss: 0.7493152618408203, Accuracy: 0.7587890625\n",
      "Batch: 34, Loss: 0.7667345404624939, Accuracy: 0.7548828125\n",
      "Batch: 35, Loss: 0.7527849674224854, Accuracy: 0.7451171875\n",
      "Batch: 36, Loss: 0.7195287942886353, Accuracy: 0.7724609375\n",
      "Batch: 37, Loss: 0.7303940653800964, Accuracy: 0.7607421875\n",
      "Batch: 38, Loss: 0.7543001174926758, Accuracy: 0.7431640625\n",
      "Batch: 39, Loss: 0.7312406301498413, Accuracy: 0.767578125\n",
      "Batch: 40, Loss: 0.7194719314575195, Accuracy: 0.7626953125\n",
      "Batch: 41, Loss: 0.6478928327560425, Accuracy: 0.7900390625\n",
      "Batch: 42, Loss: 0.5291971564292908, Accuracy: 0.8173828125\n",
      "Batch: 43, Loss: 0.6965624094009399, Accuracy: 0.7705078125\n",
      "Batch: 44, Loss: 0.7227098941802979, Accuracy: 0.7529296875\n",
      "Batch: 45, Loss: 0.6314059495925903, Accuracy: 0.787109375\n",
      "Batch: 46, Loss: 0.6814727783203125, Accuracy: 0.7783203125\n",
      "Batch: 47, Loss: 0.7178767919540405, Accuracy: 0.783203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 48, Loss: 0.6702513098716736, Accuracy: 0.7802734375\n",
      "Batch: 49, Loss: 0.759573221206665, Accuracy: 0.751953125\n",
      "Batch: 50, Loss: 0.7019790410995483, Accuracy: 0.7685546875\n",
      "Batch: 51, Loss: 0.7295967936515808, Accuracy: 0.7890625\n",
      "Batch: 52, Loss: 0.7106656432151794, Accuracy: 0.7783203125\n",
      "Batch: 53, Loss: 0.6327754259109497, Accuracy: 0.802734375\n",
      "Batch: 54, Loss: 0.6588865518569946, Accuracy: 0.7900390625\n",
      "Batch: 55, Loss: 0.7881326675415039, Accuracy: 0.7568359375\n",
      "Batch: 56, Loss: 0.7659918069839478, Accuracy: 0.755859375\n",
      "Batch: 57, Loss: 0.7055906057357788, Accuracy: 0.76953125\n",
      "Batch: 58, Loss: 0.7863059043884277, Accuracy: 0.744140625\n",
      "Batch: 59, Loss: 0.6994149684906006, Accuracy: 0.779296875\n",
      "Batch: 60, Loss: 0.6557320356369019, Accuracy: 0.7802734375\n",
      "Batch: 61, Loss: 0.7735361456871033, Accuracy: 0.7578125\n",
      "Batch: 62, Loss: 0.6584769487380981, Accuracy: 0.787109375\n",
      "Batch: 63, Loss: 0.7137680053710938, Accuracy: 0.7802734375\n",
      "Batch: 64, Loss: 0.669757604598999, Accuracy: 0.7783203125\n",
      "Batch: 65, Loss: 0.7225154638290405, Accuracy: 0.7724609375\n",
      "Batch: 66, Loss: 0.7140613794326782, Accuracy: 0.78125\n",
      "Batch: 67, Loss: 0.791975200176239, Accuracy: 0.74609375\n",
      "Batch: 68, Loss: 0.7690903544425964, Accuracy: 0.7607421875\n",
      "Batch: 69, Loss: 0.7295364141464233, Accuracy: 0.7529296875\n",
      "Batch: 70, Loss: 0.7578790187835693, Accuracy: 0.767578125\n",
      "Batch: 71, Loss: 0.7521742582321167, Accuracy: 0.7451171875\n",
      "Batch: 72, Loss: 0.6349480152130127, Accuracy: 0.7958984375\n",
      "Batch: 73, Loss: 0.6227977871894836, Accuracy: 0.8046875\n",
      "Batch: 74, Loss: 0.6372438669204712, Accuracy: 0.806640625\n",
      "Batch: 75, Loss: 0.6447693705558777, Accuracy: 0.8056640625\n",
      "Batch: 76, Loss: 0.7397074699401855, Accuracy: 0.7666015625\n",
      "Batch: 77, Loss: 0.6589640974998474, Accuracy: 0.7939453125\n",
      "Batch: 78, Loss: 0.6106469631195068, Accuracy: 0.8076171875\n",
      "Batch: 79, Loss: 0.6492976546287537, Accuracy: 0.806640625\n",
      "Batch: 80, Loss: 0.6341651678085327, Accuracy: 0.81640625\n",
      "Batch: 81, Loss: 0.7249334454536438, Accuracy: 0.73828125\n",
      "Batch: 82, Loss: 0.7152916193008423, Accuracy: 0.7646484375\n",
      "Batch: 83, Loss: 0.6347364783287048, Accuracy: 0.7939453125\n",
      "Batch: 84, Loss: 0.6712137460708618, Accuracy: 0.79296875\n",
      "Batch: 85, Loss: 0.6641050577163696, Accuracy: 0.78515625\n",
      "Batch: 86, Loss: 0.7976700067520142, Accuracy: 0.73828125\n",
      "Batch: 87, Loss: 0.6331454515457153, Accuracy: 0.794921875\n",
      "Batch: 88, Loss: 0.7179156541824341, Accuracy: 0.7900390625\n",
      "Batch: 89, Loss: 0.7082586884498596, Accuracy: 0.7666015625\n",
      "Batch: 90, Loss: 0.6846451163291931, Accuracy: 0.783203125\n",
      "Batch: 91, Loss: 0.6523181796073914, Accuracy: 0.7705078125\n",
      "Batch: 92, Loss: 0.7244875431060791, Accuracy: 0.7685546875\n",
      "Batch: 93, Loss: 0.7113610506057739, Accuracy: 0.759765625\n",
      "Batch: 94, Loss: 0.7311851382255554, Accuracy: 0.759765625\n",
      "Batch: 95, Loss: 0.7293397188186646, Accuracy: 0.7490234375\n",
      "Batch: 96, Loss: 0.7052619457244873, Accuracy: 0.7763671875\n",
      "Batch: 97, Loss: 0.5686938762664795, Accuracy: 0.822265625\n",
      "Batch: 98, Loss: 0.6990863680839539, Accuracy: 0.7685546875\n",
      "Batch: 99, Loss: 0.6918466091156006, Accuracy: 0.7646484375\n",
      "Batch: 100, Loss: 0.6883851885795593, Accuracy: 0.765625\n",
      "Batch: 101, Loss: 0.7600818872451782, Accuracy: 0.7587890625\n",
      "Batch: 102, Loss: 0.685806393623352, Accuracy: 0.775390625\n",
      "Batch: 103, Loss: 0.7392808794975281, Accuracy: 0.7685546875\n",
      "Batch: 104, Loss: 0.675477147102356, Accuracy: 0.78125\n",
      "Batch: 105, Loss: 0.7201367616653442, Accuracy: 0.7578125\n",
      "Batch: 106, Loss: 0.6095819473266602, Accuracy: 0.7998046875\n",
      "Batch: 107, Loss: 0.7068272829055786, Accuracy: 0.78125\n",
      "Batch: 108, Loss: 0.6636291742324829, Accuracy: 0.7802734375\n",
      "Batch: 109, Loss: 0.7334544658660889, Accuracy: 0.7744140625\n",
      "Batch: 110, Loss: 0.6489483118057251, Accuracy: 0.7890625\n",
      "Batch: 111, Loss: 0.7107635736465454, Accuracy: 0.7724609375\n",
      "Batch: 112, Loss: 0.6809080839157104, Accuracy: 0.78125\n",
      "Batch: 113, Loss: 0.7035825252532959, Accuracy: 0.771484375\n",
      "Batch: 114, Loss: 0.7329506874084473, Accuracy: 0.7568359375\n",
      "Batch: 115, Loss: 0.7977477312088013, Accuracy: 0.7353515625\n",
      "Batch: 116, Loss: 0.7547988891601562, Accuracy: 0.765625\n",
      "Batch: 117, Loss: 0.7272600531578064, Accuracy: 0.767578125\n",
      "Batch: 118, Loss: 0.6365352869033813, Accuracy: 0.802734375\n",
      "Batch: 119, Loss: 0.6557815074920654, Accuracy: 0.775390625\n",
      "Batch: 120, Loss: 0.6991484761238098, Accuracy: 0.76953125\n",
      "Batch: 121, Loss: 0.7557500600814819, Accuracy: 0.7421875\n",
      "Batch: 122, Loss: 0.6923251152038574, Accuracy: 0.775390625\n",
      "Batch: 123, Loss: 0.7140634059906006, Accuracy: 0.7626953125\n",
      "Batch: 124, Loss: 0.7012028098106384, Accuracy: 0.7763671875\n",
      "Batch: 125, Loss: 0.757836103439331, Accuracy: 0.7578125\n",
      "Batch: 126, Loss: 0.7028417587280273, Accuracy: 0.771484375\n",
      "Batch: 127, Loss: 0.6459877490997314, Accuracy: 0.7919921875\n",
      "Batch: 128, Loss: 0.7819495797157288, Accuracy: 0.7529296875\n",
      "Batch: 129, Loss: 0.6642429232597351, Accuracy: 0.7841796875\n",
      "Batch: 130, Loss: 0.7945139408111572, Accuracy: 0.7470703125\n",
      "Batch: 131, Loss: 0.7270651459693909, Accuracy: 0.77734375\n",
      "Batch: 132, Loss: 0.7672076225280762, Accuracy: 0.765625\n",
      "Batch: 133, Loss: 0.6996086835861206, Accuracy: 0.7705078125\n",
      "Batch: 134, Loss: 0.7072130441665649, Accuracy: 0.7490234375\n",
      "Batch: 135, Loss: 0.692753791809082, Accuracy: 0.775390625\n",
      "Batch: 136, Loss: 0.7143656611442566, Accuracy: 0.7607421875\n",
      "Batch: 137, Loss: 0.7191318273544312, Accuracy: 0.7578125\n",
      "Batch: 138, Loss: 0.638167142868042, Accuracy: 0.78515625\n",
      "Batch: 139, Loss: 0.6578903198242188, Accuracy: 0.7958984375\n",
      "Batch: 140, Loss: 0.7246735692024231, Accuracy: 0.7529296875\n",
      "Batch: 141, Loss: 0.7475427985191345, Accuracy: 0.7568359375\n",
      "Batch: 142, Loss: 0.8034313917160034, Accuracy: 0.7451171875\n",
      "Batch: 143, Loss: 0.7619434595108032, Accuracy: 0.751953125\n",
      "Batch: 144, Loss: 0.7214741706848145, Accuracy: 0.76953125\n",
      "Batch: 145, Loss: 0.6969271898269653, Accuracy: 0.765625\n",
      "Batch: 146, Loss: 0.7111624479293823, Accuracy: 0.763671875\n",
      "Batch: 147, Loss: 0.6976001262664795, Accuracy: 0.7724609375\n",
      "Batch: 148, Loss: 0.7364734411239624, Accuracy: 0.7607421875\n",
      "Batch: 149, Loss: 0.6796133518218994, Accuracy: 0.7802734375\n",
      "Batch: 150, Loss: 0.720971405506134, Accuracy: 0.7666015625\n",
      "Batch: 151, Loss: 0.6363029479980469, Accuracy: 0.783203125\n",
      "Saved Weights at epoch 50 to file Weights_50.h5\n",
      "Epoch 51/80\n",
      "Batch: 1, Loss: 0.8786717653274536, Accuracy: 0.7109375\n",
      "Batch: 2, Loss: 0.7695980072021484, Accuracy: 0.728515625\n",
      "Batch: 3, Loss: 0.6617770195007324, Accuracy: 0.77734375\n",
      "Batch: 4, Loss: 0.6444196701049805, Accuracy: 0.798828125\n",
      "Batch: 5, Loss: 0.6725926399230957, Accuracy: 0.7802734375\n",
      "Batch: 6, Loss: 0.700188398361206, Accuracy: 0.763671875\n",
      "Batch: 7, Loss: 0.6714394092559814, Accuracy: 0.7783203125\n",
      "Batch: 8, Loss: 0.6915888786315918, Accuracy: 0.7783203125\n",
      "Batch: 9, Loss: 0.6790510416030884, Accuracy: 0.78125\n",
      "Batch: 10, Loss: 0.6565231084823608, Accuracy: 0.787109375\n",
      "Batch: 11, Loss: 0.7550436854362488, Accuracy: 0.7451171875\n",
      "Batch: 12, Loss: 0.7334259152412415, Accuracy: 0.767578125\n",
      "Batch: 13, Loss: 0.6127992868423462, Accuracy: 0.80078125\n",
      "Batch: 14, Loss: 0.7436600923538208, Accuracy: 0.751953125\n",
      "Batch: 15, Loss: 0.6652320623397827, Accuracy: 0.7958984375\n",
      "Batch: 16, Loss: 0.663191556930542, Accuracy: 0.7919921875\n",
      "Batch: 17, Loss: 0.6895549893379211, Accuracy: 0.779296875\n",
      "Batch: 18, Loss: 0.722557544708252, Accuracy: 0.765625\n",
      "Batch: 19, Loss: 0.7328199744224548, Accuracy: 0.7763671875\n",
      "Batch: 20, Loss: 0.6627715826034546, Accuracy: 0.7900390625\n",
      "Batch: 21, Loss: 0.6264672875404358, Accuracy: 0.7900390625\n",
      "Batch: 22, Loss: 0.7573418021202087, Accuracy: 0.7490234375\n",
      "Batch: 23, Loss: 0.7453725934028625, Accuracy: 0.7509765625\n",
      "Batch: 24, Loss: 0.7234578728675842, Accuracy: 0.759765625\n",
      "Batch: 25, Loss: 0.6934597492218018, Accuracy: 0.7822265625\n",
      "Batch: 26, Loss: 0.5847610831260681, Accuracy: 0.828125\n",
      "Batch: 27, Loss: 0.6683217287063599, Accuracy: 0.775390625\n",
      "Batch: 28, Loss: 0.7011145949363708, Accuracy: 0.7685546875\n",
      "Batch: 29, Loss: 0.6902852654457092, Accuracy: 0.7734375\n",
      "Batch: 30, Loss: 0.6405932903289795, Accuracy: 0.798828125\n",
      "Batch: 31, Loss: 0.5798919200897217, Accuracy: 0.8193359375\n",
      "Batch: 32, Loss: 0.6543067693710327, Accuracy: 0.7998046875\n",
      "Batch: 33, Loss: 0.7276077270507812, Accuracy: 0.76953125\n",
      "Batch: 34, Loss: 0.7513188123703003, Accuracy: 0.7646484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 35, Loss: 0.714539647102356, Accuracy: 0.763671875\n",
      "Batch: 36, Loss: 0.6956450343132019, Accuracy: 0.7744140625\n",
      "Batch: 37, Loss: 0.6984061002731323, Accuracy: 0.759765625\n",
      "Batch: 38, Loss: 0.7290223240852356, Accuracy: 0.755859375\n",
      "Batch: 39, Loss: 0.723496675491333, Accuracy: 0.7734375\n",
      "Batch: 40, Loss: 0.7289345264434814, Accuracy: 0.765625\n",
      "Batch: 41, Loss: 0.6533887386322021, Accuracy: 0.78515625\n",
      "Batch: 42, Loss: 0.5410010814666748, Accuracy: 0.8212890625\n",
      "Batch: 43, Loss: 0.6617432832717896, Accuracy: 0.7861328125\n",
      "Batch: 44, Loss: 0.737866997718811, Accuracy: 0.759765625\n",
      "Batch: 45, Loss: 0.6342617869377136, Accuracy: 0.787109375\n",
      "Batch: 46, Loss: 0.638140082359314, Accuracy: 0.7939453125\n",
      "Batch: 47, Loss: 0.6784811019897461, Accuracy: 0.7919921875\n",
      "Batch: 48, Loss: 0.6616264581680298, Accuracy: 0.791015625\n",
      "Batch: 49, Loss: 0.7503159046173096, Accuracy: 0.7548828125\n",
      "Batch: 50, Loss: 0.6662631034851074, Accuracy: 0.78515625\n",
      "Batch: 51, Loss: 0.7318046689033508, Accuracy: 0.7568359375\n",
      "Batch: 52, Loss: 0.7017946243286133, Accuracy: 0.7724609375\n",
      "Batch: 53, Loss: 0.6141681671142578, Accuracy: 0.8017578125\n",
      "Batch: 54, Loss: 0.6704721450805664, Accuracy: 0.7880859375\n",
      "Batch: 55, Loss: 0.7995085716247559, Accuracy: 0.734375\n",
      "Batch: 56, Loss: 0.7823849320411682, Accuracy: 0.755859375\n",
      "Batch: 57, Loss: 0.7176824808120728, Accuracy: 0.7666015625\n",
      "Batch: 58, Loss: 0.8145393133163452, Accuracy: 0.73828125\n",
      "Batch: 59, Loss: 0.7120042443275452, Accuracy: 0.763671875\n",
      "Batch: 60, Loss: 0.6837072372436523, Accuracy: 0.771484375\n",
      "Batch: 61, Loss: 0.7212973833084106, Accuracy: 0.76171875\n",
      "Batch: 62, Loss: 0.6670649647712708, Accuracy: 0.77734375\n",
      "Batch: 63, Loss: 0.7134712934494019, Accuracy: 0.765625\n",
      "Batch: 64, Loss: 0.6711068153381348, Accuracy: 0.783203125\n",
      "Batch: 65, Loss: 0.7028495073318481, Accuracy: 0.7724609375\n",
      "Batch: 66, Loss: 0.7082273364067078, Accuracy: 0.7890625\n",
      "Batch: 67, Loss: 0.7599700689315796, Accuracy: 0.763671875\n",
      "Batch: 68, Loss: 0.7691853046417236, Accuracy: 0.7470703125\n",
      "Batch: 69, Loss: 0.7058960795402527, Accuracy: 0.7685546875\n",
      "Batch: 70, Loss: 0.7076783776283264, Accuracy: 0.79296875\n",
      "Batch: 71, Loss: 0.7318463325500488, Accuracy: 0.755859375\n",
      "Batch: 72, Loss: 0.6641629934310913, Accuracy: 0.7783203125\n",
      "Batch: 73, Loss: 0.6450306177139282, Accuracy: 0.8037109375\n",
      "Batch: 74, Loss: 0.6024386882781982, Accuracy: 0.822265625\n",
      "Batch: 75, Loss: 0.6105185747146606, Accuracy: 0.80078125\n",
      "Batch: 76, Loss: 0.7002520561218262, Accuracy: 0.7783203125\n",
      "Batch: 77, Loss: 0.6510218977928162, Accuracy: 0.79296875\n",
      "Batch: 78, Loss: 0.625615119934082, Accuracy: 0.802734375\n",
      "Batch: 79, Loss: 0.6278012990951538, Accuracy: 0.796875\n",
      "Batch: 80, Loss: 0.6419384479522705, Accuracy: 0.787109375\n",
      "Batch: 81, Loss: 0.7428773045539856, Accuracy: 0.7431640625\n",
      "Batch: 82, Loss: 0.720461905002594, Accuracy: 0.771484375\n",
      "Batch: 83, Loss: 0.6187870502471924, Accuracy: 0.794921875\n",
      "Batch: 84, Loss: 0.6900112628936768, Accuracy: 0.783203125\n",
      "Batch: 85, Loss: 0.6893752217292786, Accuracy: 0.791015625\n",
      "Batch: 86, Loss: 0.763905942440033, Accuracy: 0.748046875\n",
      "Batch: 87, Loss: 0.6366742849349976, Accuracy: 0.791015625\n",
      "Batch: 88, Loss: 0.7361547350883484, Accuracy: 0.779296875\n",
      "Batch: 89, Loss: 0.6826841831207275, Accuracy: 0.787109375\n",
      "Batch: 90, Loss: 0.6481351256370544, Accuracy: 0.80078125\n",
      "Batch: 91, Loss: 0.6553938388824463, Accuracy: 0.78125\n",
      "Batch: 92, Loss: 0.7053195834159851, Accuracy: 0.7734375\n",
      "Batch: 93, Loss: 0.6994447112083435, Accuracy: 0.77734375\n",
      "Batch: 94, Loss: 0.7039978504180908, Accuracy: 0.77734375\n",
      "Batch: 95, Loss: 0.7065045833587646, Accuracy: 0.763671875\n",
      "Batch: 96, Loss: 0.6908193826675415, Accuracy: 0.783203125\n",
      "Batch: 97, Loss: 0.5668829679489136, Accuracy: 0.8056640625\n",
      "Batch: 98, Loss: 0.7033342123031616, Accuracy: 0.775390625\n",
      "Batch: 99, Loss: 0.6810594797134399, Accuracy: 0.7861328125\n",
      "Batch: 100, Loss: 0.6723106503486633, Accuracy: 0.77734375\n",
      "Batch: 101, Loss: 0.7065497636795044, Accuracy: 0.7822265625\n",
      "Batch: 102, Loss: 0.7144109010696411, Accuracy: 0.763671875\n",
      "Batch: 103, Loss: 0.7301299571990967, Accuracy: 0.7705078125\n",
      "Batch: 104, Loss: 0.6408675312995911, Accuracy: 0.787109375\n",
      "Batch: 105, Loss: 0.6807637214660645, Accuracy: 0.76953125\n",
      "Batch: 106, Loss: 0.6652592420578003, Accuracy: 0.7822265625\n",
      "Batch: 107, Loss: 0.6997590065002441, Accuracy: 0.783203125\n",
      "Batch: 108, Loss: 0.6945099234580994, Accuracy: 0.7783203125\n",
      "Batch: 109, Loss: 0.7392678260803223, Accuracy: 0.7578125\n",
      "Batch: 110, Loss: 0.6346324682235718, Accuracy: 0.787109375\n",
      "Batch: 111, Loss: 0.7012895345687866, Accuracy: 0.7744140625\n",
      "Batch: 112, Loss: 0.6931242346763611, Accuracy: 0.775390625\n",
      "Batch: 113, Loss: 0.716168999671936, Accuracy: 0.765625\n",
      "Batch: 114, Loss: 0.7554951310157776, Accuracy: 0.748046875\n",
      "Batch: 115, Loss: 0.7705103158950806, Accuracy: 0.7607421875\n",
      "Batch: 116, Loss: 0.744175910949707, Accuracy: 0.75\n",
      "Batch: 117, Loss: 0.7719061374664307, Accuracy: 0.7509765625\n",
      "Batch: 118, Loss: 0.6271171569824219, Accuracy: 0.7998046875\n",
      "Batch: 119, Loss: 0.6325581669807434, Accuracy: 0.794921875\n",
      "Batch: 120, Loss: 0.6912453770637512, Accuracy: 0.7744140625\n",
      "Batch: 121, Loss: 0.7399531602859497, Accuracy: 0.7578125\n",
      "Batch: 122, Loss: 0.701623797416687, Accuracy: 0.7763671875\n",
      "Batch: 123, Loss: 0.6841762065887451, Accuracy: 0.787109375\n",
      "Batch: 124, Loss: 0.7102144360542297, Accuracy: 0.7734375\n",
      "Batch: 125, Loss: 0.7378597259521484, Accuracy: 0.7626953125\n",
      "Batch: 126, Loss: 0.687796950340271, Accuracy: 0.77734375\n",
      "Batch: 127, Loss: 0.6302300095558167, Accuracy: 0.798828125\n",
      "Batch: 128, Loss: 0.7841813564300537, Accuracy: 0.7412109375\n",
      "Batch: 129, Loss: 0.6687057018280029, Accuracy: 0.787109375\n",
      "Batch: 130, Loss: 0.7678031325340271, Accuracy: 0.75390625\n",
      "Batch: 131, Loss: 0.7453708648681641, Accuracy: 0.763671875\n",
      "Batch: 132, Loss: 0.7139511108398438, Accuracy: 0.7744140625\n",
      "Batch: 133, Loss: 0.6955690383911133, Accuracy: 0.783203125\n",
      "Batch: 134, Loss: 0.684252142906189, Accuracy: 0.7578125\n",
      "Batch: 135, Loss: 0.6673939228057861, Accuracy: 0.78125\n",
      "Batch: 136, Loss: 0.720109224319458, Accuracy: 0.7646484375\n",
      "Batch: 137, Loss: 0.7268878817558289, Accuracy: 0.7451171875\n",
      "Batch: 138, Loss: 0.6372729539871216, Accuracy: 0.7802734375\n",
      "Batch: 139, Loss: 0.6562947034835815, Accuracy: 0.78125\n",
      "Batch: 140, Loss: 0.7417619824409485, Accuracy: 0.759765625\n",
      "Batch: 141, Loss: 0.7777866125106812, Accuracy: 0.732421875\n",
      "Batch: 142, Loss: 0.7858937382698059, Accuracy: 0.751953125\n",
      "Batch: 143, Loss: 0.6996656060218811, Accuracy: 0.779296875\n",
      "Batch: 144, Loss: 0.6646279692649841, Accuracy: 0.78515625\n",
      "Batch: 145, Loss: 0.6543098092079163, Accuracy: 0.771484375\n",
      "Batch: 146, Loss: 0.717120885848999, Accuracy: 0.765625\n",
      "Batch: 147, Loss: 0.7082507610321045, Accuracy: 0.76953125\n",
      "Batch: 148, Loss: 0.7360867261886597, Accuracy: 0.7626953125\n",
      "Batch: 149, Loss: 0.6784123182296753, Accuracy: 0.7685546875\n",
      "Batch: 150, Loss: 0.7343093156814575, Accuracy: 0.7587890625\n",
      "Batch: 151, Loss: 0.64021235704422, Accuracy: 0.7919921875\n",
      "Epoch 52/80\n",
      "Batch: 1, Loss: 0.8930690288543701, Accuracy: 0.7255859375\n",
      "Batch: 2, Loss: 0.7853580713272095, Accuracy: 0.73046875\n",
      "Batch: 3, Loss: 0.6610180735588074, Accuracy: 0.77734375\n",
      "Batch: 4, Loss: 0.63113933801651, Accuracy: 0.8046875\n",
      "Batch: 5, Loss: 0.6602389812469482, Accuracy: 0.787109375\n",
      "Batch: 6, Loss: 0.7066261172294617, Accuracy: 0.763671875\n",
      "Batch: 7, Loss: 0.6803686022758484, Accuracy: 0.767578125\n",
      "Batch: 8, Loss: 0.6747562289237976, Accuracy: 0.7783203125\n",
      "Batch: 9, Loss: 0.6535799503326416, Accuracy: 0.7841796875\n",
      "Batch: 10, Loss: 0.6413544416427612, Accuracy: 0.7890625\n",
      "Batch: 11, Loss: 0.731757402420044, Accuracy: 0.7568359375\n",
      "Batch: 12, Loss: 0.7197949886322021, Accuracy: 0.7548828125\n",
      "Batch: 13, Loss: 0.6019081473350525, Accuracy: 0.796875\n",
      "Batch: 14, Loss: 0.7557474374771118, Accuracy: 0.759765625\n",
      "Batch: 15, Loss: 0.6512278318405151, Accuracy: 0.8037109375\n",
      "Batch: 16, Loss: 0.6311611533164978, Accuracy: 0.8046875\n",
      "Batch: 17, Loss: 0.6480515003204346, Accuracy: 0.7880859375\n",
      "Batch: 18, Loss: 0.731997013092041, Accuracy: 0.765625\n",
      "Batch: 19, Loss: 0.725589394569397, Accuracy: 0.771484375\n",
      "Batch: 20, Loss: 0.6350897550582886, Accuracy: 0.798828125\n",
      "Batch: 21, Loss: 0.6748161315917969, Accuracy: 0.78515625\n",
      "Batch: 22, Loss: 0.756553590297699, Accuracy: 0.7529296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 23, Loss: 0.7288345694541931, Accuracy: 0.765625\n",
      "Batch: 24, Loss: 0.7563355565071106, Accuracy: 0.7587890625\n",
      "Batch: 25, Loss: 0.6679585576057434, Accuracy: 0.7822265625\n",
      "Batch: 26, Loss: 0.5874495506286621, Accuracy: 0.8056640625\n",
      "Batch: 27, Loss: 0.6469396948814392, Accuracy: 0.7802734375\n",
      "Batch: 28, Loss: 0.6947499513626099, Accuracy: 0.765625\n",
      "Batch: 29, Loss: 0.6860702037811279, Accuracy: 0.7822265625\n",
      "Batch: 30, Loss: 0.6307916641235352, Accuracy: 0.7919921875\n",
      "Batch: 31, Loss: 0.61451256275177, Accuracy: 0.80859375\n",
      "Batch: 32, Loss: 0.6282477974891663, Accuracy: 0.8017578125\n",
      "Batch: 33, Loss: 0.7280621528625488, Accuracy: 0.7724609375\n",
      "Batch: 34, Loss: 0.7691898345947266, Accuracy: 0.755859375\n",
      "Batch: 35, Loss: 0.7274601459503174, Accuracy: 0.7587890625\n",
      "Batch: 36, Loss: 0.7049585580825806, Accuracy: 0.7705078125\n",
      "Batch: 37, Loss: 0.7049739360809326, Accuracy: 0.7685546875\n",
      "Batch: 38, Loss: 0.7194797396659851, Accuracy: 0.759765625\n",
      "Batch: 39, Loss: 0.7026442289352417, Accuracy: 0.7783203125\n",
      "Batch: 40, Loss: 0.6860988140106201, Accuracy: 0.7724609375\n",
      "Batch: 41, Loss: 0.621515154838562, Accuracy: 0.791015625\n",
      "Batch: 42, Loss: 0.5309361219406128, Accuracy: 0.830078125\n",
      "Batch: 43, Loss: 0.6616226434707642, Accuracy: 0.7841796875\n",
      "Batch: 44, Loss: 0.7131905555725098, Accuracy: 0.76953125\n",
      "Batch: 45, Loss: 0.6197258830070496, Accuracy: 0.79296875\n",
      "Batch: 46, Loss: 0.6538603901863098, Accuracy: 0.79296875\n",
      "Batch: 47, Loss: 0.6790856719017029, Accuracy: 0.7822265625\n",
      "Batch: 48, Loss: 0.6524741649627686, Accuracy: 0.787109375\n",
      "Batch: 49, Loss: 0.7233036756515503, Accuracy: 0.7802734375\n",
      "Batch: 50, Loss: 0.6643493175506592, Accuracy: 0.7822265625\n",
      "Batch: 51, Loss: 0.728617787361145, Accuracy: 0.7724609375\n",
      "Batch: 52, Loss: 0.6830152273178101, Accuracy: 0.787109375\n",
      "Batch: 53, Loss: 0.6069198250770569, Accuracy: 0.802734375\n",
      "Batch: 54, Loss: 0.6447083353996277, Accuracy: 0.7998046875\n",
      "Batch: 55, Loss: 0.7574665546417236, Accuracy: 0.7451171875\n",
      "Batch: 56, Loss: 0.7384405732154846, Accuracy: 0.7607421875\n",
      "Batch: 57, Loss: 0.7026235461235046, Accuracy: 0.7646484375\n",
      "Batch: 58, Loss: 0.7964480519294739, Accuracy: 0.748046875\n",
      "Batch: 59, Loss: 0.7356310486793518, Accuracy: 0.7626953125\n",
      "Batch: 60, Loss: 0.6606733798980713, Accuracy: 0.7763671875\n",
      "Batch: 61, Loss: 0.7209019660949707, Accuracy: 0.767578125\n",
      "Batch: 62, Loss: 0.641417384147644, Accuracy: 0.783203125\n",
      "Batch: 63, Loss: 0.7144998908042908, Accuracy: 0.7607421875\n",
      "Batch: 64, Loss: 0.6714866161346436, Accuracy: 0.7783203125\n",
      "Batch: 65, Loss: 0.7119402885437012, Accuracy: 0.7822265625\n",
      "Batch: 66, Loss: 0.7277722954750061, Accuracy: 0.7724609375\n",
      "Batch: 67, Loss: 0.738072395324707, Accuracy: 0.79296875\n",
      "Batch: 68, Loss: 0.7626785635948181, Accuracy: 0.7548828125\n",
      "Batch: 69, Loss: 0.7175480127334595, Accuracy: 0.767578125\n",
      "Batch: 70, Loss: 0.6971153020858765, Accuracy: 0.791015625\n",
      "Batch: 71, Loss: 0.7180606126785278, Accuracy: 0.7763671875\n",
      "Batch: 72, Loss: 0.6562461256980896, Accuracy: 0.783203125\n",
      "Batch: 73, Loss: 0.645190417766571, Accuracy: 0.7900390625\n",
      "Batch: 74, Loss: 0.6075195670127869, Accuracy: 0.814453125\n",
      "Batch: 75, Loss: 0.5982110500335693, Accuracy: 0.8115234375\n",
      "Batch: 76, Loss: 0.6943886876106262, Accuracy: 0.7939453125\n",
      "Batch: 77, Loss: 0.6289081573486328, Accuracy: 0.806640625\n",
      "Batch: 78, Loss: 0.6023455858230591, Accuracy: 0.822265625\n",
      "Batch: 79, Loss: 0.6527235507965088, Accuracy: 0.8056640625\n",
      "Batch: 80, Loss: 0.6566064953804016, Accuracy: 0.79296875\n",
      "Batch: 81, Loss: 0.6961687803268433, Accuracy: 0.7607421875\n",
      "Batch: 82, Loss: 0.7218570709228516, Accuracy: 0.7744140625\n",
      "Batch: 83, Loss: 0.6185880899429321, Accuracy: 0.8017578125\n",
      "Batch: 84, Loss: 0.6688620448112488, Accuracy: 0.78125\n",
      "Batch: 85, Loss: 0.7077731490135193, Accuracy: 0.7958984375\n",
      "Batch: 86, Loss: 0.7903913259506226, Accuracy: 0.748046875\n",
      "Batch: 87, Loss: 0.622378945350647, Accuracy: 0.802734375\n",
      "Batch: 88, Loss: 0.7275141477584839, Accuracy: 0.7724609375\n",
      "Batch: 89, Loss: 0.7262090444564819, Accuracy: 0.7705078125\n",
      "Batch: 90, Loss: 0.6766574382781982, Accuracy: 0.7919921875\n",
      "Batch: 91, Loss: 0.6519750356674194, Accuracy: 0.779296875\n",
      "Batch: 92, Loss: 0.7141438126564026, Accuracy: 0.771484375\n",
      "Batch: 93, Loss: 0.7086431980133057, Accuracy: 0.7763671875\n",
      "Batch: 94, Loss: 0.7100687026977539, Accuracy: 0.767578125\n",
      "Batch: 95, Loss: 0.6865695714950562, Accuracy: 0.763671875\n",
      "Batch: 96, Loss: 0.7039994597434998, Accuracy: 0.7646484375\n",
      "Batch: 97, Loss: 0.5662177801132202, Accuracy: 0.8046875\n",
      "Batch: 98, Loss: 0.693244457244873, Accuracy: 0.7734375\n",
      "Batch: 99, Loss: 0.6681140065193176, Accuracy: 0.783203125\n",
      "Batch: 100, Loss: 0.698062539100647, Accuracy: 0.7744140625\n",
      "Batch: 101, Loss: 0.7568663358688354, Accuracy: 0.7509765625\n",
      "Batch: 102, Loss: 0.7210339307785034, Accuracy: 0.755859375\n",
      "Batch: 103, Loss: 0.7483911514282227, Accuracy: 0.759765625\n",
      "Batch: 104, Loss: 0.650467038154602, Accuracy: 0.791015625\n",
      "Batch: 105, Loss: 0.6894400119781494, Accuracy: 0.7744140625\n",
      "Batch: 106, Loss: 0.6169633865356445, Accuracy: 0.791015625\n",
      "Batch: 107, Loss: 0.6775360107421875, Accuracy: 0.7958984375\n",
      "Batch: 108, Loss: 0.6789946556091309, Accuracy: 0.7802734375\n",
      "Batch: 109, Loss: 0.7088140249252319, Accuracy: 0.7685546875\n",
      "Batch: 110, Loss: 0.6425415277481079, Accuracy: 0.791015625\n",
      "Batch: 111, Loss: 0.6658293008804321, Accuracy: 0.779296875\n",
      "Batch: 112, Loss: 0.6894385814666748, Accuracy: 0.779296875\n",
      "Batch: 113, Loss: 0.7330805063247681, Accuracy: 0.7666015625\n",
      "Batch: 114, Loss: 0.7627391815185547, Accuracy: 0.7646484375\n",
      "Batch: 115, Loss: 0.7640669345855713, Accuracy: 0.7607421875\n",
      "Batch: 116, Loss: 0.6955254077911377, Accuracy: 0.7724609375\n",
      "Batch: 117, Loss: 0.7731674313545227, Accuracy: 0.7646484375\n",
      "Batch: 118, Loss: 0.6539281606674194, Accuracy: 0.7880859375\n",
      "Batch: 119, Loss: 0.6130870580673218, Accuracy: 0.80078125\n",
      "Batch: 120, Loss: 0.6920748949050903, Accuracy: 0.76953125\n",
      "Batch: 121, Loss: 0.7318001985549927, Accuracy: 0.755859375\n",
      "Batch: 122, Loss: 0.6655423045158386, Accuracy: 0.796875\n",
      "Batch: 123, Loss: 0.6485172510147095, Accuracy: 0.802734375\n",
      "Batch: 124, Loss: 0.7062257528305054, Accuracy: 0.7685546875\n",
      "Batch: 125, Loss: 0.7412629127502441, Accuracy: 0.75390625\n",
      "Batch: 126, Loss: 0.7120174765586853, Accuracy: 0.767578125\n",
      "Batch: 127, Loss: 0.6182651519775391, Accuracy: 0.794921875\n",
      "Batch: 128, Loss: 0.7728363871574402, Accuracy: 0.7451171875\n",
      "Batch: 129, Loss: 0.6394396424293518, Accuracy: 0.787109375\n",
      "Batch: 130, Loss: 0.7601689100265503, Accuracy: 0.759765625\n",
      "Batch: 131, Loss: 0.7189975380897522, Accuracy: 0.7470703125\n",
      "Batch: 132, Loss: 0.7504384517669678, Accuracy: 0.7646484375\n",
      "Batch: 133, Loss: 0.6599322557449341, Accuracy: 0.779296875\n",
      "Batch: 134, Loss: 0.6810606122016907, Accuracy: 0.7607421875\n",
      "Batch: 135, Loss: 0.6806329488754272, Accuracy: 0.7783203125\n",
      "Batch: 136, Loss: 0.7027052044868469, Accuracy: 0.767578125\n",
      "Batch: 137, Loss: 0.701364278793335, Accuracy: 0.7607421875\n",
      "Batch: 138, Loss: 0.6408386826515198, Accuracy: 0.7783203125\n",
      "Batch: 139, Loss: 0.6402932405471802, Accuracy: 0.78515625\n",
      "Batch: 140, Loss: 0.7430703043937683, Accuracy: 0.7646484375\n",
      "Batch: 141, Loss: 0.737278401851654, Accuracy: 0.7607421875\n",
      "Batch: 142, Loss: 0.7938880920410156, Accuracy: 0.75\n",
      "Batch: 143, Loss: 0.694976806640625, Accuracy: 0.7685546875\n",
      "Batch: 144, Loss: 0.7191381454467773, Accuracy: 0.7529296875\n",
      "Batch: 145, Loss: 0.6421810388565063, Accuracy: 0.783203125\n",
      "Batch: 146, Loss: 0.7182683944702148, Accuracy: 0.765625\n",
      "Batch: 147, Loss: 0.6728283166885376, Accuracy: 0.7919921875\n",
      "Batch: 148, Loss: 0.745577335357666, Accuracy: 0.755859375\n",
      "Batch: 149, Loss: 0.6759239435195923, Accuracy: 0.7763671875\n",
      "Batch: 150, Loss: 0.7442410588264465, Accuracy: 0.75\n",
      "Batch: 151, Loss: 0.6185362339019775, Accuracy: 0.802734375\n",
      "Epoch 53/80\n",
      "Batch: 1, Loss: 0.8754913806915283, Accuracy: 0.724609375\n",
      "Batch: 2, Loss: 0.7161287665367126, Accuracy: 0.7578125\n",
      "Batch: 3, Loss: 0.6713729500770569, Accuracy: 0.7841796875\n",
      "Batch: 4, Loss: 0.6529397964477539, Accuracy: 0.7978515625\n",
      "Batch: 5, Loss: 0.6712638735771179, Accuracy: 0.7861328125\n",
      "Batch: 6, Loss: 0.6868393421173096, Accuracy: 0.779296875\n",
      "Batch: 7, Loss: 0.6745764017105103, Accuracy: 0.7724609375\n",
      "Batch: 8, Loss: 0.6824034452438354, Accuracy: 0.7822265625\n",
      "Batch: 9, Loss: 0.6549414396286011, Accuracy: 0.775390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10, Loss: 0.6061944961547852, Accuracy: 0.79296875\n",
      "Batch: 11, Loss: 0.7164093255996704, Accuracy: 0.7607421875\n",
      "Batch: 12, Loss: 0.7047436833381653, Accuracy: 0.7724609375\n",
      "Batch: 13, Loss: 0.5564171075820923, Accuracy: 0.8251953125\n",
      "Batch: 14, Loss: 0.7277240753173828, Accuracy: 0.76953125\n",
      "Batch: 15, Loss: 0.6612656712532043, Accuracy: 0.791015625\n",
      "Batch: 16, Loss: 0.6419003009796143, Accuracy: 0.8056640625\n",
      "Batch: 17, Loss: 0.6837137937545776, Accuracy: 0.779296875\n",
      "Batch: 18, Loss: 0.706648588180542, Accuracy: 0.763671875\n",
      "Batch: 19, Loss: 0.7065651416778564, Accuracy: 0.78125\n",
      "Batch: 20, Loss: 0.6343570947647095, Accuracy: 0.7900390625\n",
      "Batch: 21, Loss: 0.6244656443595886, Accuracy: 0.7939453125\n",
      "Batch: 22, Loss: 0.7622922658920288, Accuracy: 0.7509765625\n",
      "Batch: 23, Loss: 0.7179105877876282, Accuracy: 0.7607421875\n",
      "Batch: 24, Loss: 0.7073231935501099, Accuracy: 0.767578125\n",
      "Batch: 25, Loss: 0.6566764116287231, Accuracy: 0.8076171875\n",
      "Batch: 26, Loss: 0.593543291091919, Accuracy: 0.7998046875\n",
      "Batch: 27, Loss: 0.6399604082107544, Accuracy: 0.7744140625\n",
      "Batch: 28, Loss: 0.6773456931114197, Accuracy: 0.771484375\n",
      "Batch: 29, Loss: 0.6367349624633789, Accuracy: 0.7939453125\n",
      "Batch: 30, Loss: 0.6409099102020264, Accuracy: 0.80078125\n",
      "Batch: 31, Loss: 0.6009964942932129, Accuracy: 0.796875\n",
      "Batch: 32, Loss: 0.6285457611083984, Accuracy: 0.7822265625\n",
      "Batch: 33, Loss: 0.7084131836891174, Accuracy: 0.7646484375\n",
      "Batch: 34, Loss: 0.767562747001648, Accuracy: 0.7509765625\n",
      "Batch: 35, Loss: 0.7330415844917297, Accuracy: 0.751953125\n",
      "Batch: 36, Loss: 0.7030754089355469, Accuracy: 0.771484375\n",
      "Batch: 37, Loss: 0.7151653170585632, Accuracy: 0.771484375\n",
      "Batch: 38, Loss: 0.7119922637939453, Accuracy: 0.7685546875\n",
      "Batch: 39, Loss: 0.6956758499145508, Accuracy: 0.77734375\n",
      "Batch: 40, Loss: 0.6513584852218628, Accuracy: 0.80078125\n",
      "Batch: 41, Loss: 0.6180025339126587, Accuracy: 0.8017578125\n",
      "Batch: 42, Loss: 0.5101406574249268, Accuracy: 0.8349609375\n",
      "Batch: 43, Loss: 0.6599398255348206, Accuracy: 0.7900390625\n",
      "Batch: 44, Loss: 0.6955693364143372, Accuracy: 0.775390625\n",
      "Batch: 45, Loss: 0.6129109859466553, Accuracy: 0.7939453125\n",
      "Batch: 46, Loss: 0.6180548667907715, Accuracy: 0.8056640625\n",
      "Batch: 47, Loss: 0.6908689737319946, Accuracy: 0.7919921875\n",
      "Batch: 48, Loss: 0.6366625428199768, Accuracy: 0.794921875\n",
      "Batch: 49, Loss: 0.7284968495368958, Accuracy: 0.7744140625\n",
      "Batch: 50, Loss: 0.630273163318634, Accuracy: 0.7958984375\n",
      "Batch: 51, Loss: 0.7058345675468445, Accuracy: 0.7744140625\n",
      "Batch: 52, Loss: 0.6927425861358643, Accuracy: 0.7841796875\n",
      "Batch: 53, Loss: 0.6033272743225098, Accuracy: 0.798828125\n",
      "Batch: 54, Loss: 0.6810876727104187, Accuracy: 0.775390625\n",
      "Batch: 55, Loss: 0.7250585556030273, Accuracy: 0.75\n",
      "Batch: 56, Loss: 0.7329224348068237, Accuracy: 0.7626953125\n",
      "Batch: 57, Loss: 0.7246767282485962, Accuracy: 0.76171875\n",
      "Batch: 58, Loss: 0.7508691549301147, Accuracy: 0.7666015625\n",
      "Batch: 59, Loss: 0.6776407957077026, Accuracy: 0.76953125\n",
      "Batch: 60, Loss: 0.6308084726333618, Accuracy: 0.7998046875\n",
      "Batch: 61, Loss: 0.7344421148300171, Accuracy: 0.775390625\n",
      "Batch: 62, Loss: 0.6121559143066406, Accuracy: 0.806640625\n",
      "Batch: 63, Loss: 0.7127702832221985, Accuracy: 0.7734375\n",
      "Batch: 64, Loss: 0.6676883697509766, Accuracy: 0.775390625\n",
      "Batch: 65, Loss: 0.6982315182685852, Accuracy: 0.7822265625\n",
      "Batch: 66, Loss: 0.6700198650360107, Accuracy: 0.7861328125\n",
      "Batch: 67, Loss: 0.7822751998901367, Accuracy: 0.755859375\n",
      "Batch: 68, Loss: 0.7432340383529663, Accuracy: 0.7568359375\n",
      "Batch: 69, Loss: 0.6829216480255127, Accuracy: 0.7744140625\n",
      "Batch: 70, Loss: 0.7056819796562195, Accuracy: 0.78515625\n",
      "Batch: 71, Loss: 0.7233644723892212, Accuracy: 0.7568359375\n",
      "Batch: 72, Loss: 0.6454795598983765, Accuracy: 0.78125\n",
      "Batch: 73, Loss: 0.6283847093582153, Accuracy: 0.80859375\n",
      "Batch: 74, Loss: 0.6130334138870239, Accuracy: 0.8193359375\n",
      "Batch: 75, Loss: 0.5889613628387451, Accuracy: 0.80859375\n",
      "Batch: 76, Loss: 0.6967867612838745, Accuracy: 0.7763671875\n",
      "Batch: 77, Loss: 0.6325987577438354, Accuracy: 0.7890625\n",
      "Batch: 78, Loss: 0.6031978726387024, Accuracy: 0.80078125\n",
      "Batch: 79, Loss: 0.6560223698616028, Accuracy: 0.8017578125\n",
      "Batch: 80, Loss: 0.6394748091697693, Accuracy: 0.802734375\n",
      "Batch: 81, Loss: 0.7362819910049438, Accuracy: 0.751953125\n",
      "Batch: 82, Loss: 0.6920338869094849, Accuracy: 0.775390625\n",
      "Batch: 83, Loss: 0.6048637628555298, Accuracy: 0.8115234375\n",
      "Batch: 84, Loss: 0.6660542488098145, Accuracy: 0.7861328125\n",
      "Batch: 85, Loss: 0.6495323181152344, Accuracy: 0.7841796875\n",
      "Batch: 86, Loss: 0.7614818811416626, Accuracy: 0.76953125\n",
      "Batch: 87, Loss: 0.6358006000518799, Accuracy: 0.7978515625\n",
      "Batch: 88, Loss: 0.6988275051116943, Accuracy: 0.775390625\n",
      "Batch: 89, Loss: 0.6993122696876526, Accuracy: 0.7724609375\n",
      "Batch: 90, Loss: 0.6495888233184814, Accuracy: 0.787109375\n",
      "Batch: 91, Loss: 0.6434760689735413, Accuracy: 0.78515625\n",
      "Batch: 92, Loss: 0.7108900547027588, Accuracy: 0.76953125\n",
      "Batch: 93, Loss: 0.6621789932250977, Accuracy: 0.783203125\n",
      "Batch: 94, Loss: 0.7089365720748901, Accuracy: 0.763671875\n",
      "Batch: 95, Loss: 0.7036912441253662, Accuracy: 0.767578125\n",
      "Batch: 96, Loss: 0.6764757633209229, Accuracy: 0.7822265625\n",
      "Batch: 97, Loss: 0.5565465688705444, Accuracy: 0.8154296875\n",
      "Batch: 98, Loss: 0.7057071924209595, Accuracy: 0.775390625\n",
      "Batch: 99, Loss: 0.6533640623092651, Accuracy: 0.7822265625\n",
      "Batch: 100, Loss: 0.6828058362007141, Accuracy: 0.7685546875\n",
      "Batch: 101, Loss: 0.7390310168266296, Accuracy: 0.75\n",
      "Batch: 102, Loss: 0.6893513202667236, Accuracy: 0.7685546875\n",
      "Batch: 103, Loss: 0.6961517333984375, Accuracy: 0.78125\n",
      "Batch: 104, Loss: 0.626201868057251, Accuracy: 0.7939453125\n",
      "Batch: 105, Loss: 0.6900460124015808, Accuracy: 0.7607421875\n",
      "Batch: 106, Loss: 0.6044913530349731, Accuracy: 0.8095703125\n",
      "Batch: 107, Loss: 0.6641719341278076, Accuracy: 0.7861328125\n",
      "Batch: 108, Loss: 0.6767661571502686, Accuracy: 0.7939453125\n",
      "Batch: 109, Loss: 0.7088532447814941, Accuracy: 0.7734375\n",
      "Batch: 110, Loss: 0.6314697265625, Accuracy: 0.7939453125\n",
      "Batch: 111, Loss: 0.703788161277771, Accuracy: 0.759765625\n",
      "Batch: 112, Loss: 0.6728099584579468, Accuracy: 0.767578125\n",
      "Batch: 113, Loss: 0.6628443598747253, Accuracy: 0.787109375\n",
      "Batch: 114, Loss: 0.733352780342102, Accuracy: 0.765625\n",
      "Batch: 115, Loss: 0.7517098784446716, Accuracy: 0.7509765625\n",
      "Batch: 116, Loss: 0.6742404699325562, Accuracy: 0.779296875\n",
      "Batch: 117, Loss: 0.7451745867729187, Accuracy: 0.7646484375\n",
      "Batch: 118, Loss: 0.6352719068527222, Accuracy: 0.8037109375\n",
      "Batch: 119, Loss: 0.616730809211731, Accuracy: 0.8017578125\n",
      "Batch: 120, Loss: 0.6877738237380981, Accuracy: 0.755859375\n",
      "Batch: 121, Loss: 0.7291803359985352, Accuracy: 0.7646484375\n",
      "Batch: 122, Loss: 0.6637762784957886, Accuracy: 0.787109375\n",
      "Batch: 123, Loss: 0.6578839421272278, Accuracy: 0.8017578125\n",
      "Batch: 124, Loss: 0.687573254108429, Accuracy: 0.79296875\n",
      "Batch: 125, Loss: 0.7300328016281128, Accuracy: 0.75\n",
      "Batch: 126, Loss: 0.6742162704467773, Accuracy: 0.798828125\n",
      "Batch: 127, Loss: 0.6130774021148682, Accuracy: 0.798828125\n",
      "Batch: 128, Loss: 0.7840192317962646, Accuracy: 0.7626953125\n",
      "Batch: 129, Loss: 0.6623023748397827, Accuracy: 0.79296875\n",
      "Batch: 130, Loss: 0.7484310865402222, Accuracy: 0.7587890625\n",
      "Batch: 131, Loss: 0.6974822282791138, Accuracy: 0.7724609375\n",
      "Batch: 132, Loss: 0.7285286784172058, Accuracy: 0.7822265625\n",
      "Batch: 133, Loss: 0.6718989610671997, Accuracy: 0.779296875\n",
      "Batch: 134, Loss: 0.6797513961791992, Accuracy: 0.779296875\n",
      "Batch: 135, Loss: 0.6645680665969849, Accuracy: 0.7998046875\n",
      "Batch: 136, Loss: 0.7369698286056519, Accuracy: 0.759765625\n",
      "Batch: 137, Loss: 0.6800361275672913, Accuracy: 0.7578125\n",
      "Batch: 138, Loss: 0.6326636075973511, Accuracy: 0.7880859375\n",
      "Batch: 139, Loss: 0.6342731714248657, Accuracy: 0.7958984375\n",
      "Batch: 140, Loss: 0.6838431358337402, Accuracy: 0.7607421875\n",
      "Batch: 141, Loss: 0.7122422456741333, Accuracy: 0.775390625\n",
      "Batch: 142, Loss: 0.7649000287055969, Accuracy: 0.7587890625\n",
      "Batch: 143, Loss: 0.6983268857002258, Accuracy: 0.7744140625\n",
      "Batch: 144, Loss: 0.6821340322494507, Accuracy: 0.77734375\n",
      "Batch: 145, Loss: 0.6496562361717224, Accuracy: 0.765625\n",
      "Batch: 146, Loss: 0.7415002584457397, Accuracy: 0.7431640625\n",
      "Batch: 147, Loss: 0.6679854989051819, Accuracy: 0.7841796875\n",
      "Batch: 148, Loss: 0.7411991953849792, Accuracy: 0.7607421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 149, Loss: 0.6332470774650574, Accuracy: 0.8037109375\n",
      "Batch: 150, Loss: 0.7143338322639465, Accuracy: 0.7607421875\n",
      "Batch: 151, Loss: 0.636360764503479, Accuracy: 0.79296875\n",
      "Epoch 54/80\n",
      "Batch: 1, Loss: 0.8640249967575073, Accuracy: 0.7392578125\n",
      "Batch: 2, Loss: 0.7225083112716675, Accuracy: 0.751953125\n",
      "Batch: 3, Loss: 0.6357001662254333, Accuracy: 0.7822265625\n",
      "Batch: 4, Loss: 0.6222352981567383, Accuracy: 0.80078125\n",
      "Batch: 5, Loss: 0.6635975241661072, Accuracy: 0.77734375\n",
      "Batch: 6, Loss: 0.6587825417518616, Accuracy: 0.7802734375\n",
      "Batch: 7, Loss: 0.6680291891098022, Accuracy: 0.7685546875\n",
      "Batch: 8, Loss: 0.6405333280563354, Accuracy: 0.791015625\n",
      "Batch: 9, Loss: 0.6275134682655334, Accuracy: 0.80078125\n",
      "Batch: 10, Loss: 0.6014525890350342, Accuracy: 0.79296875\n",
      "Batch: 11, Loss: 0.7135705947875977, Accuracy: 0.7568359375\n",
      "Batch: 12, Loss: 0.7389034032821655, Accuracy: 0.7626953125\n",
      "Batch: 13, Loss: 0.5765348672866821, Accuracy: 0.8173828125\n",
      "Batch: 14, Loss: 0.7368643283843994, Accuracy: 0.7578125\n",
      "Batch: 15, Loss: 0.647660493850708, Accuracy: 0.8056640625\n",
      "Batch: 16, Loss: 0.6479101181030273, Accuracy: 0.802734375\n",
      "Batch: 17, Loss: 0.6609287261962891, Accuracy: 0.7919921875\n",
      "Batch: 18, Loss: 0.7045369148254395, Accuracy: 0.7705078125\n",
      "Batch: 19, Loss: 0.6955649852752686, Accuracy: 0.779296875\n",
      "Batch: 20, Loss: 0.6200902462005615, Accuracy: 0.814453125\n",
      "Batch: 21, Loss: 0.6010355949401855, Accuracy: 0.8095703125\n",
      "Batch: 22, Loss: 0.7789522409439087, Accuracy: 0.73828125\n",
      "Batch: 23, Loss: 0.7083107233047485, Accuracy: 0.7578125\n",
      "Batch: 24, Loss: 0.73098224401474, Accuracy: 0.759765625\n",
      "Batch: 25, Loss: 0.6401598453521729, Accuracy: 0.796875\n",
      "Batch: 26, Loss: 0.5659242868423462, Accuracy: 0.8193359375\n",
      "Batch: 27, Loss: 0.661710262298584, Accuracy: 0.77734375\n",
      "Batch: 28, Loss: 0.6603572964668274, Accuracy: 0.77734375\n",
      "Batch: 29, Loss: 0.645510733127594, Accuracy: 0.79296875\n",
      "Batch: 30, Loss: 0.617594301700592, Accuracy: 0.8056640625\n",
      "Batch: 31, Loss: 0.5942151546478271, Accuracy: 0.8076171875\n",
      "Batch: 32, Loss: 0.6189385056495667, Accuracy: 0.8056640625\n",
      "Batch: 33, Loss: 0.724632740020752, Accuracy: 0.771484375\n",
      "Batch: 34, Loss: 0.7273322939872742, Accuracy: 0.76171875\n",
      "Batch: 35, Loss: 0.6952033042907715, Accuracy: 0.76953125\n",
      "Batch: 36, Loss: 0.6946303844451904, Accuracy: 0.775390625\n",
      "Batch: 37, Loss: 0.681779146194458, Accuracy: 0.7744140625\n",
      "Batch: 38, Loss: 0.7100973725318909, Accuracy: 0.7587890625\n",
      "Batch: 39, Loss: 0.6896951198577881, Accuracy: 0.7724609375\n",
      "Batch: 40, Loss: 0.6682801842689514, Accuracy: 0.783203125\n",
      "Batch: 41, Loss: 0.5948764085769653, Accuracy: 0.8134765625\n",
      "Batch: 42, Loss: 0.5240838527679443, Accuracy: 0.8291015625\n",
      "Batch: 43, Loss: 0.6419830322265625, Accuracy: 0.794921875\n",
      "Batch: 44, Loss: 0.7072255611419678, Accuracy: 0.7666015625\n",
      "Batch: 45, Loss: 0.5909664630889893, Accuracy: 0.806640625\n",
      "Batch: 46, Loss: 0.6316556930541992, Accuracy: 0.8046875\n",
      "Batch: 47, Loss: 0.6429858207702637, Accuracy: 0.7998046875\n",
      "Batch: 48, Loss: 0.6228340864181519, Accuracy: 0.798828125\n",
      "Batch: 49, Loss: 0.7320256233215332, Accuracy: 0.7509765625\n",
      "Batch: 50, Loss: 0.6238465905189514, Accuracy: 0.7978515625\n",
      "Batch: 51, Loss: 0.721243143081665, Accuracy: 0.76953125\n",
      "Batch: 52, Loss: 0.664565920829773, Accuracy: 0.791015625\n",
      "Batch: 53, Loss: 0.6147212982177734, Accuracy: 0.7958984375\n",
      "Batch: 54, Loss: 0.6340545415878296, Accuracy: 0.8017578125\n",
      "Batch: 55, Loss: 0.6945511102676392, Accuracy: 0.771484375\n",
      "Batch: 56, Loss: 0.7127355337142944, Accuracy: 0.7626953125\n",
      "Batch: 57, Loss: 0.6711345314979553, Accuracy: 0.7802734375\n",
      "Batch: 58, Loss: 0.7610564231872559, Accuracy: 0.748046875\n",
      "Batch: 59, Loss: 0.6456091403961182, Accuracy: 0.796875\n",
      "Batch: 60, Loss: 0.601447343826294, Accuracy: 0.7998046875\n",
      "Batch: 61, Loss: 0.7511836290359497, Accuracy: 0.7548828125\n",
      "Batch: 62, Loss: 0.6408520340919495, Accuracy: 0.7841796875\n",
      "Batch: 63, Loss: 0.712011456489563, Accuracy: 0.767578125\n",
      "Batch: 64, Loss: 0.6726430654525757, Accuracy: 0.787109375\n",
      "Batch: 65, Loss: 0.7086000442504883, Accuracy: 0.7783203125\n",
      "Batch: 66, Loss: 0.7129215002059937, Accuracy: 0.775390625\n",
      "Batch: 67, Loss: 0.7404792904853821, Accuracy: 0.759765625\n",
      "Batch: 68, Loss: 0.7564638257026672, Accuracy: 0.7529296875\n",
      "Batch: 69, Loss: 0.6727967262268066, Accuracy: 0.7744140625\n",
      "Batch: 70, Loss: 0.7004262208938599, Accuracy: 0.78515625\n",
      "Batch: 71, Loss: 0.7112027406692505, Accuracy: 0.7744140625\n",
      "Batch: 72, Loss: 0.6394062042236328, Accuracy: 0.7919921875\n",
      "Batch: 73, Loss: 0.6396322846412659, Accuracy: 0.8046875\n",
      "Batch: 74, Loss: 0.6190253496170044, Accuracy: 0.806640625\n",
      "Batch: 75, Loss: 0.5687686800956726, Accuracy: 0.81640625\n",
      "Batch: 76, Loss: 0.687670111656189, Accuracy: 0.775390625\n",
      "Batch: 77, Loss: 0.6294677257537842, Accuracy: 0.814453125\n",
      "Batch: 78, Loss: 0.5744168162345886, Accuracy: 0.818359375\n",
      "Batch: 79, Loss: 0.6088227033615112, Accuracy: 0.81640625\n",
      "Batch: 80, Loss: 0.622244656085968, Accuracy: 0.8017578125\n",
      "Batch: 81, Loss: 0.6814666986465454, Accuracy: 0.7705078125\n",
      "Batch: 82, Loss: 0.6769314408302307, Accuracy: 0.7822265625\n",
      "Batch: 83, Loss: 0.6253618597984314, Accuracy: 0.80859375\n",
      "Batch: 84, Loss: 0.6641138195991516, Accuracy: 0.7861328125\n",
      "Batch: 85, Loss: 0.632246732711792, Accuracy: 0.7919921875\n",
      "Batch: 86, Loss: 0.7598477005958557, Accuracy: 0.751953125\n",
      "Batch: 87, Loss: 0.6342756152153015, Accuracy: 0.791015625\n",
      "Batch: 88, Loss: 0.7149138450622559, Accuracy: 0.779296875\n",
      "Batch: 89, Loss: 0.6655120849609375, Accuracy: 0.791015625\n",
      "Batch: 90, Loss: 0.65834641456604, Accuracy: 0.7939453125\n",
      "Batch: 91, Loss: 0.6244721412658691, Accuracy: 0.80078125\n",
      "Batch: 92, Loss: 0.6798224449157715, Accuracy: 0.79296875\n",
      "Batch: 93, Loss: 0.7021089196205139, Accuracy: 0.767578125\n",
      "Batch: 94, Loss: 0.6967780590057373, Accuracy: 0.759765625\n",
      "Batch: 95, Loss: 0.6959331035614014, Accuracy: 0.7705078125\n",
      "Batch: 96, Loss: 0.6565533876419067, Accuracy: 0.7822265625\n",
      "Batch: 97, Loss: 0.5360181927680969, Accuracy: 0.8310546875\n",
      "Batch: 98, Loss: 0.6929738521575928, Accuracy: 0.7841796875\n",
      "Batch: 99, Loss: 0.6497572660446167, Accuracy: 0.7890625\n",
      "Batch: 100, Loss: 0.6922216415405273, Accuracy: 0.771484375\n",
      "Batch: 101, Loss: 0.7270717620849609, Accuracy: 0.77734375\n",
      "Batch: 102, Loss: 0.6914600133895874, Accuracy: 0.7802734375\n",
      "Batch: 103, Loss: 0.7281014919281006, Accuracy: 0.775390625\n",
      "Batch: 104, Loss: 0.630780816078186, Accuracy: 0.7978515625\n",
      "Batch: 105, Loss: 0.6477587223052979, Accuracy: 0.787109375\n",
      "Batch: 106, Loss: 0.6070045828819275, Accuracy: 0.8046875\n",
      "Batch: 107, Loss: 0.6827533841133118, Accuracy: 0.7900390625\n",
      "Batch: 108, Loss: 0.6569023132324219, Accuracy: 0.79296875\n",
      "Batch: 109, Loss: 0.7026342749595642, Accuracy: 0.7763671875\n",
      "Batch: 110, Loss: 0.6117932796478271, Accuracy: 0.8017578125\n",
      "Batch: 111, Loss: 0.6530876159667969, Accuracy: 0.7783203125\n",
      "Batch: 112, Loss: 0.7009075880050659, Accuracy: 0.76953125\n",
      "Batch: 113, Loss: 0.6787987947463989, Accuracy: 0.76953125\n",
      "Batch: 114, Loss: 0.687427282333374, Accuracy: 0.7734375\n",
      "Batch: 115, Loss: 0.7722821235656738, Accuracy: 0.7490234375\n",
      "Batch: 116, Loss: 0.7258157730102539, Accuracy: 0.7578125\n",
      "Batch: 117, Loss: 0.7409912943840027, Accuracy: 0.7734375\n",
      "Batch: 118, Loss: 0.6366380453109741, Accuracy: 0.802734375\n",
      "Batch: 119, Loss: 0.5990525484085083, Accuracy: 0.8125\n",
      "Batch: 120, Loss: 0.6875594258308411, Accuracy: 0.7646484375\n",
      "Batch: 121, Loss: 0.7189155220985413, Accuracy: 0.7685546875\n",
      "Batch: 122, Loss: 0.6680538654327393, Accuracy: 0.7841796875\n",
      "Batch: 123, Loss: 0.6640843152999878, Accuracy: 0.791015625\n",
      "Batch: 124, Loss: 0.6736406087875366, Accuracy: 0.7880859375\n",
      "Batch: 125, Loss: 0.706289529800415, Accuracy: 0.77734375\n",
      "Batch: 126, Loss: 0.6997746229171753, Accuracy: 0.7734375\n",
      "Batch: 127, Loss: 0.5851805806159973, Accuracy: 0.80078125\n",
      "Batch: 128, Loss: 0.7555307149887085, Accuracy: 0.76171875\n",
      "Batch: 129, Loss: 0.6438367366790771, Accuracy: 0.7822265625\n",
      "Batch: 130, Loss: 0.7436228394508362, Accuracy: 0.74609375\n",
      "Batch: 131, Loss: 0.7064731121063232, Accuracy: 0.759765625\n",
      "Batch: 132, Loss: 0.7030168771743774, Accuracy: 0.7626953125\n",
      "Batch: 133, Loss: 0.6971365213394165, Accuracy: 0.763671875\n",
      "Batch: 134, Loss: 0.675589382648468, Accuracy: 0.7666015625\n",
      "Batch: 135, Loss: 0.6231827735900879, Accuracy: 0.8125\n",
      "Batch: 136, Loss: 0.6968526840209961, Accuracy: 0.7841796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 137, Loss: 0.6899269819259644, Accuracy: 0.7724609375\n",
      "Batch: 138, Loss: 0.6177704930305481, Accuracy: 0.783203125\n",
      "Batch: 139, Loss: 0.6286458373069763, Accuracy: 0.77734375\n",
      "Batch: 140, Loss: 0.7003087997436523, Accuracy: 0.76171875\n",
      "Batch: 141, Loss: 0.7015281915664673, Accuracy: 0.7607421875\n",
      "Batch: 142, Loss: 0.7224253416061401, Accuracy: 0.765625\n",
      "Batch: 143, Loss: 0.6605655550956726, Accuracy: 0.7705078125\n",
      "Batch: 144, Loss: 0.6966186761856079, Accuracy: 0.7763671875\n",
      "Batch: 145, Loss: 0.6437211036682129, Accuracy: 0.775390625\n",
      "Batch: 146, Loss: 0.7120416164398193, Accuracy: 0.7734375\n",
      "Batch: 147, Loss: 0.6790333986282349, Accuracy: 0.783203125\n",
      "Batch: 148, Loss: 0.7601176500320435, Accuracy: 0.7412109375\n",
      "Batch: 149, Loss: 0.6818016767501831, Accuracy: 0.7724609375\n",
      "Batch: 150, Loss: 0.6831325888633728, Accuracy: 0.7841796875\n",
      "Batch: 151, Loss: 0.625218391418457, Accuracy: 0.798828125\n",
      "Epoch 55/80\n",
      "Batch: 1, Loss: 0.8479622602462769, Accuracy: 0.7412109375\n",
      "Batch: 2, Loss: 0.7150071859359741, Accuracy: 0.748046875\n",
      "Batch: 3, Loss: 0.6329364776611328, Accuracy: 0.791015625\n",
      "Batch: 4, Loss: 0.6216011643409729, Accuracy: 0.80078125\n",
      "Batch: 5, Loss: 0.6578619480133057, Accuracy: 0.7783203125\n",
      "Batch: 6, Loss: 0.6673018932342529, Accuracy: 0.7802734375\n",
      "Batch: 7, Loss: 0.6684279441833496, Accuracy: 0.779296875\n",
      "Batch: 8, Loss: 0.6684280037879944, Accuracy: 0.7666015625\n",
      "Batch: 9, Loss: 0.6331764459609985, Accuracy: 0.8017578125\n",
      "Batch: 10, Loss: 0.6258732676506042, Accuracy: 0.779296875\n",
      "Batch: 11, Loss: 0.7095291614532471, Accuracy: 0.7578125\n",
      "Batch: 12, Loss: 0.6814713478088379, Accuracy: 0.7783203125\n",
      "Batch: 13, Loss: 0.5485681295394897, Accuracy: 0.8291015625\n",
      "Batch: 14, Loss: 0.7323596477508545, Accuracy: 0.7607421875\n",
      "Batch: 15, Loss: 0.6438283324241638, Accuracy: 0.79296875\n",
      "Batch: 16, Loss: 0.6172734498977661, Accuracy: 0.810546875\n",
      "Batch: 17, Loss: 0.6663301587104797, Accuracy: 0.775390625\n",
      "Batch: 18, Loss: 0.694471538066864, Accuracy: 0.7705078125\n",
      "Batch: 19, Loss: 0.7232841849327087, Accuracy: 0.77734375\n",
      "Batch: 20, Loss: 0.6355111598968506, Accuracy: 0.7939453125\n",
      "Batch: 21, Loss: 0.6385707259178162, Accuracy: 0.796875\n",
      "Batch: 22, Loss: 0.7473101615905762, Accuracy: 0.765625\n",
      "Batch: 23, Loss: 0.699115514755249, Accuracy: 0.771484375\n",
      "Batch: 24, Loss: 0.6806252002716064, Accuracy: 0.78125\n",
      "Batch: 25, Loss: 0.6467016339302063, Accuracy: 0.7919921875\n",
      "Batch: 26, Loss: 0.5631614923477173, Accuracy: 0.8173828125\n",
      "Batch: 27, Loss: 0.650708794593811, Accuracy: 0.7919921875\n",
      "Batch: 28, Loss: 0.6543087959289551, Accuracy: 0.7841796875\n",
      "Batch: 29, Loss: 0.6531500220298767, Accuracy: 0.791015625\n",
      "Batch: 30, Loss: 0.5971060395240784, Accuracy: 0.8134765625\n",
      "Batch: 31, Loss: 0.6299804449081421, Accuracy: 0.7861328125\n",
      "Batch: 32, Loss: 0.6512720584869385, Accuracy: 0.796875\n",
      "Batch: 33, Loss: 0.7278748154640198, Accuracy: 0.7705078125\n",
      "Batch: 34, Loss: 0.7166021466255188, Accuracy: 0.7666015625\n",
      "Batch: 35, Loss: 0.7169528007507324, Accuracy: 0.7578125\n",
      "Batch: 36, Loss: 0.6722820401191711, Accuracy: 0.7861328125\n",
      "Batch: 37, Loss: 0.696847677230835, Accuracy: 0.7783203125\n",
      "Batch: 38, Loss: 0.7188320159912109, Accuracy: 0.76953125\n",
      "Batch: 39, Loss: 0.6844050884246826, Accuracy: 0.7880859375\n",
      "Batch: 40, Loss: 0.6333268880844116, Accuracy: 0.791015625\n",
      "Batch: 41, Loss: 0.5882564783096313, Accuracy: 0.796875\n",
      "Batch: 42, Loss: 0.49666696786880493, Accuracy: 0.82421875\n",
      "Batch: 43, Loss: 0.6719551086425781, Accuracy: 0.767578125\n",
      "Batch: 44, Loss: 0.6753023266792297, Accuracy: 0.7880859375\n",
      "Batch: 45, Loss: 0.6179255247116089, Accuracy: 0.7958984375\n",
      "Batch: 46, Loss: 0.6362494230270386, Accuracy: 0.791015625\n",
      "Batch: 47, Loss: 0.6788609623908997, Accuracy: 0.7998046875\n",
      "Batch: 48, Loss: 0.6195951700210571, Accuracy: 0.8076171875\n",
      "Batch: 49, Loss: 0.6857819557189941, Accuracy: 0.7724609375\n",
      "Batch: 50, Loss: 0.6443690657615662, Accuracy: 0.7939453125\n",
      "Batch: 51, Loss: 0.6629258990287781, Accuracy: 0.794921875\n",
      "Batch: 52, Loss: 0.6345416903495789, Accuracy: 0.798828125\n",
      "Batch: 53, Loss: 0.5982767343521118, Accuracy: 0.8046875\n",
      "Batch: 54, Loss: 0.6521621942520142, Accuracy: 0.78515625\n",
      "Batch: 55, Loss: 0.7380091547966003, Accuracy: 0.7431640625\n",
      "Batch: 56, Loss: 0.7025971412658691, Accuracy: 0.759765625\n",
      "Batch: 57, Loss: 0.695172905921936, Accuracy: 0.7763671875\n",
      "Batch: 58, Loss: 0.774749755859375, Accuracy: 0.75\n",
      "Batch: 59, Loss: 0.6529934406280518, Accuracy: 0.7958984375\n",
      "Batch: 60, Loss: 0.6344531774520874, Accuracy: 0.7734375\n",
      "Batch: 61, Loss: 0.6686464548110962, Accuracy: 0.7646484375\n",
      "Batch: 62, Loss: 0.6409050226211548, Accuracy: 0.7841796875\n",
      "Batch: 63, Loss: 0.7119675278663635, Accuracy: 0.7666015625\n",
      "Batch: 64, Loss: 0.6236749887466431, Accuracy: 0.794921875\n",
      "Batch: 65, Loss: 0.6878272294998169, Accuracy: 0.77734375\n",
      "Batch: 66, Loss: 0.6849015951156616, Accuracy: 0.779296875\n",
      "Batch: 67, Loss: 0.7349687814712524, Accuracy: 0.7734375\n",
      "Batch: 68, Loss: 0.7259475588798523, Accuracy: 0.771484375\n",
      "Batch: 69, Loss: 0.6949613094329834, Accuracy: 0.7734375\n",
      "Batch: 70, Loss: 0.7383439540863037, Accuracy: 0.7763671875\n",
      "Batch: 71, Loss: 0.718021810054779, Accuracy: 0.763671875\n",
      "Batch: 72, Loss: 0.6285399198532104, Accuracy: 0.802734375\n",
      "Batch: 73, Loss: 0.6183872222900391, Accuracy: 0.810546875\n",
      "Batch: 74, Loss: 0.6226752400398254, Accuracy: 0.798828125\n",
      "Batch: 75, Loss: 0.5854870080947876, Accuracy: 0.806640625\n",
      "Batch: 76, Loss: 0.6627693772315979, Accuracy: 0.79296875\n",
      "Batch: 77, Loss: 0.6019803285598755, Accuracy: 0.8017578125\n",
      "Batch: 78, Loss: 0.6130937337875366, Accuracy: 0.8076171875\n",
      "Batch: 79, Loss: 0.6167885065078735, Accuracy: 0.7978515625\n",
      "Batch: 80, Loss: 0.6305620670318604, Accuracy: 0.78515625\n",
      "Batch: 81, Loss: 0.7065445184707642, Accuracy: 0.7578125\n",
      "Batch: 82, Loss: 0.6610292196273804, Accuracy: 0.7783203125\n",
      "Batch: 83, Loss: 0.5702518224716187, Accuracy: 0.8125\n",
      "Batch: 84, Loss: 0.6509996056556702, Accuracy: 0.7890625\n",
      "Batch: 85, Loss: 0.6477290391921997, Accuracy: 0.80078125\n",
      "Batch: 86, Loss: 0.7367640733718872, Accuracy: 0.755859375\n",
      "Batch: 87, Loss: 0.6083315014839172, Accuracy: 0.8046875\n",
      "Batch: 88, Loss: 0.6829927563667297, Accuracy: 0.783203125\n",
      "Batch: 89, Loss: 0.6965546607971191, Accuracy: 0.765625\n",
      "Batch: 90, Loss: 0.6573705673217773, Accuracy: 0.7900390625\n",
      "Batch: 91, Loss: 0.6034889221191406, Accuracy: 0.79296875\n",
      "Batch: 92, Loss: 0.6705283522605896, Accuracy: 0.7919921875\n",
      "Batch: 93, Loss: 0.6624995470046997, Accuracy: 0.78125\n",
      "Batch: 94, Loss: 0.6550418138504028, Accuracy: 0.7900390625\n",
      "Batch: 95, Loss: 0.6755014061927795, Accuracy: 0.7724609375\n",
      "Batch: 96, Loss: 0.6503522396087646, Accuracy: 0.791015625\n",
      "Batch: 97, Loss: 0.525235652923584, Accuracy: 0.826171875\n",
      "Batch: 98, Loss: 0.6832395195960999, Accuracy: 0.7734375\n",
      "Batch: 99, Loss: 0.6417585015296936, Accuracy: 0.794921875\n",
      "Batch: 100, Loss: 0.6623623371124268, Accuracy: 0.779296875\n",
      "Batch: 101, Loss: 0.699345052242279, Accuracy: 0.76953125\n",
      "Batch: 102, Loss: 0.6633187532424927, Accuracy: 0.78515625\n",
      "Batch: 103, Loss: 0.6783732175827026, Accuracy: 0.7890625\n",
      "Batch: 104, Loss: 0.6307146549224854, Accuracy: 0.7802734375\n",
      "Batch: 105, Loss: 0.6636770367622375, Accuracy: 0.783203125\n",
      "Batch: 106, Loss: 0.6087530851364136, Accuracy: 0.8017578125\n",
      "Batch: 107, Loss: 0.6545130610466003, Accuracy: 0.8076171875\n",
      "Batch: 108, Loss: 0.6595628261566162, Accuracy: 0.791015625\n",
      "Batch: 109, Loss: 0.7203497290611267, Accuracy: 0.7607421875\n",
      "Batch: 110, Loss: 0.6161037683486938, Accuracy: 0.791015625\n",
      "Batch: 111, Loss: 0.6611777544021606, Accuracy: 0.779296875\n",
      "Batch: 112, Loss: 0.6610028743743896, Accuracy: 0.7822265625\n",
      "Batch: 113, Loss: 0.6668046712875366, Accuracy: 0.79296875\n",
      "Batch: 114, Loss: 0.7114295363426208, Accuracy: 0.7607421875\n",
      "Batch: 115, Loss: 0.7509391903877258, Accuracy: 0.751953125\n",
      "Batch: 116, Loss: 0.680070161819458, Accuracy: 0.7890625\n",
      "Batch: 117, Loss: 0.730758547782898, Accuracy: 0.7705078125\n",
      "Batch: 118, Loss: 0.6351031064987183, Accuracy: 0.7880859375\n",
      "Batch: 119, Loss: 0.6125385761260986, Accuracy: 0.8037109375\n",
      "Batch: 120, Loss: 0.663983166217804, Accuracy: 0.7734375\n",
      "Batch: 121, Loss: 0.7013338804244995, Accuracy: 0.7666015625\n",
      "Batch: 122, Loss: 0.6881490349769592, Accuracy: 0.7724609375\n",
      "Batch: 123, Loss: 0.6258848905563354, Accuracy: 0.80078125\n",
      "Batch: 124, Loss: 0.6773385405540466, Accuracy: 0.783203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 125, Loss: 0.7426668405532837, Accuracy: 0.7548828125\n",
      "Batch: 126, Loss: 0.6728668808937073, Accuracy: 0.7822265625\n",
      "Batch: 127, Loss: 0.5852236151695251, Accuracy: 0.810546875\n",
      "Batch: 128, Loss: 0.7363108396530151, Accuracy: 0.7744140625\n",
      "Batch: 129, Loss: 0.6201684474945068, Accuracy: 0.8037109375\n",
      "Batch: 130, Loss: 0.7328957915306091, Accuracy: 0.759765625\n",
      "Batch: 131, Loss: 0.709425151348114, Accuracy: 0.7646484375\n",
      "Batch: 132, Loss: 0.7057397365570068, Accuracy: 0.7734375\n",
      "Batch: 133, Loss: 0.6342151165008545, Accuracy: 0.78515625\n",
      "Batch: 134, Loss: 0.6418288946151733, Accuracy: 0.7724609375\n",
      "Batch: 135, Loss: 0.6416932344436646, Accuracy: 0.796875\n",
      "Batch: 136, Loss: 0.6874311566352844, Accuracy: 0.7783203125\n",
      "Batch: 137, Loss: 0.6693649291992188, Accuracy: 0.7666015625\n",
      "Batch: 138, Loss: 0.6391170024871826, Accuracy: 0.7900390625\n",
      "Batch: 139, Loss: 0.6434599161148071, Accuracy: 0.7939453125\n",
      "Batch: 140, Loss: 0.6893593072891235, Accuracy: 0.775390625\n",
      "Batch: 141, Loss: 0.6923181414604187, Accuracy: 0.767578125\n",
      "Batch: 142, Loss: 0.7353591322898865, Accuracy: 0.759765625\n",
      "Batch: 143, Loss: 0.6543158292770386, Accuracy: 0.78515625\n",
      "Batch: 144, Loss: 0.6739972233772278, Accuracy: 0.7890625\n",
      "Batch: 145, Loss: 0.6331701874732971, Accuracy: 0.78125\n",
      "Batch: 146, Loss: 0.6950446367263794, Accuracy: 0.76953125\n",
      "Batch: 147, Loss: 0.6463271975517273, Accuracy: 0.7822265625\n",
      "Batch: 148, Loss: 0.7188856601715088, Accuracy: 0.76953125\n",
      "Batch: 149, Loss: 0.6520206332206726, Accuracy: 0.779296875\n",
      "Batch: 150, Loss: 0.7160395383834839, Accuracy: 0.7685546875\n",
      "Batch: 151, Loss: 0.6330617070198059, Accuracy: 0.7998046875\n",
      "Epoch 56/80\n",
      "Batch: 1, Loss: 0.8896998763084412, Accuracy: 0.724609375\n",
      "Batch: 2, Loss: 0.7046356201171875, Accuracy: 0.759765625\n",
      "Batch: 3, Loss: 0.629564642906189, Accuracy: 0.7978515625\n",
      "Batch: 4, Loss: 0.613566517829895, Accuracy: 0.802734375\n",
      "Batch: 5, Loss: 0.6358489990234375, Accuracy: 0.791015625\n",
      "Batch: 6, Loss: 0.7107967138290405, Accuracy: 0.7705078125\n",
      "Batch: 7, Loss: 0.6547239422798157, Accuracy: 0.7861328125\n",
      "Batch: 8, Loss: 0.6323935985565186, Accuracy: 0.7841796875\n",
      "Batch: 9, Loss: 0.6164971590042114, Accuracy: 0.7998046875\n",
      "Batch: 10, Loss: 0.578355073928833, Accuracy: 0.8125\n",
      "Batch: 11, Loss: 0.6944066882133484, Accuracy: 0.775390625\n",
      "Batch: 12, Loss: 0.6886482238769531, Accuracy: 0.7763671875\n",
      "Batch: 13, Loss: 0.5701740980148315, Accuracy: 0.8056640625\n",
      "Batch: 14, Loss: 0.7536708116531372, Accuracy: 0.7578125\n",
      "Batch: 15, Loss: 0.6252591013908386, Accuracy: 0.8017578125\n",
      "Batch: 16, Loss: 0.5962615609169006, Accuracy: 0.81640625\n",
      "Batch: 17, Loss: 0.6539705991744995, Accuracy: 0.794921875\n",
      "Batch: 18, Loss: 0.6870734691619873, Accuracy: 0.7783203125\n",
      "Batch: 19, Loss: 0.6913095712661743, Accuracy: 0.77734375\n",
      "Batch: 20, Loss: 0.6198089122772217, Accuracy: 0.7978515625\n",
      "Batch: 21, Loss: 0.6147968173027039, Accuracy: 0.802734375\n",
      "Batch: 22, Loss: 0.7539129257202148, Accuracy: 0.748046875\n",
      "Batch: 23, Loss: 0.7069724798202515, Accuracy: 0.755859375\n",
      "Batch: 24, Loss: 0.7172775268554688, Accuracy: 0.7734375\n",
      "Batch: 25, Loss: 0.6545411944389343, Accuracy: 0.80078125\n",
      "Batch: 26, Loss: 0.5601924657821655, Accuracy: 0.826171875\n",
      "Batch: 27, Loss: 0.629945695400238, Accuracy: 0.7783203125\n",
      "Batch: 28, Loss: 0.6507827043533325, Accuracy: 0.79296875\n",
      "Batch: 29, Loss: 0.6255172491073608, Accuracy: 0.7978515625\n",
      "Batch: 30, Loss: 0.6034113764762878, Accuracy: 0.7978515625\n",
      "Batch: 31, Loss: 0.5817642211914062, Accuracy: 0.8115234375\n",
      "Batch: 32, Loss: 0.5907737016677856, Accuracy: 0.810546875\n",
      "Batch: 33, Loss: 0.7013006806373596, Accuracy: 0.7841796875\n",
      "Batch: 34, Loss: 0.7094639539718628, Accuracy: 0.755859375\n",
      "Batch: 35, Loss: 0.6978386044502258, Accuracy: 0.7744140625\n",
      "Batch: 36, Loss: 0.6890267133712769, Accuracy: 0.7822265625\n",
      "Batch: 37, Loss: 0.7014695405960083, Accuracy: 0.77734375\n",
      "Batch: 38, Loss: 0.6929559707641602, Accuracy: 0.76953125\n",
      "Batch: 39, Loss: 0.6600334048271179, Accuracy: 0.76953125\n",
      "Batch: 40, Loss: 0.6442066431045532, Accuracy: 0.7822265625\n",
      "Batch: 41, Loss: 0.5929387211799622, Accuracy: 0.80078125\n",
      "Batch: 42, Loss: 0.4857938885688782, Accuracy: 0.83203125\n",
      "Batch: 43, Loss: 0.6324357390403748, Accuracy: 0.7890625\n",
      "Batch: 44, Loss: 0.6497287154197693, Accuracy: 0.783203125\n",
      "Batch: 45, Loss: 0.6061584949493408, Accuracy: 0.802734375\n",
      "Batch: 46, Loss: 0.6081949472427368, Accuracy: 0.7978515625\n",
      "Batch: 47, Loss: 0.6635485887527466, Accuracy: 0.7958984375\n",
      "Batch: 48, Loss: 0.6501568555831909, Accuracy: 0.7978515625\n",
      "Batch: 49, Loss: 0.6977295875549316, Accuracy: 0.78515625\n",
      "Batch: 50, Loss: 0.632465124130249, Accuracy: 0.798828125\n",
      "Batch: 51, Loss: 0.6734034419059753, Accuracy: 0.7841796875\n",
      "Batch: 52, Loss: 0.677511990070343, Accuracy: 0.771484375\n",
      "Batch: 53, Loss: 0.6220711469650269, Accuracy: 0.7978515625\n",
      "Batch: 54, Loss: 0.5983046889305115, Accuracy: 0.794921875\n",
      "Batch: 55, Loss: 0.6975119113922119, Accuracy: 0.7646484375\n",
      "Batch: 56, Loss: 0.72832190990448, Accuracy: 0.75390625\n",
      "Batch: 57, Loss: 0.7118370532989502, Accuracy: 0.763671875\n",
      "Batch: 58, Loss: 0.7624081969261169, Accuracy: 0.7587890625\n",
      "Batch: 59, Loss: 0.6643975377082825, Accuracy: 0.791015625\n",
      "Batch: 60, Loss: 0.6315427422523499, Accuracy: 0.779296875\n",
      "Batch: 61, Loss: 0.7066446542739868, Accuracy: 0.7744140625\n",
      "Batch: 62, Loss: 0.6412266492843628, Accuracy: 0.7744140625\n",
      "Batch: 63, Loss: 0.6620484590530396, Accuracy: 0.7880859375\n",
      "Batch: 64, Loss: 0.6184217929840088, Accuracy: 0.7998046875\n",
      "Batch: 65, Loss: 0.6748917102813721, Accuracy: 0.7841796875\n",
      "Batch: 66, Loss: 0.6792187690734863, Accuracy: 0.7861328125\n",
      "Batch: 67, Loss: 0.7206786870956421, Accuracy: 0.7802734375\n",
      "Batch: 68, Loss: 0.6934778094291687, Accuracy: 0.7822265625\n",
      "Batch: 69, Loss: 0.6795759201049805, Accuracy: 0.775390625\n",
      "Batch: 70, Loss: 0.6960880160331726, Accuracy: 0.7900390625\n",
      "Batch: 71, Loss: 0.6950640678405762, Accuracy: 0.7802734375\n",
      "Batch: 72, Loss: 0.6091745495796204, Accuracy: 0.8056640625\n",
      "Batch: 73, Loss: 0.6142295598983765, Accuracy: 0.80078125\n",
      "Batch: 74, Loss: 0.5931506156921387, Accuracy: 0.8173828125\n",
      "Batch: 75, Loss: 0.5831030607223511, Accuracy: 0.8125\n",
      "Batch: 76, Loss: 0.7073131799697876, Accuracy: 0.7783203125\n",
      "Batch: 77, Loss: 0.5853455066680908, Accuracy: 0.818359375\n",
      "Batch: 78, Loss: 0.608394980430603, Accuracy: 0.80859375\n",
      "Batch: 79, Loss: 0.6188863515853882, Accuracy: 0.8115234375\n",
      "Batch: 80, Loss: 0.603503406047821, Accuracy: 0.814453125\n",
      "Batch: 81, Loss: 0.6863288879394531, Accuracy: 0.7685546875\n",
      "Batch: 82, Loss: 0.6645683646202087, Accuracy: 0.7783203125\n",
      "Batch: 83, Loss: 0.5937511920928955, Accuracy: 0.8154296875\n",
      "Batch: 84, Loss: 0.652292013168335, Accuracy: 0.779296875\n",
      "Batch: 85, Loss: 0.6474177837371826, Accuracy: 0.7978515625\n",
      "Batch: 86, Loss: 0.7510894536972046, Accuracy: 0.767578125\n",
      "Batch: 87, Loss: 0.5985726714134216, Accuracy: 0.798828125\n",
      "Batch: 88, Loss: 0.6824487447738647, Accuracy: 0.7822265625\n",
      "Batch: 89, Loss: 0.667396068572998, Accuracy: 0.78515625\n",
      "Batch: 90, Loss: 0.6540409326553345, Accuracy: 0.7861328125\n",
      "Batch: 91, Loss: 0.6548137664794922, Accuracy: 0.7783203125\n",
      "Batch: 92, Loss: 0.6767349243164062, Accuracy: 0.7685546875\n",
      "Batch: 93, Loss: 0.6815371513366699, Accuracy: 0.775390625\n",
      "Batch: 94, Loss: 0.7008616924285889, Accuracy: 0.7685546875\n",
      "Batch: 95, Loss: 0.6712385416030884, Accuracy: 0.7783203125\n",
      "Batch: 96, Loss: 0.6564624309539795, Accuracy: 0.7841796875\n",
      "Batch: 97, Loss: 0.5361766815185547, Accuracy: 0.8369140625\n",
      "Batch: 98, Loss: 0.6875518560409546, Accuracy: 0.7705078125\n",
      "Batch: 99, Loss: 0.6234337091445923, Accuracy: 0.7861328125\n",
      "Batch: 100, Loss: 0.7014310359954834, Accuracy: 0.7705078125\n",
      "Batch: 101, Loss: 0.6863806247711182, Accuracy: 0.779296875\n",
      "Batch: 102, Loss: 0.6559355854988098, Accuracy: 0.7841796875\n",
      "Batch: 103, Loss: 0.6812248826026917, Accuracy: 0.775390625\n",
      "Batch: 104, Loss: 0.6591352820396423, Accuracy: 0.77734375\n",
      "Batch: 105, Loss: 0.6693037152290344, Accuracy: 0.7841796875\n",
      "Batch: 106, Loss: 0.6210046410560608, Accuracy: 0.7900390625\n",
      "Batch: 107, Loss: 0.6509467363357544, Accuracy: 0.79296875\n",
      "Batch: 108, Loss: 0.6780449151992798, Accuracy: 0.783203125\n",
      "Batch: 109, Loss: 0.7075306177139282, Accuracy: 0.763671875\n",
      "Batch: 110, Loss: 0.6008194088935852, Accuracy: 0.796875\n",
      "Batch: 111, Loss: 0.6530448198318481, Accuracy: 0.7890625\n",
      "Batch: 112, Loss: 0.6687335968017578, Accuracy: 0.7861328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 113, Loss: 0.6555662751197815, Accuracy: 0.7880859375\n",
      "Batch: 114, Loss: 0.6883573532104492, Accuracy: 0.7841796875\n",
      "Batch: 115, Loss: 0.763515293598175, Accuracy: 0.744140625\n",
      "Batch: 116, Loss: 0.6591672897338867, Accuracy: 0.775390625\n",
      "Batch: 117, Loss: 0.6818857192993164, Accuracy: 0.7822265625\n",
      "Batch: 118, Loss: 0.6477429866790771, Accuracy: 0.7900390625\n",
      "Batch: 119, Loss: 0.5673942565917969, Accuracy: 0.8212890625\n",
      "Batch: 120, Loss: 0.6256979703903198, Accuracy: 0.78125\n",
      "Batch: 121, Loss: 0.7224531769752502, Accuracy: 0.771484375\n",
      "Batch: 122, Loss: 0.6396936774253845, Accuracy: 0.7958984375\n",
      "Batch: 123, Loss: 0.6357005834579468, Accuracy: 0.794921875\n",
      "Batch: 124, Loss: 0.6866289377212524, Accuracy: 0.7724609375\n",
      "Batch: 125, Loss: 0.6822555065155029, Accuracy: 0.7890625\n",
      "Batch: 126, Loss: 0.686599850654602, Accuracy: 0.7822265625\n",
      "Batch: 127, Loss: 0.574709951877594, Accuracy: 0.8134765625\n",
      "Batch: 128, Loss: 0.7543407678604126, Accuracy: 0.7666015625\n",
      "Batch: 129, Loss: 0.6553499698638916, Accuracy: 0.7763671875\n",
      "Batch: 130, Loss: 0.7248308658599854, Accuracy: 0.74609375\n",
      "Batch: 131, Loss: 0.6969187259674072, Accuracy: 0.7763671875\n",
      "Batch: 132, Loss: 0.695007860660553, Accuracy: 0.7822265625\n",
      "Batch: 133, Loss: 0.6554499864578247, Accuracy: 0.779296875\n",
      "Batch: 134, Loss: 0.6787290573120117, Accuracy: 0.7744140625\n",
      "Batch: 135, Loss: 0.6502547264099121, Accuracy: 0.7939453125\n",
      "Batch: 136, Loss: 0.6863482594490051, Accuracy: 0.7783203125\n",
      "Batch: 137, Loss: 0.6765938997268677, Accuracy: 0.76171875\n",
      "Batch: 138, Loss: 0.6113204956054688, Accuracy: 0.7890625\n",
      "Batch: 139, Loss: 0.6239407658576965, Accuracy: 0.791015625\n",
      "Batch: 140, Loss: 0.6480304002761841, Accuracy: 0.7890625\n",
      "Batch: 141, Loss: 0.6976538300514221, Accuracy: 0.7734375\n",
      "Batch: 142, Loss: 0.7758665084838867, Accuracy: 0.763671875\n",
      "Batch: 143, Loss: 0.6650615334510803, Accuracy: 0.783203125\n",
      "Batch: 144, Loss: 0.6705499291419983, Accuracy: 0.7890625\n",
      "Batch: 145, Loss: 0.615180253982544, Accuracy: 0.7958984375\n",
      "Batch: 146, Loss: 0.6411036252975464, Accuracy: 0.802734375\n",
      "Batch: 147, Loss: 0.6154049634933472, Accuracy: 0.7880859375\n",
      "Batch: 148, Loss: 0.7301793098449707, Accuracy: 0.76953125\n",
      "Batch: 149, Loss: 0.6245566606521606, Accuracy: 0.794921875\n",
      "Batch: 150, Loss: 0.6808499693870544, Accuracy: 0.7763671875\n",
      "Batch: 151, Loss: 0.5869300365447998, Accuracy: 0.806640625\n",
      "Epoch 57/80\n",
      "Batch: 1, Loss: 0.8379291296005249, Accuracy: 0.7392578125\n",
      "Batch: 2, Loss: 0.6992838382720947, Accuracy: 0.7568359375\n",
      "Batch: 3, Loss: 0.6406741142272949, Accuracy: 0.7880859375\n",
      "Batch: 4, Loss: 0.6133208274841309, Accuracy: 0.8154296875\n",
      "Batch: 5, Loss: 0.6601893901824951, Accuracy: 0.7822265625\n",
      "Batch: 6, Loss: 0.6974271535873413, Accuracy: 0.7734375\n",
      "Batch: 7, Loss: 0.6660159826278687, Accuracy: 0.7685546875\n",
      "Batch: 8, Loss: 0.6457959413528442, Accuracy: 0.7900390625\n",
      "Batch: 9, Loss: 0.6269758939743042, Accuracy: 0.8017578125\n",
      "Batch: 10, Loss: 0.6043186187744141, Accuracy: 0.8134765625\n",
      "Batch: 11, Loss: 0.7106751799583435, Accuracy: 0.751953125\n",
      "Batch: 12, Loss: 0.6551473140716553, Accuracy: 0.7919921875\n",
      "Batch: 13, Loss: 0.5724660158157349, Accuracy: 0.8173828125\n",
      "Batch: 14, Loss: 0.6876919269561768, Accuracy: 0.783203125\n",
      "Batch: 15, Loss: 0.6015154719352722, Accuracy: 0.7978515625\n",
      "Batch: 16, Loss: 0.6277730464935303, Accuracy: 0.794921875\n",
      "Batch: 17, Loss: 0.6244431138038635, Accuracy: 0.794921875\n",
      "Batch: 18, Loss: 0.696133017539978, Accuracy: 0.7705078125\n",
      "Batch: 19, Loss: 0.6864927411079407, Accuracy: 0.7841796875\n",
      "Batch: 20, Loss: 0.5890712141990662, Accuracy: 0.8125\n",
      "Batch: 21, Loss: 0.5884407758712769, Accuracy: 0.80859375\n",
      "Batch: 22, Loss: 0.7372255921363831, Accuracy: 0.7451171875\n",
      "Batch: 23, Loss: 0.693412184715271, Accuracy: 0.765625\n",
      "Batch: 24, Loss: 0.6811707019805908, Accuracy: 0.76953125\n",
      "Batch: 25, Loss: 0.6232273578643799, Accuracy: 0.8037109375\n",
      "Batch: 26, Loss: 0.5414714813232422, Accuracy: 0.8173828125\n",
      "Batch: 27, Loss: 0.6180588006973267, Accuracy: 0.79296875\n",
      "Batch: 28, Loss: 0.6184237003326416, Accuracy: 0.787109375\n",
      "Batch: 29, Loss: 0.6211879253387451, Accuracy: 0.798828125\n",
      "Batch: 30, Loss: 0.5902090668678284, Accuracy: 0.810546875\n",
      "Batch: 31, Loss: 0.5698861479759216, Accuracy: 0.826171875\n",
      "Batch: 32, Loss: 0.5835399627685547, Accuracy: 0.8095703125\n",
      "Batch: 33, Loss: 0.6975258588790894, Accuracy: 0.7685546875\n",
      "Batch: 34, Loss: 0.7099568843841553, Accuracy: 0.7705078125\n",
      "Batch: 35, Loss: 0.670975923538208, Accuracy: 0.779296875\n",
      "Batch: 36, Loss: 0.6677455902099609, Accuracy: 0.7880859375\n",
      "Batch: 37, Loss: 0.6797353029251099, Accuracy: 0.787109375\n",
      "Batch: 38, Loss: 0.7052534818649292, Accuracy: 0.7578125\n",
      "Batch: 39, Loss: 0.6768803596496582, Accuracy: 0.7861328125\n",
      "Batch: 40, Loss: 0.6542986035346985, Accuracy: 0.787109375\n",
      "Batch: 41, Loss: 0.5818232297897339, Accuracy: 0.8095703125\n",
      "Batch: 42, Loss: 0.5016568899154663, Accuracy: 0.837890625\n",
      "Batch: 43, Loss: 0.6462334394454956, Accuracy: 0.7890625\n",
      "Batch: 44, Loss: 0.6640045642852783, Accuracy: 0.78515625\n",
      "Batch: 45, Loss: 0.554686963558197, Accuracy: 0.8134765625\n",
      "Batch: 46, Loss: 0.5926523208618164, Accuracy: 0.810546875\n",
      "Batch: 47, Loss: 0.6149182319641113, Accuracy: 0.8154296875\n",
      "Batch: 48, Loss: 0.6026246547698975, Accuracy: 0.787109375\n",
      "Batch: 49, Loss: 0.6879261136054993, Accuracy: 0.7890625\n",
      "Batch: 50, Loss: 0.6471719145774841, Accuracy: 0.7744140625\n",
      "Batch: 51, Loss: 0.6658422946929932, Accuracy: 0.7783203125\n",
      "Batch: 52, Loss: 0.6559685468673706, Accuracy: 0.7958984375\n",
      "Batch: 53, Loss: 0.5781437158584595, Accuracy: 0.8095703125\n",
      "Batch: 54, Loss: 0.626872181892395, Accuracy: 0.7939453125\n",
      "Batch: 55, Loss: 0.6951351165771484, Accuracy: 0.7607421875\n",
      "Batch: 56, Loss: 0.6887643337249756, Accuracy: 0.775390625\n",
      "Batch: 57, Loss: 0.7019671201705933, Accuracy: 0.787109375\n",
      "Batch: 58, Loss: 0.7485647201538086, Accuracy: 0.7705078125\n",
      "Batch: 59, Loss: 0.6406417489051819, Accuracy: 0.794921875\n",
      "Batch: 60, Loss: 0.6338274478912354, Accuracy: 0.7763671875\n",
      "Batch: 61, Loss: 0.7186509966850281, Accuracy: 0.7724609375\n",
      "Batch: 62, Loss: 0.6118181347846985, Accuracy: 0.8046875\n",
      "Batch: 63, Loss: 0.6910693645477295, Accuracy: 0.78125\n",
      "Batch: 64, Loss: 0.6141437292098999, Accuracy: 0.794921875\n",
      "Batch: 65, Loss: 0.6828548908233643, Accuracy: 0.7822265625\n",
      "Batch: 66, Loss: 0.7107544541358948, Accuracy: 0.7734375\n",
      "Batch: 67, Loss: 0.7030532956123352, Accuracy: 0.783203125\n",
      "Batch: 68, Loss: 0.7256780862808228, Accuracy: 0.765625\n",
      "Batch: 69, Loss: 0.6878820061683655, Accuracy: 0.7646484375\n",
      "Batch: 70, Loss: 0.6751714944839478, Accuracy: 0.7763671875\n",
      "Batch: 71, Loss: 0.6481771469116211, Accuracy: 0.7880859375\n",
      "Batch: 72, Loss: 0.6158257126808167, Accuracy: 0.8037109375\n",
      "Batch: 73, Loss: 0.5885037779808044, Accuracy: 0.814453125\n",
      "Batch: 74, Loss: 0.5734556913375854, Accuracy: 0.82421875\n",
      "Batch: 75, Loss: 0.5995442867279053, Accuracy: 0.8095703125\n",
      "Batch: 76, Loss: 0.6807649731636047, Accuracy: 0.7802734375\n",
      "Batch: 77, Loss: 0.6056073904037476, Accuracy: 0.80078125\n",
      "Batch: 78, Loss: 0.5576589107513428, Accuracy: 0.8330078125\n",
      "Batch: 79, Loss: 0.5867899060249329, Accuracy: 0.8310546875\n",
      "Batch: 80, Loss: 0.5991203188896179, Accuracy: 0.8076171875\n",
      "Batch: 81, Loss: 0.6763887405395508, Accuracy: 0.7705078125\n",
      "Batch: 82, Loss: 0.6776361465454102, Accuracy: 0.7666015625\n",
      "Batch: 83, Loss: 0.5876095294952393, Accuracy: 0.8291015625\n",
      "Batch: 84, Loss: 0.6471977829933167, Accuracy: 0.791015625\n",
      "Batch: 85, Loss: 0.6219148635864258, Accuracy: 0.794921875\n",
      "Batch: 86, Loss: 0.7196632623672485, Accuracy: 0.7724609375\n",
      "Batch: 87, Loss: 0.6005693078041077, Accuracy: 0.8115234375\n",
      "Batch: 88, Loss: 0.6624014377593994, Accuracy: 0.8017578125\n",
      "Batch: 89, Loss: 0.6979928016662598, Accuracy: 0.7685546875\n",
      "Batch: 90, Loss: 0.6226657629013062, Accuracy: 0.8037109375\n",
      "Batch: 91, Loss: 0.5882446765899658, Accuracy: 0.80078125\n",
      "Batch: 92, Loss: 0.6780584454536438, Accuracy: 0.78125\n",
      "Batch: 93, Loss: 0.6573273539543152, Accuracy: 0.7890625\n",
      "Batch: 94, Loss: 0.6788643598556519, Accuracy: 0.775390625\n",
      "Batch: 95, Loss: 0.6666930317878723, Accuracy: 0.7705078125\n",
      "Batch: 96, Loss: 0.6683294773101807, Accuracy: 0.77734375\n",
      "Batch: 97, Loss: 0.5379525423049927, Accuracy: 0.8291015625\n",
      "Batch: 98, Loss: 0.6515504121780396, Accuracy: 0.7783203125\n",
      "Batch: 99, Loss: 0.6458569169044495, Accuracy: 0.783203125\n",
      "Batch: 100, Loss: 0.656592845916748, Accuracy: 0.791015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 101, Loss: 0.7041252851486206, Accuracy: 0.7705078125\n",
      "Batch: 102, Loss: 0.6500546336174011, Accuracy: 0.791015625\n",
      "Batch: 103, Loss: 0.6530377268791199, Accuracy: 0.7998046875\n",
      "Batch: 104, Loss: 0.6308286190032959, Accuracy: 0.79296875\n",
      "Batch: 105, Loss: 0.6598237752914429, Accuracy: 0.7705078125\n",
      "Batch: 106, Loss: 0.6176689267158508, Accuracy: 0.7958984375\n",
      "Batch: 107, Loss: 0.6650753021240234, Accuracy: 0.7939453125\n",
      "Batch: 108, Loss: 0.640293538570404, Accuracy: 0.7998046875\n",
      "Batch: 109, Loss: 0.688784122467041, Accuracy: 0.7744140625\n",
      "Batch: 110, Loss: 0.5861416459083557, Accuracy: 0.8095703125\n",
      "Batch: 111, Loss: 0.6304407119750977, Accuracy: 0.7880859375\n",
      "Batch: 112, Loss: 0.6929530501365662, Accuracy: 0.7763671875\n",
      "Batch: 113, Loss: 0.672607958316803, Accuracy: 0.771484375\n",
      "Batch: 114, Loss: 0.6627646684646606, Accuracy: 0.7822265625\n",
      "Batch: 115, Loss: 0.718154788017273, Accuracy: 0.763671875\n",
      "Batch: 116, Loss: 0.6574735641479492, Accuracy: 0.7880859375\n",
      "Batch: 117, Loss: 0.6924328804016113, Accuracy: 0.7763671875\n",
      "Batch: 118, Loss: 0.6121855974197388, Accuracy: 0.7958984375\n",
      "Batch: 119, Loss: 0.584941029548645, Accuracy: 0.798828125\n",
      "Batch: 120, Loss: 0.6302947998046875, Accuracy: 0.798828125\n",
      "Batch: 121, Loss: 0.7259881496429443, Accuracy: 0.779296875\n",
      "Batch: 122, Loss: 0.6326515674591064, Accuracy: 0.79296875\n",
      "Batch: 123, Loss: 0.6204276084899902, Accuracy: 0.81640625\n",
      "Batch: 124, Loss: 0.6780047416687012, Accuracy: 0.7900390625\n",
      "Batch: 125, Loss: 0.7077388763427734, Accuracy: 0.7890625\n",
      "Batch: 126, Loss: 0.6808834671974182, Accuracy: 0.76953125\n",
      "Batch: 127, Loss: 0.5853745937347412, Accuracy: 0.8076171875\n",
      "Batch: 128, Loss: 0.7280824780464172, Accuracy: 0.775390625\n",
      "Batch: 129, Loss: 0.6063188910484314, Accuracy: 0.80078125\n",
      "Batch: 130, Loss: 0.7593282461166382, Accuracy: 0.7578125\n",
      "Batch: 131, Loss: 0.7251632809638977, Accuracy: 0.755859375\n",
      "Batch: 132, Loss: 0.6900113821029663, Accuracy: 0.779296875\n",
      "Batch: 133, Loss: 0.647308886051178, Accuracy: 0.7802734375\n",
      "Batch: 134, Loss: 0.660246729850769, Accuracy: 0.78125\n",
      "Batch: 135, Loss: 0.6314915418624878, Accuracy: 0.810546875\n",
      "Batch: 136, Loss: 0.64932781457901, Accuracy: 0.7841796875\n",
      "Batch: 137, Loss: 0.6868407726287842, Accuracy: 0.755859375\n",
      "Batch: 138, Loss: 0.6265895962715149, Accuracy: 0.78125\n",
      "Batch: 139, Loss: 0.633837103843689, Accuracy: 0.787109375\n",
      "Batch: 140, Loss: 0.687387228012085, Accuracy: 0.7783203125\n",
      "Batch: 141, Loss: 0.6945870518684387, Accuracy: 0.7685546875\n",
      "Batch: 142, Loss: 0.7508659362792969, Accuracy: 0.7607421875\n",
      "Batch: 143, Loss: 0.6586765050888062, Accuracy: 0.76953125\n",
      "Batch: 144, Loss: 0.6441546082496643, Accuracy: 0.783203125\n",
      "Batch: 145, Loss: 0.6234394907951355, Accuracy: 0.7919921875\n",
      "Batch: 146, Loss: 0.7140082716941833, Accuracy: 0.75\n",
      "Batch: 147, Loss: 0.6588364839553833, Accuracy: 0.80078125\n",
      "Batch: 148, Loss: 0.6985653042793274, Accuracy: 0.771484375\n",
      "Batch: 149, Loss: 0.6193516850471497, Accuracy: 0.798828125\n",
      "Batch: 150, Loss: 0.678755521774292, Accuracy: 0.78515625\n",
      "Batch: 151, Loss: 0.5802728533744812, Accuracy: 0.8115234375\n",
      "Epoch 58/80\n",
      "Batch: 1, Loss: 0.8112318515777588, Accuracy: 0.7412109375\n",
      "Batch: 2, Loss: 0.6686526536941528, Accuracy: 0.76171875\n",
      "Batch: 3, Loss: 0.6245073080062866, Accuracy: 0.7939453125\n",
      "Batch: 4, Loss: 0.58676677942276, Accuracy: 0.80078125\n",
      "Batch: 5, Loss: 0.6390350461006165, Accuracy: 0.796875\n",
      "Batch: 6, Loss: 0.6465321779251099, Accuracy: 0.779296875\n",
      "Batch: 7, Loss: 0.6354096531867981, Accuracy: 0.7900390625\n",
      "Batch: 8, Loss: 0.6210420727729797, Accuracy: 0.806640625\n",
      "Batch: 9, Loss: 0.6309201717376709, Accuracy: 0.7841796875\n",
      "Batch: 10, Loss: 0.600811243057251, Accuracy: 0.80859375\n",
      "Batch: 11, Loss: 0.7365990877151489, Accuracy: 0.7431640625\n",
      "Batch: 12, Loss: 0.7048836946487427, Accuracy: 0.767578125\n",
      "Batch: 13, Loss: 0.5322732329368591, Accuracy: 0.830078125\n",
      "Batch: 14, Loss: 0.7288444638252258, Accuracy: 0.7548828125\n",
      "Batch: 15, Loss: 0.5865340232849121, Accuracy: 0.8134765625\n",
      "Batch: 16, Loss: 0.6033669710159302, Accuracy: 0.7939453125\n",
      "Batch: 17, Loss: 0.6211833953857422, Accuracy: 0.7958984375\n",
      "Batch: 18, Loss: 0.685146689414978, Accuracy: 0.775390625\n",
      "Batch: 19, Loss: 0.6937841176986694, Accuracy: 0.78125\n",
      "Batch: 20, Loss: 0.5932493209838867, Accuracy: 0.814453125\n",
      "Batch: 21, Loss: 0.5996096730232239, Accuracy: 0.80859375\n",
      "Batch: 22, Loss: 0.743757963180542, Accuracy: 0.7666015625\n",
      "Batch: 23, Loss: 0.6813591718673706, Accuracy: 0.7607421875\n",
      "Batch: 24, Loss: 0.6911994218826294, Accuracy: 0.7724609375\n",
      "Batch: 25, Loss: 0.631621241569519, Accuracy: 0.796875\n",
      "Batch: 26, Loss: 0.5462881922721863, Accuracy: 0.826171875\n",
      "Batch: 27, Loss: 0.630262017250061, Accuracy: 0.7958984375\n",
      "Batch: 28, Loss: 0.6372873187065125, Accuracy: 0.7900390625\n",
      "Batch: 29, Loss: 0.6138803958892822, Accuracy: 0.7978515625\n",
      "Batch: 30, Loss: 0.5954268574714661, Accuracy: 0.8134765625\n",
      "Batch: 31, Loss: 0.5761854648590088, Accuracy: 0.826171875\n",
      "Batch: 32, Loss: 0.6160550713539124, Accuracy: 0.798828125\n",
      "Batch: 33, Loss: 0.7174817323684692, Accuracy: 0.7607421875\n",
      "Batch: 34, Loss: 0.7236847281455994, Accuracy: 0.76953125\n",
      "Batch: 35, Loss: 0.6970582008361816, Accuracy: 0.767578125\n",
      "Batch: 36, Loss: 0.6649499535560608, Accuracy: 0.7880859375\n",
      "Batch: 37, Loss: 0.6750680208206177, Accuracy: 0.771484375\n",
      "Batch: 38, Loss: 0.7005211114883423, Accuracy: 0.7685546875\n",
      "Batch: 39, Loss: 0.6568401455879211, Accuracy: 0.783203125\n",
      "Batch: 40, Loss: 0.629592776298523, Accuracy: 0.7939453125\n",
      "Batch: 41, Loss: 0.6087461709976196, Accuracy: 0.8017578125\n",
      "Batch: 42, Loss: 0.49230533838272095, Accuracy: 0.8310546875\n",
      "Batch: 43, Loss: 0.6405998468399048, Accuracy: 0.7880859375\n",
      "Batch: 44, Loss: 0.6355512142181396, Accuracy: 0.783203125\n",
      "Batch: 45, Loss: 0.5998870730400085, Accuracy: 0.802734375\n",
      "Batch: 46, Loss: 0.5883515477180481, Accuracy: 0.8046875\n",
      "Batch: 47, Loss: 0.6449252963066101, Accuracy: 0.8046875\n",
      "Batch: 48, Loss: 0.648853063583374, Accuracy: 0.798828125\n",
      "Batch: 49, Loss: 0.6815909743309021, Accuracy: 0.7880859375\n",
      "Batch: 50, Loss: 0.6134833693504333, Accuracy: 0.7900390625\n",
      "Batch: 51, Loss: 0.6818091869354248, Accuracy: 0.78125\n",
      "Batch: 52, Loss: 0.6395199298858643, Accuracy: 0.794921875\n",
      "Batch: 53, Loss: 0.5959949493408203, Accuracy: 0.8076171875\n",
      "Batch: 54, Loss: 0.6062098741531372, Accuracy: 0.810546875\n",
      "Batch: 55, Loss: 0.6900894045829773, Accuracy: 0.76171875\n",
      "Batch: 56, Loss: 0.7182216644287109, Accuracy: 0.7587890625\n",
      "Batch: 57, Loss: 0.6607505679130554, Accuracy: 0.78515625\n",
      "Batch: 58, Loss: 0.7085956335067749, Accuracy: 0.779296875\n",
      "Batch: 59, Loss: 0.6293953061103821, Accuracy: 0.8115234375\n",
      "Batch: 60, Loss: 0.6062529683113098, Accuracy: 0.796875\n",
      "Batch: 61, Loss: 0.6672861576080322, Accuracy: 0.779296875\n",
      "Batch: 62, Loss: 0.6062024235725403, Accuracy: 0.798828125\n",
      "Batch: 63, Loss: 0.6582424640655518, Accuracy: 0.7763671875\n",
      "Batch: 64, Loss: 0.6385565996170044, Accuracy: 0.787109375\n",
      "Batch: 65, Loss: 0.6792848110198975, Accuracy: 0.7822265625\n",
      "Batch: 66, Loss: 0.651889979839325, Accuracy: 0.798828125\n",
      "Batch: 67, Loss: 0.7344496250152588, Accuracy: 0.78515625\n",
      "Batch: 68, Loss: 0.7332208156585693, Accuracy: 0.7666015625\n",
      "Batch: 69, Loss: 0.6474853157997131, Accuracy: 0.7822265625\n",
      "Batch: 70, Loss: 0.6929131746292114, Accuracy: 0.7861328125\n",
      "Batch: 71, Loss: 0.6779378652572632, Accuracy: 0.7841796875\n",
      "Batch: 72, Loss: 0.6232450008392334, Accuracy: 0.8037109375\n",
      "Batch: 73, Loss: 0.6055211424827576, Accuracy: 0.8115234375\n",
      "Batch: 74, Loss: 0.575873613357544, Accuracy: 0.8154296875\n",
      "Batch: 75, Loss: 0.5900405645370483, Accuracy: 0.8115234375\n",
      "Batch: 76, Loss: 0.6454546451568604, Accuracy: 0.806640625\n",
      "Batch: 77, Loss: 0.5677805542945862, Accuracy: 0.810546875\n",
      "Batch: 78, Loss: 0.6119421720504761, Accuracy: 0.8046875\n",
      "Batch: 79, Loss: 0.6005521416664124, Accuracy: 0.8115234375\n",
      "Batch: 80, Loss: 0.593666672706604, Accuracy: 0.8037109375\n",
      "Batch: 81, Loss: 0.6771142482757568, Accuracy: 0.7666015625\n",
      "Batch: 82, Loss: 0.639241635799408, Accuracy: 0.78515625\n",
      "Batch: 83, Loss: 0.6113887429237366, Accuracy: 0.8154296875\n",
      "Batch: 84, Loss: 0.6401479840278625, Accuracy: 0.7919921875\n",
      "Batch: 85, Loss: 0.6380606889724731, Accuracy: 0.7880859375\n",
      "Batch: 86, Loss: 0.6902823448181152, Accuracy: 0.7783203125\n",
      "Batch: 87, Loss: 0.6034097671508789, Accuracy: 0.7978515625\n",
      "Batch: 88, Loss: 0.6793647408485413, Accuracy: 0.7939453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 89, Loss: 0.6514664888381958, Accuracy: 0.7861328125\n",
      "Batch: 90, Loss: 0.5908958911895752, Accuracy: 0.8232421875\n",
      "Batch: 91, Loss: 0.6262524127960205, Accuracy: 0.7958984375\n",
      "Batch: 92, Loss: 0.6466883420944214, Accuracy: 0.798828125\n",
      "Batch: 93, Loss: 0.6551511883735657, Accuracy: 0.7880859375\n",
      "Batch: 94, Loss: 0.6859825253486633, Accuracy: 0.771484375\n",
      "Batch: 95, Loss: 0.6585503220558167, Accuracy: 0.7822265625\n",
      "Batch: 96, Loss: 0.6442202925682068, Accuracy: 0.7822265625\n",
      "Batch: 97, Loss: 0.5304809212684631, Accuracy: 0.8291015625\n",
      "Batch: 98, Loss: 0.6526891589164734, Accuracy: 0.787109375\n",
      "Batch: 99, Loss: 0.6183568835258484, Accuracy: 0.79296875\n",
      "Batch: 100, Loss: 0.6391474008560181, Accuracy: 0.791015625\n",
      "Batch: 101, Loss: 0.6797711849212646, Accuracy: 0.7744140625\n",
      "Batch: 102, Loss: 0.659447193145752, Accuracy: 0.7880859375\n",
      "Batch: 103, Loss: 0.6780284643173218, Accuracy: 0.7880859375\n",
      "Batch: 104, Loss: 0.6114915609359741, Accuracy: 0.806640625\n",
      "Batch: 105, Loss: 0.6664587259292603, Accuracy: 0.7841796875\n",
      "Batch: 106, Loss: 0.5686197876930237, Accuracy: 0.8203125\n",
      "Batch: 107, Loss: 0.6693967580795288, Accuracy: 0.7802734375\n",
      "Batch: 108, Loss: 0.6249654293060303, Accuracy: 0.8037109375\n",
      "Batch: 109, Loss: 0.6774506568908691, Accuracy: 0.7802734375\n",
      "Batch: 110, Loss: 0.6175092458724976, Accuracy: 0.8046875\n",
      "Batch: 111, Loss: 0.6482566595077515, Accuracy: 0.783203125\n",
      "Batch: 112, Loss: 0.6586767435073853, Accuracy: 0.7802734375\n",
      "Batch: 113, Loss: 0.646547257900238, Accuracy: 0.7978515625\n",
      "Batch: 114, Loss: 0.6937793493270874, Accuracy: 0.7734375\n",
      "Batch: 115, Loss: 0.7266583442687988, Accuracy: 0.76953125\n",
      "Batch: 116, Loss: 0.6838176250457764, Accuracy: 0.7685546875\n",
      "Batch: 117, Loss: 0.7068222761154175, Accuracy: 0.7744140625\n",
      "Batch: 118, Loss: 0.6127734184265137, Accuracy: 0.7998046875\n",
      "Batch: 119, Loss: 0.5410333871841431, Accuracy: 0.8310546875\n",
      "Batch: 120, Loss: 0.657885730266571, Accuracy: 0.7802734375\n",
      "Batch: 121, Loss: 0.7008844614028931, Accuracy: 0.7763671875\n",
      "Batch: 122, Loss: 0.6551585793495178, Accuracy: 0.787109375\n",
      "Batch: 123, Loss: 0.6359231472015381, Accuracy: 0.7861328125\n",
      "Batch: 124, Loss: 0.6840388774871826, Accuracy: 0.7763671875\n",
      "Batch: 125, Loss: 0.6906076669692993, Accuracy: 0.7783203125\n",
      "Batch: 126, Loss: 0.6596014499664307, Accuracy: 0.779296875\n",
      "Batch: 127, Loss: 0.5697757005691528, Accuracy: 0.8271484375\n",
      "Batch: 128, Loss: 0.7093780040740967, Accuracy: 0.7744140625\n",
      "Batch: 129, Loss: 0.6523998975753784, Accuracy: 0.7978515625\n",
      "Batch: 130, Loss: 0.7593221068382263, Accuracy: 0.7548828125\n",
      "Batch: 131, Loss: 0.6760502457618713, Accuracy: 0.7880859375\n",
      "Batch: 132, Loss: 0.6807025074958801, Accuracy: 0.79296875\n",
      "Batch: 133, Loss: 0.6399164199829102, Accuracy: 0.7900390625\n",
      "Batch: 134, Loss: 0.6843810081481934, Accuracy: 0.76171875\n",
      "Batch: 135, Loss: 0.6064407825469971, Accuracy: 0.798828125\n",
      "Batch: 136, Loss: 0.6852439641952515, Accuracy: 0.7841796875\n",
      "Batch: 137, Loss: 0.6783386468887329, Accuracy: 0.7666015625\n",
      "Batch: 138, Loss: 0.6022114157676697, Accuracy: 0.791015625\n",
      "Batch: 139, Loss: 0.5885159969329834, Accuracy: 0.7998046875\n",
      "Batch: 140, Loss: 0.6628847122192383, Accuracy: 0.7763671875\n",
      "Batch: 141, Loss: 0.7246658802032471, Accuracy: 0.7646484375\n",
      "Batch: 142, Loss: 0.729066014289856, Accuracy: 0.7763671875\n",
      "Batch: 143, Loss: 0.6349623203277588, Accuracy: 0.7958984375\n",
      "Batch: 144, Loss: 0.6691933870315552, Accuracy: 0.79296875\n",
      "Batch: 145, Loss: 0.6127184629440308, Accuracy: 0.7861328125\n",
      "Batch: 146, Loss: 0.6662305593490601, Accuracy: 0.78125\n",
      "Batch: 147, Loss: 0.64256751537323, Accuracy: 0.7900390625\n",
      "Batch: 148, Loss: 0.6924072504043579, Accuracy: 0.765625\n",
      "Batch: 149, Loss: 0.6364388465881348, Accuracy: 0.7802734375\n",
      "Batch: 150, Loss: 0.6602178812026978, Accuracy: 0.794921875\n",
      "Batch: 151, Loss: 0.6312471628189087, Accuracy: 0.8037109375\n",
      "Epoch 59/80\n",
      "Batch: 1, Loss: 0.8427838683128357, Accuracy: 0.7392578125\n",
      "Batch: 2, Loss: 0.7254028916358948, Accuracy: 0.755859375\n",
      "Batch: 3, Loss: 0.6284151077270508, Accuracy: 0.7978515625\n",
      "Batch: 4, Loss: 0.6062471866607666, Accuracy: 0.8076171875\n",
      "Batch: 5, Loss: 0.6146526336669922, Accuracy: 0.794921875\n",
      "Batch: 6, Loss: 0.647149384021759, Accuracy: 0.775390625\n",
      "Batch: 7, Loss: 0.6368176341056824, Accuracy: 0.79296875\n",
      "Batch: 8, Loss: 0.6095061302185059, Accuracy: 0.798828125\n",
      "Batch: 9, Loss: 0.629562258720398, Accuracy: 0.7978515625\n",
      "Batch: 10, Loss: 0.5958157777786255, Accuracy: 0.7998046875\n",
      "Batch: 11, Loss: 0.6724867820739746, Accuracy: 0.7734375\n",
      "Batch: 12, Loss: 0.7153723239898682, Accuracy: 0.78125\n",
      "Batch: 13, Loss: 0.5463310480117798, Accuracy: 0.826171875\n",
      "Batch: 14, Loss: 0.7098971009254456, Accuracy: 0.74609375\n",
      "Batch: 15, Loss: 0.6198148727416992, Accuracy: 0.8125\n",
      "Batch: 16, Loss: 0.6401282548904419, Accuracy: 0.806640625\n",
      "Batch: 17, Loss: 0.6362413167953491, Accuracy: 0.7880859375\n",
      "Batch: 18, Loss: 0.6760802268981934, Accuracy: 0.7666015625\n",
      "Batch: 19, Loss: 0.6471063494682312, Accuracy: 0.7998046875\n",
      "Batch: 20, Loss: 0.585220217704773, Accuracy: 0.814453125\n",
      "Batch: 21, Loss: 0.5754814147949219, Accuracy: 0.796875\n",
      "Batch: 22, Loss: 0.6992727518081665, Accuracy: 0.7685546875\n",
      "Batch: 23, Loss: 0.7125897407531738, Accuracy: 0.7783203125\n",
      "Batch: 24, Loss: 0.6826443672180176, Accuracy: 0.7763671875\n",
      "Batch: 25, Loss: 0.650607705116272, Accuracy: 0.7783203125\n",
      "Batch: 26, Loss: 0.5363578796386719, Accuracy: 0.8310546875\n",
      "Batch: 27, Loss: 0.6223960518836975, Accuracy: 0.7939453125\n",
      "Batch: 28, Loss: 0.6245366334915161, Accuracy: 0.78515625\n",
      "Batch: 29, Loss: 0.6141546368598938, Accuracy: 0.794921875\n",
      "Batch: 30, Loss: 0.6014269590377808, Accuracy: 0.802734375\n",
      "Batch: 31, Loss: 0.554625391960144, Accuracy: 0.8203125\n",
      "Batch: 32, Loss: 0.6066511869430542, Accuracy: 0.8056640625\n",
      "Batch: 33, Loss: 0.6947519779205322, Accuracy: 0.7734375\n",
      "Batch: 34, Loss: 0.7119829058647156, Accuracy: 0.7646484375\n",
      "Batch: 35, Loss: 0.6721360683441162, Accuracy: 0.7802734375\n",
      "Batch: 36, Loss: 0.6601307988166809, Accuracy: 0.77734375\n",
      "Batch: 37, Loss: 0.6739729642868042, Accuracy: 0.7744140625\n",
      "Batch: 38, Loss: 0.6657669544219971, Accuracy: 0.7685546875\n",
      "Batch: 39, Loss: 0.6578599214553833, Accuracy: 0.7763671875\n",
      "Batch: 40, Loss: 0.6349632143974304, Accuracy: 0.779296875\n",
      "Batch: 41, Loss: 0.5687728524208069, Accuracy: 0.810546875\n",
      "Batch: 42, Loss: 0.5178815126419067, Accuracy: 0.8173828125\n",
      "Batch: 43, Loss: 0.6254582405090332, Accuracy: 0.7939453125\n",
      "Batch: 44, Loss: 0.6512928605079651, Accuracy: 0.7861328125\n",
      "Batch: 45, Loss: 0.555149495601654, Accuracy: 0.80859375\n",
      "Batch: 46, Loss: 0.5771192312240601, Accuracy: 0.82421875\n",
      "Batch: 47, Loss: 0.6590753793716431, Accuracy: 0.8017578125\n",
      "Batch: 48, Loss: 0.618527352809906, Accuracy: 0.794921875\n",
      "Batch: 49, Loss: 0.6838829517364502, Accuracy: 0.7890625\n",
      "Batch: 50, Loss: 0.5921476483345032, Accuracy: 0.80859375\n",
      "Batch: 51, Loss: 0.6514352560043335, Accuracy: 0.794921875\n",
      "Batch: 52, Loss: 0.6509406566619873, Accuracy: 0.791015625\n",
      "Batch: 53, Loss: 0.5872267484664917, Accuracy: 0.8134765625\n",
      "Batch: 54, Loss: 0.6121498346328735, Accuracy: 0.798828125\n",
      "Batch: 55, Loss: 0.6920205354690552, Accuracy: 0.7734375\n",
      "Batch: 56, Loss: 0.6884152889251709, Accuracy: 0.7744140625\n",
      "Batch: 57, Loss: 0.6700711250305176, Accuracy: 0.775390625\n",
      "Batch: 58, Loss: 0.7217429876327515, Accuracy: 0.7626953125\n",
      "Batch: 59, Loss: 0.6268887519836426, Accuracy: 0.8037109375\n",
      "Batch: 60, Loss: 0.6008575558662415, Accuracy: 0.796875\n",
      "Batch: 61, Loss: 0.6819994449615479, Accuracy: 0.7880859375\n",
      "Batch: 62, Loss: 0.6004869937896729, Accuracy: 0.7880859375\n",
      "Batch: 63, Loss: 0.6430107355117798, Accuracy: 0.7841796875\n",
      "Batch: 64, Loss: 0.6063166856765747, Accuracy: 0.7978515625\n",
      "Batch: 65, Loss: 0.6665335893630981, Accuracy: 0.791015625\n",
      "Batch: 66, Loss: 0.6544491052627563, Accuracy: 0.791015625\n",
      "Batch: 67, Loss: 0.7090209126472473, Accuracy: 0.779296875\n",
      "Batch: 68, Loss: 0.7330327033996582, Accuracy: 0.765625\n",
      "Batch: 69, Loss: 0.6557619571685791, Accuracy: 0.77734375\n",
      "Batch: 70, Loss: 0.6684662103652954, Accuracy: 0.798828125\n",
      "Batch: 71, Loss: 0.6440075635910034, Accuracy: 0.7763671875\n",
      "Batch: 72, Loss: 0.6114369630813599, Accuracy: 0.8134765625\n",
      "Batch: 73, Loss: 0.5867781639099121, Accuracy: 0.8115234375\n",
      "Batch: 74, Loss: 0.6028888821601868, Accuracy: 0.8232421875\n",
      "Batch: 75, Loss: 0.5536512136459351, Accuracy: 0.82421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 76, Loss: 0.617798924446106, Accuracy: 0.8037109375\n",
      "Batch: 77, Loss: 0.5628694891929626, Accuracy: 0.802734375\n",
      "Batch: 78, Loss: 0.5921148657798767, Accuracy: 0.810546875\n",
      "Batch: 79, Loss: 0.5988864898681641, Accuracy: 0.8115234375\n",
      "Batch: 80, Loss: 0.6029536724090576, Accuracy: 0.810546875\n",
      "Batch: 81, Loss: 0.693142831325531, Accuracy: 0.7509765625\n",
      "Batch: 82, Loss: 0.6508581638336182, Accuracy: 0.7734375\n",
      "Batch: 83, Loss: 0.5731341242790222, Accuracy: 0.826171875\n",
      "Batch: 84, Loss: 0.6455188989639282, Accuracy: 0.794921875\n",
      "Batch: 85, Loss: 0.5877302885055542, Accuracy: 0.8095703125\n",
      "Batch: 86, Loss: 0.7359944581985474, Accuracy: 0.775390625\n",
      "Batch: 87, Loss: 0.6006377935409546, Accuracy: 0.8056640625\n",
      "Batch: 88, Loss: 0.665019154548645, Accuracy: 0.7939453125\n",
      "Batch: 89, Loss: 0.6486874222755432, Accuracy: 0.78515625\n",
      "Batch: 90, Loss: 0.626338541507721, Accuracy: 0.798828125\n",
      "Batch: 91, Loss: 0.6004321575164795, Accuracy: 0.794921875\n",
      "Batch: 92, Loss: 0.6533522605895996, Accuracy: 0.7900390625\n",
      "Batch: 93, Loss: 0.6463265419006348, Accuracy: 0.7802734375\n",
      "Batch: 94, Loss: 0.6609494686126709, Accuracy: 0.783203125\n",
      "Batch: 95, Loss: 0.661724328994751, Accuracy: 0.783203125\n",
      "Batch: 96, Loss: 0.6511300802230835, Accuracy: 0.7919921875\n",
      "Batch: 97, Loss: 0.5215888619422913, Accuracy: 0.8291015625\n",
      "Batch: 98, Loss: 0.6475494503974915, Accuracy: 0.7958984375\n",
      "Batch: 99, Loss: 0.6357393264770508, Accuracy: 0.7861328125\n",
      "Batch: 100, Loss: 0.672605574131012, Accuracy: 0.7724609375\n",
      "Batch: 101, Loss: 0.6702894568443298, Accuracy: 0.79296875\n",
      "Batch: 102, Loss: 0.6623005867004395, Accuracy: 0.7861328125\n",
      "Batch: 103, Loss: 0.6108565926551819, Accuracy: 0.8046875\n",
      "Batch: 104, Loss: 0.6314157843589783, Accuracy: 0.7978515625\n",
      "Batch: 105, Loss: 0.6324008703231812, Accuracy: 0.787109375\n",
      "Batch: 106, Loss: 0.5833985209465027, Accuracy: 0.806640625\n",
      "Batch: 107, Loss: 0.6162189245223999, Accuracy: 0.80859375\n",
      "Batch: 108, Loss: 0.6217775940895081, Accuracy: 0.79296875\n",
      "Batch: 109, Loss: 0.6933281421661377, Accuracy: 0.7763671875\n",
      "Batch: 110, Loss: 0.6141247153282166, Accuracy: 0.8046875\n",
      "Batch: 111, Loss: 0.6644386053085327, Accuracy: 0.7998046875\n",
      "Batch: 112, Loss: 0.6469920873641968, Accuracy: 0.7880859375\n",
      "Batch: 113, Loss: 0.6525964140892029, Accuracy: 0.79296875\n",
      "Batch: 114, Loss: 0.6565991640090942, Accuracy: 0.7841796875\n",
      "Batch: 115, Loss: 0.7118587493896484, Accuracy: 0.7744140625\n",
      "Batch: 116, Loss: 0.6607457399368286, Accuracy: 0.7822265625\n",
      "Batch: 117, Loss: 0.6982834935188293, Accuracy: 0.775390625\n",
      "Batch: 118, Loss: 0.5844087600708008, Accuracy: 0.8173828125\n",
      "Batch: 119, Loss: 0.5789800882339478, Accuracy: 0.8134765625\n",
      "Batch: 120, Loss: 0.6264766454696655, Accuracy: 0.7783203125\n",
      "Batch: 121, Loss: 0.6615606546401978, Accuracy: 0.7900390625\n",
      "Batch: 122, Loss: 0.6118953824043274, Accuracy: 0.7939453125\n",
      "Batch: 123, Loss: 0.5947046279907227, Accuracy: 0.814453125\n",
      "Batch: 124, Loss: 0.6435768008232117, Accuracy: 0.791015625\n",
      "Batch: 125, Loss: 0.6788448691368103, Accuracy: 0.7978515625\n",
      "Batch: 126, Loss: 0.6388773918151855, Accuracy: 0.7861328125\n",
      "Batch: 127, Loss: 0.5587741136550903, Accuracy: 0.8251953125\n",
      "Batch: 128, Loss: 0.7254992127418518, Accuracy: 0.779296875\n",
      "Batch: 129, Loss: 0.590642511844635, Accuracy: 0.814453125\n",
      "Batch: 130, Loss: 0.7119125723838806, Accuracy: 0.7548828125\n",
      "Batch: 131, Loss: 0.6480296850204468, Accuracy: 0.7734375\n",
      "Batch: 132, Loss: 0.6709374785423279, Accuracy: 0.787109375\n",
      "Batch: 133, Loss: 0.6761393547058105, Accuracy: 0.783203125\n",
      "Batch: 134, Loss: 0.6294562220573425, Accuracy: 0.78515625\n",
      "Batch: 135, Loss: 0.5881453156471252, Accuracy: 0.810546875\n",
      "Batch: 136, Loss: 0.6323030591011047, Accuracy: 0.796875\n",
      "Batch: 137, Loss: 0.6542491912841797, Accuracy: 0.775390625\n",
      "Batch: 138, Loss: 0.5945023894309998, Accuracy: 0.7919921875\n",
      "Batch: 139, Loss: 0.6322470903396606, Accuracy: 0.7900390625\n",
      "Batch: 140, Loss: 0.6648521423339844, Accuracy: 0.779296875\n",
      "Batch: 141, Loss: 0.6796334981918335, Accuracy: 0.76953125\n",
      "Batch: 142, Loss: 0.7448297142982483, Accuracy: 0.7568359375\n",
      "Batch: 143, Loss: 0.6397154331207275, Accuracy: 0.77734375\n",
      "Batch: 144, Loss: 0.6648857593536377, Accuracy: 0.779296875\n",
      "Batch: 145, Loss: 0.6112585663795471, Accuracy: 0.796875\n",
      "Batch: 146, Loss: 0.6719475388526917, Accuracy: 0.783203125\n",
      "Batch: 147, Loss: 0.6202157735824585, Accuracy: 0.796875\n",
      "Batch: 148, Loss: 0.6734499931335449, Accuracy: 0.7802734375\n",
      "Batch: 149, Loss: 0.6239802837371826, Accuracy: 0.7900390625\n",
      "Batch: 150, Loss: 0.6688791513442993, Accuracy: 0.791015625\n",
      "Batch: 151, Loss: 0.5973182916641235, Accuracy: 0.8046875\n",
      "Epoch 60/80\n",
      "Batch: 1, Loss: 0.8347295522689819, Accuracy: 0.7392578125\n",
      "Batch: 2, Loss: 0.6816145181655884, Accuracy: 0.7734375\n",
      "Batch: 3, Loss: 0.6297340393066406, Accuracy: 0.7861328125\n",
      "Batch: 4, Loss: 0.6080213785171509, Accuracy: 0.7998046875\n",
      "Batch: 5, Loss: 0.6359878778457642, Accuracy: 0.7919921875\n",
      "Batch: 6, Loss: 0.6466119289398193, Accuracy: 0.796875\n",
      "Batch: 7, Loss: 0.6612199544906616, Accuracy: 0.77734375\n",
      "Batch: 8, Loss: 0.5828276872634888, Accuracy: 0.8017578125\n",
      "Batch: 9, Loss: 0.5845229625701904, Accuracy: 0.8046875\n",
      "Batch: 10, Loss: 0.6165481805801392, Accuracy: 0.802734375\n",
      "Batch: 11, Loss: 0.6661931276321411, Accuracy: 0.77734375\n",
      "Batch: 12, Loss: 0.6950127482414246, Accuracy: 0.7841796875\n",
      "Batch: 13, Loss: 0.5901826620101929, Accuracy: 0.8076171875\n",
      "Batch: 14, Loss: 0.712954044342041, Accuracy: 0.76953125\n",
      "Batch: 15, Loss: 0.6080746650695801, Accuracy: 0.806640625\n",
      "Batch: 16, Loss: 0.5865916013717651, Accuracy: 0.8056640625\n",
      "Batch: 17, Loss: 0.6557161808013916, Accuracy: 0.794921875\n",
      "Batch: 18, Loss: 0.6521734595298767, Accuracy: 0.787109375\n",
      "Batch: 19, Loss: 0.6274576187133789, Accuracy: 0.8046875\n",
      "Batch: 20, Loss: 0.6306549310684204, Accuracy: 0.8037109375\n",
      "Batch: 21, Loss: 0.57799232006073, Accuracy: 0.8115234375\n",
      "Batch: 22, Loss: 0.7381130456924438, Accuracy: 0.7509765625\n",
      "Batch: 23, Loss: 0.7036327719688416, Accuracy: 0.7587890625\n",
      "Batch: 24, Loss: 0.6610912084579468, Accuracy: 0.7958984375\n",
      "Batch: 25, Loss: 0.6542025804519653, Accuracy: 0.794921875\n",
      "Batch: 26, Loss: 0.5585507154464722, Accuracy: 0.8056640625\n",
      "Batch: 27, Loss: 0.6064384579658508, Accuracy: 0.7998046875\n",
      "Batch: 28, Loss: 0.6176862716674805, Accuracy: 0.7939453125\n",
      "Batch: 29, Loss: 0.5998258590698242, Accuracy: 0.80859375\n",
      "Batch: 30, Loss: 0.5928515195846558, Accuracy: 0.8095703125\n",
      "Batch: 31, Loss: 0.550579845905304, Accuracy: 0.8203125\n",
      "Batch: 32, Loss: 0.592959463596344, Accuracy: 0.8037109375\n",
      "Batch: 33, Loss: 0.6914846897125244, Accuracy: 0.7587890625\n",
      "Batch: 34, Loss: 0.7037394046783447, Accuracy: 0.771484375\n",
      "Batch: 35, Loss: 0.680947482585907, Accuracy: 0.7685546875\n",
      "Batch: 36, Loss: 0.6520252227783203, Accuracy: 0.796875\n",
      "Batch: 37, Loss: 0.6748262047767639, Accuracy: 0.771484375\n",
      "Batch: 38, Loss: 0.6833277940750122, Accuracy: 0.7685546875\n",
      "Batch: 39, Loss: 0.6636936664581299, Accuracy: 0.7880859375\n",
      "Batch: 40, Loss: 0.6184839010238647, Accuracy: 0.79296875\n",
      "Batch: 41, Loss: 0.5860535502433777, Accuracy: 0.80859375\n",
      "Batch: 42, Loss: 0.4845994710922241, Accuracy: 0.8427734375\n",
      "Batch: 43, Loss: 0.5819263458251953, Accuracy: 0.8076171875\n",
      "Batch: 44, Loss: 0.6579331159591675, Accuracy: 0.783203125\n",
      "Batch: 45, Loss: 0.5706391334533691, Accuracy: 0.8134765625\n",
      "Batch: 46, Loss: 0.592038094997406, Accuracy: 0.8076171875\n",
      "Batch: 47, Loss: 0.6684378385543823, Accuracy: 0.80078125\n",
      "Batch: 48, Loss: 0.6185470223426819, Accuracy: 0.7978515625\n",
      "Batch: 49, Loss: 0.6785891056060791, Accuracy: 0.7705078125\n",
      "Batch: 50, Loss: 0.6554538011550903, Accuracy: 0.775390625\n",
      "Batch: 51, Loss: 0.6675163507461548, Accuracy: 0.794921875\n",
      "Batch: 52, Loss: 0.6150335669517517, Accuracy: 0.8056640625\n",
      "Batch: 53, Loss: 0.5701628923416138, Accuracy: 0.814453125\n",
      "Batch: 54, Loss: 0.6394149661064148, Accuracy: 0.7919921875\n",
      "Batch: 55, Loss: 0.6757466793060303, Accuracy: 0.7763671875\n",
      "Batch: 56, Loss: 0.7089093923568726, Accuracy: 0.755859375\n",
      "Batch: 57, Loss: 0.6608518362045288, Accuracy: 0.7802734375\n",
      "Batch: 58, Loss: 0.7471681833267212, Accuracy: 0.759765625\n",
      "Batch: 59, Loss: 0.6232370734214783, Accuracy: 0.7978515625\n",
      "Batch: 60, Loss: 0.6194549798965454, Accuracy: 0.7890625\n",
      "Batch: 61, Loss: 0.6888711452484131, Accuracy: 0.78515625\n",
      "Batch: 62, Loss: 0.5850831866264343, Accuracy: 0.8037109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 63, Loss: 0.6705669164657593, Accuracy: 0.7802734375\n",
      "Batch: 64, Loss: 0.6077723503112793, Accuracy: 0.8125\n",
      "Batch: 65, Loss: 0.6637580394744873, Accuracy: 0.7861328125\n",
      "Batch: 66, Loss: 0.6517866849899292, Accuracy: 0.7919921875\n",
      "Batch: 67, Loss: 0.7003339529037476, Accuracy: 0.77734375\n",
      "Batch: 68, Loss: 0.707274317741394, Accuracy: 0.767578125\n",
      "Batch: 69, Loss: 0.654852032661438, Accuracy: 0.7744140625\n",
      "Batch: 70, Loss: 0.7029662132263184, Accuracy: 0.7666015625\n",
      "Batch: 71, Loss: 0.6675847768783569, Accuracy: 0.7802734375\n",
      "Batch: 72, Loss: 0.6234645247459412, Accuracy: 0.794921875\n",
      "Batch: 73, Loss: 0.6136326789855957, Accuracy: 0.8046875\n",
      "Batch: 74, Loss: 0.5638332962989807, Accuracy: 0.8408203125\n",
      "Batch: 75, Loss: 0.5795606374740601, Accuracy: 0.814453125\n",
      "Batch: 76, Loss: 0.6437811851501465, Accuracy: 0.794921875\n",
      "Batch: 77, Loss: 0.585430383682251, Accuracy: 0.80859375\n",
      "Batch: 78, Loss: 0.5601149797439575, Accuracy: 0.8369140625\n",
      "Batch: 79, Loss: 0.6001935601234436, Accuracy: 0.81640625\n",
      "Batch: 80, Loss: 0.5580089092254639, Accuracy: 0.8154296875\n",
      "Batch: 81, Loss: 0.6666507124900818, Accuracy: 0.765625\n",
      "Batch: 82, Loss: 0.6247925758361816, Accuracy: 0.80859375\n",
      "Batch: 83, Loss: 0.5579863786697388, Accuracy: 0.8271484375\n",
      "Batch: 84, Loss: 0.6109477281570435, Accuracy: 0.7998046875\n",
      "Batch: 85, Loss: 0.6272587776184082, Accuracy: 0.80859375\n",
      "Batch: 86, Loss: 0.7298368811607361, Accuracy: 0.7744140625\n",
      "Batch: 87, Loss: 0.6261042356491089, Accuracy: 0.791015625\n",
      "Batch: 88, Loss: 0.62987220287323, Accuracy: 0.79296875\n",
      "Batch: 89, Loss: 0.6516208648681641, Accuracy: 0.7890625\n",
      "Batch: 90, Loss: 0.591707706451416, Accuracy: 0.798828125\n",
      "Batch: 91, Loss: 0.5980008244514465, Accuracy: 0.798828125\n",
      "Batch: 92, Loss: 0.6352837085723877, Accuracy: 0.7998046875\n",
      "Batch: 93, Loss: 0.6122866868972778, Accuracy: 0.8056640625\n",
      "Batch: 94, Loss: 0.6595351696014404, Accuracy: 0.791015625\n",
      "Batch: 95, Loss: 0.6271842122077942, Accuracy: 0.787109375\n",
      "Batch: 96, Loss: 0.6292482614517212, Accuracy: 0.798828125\n",
      "Batch: 97, Loss: 0.5483987927436829, Accuracy: 0.8212890625\n",
      "Batch: 98, Loss: 0.6524060368537903, Accuracy: 0.783203125\n",
      "Batch: 99, Loss: 0.6268812417984009, Accuracy: 0.7783203125\n",
      "Batch: 100, Loss: 0.6342366933822632, Accuracy: 0.7890625\n",
      "Batch: 101, Loss: 0.6352642774581909, Accuracy: 0.7978515625\n",
      "Batch: 102, Loss: 0.6557314991950989, Accuracy: 0.7890625\n",
      "Batch: 103, Loss: 0.6342859864234924, Accuracy: 0.7998046875\n",
      "Batch: 104, Loss: 0.6058446764945984, Accuracy: 0.80859375\n",
      "Batch: 105, Loss: 0.6339630484580994, Accuracy: 0.7890625\n",
      "Batch: 106, Loss: 0.5827224254608154, Accuracy: 0.8115234375\n",
      "Batch: 107, Loss: 0.611486554145813, Accuracy: 0.8046875\n",
      "Batch: 108, Loss: 0.6273529529571533, Accuracy: 0.80078125\n",
      "Batch: 109, Loss: 0.6806716918945312, Accuracy: 0.7646484375\n",
      "Batch: 110, Loss: 0.5813274383544922, Accuracy: 0.8037109375\n",
      "Batch: 111, Loss: 0.6672535538673401, Accuracy: 0.7919921875\n",
      "Batch: 112, Loss: 0.6424281597137451, Accuracy: 0.78515625\n",
      "Batch: 113, Loss: 0.6424369812011719, Accuracy: 0.7822265625\n",
      "Batch: 114, Loss: 0.6713166832923889, Accuracy: 0.783203125\n",
      "Batch: 115, Loss: 0.7192780375480652, Accuracy: 0.7607421875\n",
      "Batch: 116, Loss: 0.6255859136581421, Accuracy: 0.7919921875\n",
      "Batch: 117, Loss: 0.6690962314605713, Accuracy: 0.7783203125\n",
      "Batch: 118, Loss: 0.6172988414764404, Accuracy: 0.791015625\n",
      "Batch: 119, Loss: 0.5697410106658936, Accuracy: 0.8193359375\n",
      "Batch: 120, Loss: 0.5976431369781494, Accuracy: 0.794921875\n",
      "Batch: 121, Loss: 0.6778632402420044, Accuracy: 0.775390625\n",
      "Batch: 122, Loss: 0.6263539791107178, Accuracy: 0.796875\n",
      "Batch: 123, Loss: 0.5958317518234253, Accuracy: 0.8095703125\n",
      "Batch: 124, Loss: 0.6835588216781616, Accuracy: 0.7734375\n",
      "Batch: 125, Loss: 0.698997437953949, Accuracy: 0.783203125\n",
      "Batch: 126, Loss: 0.6432137489318848, Accuracy: 0.7919921875\n",
      "Batch: 127, Loss: 0.5471547842025757, Accuracy: 0.8251953125\n",
      "Batch: 128, Loss: 0.7045021057128906, Accuracy: 0.767578125\n",
      "Batch: 129, Loss: 0.5993033647537231, Accuracy: 0.8193359375\n",
      "Batch: 130, Loss: 0.7030963897705078, Accuracy: 0.7587890625\n",
      "Batch: 131, Loss: 0.6323344707489014, Accuracy: 0.7861328125\n",
      "Batch: 132, Loss: 0.6731375455856323, Accuracy: 0.798828125\n",
      "Batch: 133, Loss: 0.6269019842147827, Accuracy: 0.802734375\n",
      "Batch: 134, Loss: 0.6438132524490356, Accuracy: 0.7802734375\n",
      "Batch: 135, Loss: 0.6112610697746277, Accuracy: 0.7958984375\n",
      "Batch: 136, Loss: 0.6355171203613281, Accuracy: 0.791015625\n",
      "Batch: 137, Loss: 0.6745401620864868, Accuracy: 0.763671875\n",
      "Batch: 138, Loss: 0.6017532348632812, Accuracy: 0.798828125\n",
      "Batch: 139, Loss: 0.5825145244598389, Accuracy: 0.8056640625\n",
      "Batch: 140, Loss: 0.6599519848823547, Accuracy: 0.7861328125\n",
      "Batch: 141, Loss: 0.6743870377540588, Accuracy: 0.791015625\n",
      "Batch: 142, Loss: 0.6975904703140259, Accuracy: 0.771484375\n",
      "Batch: 143, Loss: 0.6631900072097778, Accuracy: 0.7763671875\n",
      "Batch: 144, Loss: 0.6570408344268799, Accuracy: 0.80078125\n",
      "Batch: 145, Loss: 0.5975092649459839, Accuracy: 0.7763671875\n",
      "Batch: 146, Loss: 0.6549311876296997, Accuracy: 0.7900390625\n",
      "Batch: 147, Loss: 0.6055722236633301, Accuracy: 0.810546875\n",
      "Batch: 148, Loss: 0.6915876865386963, Accuracy: 0.783203125\n",
      "Batch: 149, Loss: 0.6172971725463867, Accuracy: 0.7880859375\n",
      "Batch: 150, Loss: 0.644691526889801, Accuracy: 0.78515625\n",
      "Batch: 151, Loss: 0.5979882478713989, Accuracy: 0.8056640625\n",
      "Saved Weights at epoch 60 to file Weights_60.h5\n",
      "Epoch 61/80\n",
      "Batch: 1, Loss: 0.82358717918396, Accuracy: 0.74609375\n",
      "Batch: 2, Loss: 0.709629237651825, Accuracy: 0.7451171875\n",
      "Batch: 3, Loss: 0.6288039088249207, Accuracy: 0.796875\n",
      "Batch: 4, Loss: 0.5582817792892456, Accuracy: 0.8154296875\n",
      "Batch: 5, Loss: 0.5775177478790283, Accuracy: 0.8037109375\n",
      "Batch: 6, Loss: 0.6315286159515381, Accuracy: 0.7802734375\n",
      "Batch: 7, Loss: 0.6079189777374268, Accuracy: 0.7890625\n",
      "Batch: 8, Loss: 0.6107439994812012, Accuracy: 0.78515625\n",
      "Batch: 9, Loss: 0.6251027584075928, Accuracy: 0.7998046875\n",
      "Batch: 10, Loss: 0.5883595943450928, Accuracy: 0.806640625\n",
      "Batch: 11, Loss: 0.6585772037506104, Accuracy: 0.7744140625\n",
      "Batch: 12, Loss: 0.6477674841880798, Accuracy: 0.7861328125\n",
      "Batch: 13, Loss: 0.532729983329773, Accuracy: 0.822265625\n",
      "Batch: 14, Loss: 0.6765275001525879, Accuracy: 0.7734375\n",
      "Batch: 15, Loss: 0.5720809698104858, Accuracy: 0.826171875\n",
      "Batch: 16, Loss: 0.5847538113594055, Accuracy: 0.810546875\n",
      "Batch: 17, Loss: 0.64891517162323, Accuracy: 0.7900390625\n",
      "Batch: 18, Loss: 0.6799286603927612, Accuracy: 0.7705078125\n",
      "Batch: 19, Loss: 0.6845463514328003, Accuracy: 0.787109375\n",
      "Batch: 20, Loss: 0.5939252376556396, Accuracy: 0.802734375\n",
      "Batch: 21, Loss: 0.5797282457351685, Accuracy: 0.8134765625\n",
      "Batch: 22, Loss: 0.7238707542419434, Accuracy: 0.7529296875\n",
      "Batch: 23, Loss: 0.6445145606994629, Accuracy: 0.798828125\n",
      "Batch: 24, Loss: 0.6749794483184814, Accuracy: 0.7861328125\n",
      "Batch: 25, Loss: 0.6325533390045166, Accuracy: 0.7939453125\n",
      "Batch: 26, Loss: 0.520466685295105, Accuracy: 0.8310546875\n",
      "Batch: 27, Loss: 0.6251682043075562, Accuracy: 0.78125\n",
      "Batch: 28, Loss: 0.5808569192886353, Accuracy: 0.7958984375\n",
      "Batch: 29, Loss: 0.608675479888916, Accuracy: 0.794921875\n",
      "Batch: 30, Loss: 0.5562407374382019, Accuracy: 0.82421875\n",
      "Batch: 31, Loss: 0.5436623096466064, Accuracy: 0.8154296875\n",
      "Batch: 32, Loss: 0.5643659830093384, Accuracy: 0.8193359375\n",
      "Batch: 33, Loss: 0.6654605269432068, Accuracy: 0.78515625\n",
      "Batch: 34, Loss: 0.6979529857635498, Accuracy: 0.763671875\n",
      "Batch: 35, Loss: 0.7025293707847595, Accuracy: 0.77734375\n",
      "Batch: 36, Loss: 0.6307103037834167, Accuracy: 0.7900390625\n",
      "Batch: 37, Loss: 0.6724045276641846, Accuracy: 0.77734375\n",
      "Batch: 38, Loss: 0.6386606097221375, Accuracy: 0.783203125\n",
      "Batch: 39, Loss: 0.6395065188407898, Accuracy: 0.7802734375\n",
      "Batch: 40, Loss: 0.636048436164856, Accuracy: 0.8017578125\n",
      "Batch: 41, Loss: 0.5883053541183472, Accuracy: 0.8095703125\n",
      "Batch: 42, Loss: 0.5075815320014954, Accuracy: 0.8330078125\n",
      "Batch: 43, Loss: 0.6316904425621033, Accuracy: 0.802734375\n",
      "Batch: 44, Loss: 0.6666566133499146, Accuracy: 0.7880859375\n",
      "Batch: 45, Loss: 0.5793416500091553, Accuracy: 0.8115234375\n",
      "Batch: 46, Loss: 0.5908700823783875, Accuracy: 0.802734375\n",
      "Batch: 47, Loss: 0.638338565826416, Accuracy: 0.80859375\n",
      "Batch: 48, Loss: 0.5781971216201782, Accuracy: 0.8125\n",
      "Batch: 49, Loss: 0.6769091486930847, Accuracy: 0.7705078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Loss: 0.6089760661125183, Accuracy: 0.796875\n",
      "Batch: 51, Loss: 0.6495203375816345, Accuracy: 0.7880859375\n",
      "Batch: 52, Loss: 0.621231734752655, Accuracy: 0.7919921875\n",
      "Batch: 53, Loss: 0.5596931576728821, Accuracy: 0.810546875\n",
      "Batch: 54, Loss: 0.6119549870491028, Accuracy: 0.79296875\n",
      "Batch: 55, Loss: 0.6978862285614014, Accuracy: 0.7705078125\n",
      "Batch: 56, Loss: 0.6780910491943359, Accuracy: 0.7802734375\n",
      "Batch: 57, Loss: 0.666515588760376, Accuracy: 0.7822265625\n",
      "Batch: 58, Loss: 0.7159838676452637, Accuracy: 0.767578125\n",
      "Batch: 59, Loss: 0.5927284955978394, Accuracy: 0.7998046875\n",
      "Batch: 60, Loss: 0.6016750931739807, Accuracy: 0.794921875\n",
      "Batch: 61, Loss: 0.6708508729934692, Accuracy: 0.77734375\n",
      "Batch: 62, Loss: 0.5775526165962219, Accuracy: 0.80078125\n",
      "Batch: 63, Loss: 0.6235202550888062, Accuracy: 0.794921875\n",
      "Batch: 64, Loss: 0.6421921253204346, Accuracy: 0.77734375\n",
      "Batch: 65, Loss: 0.6679167747497559, Accuracy: 0.7880859375\n",
      "Batch: 66, Loss: 0.6452171802520752, Accuracy: 0.7890625\n",
      "Batch: 67, Loss: 0.707819402217865, Accuracy: 0.7939453125\n",
      "Batch: 68, Loss: 0.6999136209487915, Accuracy: 0.763671875\n",
      "Batch: 69, Loss: 0.673526406288147, Accuracy: 0.7744140625\n",
      "Batch: 70, Loss: 0.6527079343795776, Accuracy: 0.7958984375\n",
      "Batch: 71, Loss: 0.6680939793586731, Accuracy: 0.7822265625\n",
      "Batch: 72, Loss: 0.6075341701507568, Accuracy: 0.802734375\n",
      "Batch: 73, Loss: 0.56978440284729, Accuracy: 0.828125\n",
      "Batch: 74, Loss: 0.5608117580413818, Accuracy: 0.8349609375\n",
      "Batch: 75, Loss: 0.5433763265609741, Accuracy: 0.8359375\n",
      "Batch: 76, Loss: 0.6470215320587158, Accuracy: 0.79296875\n",
      "Batch: 77, Loss: 0.5586895942687988, Accuracy: 0.828125\n",
      "Batch: 78, Loss: 0.5935223698616028, Accuracy: 0.8046875\n",
      "Batch: 79, Loss: 0.582429051399231, Accuracy: 0.8251953125\n",
      "Batch: 80, Loss: 0.6029788851737976, Accuracy: 0.8076171875\n",
      "Batch: 81, Loss: 0.6925387382507324, Accuracy: 0.7666015625\n",
      "Batch: 82, Loss: 0.622051477432251, Accuracy: 0.7919921875\n",
      "Batch: 83, Loss: 0.5425184965133667, Accuracy: 0.830078125\n",
      "Batch: 84, Loss: 0.633154571056366, Accuracy: 0.7939453125\n",
      "Batch: 85, Loss: 0.6120010018348694, Accuracy: 0.8046875\n",
      "Batch: 86, Loss: 0.7297989130020142, Accuracy: 0.7646484375\n",
      "Batch: 87, Loss: 0.5938441753387451, Accuracy: 0.8037109375\n",
      "Batch: 88, Loss: 0.667731761932373, Accuracy: 0.7978515625\n",
      "Batch: 89, Loss: 0.6280176043510437, Accuracy: 0.7880859375\n",
      "Batch: 90, Loss: 0.5886029601097107, Accuracy: 0.8046875\n",
      "Batch: 91, Loss: 0.5842015743255615, Accuracy: 0.8076171875\n",
      "Batch: 92, Loss: 0.6387474536895752, Accuracy: 0.791015625\n",
      "Batch: 93, Loss: 0.6513733863830566, Accuracy: 0.78515625\n",
      "Batch: 94, Loss: 0.6867446899414062, Accuracy: 0.78125\n",
      "Batch: 95, Loss: 0.619391679763794, Accuracy: 0.7919921875\n",
      "Batch: 96, Loss: 0.6148437261581421, Accuracy: 0.8056640625\n",
      "Batch: 97, Loss: 0.5117301940917969, Accuracy: 0.83203125\n",
      "Batch: 98, Loss: 0.6321069002151489, Accuracy: 0.8017578125\n",
      "Batch: 99, Loss: 0.6170773506164551, Accuracy: 0.7958984375\n",
      "Batch: 100, Loss: 0.6299389004707336, Accuracy: 0.791015625\n",
      "Batch: 101, Loss: 0.6589597463607788, Accuracy: 0.77734375\n",
      "Batch: 102, Loss: 0.6507266759872437, Accuracy: 0.783203125\n",
      "Batch: 103, Loss: 0.6610338687896729, Accuracy: 0.802734375\n",
      "Batch: 104, Loss: 0.5915564298629761, Accuracy: 0.80859375\n",
      "Batch: 105, Loss: 0.6279419660568237, Accuracy: 0.7900390625\n",
      "Batch: 106, Loss: 0.5793190002441406, Accuracy: 0.802734375\n",
      "Batch: 107, Loss: 0.6216280460357666, Accuracy: 0.798828125\n",
      "Batch: 108, Loss: 0.6225295066833496, Accuracy: 0.7890625\n",
      "Batch: 109, Loss: 0.6489446759223938, Accuracy: 0.78515625\n",
      "Batch: 110, Loss: 0.5773634910583496, Accuracy: 0.8037109375\n",
      "Batch: 111, Loss: 0.6309630870819092, Accuracy: 0.7919921875\n",
      "Batch: 112, Loss: 0.6335251331329346, Accuracy: 0.7880859375\n",
      "Batch: 113, Loss: 0.6246330142021179, Accuracy: 0.791015625\n",
      "Batch: 114, Loss: 0.6378501653671265, Accuracy: 0.791015625\n",
      "Batch: 115, Loss: 0.7150311470031738, Accuracy: 0.763671875\n",
      "Batch: 116, Loss: 0.6426303386688232, Accuracy: 0.779296875\n",
      "Batch: 117, Loss: 0.6772851943969727, Accuracy: 0.78125\n",
      "Batch: 118, Loss: 0.6044297218322754, Accuracy: 0.806640625\n",
      "Batch: 119, Loss: 0.5660240650177002, Accuracy: 0.818359375\n",
      "Batch: 120, Loss: 0.6166481971740723, Accuracy: 0.791015625\n",
      "Batch: 121, Loss: 0.699554443359375, Accuracy: 0.7734375\n",
      "Batch: 122, Loss: 0.6125621199607849, Accuracy: 0.80859375\n",
      "Batch: 123, Loss: 0.5874037742614746, Accuracy: 0.8125\n",
      "Batch: 124, Loss: 0.6368676424026489, Accuracy: 0.8037109375\n",
      "Batch: 125, Loss: 0.6508089900016785, Accuracy: 0.7802734375\n",
      "Batch: 126, Loss: 0.6354783177375793, Accuracy: 0.7900390625\n",
      "Batch: 127, Loss: 0.5335992574691772, Accuracy: 0.8232421875\n",
      "Batch: 128, Loss: 0.6934163570404053, Accuracy: 0.77734375\n",
      "Batch: 129, Loss: 0.59317946434021, Accuracy: 0.8232421875\n",
      "Batch: 130, Loss: 0.6776111721992493, Accuracy: 0.767578125\n",
      "Batch: 131, Loss: 0.6336371302604675, Accuracy: 0.779296875\n",
      "Batch: 132, Loss: 0.654110848903656, Accuracy: 0.80078125\n",
      "Batch: 133, Loss: 0.6350802183151245, Accuracy: 0.798828125\n",
      "Batch: 134, Loss: 0.6432610750198364, Accuracy: 0.7744140625\n",
      "Batch: 135, Loss: 0.58689945936203, Accuracy: 0.806640625\n",
      "Batch: 136, Loss: 0.6171125769615173, Accuracy: 0.802734375\n",
      "Batch: 137, Loss: 0.6468496322631836, Accuracy: 0.779296875\n",
      "Batch: 138, Loss: 0.5914840698242188, Accuracy: 0.7998046875\n",
      "Batch: 139, Loss: 0.598773717880249, Accuracy: 0.7958984375\n",
      "Batch: 140, Loss: 0.6736190319061279, Accuracy: 0.7822265625\n",
      "Batch: 141, Loss: 0.6837003231048584, Accuracy: 0.77734375\n",
      "Batch: 142, Loss: 0.7015593647956848, Accuracy: 0.77734375\n",
      "Batch: 143, Loss: 0.6610375642776489, Accuracy: 0.78125\n",
      "Batch: 144, Loss: 0.630268931388855, Accuracy: 0.80078125\n",
      "Batch: 145, Loss: 0.5780161619186401, Accuracy: 0.8056640625\n",
      "Batch: 146, Loss: 0.6330164670944214, Accuracy: 0.7900390625\n",
      "Batch: 147, Loss: 0.6272351145744324, Accuracy: 0.78515625\n",
      "Batch: 148, Loss: 0.6622679233551025, Accuracy: 0.7734375\n",
      "Batch: 149, Loss: 0.6079992651939392, Accuracy: 0.802734375\n",
      "Batch: 150, Loss: 0.6745656132698059, Accuracy: 0.7900390625\n",
      "Batch: 151, Loss: 0.5809036493301392, Accuracy: 0.818359375\n",
      "Epoch 62/80\n",
      "Batch: 1, Loss: 0.8025487065315247, Accuracy: 0.751953125\n",
      "Batch: 2, Loss: 0.6956177949905396, Accuracy: 0.7607421875\n",
      "Batch: 3, Loss: 0.6088677644729614, Accuracy: 0.796875\n",
      "Batch: 4, Loss: 0.5633081197738647, Accuracy: 0.822265625\n",
      "Batch: 5, Loss: 0.5991636514663696, Accuracy: 0.80859375\n",
      "Batch: 6, Loss: 0.6175003051757812, Accuracy: 0.7958984375\n",
      "Batch: 7, Loss: 0.644792377948761, Accuracy: 0.7861328125\n",
      "Batch: 8, Loss: 0.6155803203582764, Accuracy: 0.7919921875\n",
      "Batch: 9, Loss: 0.5818010568618774, Accuracy: 0.802734375\n",
      "Batch: 10, Loss: 0.5824226140975952, Accuracy: 0.806640625\n",
      "Batch: 11, Loss: 0.683234453201294, Accuracy: 0.779296875\n",
      "Batch: 12, Loss: 0.6462986469268799, Accuracy: 0.7890625\n",
      "Batch: 13, Loss: 0.5305018424987793, Accuracy: 0.83203125\n",
      "Batch: 14, Loss: 0.6958471536636353, Accuracy: 0.765625\n",
      "Batch: 15, Loss: 0.5715962052345276, Accuracy: 0.8212890625\n",
      "Batch: 16, Loss: 0.5989508628845215, Accuracy: 0.8076171875\n",
      "Batch: 17, Loss: 0.6205466985702515, Accuracy: 0.8076171875\n",
      "Batch: 18, Loss: 0.6469395756721497, Accuracy: 0.7744140625\n",
      "Batch: 19, Loss: 0.6822423934936523, Accuracy: 0.78125\n",
      "Batch: 20, Loss: 0.5907368063926697, Accuracy: 0.8173828125\n",
      "Batch: 21, Loss: 0.5732791423797607, Accuracy: 0.8154296875\n",
      "Batch: 22, Loss: 0.7179644107818604, Accuracy: 0.7724609375\n",
      "Batch: 23, Loss: 0.653914749622345, Accuracy: 0.783203125\n",
      "Batch: 24, Loss: 0.6588289737701416, Accuracy: 0.779296875\n",
      "Batch: 25, Loss: 0.6118130683898926, Accuracy: 0.7900390625\n",
      "Batch: 26, Loss: 0.5416989922523499, Accuracy: 0.8193359375\n",
      "Batch: 27, Loss: 0.577460527420044, Accuracy: 0.8134765625\n",
      "Batch: 28, Loss: 0.6233372688293457, Accuracy: 0.787109375\n",
      "Batch: 29, Loss: 0.5951653122901917, Accuracy: 0.8056640625\n",
      "Batch: 30, Loss: 0.5806334614753723, Accuracy: 0.802734375\n",
      "Batch: 31, Loss: 0.5216200947761536, Accuracy: 0.8310546875\n",
      "Batch: 32, Loss: 0.5858601331710815, Accuracy: 0.810546875\n",
      "Batch: 33, Loss: 0.6746491193771362, Accuracy: 0.7880859375\n",
      "Batch: 34, Loss: 0.7156413793563843, Accuracy: 0.7607421875\n",
      "Batch: 35, Loss: 0.6278529167175293, Accuracy: 0.7890625\n",
      "Batch: 36, Loss: 0.6209721565246582, Accuracy: 0.8056640625\n",
      "Batch: 37, Loss: 0.6620624661445618, Accuracy: 0.7724609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 38, Loss: 0.6638145446777344, Accuracy: 0.771484375\n",
      "Batch: 39, Loss: 0.6275478005409241, Accuracy: 0.79296875\n",
      "Batch: 40, Loss: 0.6090853214263916, Accuracy: 0.8037109375\n",
      "Batch: 41, Loss: 0.5475163459777832, Accuracy: 0.828125\n",
      "Batch: 42, Loss: 0.46147269010543823, Accuracy: 0.8447265625\n",
      "Batch: 43, Loss: 0.562170147895813, Accuracy: 0.8154296875\n",
      "Batch: 44, Loss: 0.6585657596588135, Accuracy: 0.7763671875\n",
      "Batch: 45, Loss: 0.560135006904602, Accuracy: 0.8310546875\n",
      "Batch: 46, Loss: 0.5817084312438965, Accuracy: 0.8115234375\n",
      "Batch: 47, Loss: 0.61812424659729, Accuracy: 0.8046875\n",
      "Batch: 48, Loss: 0.5926541090011597, Accuracy: 0.802734375\n",
      "Batch: 49, Loss: 0.6388060450553894, Accuracy: 0.7822265625\n",
      "Batch: 50, Loss: 0.6057698726654053, Accuracy: 0.7919921875\n",
      "Batch: 51, Loss: 0.6413649320602417, Accuracy: 0.7919921875\n",
      "Batch: 52, Loss: 0.6002709269523621, Accuracy: 0.822265625\n",
      "Batch: 53, Loss: 0.552398681640625, Accuracy: 0.8193359375\n",
      "Batch: 54, Loss: 0.5848858952522278, Accuracy: 0.8095703125\n",
      "Batch: 55, Loss: 0.680591881275177, Accuracy: 0.7626953125\n",
      "Batch: 56, Loss: 0.655093789100647, Accuracy: 0.7822265625\n",
      "Batch: 57, Loss: 0.626922070980072, Accuracy: 0.8017578125\n",
      "Batch: 58, Loss: 0.7246576547622681, Accuracy: 0.7744140625\n",
      "Batch: 59, Loss: 0.6156987547874451, Accuracy: 0.798828125\n",
      "Batch: 60, Loss: 0.6025567054748535, Accuracy: 0.7978515625\n",
      "Batch: 61, Loss: 0.6538540124893188, Accuracy: 0.7900390625\n",
      "Batch: 62, Loss: 0.5509471893310547, Accuracy: 0.818359375\n",
      "Batch: 63, Loss: 0.6566234827041626, Accuracy: 0.78515625\n",
      "Batch: 64, Loss: 0.6114888191223145, Accuracy: 0.806640625\n",
      "Batch: 65, Loss: 0.6186568737030029, Accuracy: 0.791015625\n",
      "Batch: 66, Loss: 0.603800892829895, Accuracy: 0.8046875\n",
      "Batch: 67, Loss: 0.6603854894638062, Accuracy: 0.79296875\n",
      "Batch: 68, Loss: 0.6779875755310059, Accuracy: 0.779296875\n",
      "Batch: 69, Loss: 0.6466677784919739, Accuracy: 0.78125\n",
      "Batch: 70, Loss: 0.6442699432373047, Accuracy: 0.8037109375\n",
      "Batch: 71, Loss: 0.6681423187255859, Accuracy: 0.7890625\n",
      "Batch: 72, Loss: 0.6048772931098938, Accuracy: 0.794921875\n",
      "Batch: 73, Loss: 0.5702192783355713, Accuracy: 0.81640625\n",
      "Batch: 74, Loss: 0.5600225925445557, Accuracy: 0.8232421875\n",
      "Batch: 75, Loss: 0.5314152836799622, Accuracy: 0.826171875\n",
      "Batch: 76, Loss: 0.6064919233322144, Accuracy: 0.8154296875\n",
      "Batch: 77, Loss: 0.544196605682373, Accuracy: 0.822265625\n",
      "Batch: 78, Loss: 0.5792179107666016, Accuracy: 0.8115234375\n",
      "Batch: 79, Loss: 0.610373854637146, Accuracy: 0.8154296875\n",
      "Batch: 80, Loss: 0.5942591428756714, Accuracy: 0.8076171875\n",
      "Batch: 81, Loss: 0.6491876840591431, Accuracy: 0.77734375\n",
      "Batch: 82, Loss: 0.586799144744873, Accuracy: 0.8037109375\n",
      "Batch: 83, Loss: 0.5791083574295044, Accuracy: 0.8203125\n",
      "Batch: 84, Loss: 0.6305750608444214, Accuracy: 0.810546875\n",
      "Batch: 85, Loss: 0.5454760193824768, Accuracy: 0.82421875\n",
      "Batch: 86, Loss: 0.6815269589424133, Accuracy: 0.775390625\n",
      "Batch: 87, Loss: 0.5870397686958313, Accuracy: 0.8203125\n",
      "Batch: 88, Loss: 0.6378859877586365, Accuracy: 0.78515625\n",
      "Batch: 89, Loss: 0.6268219947814941, Accuracy: 0.798828125\n",
      "Batch: 90, Loss: 0.5936100482940674, Accuracy: 0.8095703125\n",
      "Batch: 91, Loss: 0.572126030921936, Accuracy: 0.8134765625\n",
      "Batch: 92, Loss: 0.6427550315856934, Accuracy: 0.79296875\n",
      "Batch: 93, Loss: 0.6341080665588379, Accuracy: 0.796875\n",
      "Batch: 94, Loss: 0.6395504474639893, Accuracy: 0.7958984375\n",
      "Batch: 95, Loss: 0.6484112739562988, Accuracy: 0.775390625\n",
      "Batch: 96, Loss: 0.6245378255844116, Accuracy: 0.8017578125\n",
      "Batch: 97, Loss: 0.5113005638122559, Accuracy: 0.8388671875\n",
      "Batch: 98, Loss: 0.6348681449890137, Accuracy: 0.8037109375\n",
      "Batch: 99, Loss: 0.5955846905708313, Accuracy: 0.7998046875\n",
      "Batch: 100, Loss: 0.6207150220870972, Accuracy: 0.79296875\n",
      "Batch: 101, Loss: 0.6825059652328491, Accuracy: 0.7802734375\n",
      "Batch: 102, Loss: 0.6587144136428833, Accuracy: 0.783203125\n",
      "Batch: 103, Loss: 0.6409359574317932, Accuracy: 0.7919921875\n",
      "Batch: 104, Loss: 0.5769420862197876, Accuracy: 0.8095703125\n",
      "Batch: 105, Loss: 0.6172628402709961, Accuracy: 0.802734375\n",
      "Batch: 106, Loss: 0.5305153727531433, Accuracy: 0.83203125\n",
      "Batch: 107, Loss: 0.6279921531677246, Accuracy: 0.7998046875\n",
      "Batch: 108, Loss: 0.6054974794387817, Accuracy: 0.8037109375\n",
      "Batch: 109, Loss: 0.6765843629837036, Accuracy: 0.7744140625\n",
      "Batch: 110, Loss: 0.6018058061599731, Accuracy: 0.794921875\n",
      "Batch: 111, Loss: 0.6007922887802124, Accuracy: 0.787109375\n",
      "Batch: 112, Loss: 0.6355471611022949, Accuracy: 0.7822265625\n",
      "Batch: 113, Loss: 0.6253564357757568, Accuracy: 0.8046875\n",
      "Batch: 114, Loss: 0.6566042900085449, Accuracy: 0.7734375\n",
      "Batch: 115, Loss: 0.7165374755859375, Accuracy: 0.7568359375\n",
      "Batch: 116, Loss: 0.6347883343696594, Accuracy: 0.7919921875\n",
      "Batch: 117, Loss: 0.6488173007965088, Accuracy: 0.78515625\n",
      "Batch: 118, Loss: 0.5816847681999207, Accuracy: 0.8193359375\n",
      "Batch: 119, Loss: 0.5574212074279785, Accuracy: 0.8095703125\n",
      "Batch: 120, Loss: 0.6224460601806641, Accuracy: 0.7744140625\n",
      "Batch: 121, Loss: 0.6653071641921997, Accuracy: 0.7861328125\n",
      "Batch: 122, Loss: 0.6368953585624695, Accuracy: 0.7861328125\n",
      "Batch: 123, Loss: 0.5886813998222351, Accuracy: 0.8056640625\n",
      "Batch: 124, Loss: 0.6255849003791809, Accuracy: 0.802734375\n",
      "Batch: 125, Loss: 0.6693543791770935, Accuracy: 0.7939453125\n",
      "Batch: 126, Loss: 0.6817148923873901, Accuracy: 0.7705078125\n",
      "Batch: 127, Loss: 0.5639849305152893, Accuracy: 0.830078125\n",
      "Batch: 128, Loss: 0.6973790526390076, Accuracy: 0.779296875\n",
      "Batch: 129, Loss: 0.5668142437934875, Accuracy: 0.8173828125\n",
      "Batch: 130, Loss: 0.7394639849662781, Accuracy: 0.7548828125\n",
      "Batch: 131, Loss: 0.6595817804336548, Accuracy: 0.7734375\n",
      "Batch: 132, Loss: 0.6989746689796448, Accuracy: 0.7861328125\n",
      "Batch: 133, Loss: 0.6280382871627808, Accuracy: 0.787109375\n",
      "Batch: 134, Loss: 0.6470285058021545, Accuracy: 0.794921875\n",
      "Batch: 135, Loss: 0.5852068662643433, Accuracy: 0.7978515625\n",
      "Batch: 136, Loss: 0.6271584033966064, Accuracy: 0.7978515625\n",
      "Batch: 137, Loss: 0.6455940008163452, Accuracy: 0.7900390625\n",
      "Batch: 138, Loss: 0.569669783115387, Accuracy: 0.796875\n",
      "Batch: 139, Loss: 0.5802438259124756, Accuracy: 0.80859375\n",
      "Batch: 140, Loss: 0.6383813619613647, Accuracy: 0.77734375\n",
      "Batch: 141, Loss: 0.6522057056427002, Accuracy: 0.78125\n",
      "Batch: 142, Loss: 0.6915051341056824, Accuracy: 0.76953125\n",
      "Batch: 143, Loss: 0.6087984442710876, Accuracy: 0.796875\n",
      "Batch: 144, Loss: 0.6485732197761536, Accuracy: 0.791015625\n",
      "Batch: 145, Loss: 0.5824389457702637, Accuracy: 0.796875\n",
      "Batch: 146, Loss: 0.6571508049964905, Accuracy: 0.78125\n",
      "Batch: 147, Loss: 0.5965884923934937, Accuracy: 0.806640625\n",
      "Batch: 148, Loss: 0.6934317350387573, Accuracy: 0.7568359375\n",
      "Batch: 149, Loss: 0.6143670678138733, Accuracy: 0.7919921875\n",
      "Batch: 150, Loss: 0.6541510820388794, Accuracy: 0.7919921875\n",
      "Batch: 151, Loss: 0.5755000710487366, Accuracy: 0.82421875\n",
      "Epoch 63/80\n",
      "Batch: 1, Loss: 0.8291152119636536, Accuracy: 0.75390625\n",
      "Batch: 2, Loss: 0.6648098230361938, Accuracy: 0.771484375\n",
      "Batch: 3, Loss: 0.6330553293228149, Accuracy: 0.7822265625\n",
      "Batch: 4, Loss: 0.5758674144744873, Accuracy: 0.814453125\n",
      "Batch: 5, Loss: 0.6131608486175537, Accuracy: 0.7919921875\n",
      "Batch: 6, Loss: 0.5976302623748779, Accuracy: 0.7978515625\n",
      "Batch: 7, Loss: 0.603584885597229, Accuracy: 0.8017578125\n",
      "Batch: 8, Loss: 0.6114636659622192, Accuracy: 0.7890625\n",
      "Batch: 9, Loss: 0.5754116773605347, Accuracy: 0.814453125\n",
      "Batch: 10, Loss: 0.5629755258560181, Accuracy: 0.8134765625\n",
      "Batch: 11, Loss: 0.6650090217590332, Accuracy: 0.7841796875\n",
      "Batch: 12, Loss: 0.6564953327178955, Accuracy: 0.7861328125\n",
      "Batch: 13, Loss: 0.5366224050521851, Accuracy: 0.833984375\n",
      "Batch: 14, Loss: 0.6692878007888794, Accuracy: 0.771484375\n",
      "Batch: 15, Loss: 0.5658499002456665, Accuracy: 0.8251953125\n",
      "Batch: 16, Loss: 0.5801575183868408, Accuracy: 0.8134765625\n",
      "Batch: 17, Loss: 0.6033933162689209, Accuracy: 0.8037109375\n",
      "Batch: 18, Loss: 0.652440071105957, Accuracy: 0.7900390625\n",
      "Batch: 19, Loss: 0.6326649785041809, Accuracy: 0.7939453125\n",
      "Batch: 20, Loss: 0.5525270700454712, Accuracy: 0.830078125\n",
      "Batch: 21, Loss: 0.5377398729324341, Accuracy: 0.830078125\n",
      "Batch: 22, Loss: 0.7125496864318848, Accuracy: 0.771484375\n",
      "Batch: 23, Loss: 0.6620564460754395, Accuracy: 0.7861328125\n",
      "Batch: 24, Loss: 0.6610207557678223, Accuracy: 0.8017578125\n",
      "Batch: 25, Loss: 0.5757389664649963, Accuracy: 0.8134765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 26, Loss: 0.500518798828125, Accuracy: 0.841796875\n",
      "Batch: 27, Loss: 0.6029428839683533, Accuracy: 0.7900390625\n",
      "Batch: 28, Loss: 0.5937400460243225, Accuracy: 0.8037109375\n",
      "Batch: 29, Loss: 0.5924117565155029, Accuracy: 0.8076171875\n",
      "Batch: 30, Loss: 0.5518091320991516, Accuracy: 0.828125\n",
      "Batch: 31, Loss: 0.5409767627716064, Accuracy: 0.81640625\n",
      "Batch: 32, Loss: 0.5799181461334229, Accuracy: 0.798828125\n",
      "Batch: 33, Loss: 0.6574389934539795, Accuracy: 0.76953125\n",
      "Batch: 34, Loss: 0.7128267288208008, Accuracy: 0.76953125\n",
      "Batch: 35, Loss: 0.6278249025344849, Accuracy: 0.7900390625\n",
      "Batch: 36, Loss: 0.614669919013977, Accuracy: 0.8154296875\n",
      "Batch: 37, Loss: 0.6591581702232361, Accuracy: 0.78515625\n",
      "Batch: 38, Loss: 0.6516133546829224, Accuracy: 0.7744140625\n",
      "Batch: 39, Loss: 0.6485333442687988, Accuracy: 0.79296875\n",
      "Batch: 40, Loss: 0.6160937547683716, Accuracy: 0.7978515625\n",
      "Batch: 41, Loss: 0.560930609703064, Accuracy: 0.810546875\n",
      "Batch: 42, Loss: 0.46644043922424316, Accuracy: 0.8388671875\n",
      "Batch: 43, Loss: 0.5767308473587036, Accuracy: 0.8037109375\n",
      "Batch: 44, Loss: 0.6172798871994019, Accuracy: 0.7958984375\n",
      "Batch: 45, Loss: 0.5463989973068237, Accuracy: 0.822265625\n",
      "Batch: 46, Loss: 0.5722982287406921, Accuracy: 0.8125\n",
      "Batch: 47, Loss: 0.6628713607788086, Accuracy: 0.7861328125\n",
      "Batch: 48, Loss: 0.6122860908508301, Accuracy: 0.7900390625\n",
      "Batch: 49, Loss: 0.6713213920593262, Accuracy: 0.787109375\n",
      "Batch: 50, Loss: 0.6013136506080627, Accuracy: 0.80859375\n",
      "Batch: 51, Loss: 0.6262231469154358, Accuracy: 0.8017578125\n",
      "Batch: 52, Loss: 0.5844559669494629, Accuracy: 0.80859375\n",
      "Batch: 53, Loss: 0.5546315908432007, Accuracy: 0.81640625\n",
      "Batch: 54, Loss: 0.5760867595672607, Accuracy: 0.8115234375\n",
      "Batch: 55, Loss: 0.6536954045295715, Accuracy: 0.7734375\n",
      "Batch: 56, Loss: 0.6596827507019043, Accuracy: 0.7841796875\n",
      "Batch: 57, Loss: 0.6607842445373535, Accuracy: 0.7890625\n",
      "Batch: 58, Loss: 0.6953673362731934, Accuracy: 0.7802734375\n",
      "Batch: 59, Loss: 0.6459536552429199, Accuracy: 0.7763671875\n",
      "Batch: 60, Loss: 0.5805105566978455, Accuracy: 0.8076171875\n",
      "Batch: 61, Loss: 0.6833071112632751, Accuracy: 0.7734375\n",
      "Batch: 62, Loss: 0.5836076736450195, Accuracy: 0.8037109375\n",
      "Batch: 63, Loss: 0.6211364269256592, Accuracy: 0.7958984375\n",
      "Batch: 64, Loss: 0.5961557626724243, Accuracy: 0.791015625\n",
      "Batch: 65, Loss: 0.6041335463523865, Accuracy: 0.81640625\n",
      "Batch: 66, Loss: 0.5988394021987915, Accuracy: 0.8125\n",
      "Batch: 67, Loss: 0.7149437665939331, Accuracy: 0.759765625\n",
      "Batch: 68, Loss: 0.6807579398155212, Accuracy: 0.783203125\n",
      "Batch: 69, Loss: 0.6519870758056641, Accuracy: 0.7841796875\n",
      "Batch: 70, Loss: 0.6819851398468018, Accuracy: 0.79296875\n",
      "Batch: 71, Loss: 0.6681163311004639, Accuracy: 0.78125\n",
      "Batch: 72, Loss: 0.5723875761032104, Accuracy: 0.8076171875\n",
      "Batch: 73, Loss: 0.5803265571594238, Accuracy: 0.8271484375\n",
      "Batch: 74, Loss: 0.5592666864395142, Accuracy: 0.8212890625\n",
      "Batch: 75, Loss: 0.5288101434707642, Accuracy: 0.8388671875\n",
      "Batch: 76, Loss: 0.6259480118751526, Accuracy: 0.8046875\n",
      "Batch: 77, Loss: 0.5365899801254272, Accuracy: 0.833984375\n",
      "Batch: 78, Loss: 0.5915374755859375, Accuracy: 0.8193359375\n",
      "Batch: 79, Loss: 0.5843089818954468, Accuracy: 0.8212890625\n",
      "Batch: 80, Loss: 0.5680291652679443, Accuracy: 0.8134765625\n",
      "Batch: 81, Loss: 0.6605460047721863, Accuracy: 0.775390625\n",
      "Batch: 82, Loss: 0.6174170970916748, Accuracy: 0.7861328125\n",
      "Batch: 83, Loss: 0.5666970014572144, Accuracy: 0.8193359375\n",
      "Batch: 84, Loss: 0.6159968972206116, Accuracy: 0.8076171875\n",
      "Batch: 85, Loss: 0.5992111563682556, Accuracy: 0.7998046875\n",
      "Batch: 86, Loss: 0.6979314088821411, Accuracy: 0.7841796875\n",
      "Batch: 87, Loss: 0.58112633228302, Accuracy: 0.8115234375\n",
      "Batch: 88, Loss: 0.6313105821609497, Accuracy: 0.7890625\n",
      "Batch: 89, Loss: 0.6156939268112183, Accuracy: 0.8056640625\n",
      "Batch: 90, Loss: 0.5795983672142029, Accuracy: 0.80859375\n",
      "Batch: 91, Loss: 0.5905413627624512, Accuracy: 0.7978515625\n",
      "Batch: 92, Loss: 0.6623791456222534, Accuracy: 0.7919921875\n",
      "Batch: 93, Loss: 0.6242977380752563, Accuracy: 0.7861328125\n",
      "Batch: 94, Loss: 0.63129723072052, Accuracy: 0.794921875\n",
      "Batch: 95, Loss: 0.625177800655365, Accuracy: 0.7939453125\n",
      "Batch: 96, Loss: 0.6076375246047974, Accuracy: 0.7978515625\n",
      "Batch: 97, Loss: 0.4863537847995758, Accuracy: 0.83984375\n",
      "Batch: 98, Loss: 0.6505260467529297, Accuracy: 0.7978515625\n",
      "Batch: 99, Loss: 0.6084187626838684, Accuracy: 0.7998046875\n",
      "Batch: 100, Loss: 0.596239447593689, Accuracy: 0.8056640625\n",
      "Batch: 101, Loss: 0.6872670650482178, Accuracy: 0.763671875\n",
      "Batch: 102, Loss: 0.6177253723144531, Accuracy: 0.80078125\n",
      "Batch: 103, Loss: 0.6097662448883057, Accuracy: 0.80078125\n",
      "Batch: 104, Loss: 0.597596287727356, Accuracy: 0.7958984375\n",
      "Batch: 105, Loss: 0.6084581613540649, Accuracy: 0.798828125\n",
      "Batch: 106, Loss: 0.5537366271018982, Accuracy: 0.826171875\n",
      "Batch: 107, Loss: 0.6174484491348267, Accuracy: 0.8017578125\n",
      "Batch: 108, Loss: 0.6112669706344604, Accuracy: 0.8076171875\n",
      "Batch: 109, Loss: 0.6326935291290283, Accuracy: 0.783203125\n",
      "Batch: 110, Loss: 0.5589197278022766, Accuracy: 0.8125\n",
      "Batch: 111, Loss: 0.6163220405578613, Accuracy: 0.7900390625\n",
      "Batch: 112, Loss: 0.6421560645103455, Accuracy: 0.7802734375\n",
      "Batch: 113, Loss: 0.6493504047393799, Accuracy: 0.7919921875\n",
      "Batch: 114, Loss: 0.6213973760604858, Accuracy: 0.794921875\n",
      "Batch: 115, Loss: 0.6806069016456604, Accuracy: 0.78125\n",
      "Batch: 116, Loss: 0.6329793930053711, Accuracy: 0.7861328125\n",
      "Batch: 117, Loss: 0.6662440299987793, Accuracy: 0.794921875\n",
      "Batch: 118, Loss: 0.5746356248855591, Accuracy: 0.8203125\n",
      "Batch: 119, Loss: 0.5694242715835571, Accuracy: 0.814453125\n",
      "Batch: 120, Loss: 0.6279001832008362, Accuracy: 0.7939453125\n",
      "Batch: 121, Loss: 0.6427339315414429, Accuracy: 0.787109375\n",
      "Batch: 122, Loss: 0.6334792375564575, Accuracy: 0.796875\n",
      "Batch: 123, Loss: 0.5829923152923584, Accuracy: 0.810546875\n",
      "Batch: 124, Loss: 0.6463038921356201, Accuracy: 0.7939453125\n",
      "Batch: 125, Loss: 0.6952055096626282, Accuracy: 0.76171875\n",
      "Batch: 126, Loss: 0.6417474150657654, Accuracy: 0.80078125\n",
      "Batch: 127, Loss: 0.5506960153579712, Accuracy: 0.826171875\n",
      "Batch: 128, Loss: 0.6923690438270569, Accuracy: 0.78125\n",
      "Batch: 129, Loss: 0.5919914245605469, Accuracy: 0.8056640625\n",
      "Batch: 130, Loss: 0.6912171244621277, Accuracy: 0.7744140625\n",
      "Batch: 131, Loss: 0.6377431154251099, Accuracy: 0.798828125\n",
      "Batch: 132, Loss: 0.6617445945739746, Accuracy: 0.791015625\n",
      "Batch: 133, Loss: 0.5894619226455688, Accuracy: 0.8076171875\n",
      "Batch: 134, Loss: 0.6476898789405823, Accuracy: 0.7802734375\n",
      "Batch: 135, Loss: 0.5764492750167847, Accuracy: 0.818359375\n",
      "Batch: 136, Loss: 0.6274418830871582, Accuracy: 0.7890625\n",
      "Batch: 137, Loss: 0.6119245290756226, Accuracy: 0.787109375\n",
      "Batch: 138, Loss: 0.6028105020523071, Accuracy: 0.7900390625\n",
      "Batch: 139, Loss: 0.5627670884132385, Accuracy: 0.8115234375\n",
      "Batch: 140, Loss: 0.633312463760376, Accuracy: 0.783203125\n",
      "Batch: 141, Loss: 0.662724494934082, Accuracy: 0.78125\n",
      "Batch: 142, Loss: 0.6976752877235413, Accuracy: 0.783203125\n",
      "Batch: 143, Loss: 0.6326037645339966, Accuracy: 0.783203125\n",
      "Batch: 144, Loss: 0.6290077567100525, Accuracy: 0.80078125\n",
      "Batch: 145, Loss: 0.5438420176506042, Accuracy: 0.8173828125\n",
      "Batch: 146, Loss: 0.6275023221969604, Accuracy: 0.7919921875\n",
      "Batch: 147, Loss: 0.6077326536178589, Accuracy: 0.8046875\n",
      "Batch: 148, Loss: 0.6577320098876953, Accuracy: 0.794921875\n",
      "Batch: 149, Loss: 0.5870234966278076, Accuracy: 0.81640625\n",
      "Batch: 150, Loss: 0.6629199981689453, Accuracy: 0.7919921875\n",
      "Batch: 151, Loss: 0.5566636323928833, Accuracy: 0.828125\n",
      "Epoch 64/80\n",
      "Batch: 1, Loss: 0.8254368901252747, Accuracy: 0.7490234375\n",
      "Batch: 2, Loss: 0.6525946855545044, Accuracy: 0.7705078125\n",
      "Batch: 3, Loss: 0.5758686065673828, Accuracy: 0.798828125\n",
      "Batch: 4, Loss: 0.5714795589447021, Accuracy: 0.8203125\n",
      "Batch: 5, Loss: 0.5917942523956299, Accuracy: 0.810546875\n",
      "Batch: 6, Loss: 0.6440362930297852, Accuracy: 0.78515625\n",
      "Batch: 7, Loss: 0.6090859174728394, Accuracy: 0.8037109375\n",
      "Batch: 8, Loss: 0.5982327461242676, Accuracy: 0.810546875\n",
      "Batch: 9, Loss: 0.5811710357666016, Accuracy: 0.8154296875\n",
      "Batch: 10, Loss: 0.6068927049636841, Accuracy: 0.7958984375\n",
      "Batch: 11, Loss: 0.6571727991104126, Accuracy: 0.77734375\n",
      "Batch: 12, Loss: 0.634101390838623, Accuracy: 0.7890625\n",
      "Batch: 13, Loss: 0.49791446328163147, Accuracy: 0.8369140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14, Loss: 0.6747381687164307, Accuracy: 0.7783203125\n",
      "Batch: 15, Loss: 0.5895533561706543, Accuracy: 0.8154296875\n",
      "Batch: 16, Loss: 0.545387864112854, Accuracy: 0.8251953125\n",
      "Batch: 17, Loss: 0.6005210876464844, Accuracy: 0.8056640625\n",
      "Batch: 18, Loss: 0.6344668865203857, Accuracy: 0.7919921875\n",
      "Batch: 19, Loss: 0.6086572408676147, Accuracy: 0.818359375\n",
      "Batch: 20, Loss: 0.5508383512496948, Accuracy: 0.84375\n",
      "Batch: 21, Loss: 0.5559790134429932, Accuracy: 0.810546875\n",
      "Batch: 22, Loss: 0.7237796187400818, Accuracy: 0.7568359375\n",
      "Batch: 23, Loss: 0.6532647609710693, Accuracy: 0.7861328125\n",
      "Batch: 24, Loss: 0.6614302396774292, Accuracy: 0.76953125\n",
      "Batch: 25, Loss: 0.5896483063697815, Accuracy: 0.8115234375\n",
      "Batch: 26, Loss: 0.515792191028595, Accuracy: 0.8212890625\n",
      "Batch: 27, Loss: 0.592605710029602, Accuracy: 0.798828125\n",
      "Batch: 28, Loss: 0.6057687997817993, Accuracy: 0.7958984375\n",
      "Batch: 29, Loss: 0.5528903007507324, Accuracy: 0.8125\n",
      "Batch: 30, Loss: 0.5662363767623901, Accuracy: 0.814453125\n",
      "Batch: 31, Loss: 0.5260730981826782, Accuracy: 0.826171875\n",
      "Batch: 32, Loss: 0.5482649803161621, Accuracy: 0.8037109375\n",
      "Batch: 33, Loss: 0.611670732498169, Accuracy: 0.7939453125\n",
      "Batch: 34, Loss: 0.6629093885421753, Accuracy: 0.779296875\n",
      "Batch: 35, Loss: 0.6250035762786865, Accuracy: 0.79296875\n",
      "Batch: 36, Loss: 0.6120103597640991, Accuracy: 0.80859375\n",
      "Batch: 37, Loss: 0.6269757747650146, Accuracy: 0.7861328125\n",
      "Batch: 38, Loss: 0.696179986000061, Accuracy: 0.76171875\n",
      "Batch: 39, Loss: 0.6429783701896667, Accuracy: 0.7890625\n",
      "Batch: 40, Loss: 0.6131492257118225, Accuracy: 0.7939453125\n",
      "Batch: 41, Loss: 0.5486524105072021, Accuracy: 0.8212890625\n",
      "Batch: 42, Loss: 0.4770236909389496, Accuracy: 0.8359375\n",
      "Batch: 43, Loss: 0.5667091608047485, Accuracy: 0.814453125\n",
      "Batch: 44, Loss: 0.6269785761833191, Accuracy: 0.8056640625\n",
      "Batch: 45, Loss: 0.5263199210166931, Accuracy: 0.828125\n",
      "Batch: 46, Loss: 0.5524184703826904, Accuracy: 0.8203125\n",
      "Batch: 47, Loss: 0.6364079713821411, Accuracy: 0.8056640625\n",
      "Batch: 48, Loss: 0.6189273595809937, Accuracy: 0.7978515625\n",
      "Batch: 49, Loss: 0.6646730303764343, Accuracy: 0.7880859375\n",
      "Batch: 50, Loss: 0.6131914258003235, Accuracy: 0.80859375\n",
      "Batch: 51, Loss: 0.6386802196502686, Accuracy: 0.7939453125\n",
      "Batch: 52, Loss: 0.5740132331848145, Accuracy: 0.8173828125\n",
      "Batch: 53, Loss: 0.5454411506652832, Accuracy: 0.822265625\n",
      "Batch: 54, Loss: 0.587178111076355, Accuracy: 0.8046875\n",
      "Batch: 55, Loss: 0.6436743140220642, Accuracy: 0.783203125\n",
      "Batch: 56, Loss: 0.6466686725616455, Accuracy: 0.7900390625\n",
      "Batch: 57, Loss: 0.6675971150398254, Accuracy: 0.78125\n",
      "Batch: 58, Loss: 0.7028555274009705, Accuracy: 0.7587890625\n",
      "Batch: 59, Loss: 0.6026604175567627, Accuracy: 0.80078125\n",
      "Batch: 60, Loss: 0.5738113522529602, Accuracy: 0.8017578125\n",
      "Batch: 61, Loss: 0.6495190858840942, Accuracy: 0.7880859375\n",
      "Batch: 62, Loss: 0.5778024196624756, Accuracy: 0.7998046875\n",
      "Batch: 63, Loss: 0.6354714632034302, Accuracy: 0.7900390625\n",
      "Batch: 64, Loss: 0.5989106893539429, Accuracy: 0.806640625\n",
      "Batch: 65, Loss: 0.6221436858177185, Accuracy: 0.7890625\n",
      "Batch: 66, Loss: 0.6382697820663452, Accuracy: 0.7783203125\n",
      "Batch: 67, Loss: 0.7041119337081909, Accuracy: 0.7744140625\n",
      "Batch: 68, Loss: 0.6919606328010559, Accuracy: 0.7724609375\n",
      "Batch: 69, Loss: 0.6548811197280884, Accuracy: 0.7783203125\n",
      "Batch: 70, Loss: 0.6342445611953735, Accuracy: 0.7958984375\n",
      "Batch: 71, Loss: 0.6673139333724976, Accuracy: 0.7802734375\n",
      "Batch: 72, Loss: 0.5821825265884399, Accuracy: 0.8095703125\n",
      "Batch: 73, Loss: 0.5809718370437622, Accuracy: 0.8134765625\n",
      "Batch: 74, Loss: 0.5418796539306641, Accuracy: 0.8330078125\n",
      "Batch: 75, Loss: 0.5046115517616272, Accuracy: 0.833984375\n",
      "Batch: 76, Loss: 0.6445716023445129, Accuracy: 0.791015625\n",
      "Batch: 77, Loss: 0.5359507203102112, Accuracy: 0.8203125\n",
      "Batch: 78, Loss: 0.5687808394432068, Accuracy: 0.8212890625\n",
      "Batch: 79, Loss: 0.5756412744522095, Accuracy: 0.8154296875\n",
      "Batch: 80, Loss: 0.5783722996711731, Accuracy: 0.8154296875\n",
      "Batch: 81, Loss: 0.6381086707115173, Accuracy: 0.7861328125\n",
      "Batch: 82, Loss: 0.6149353384971619, Accuracy: 0.8037109375\n",
      "Batch: 83, Loss: 0.5459351539611816, Accuracy: 0.8310546875\n",
      "Batch: 84, Loss: 0.6036906242370605, Accuracy: 0.8056640625\n",
      "Batch: 85, Loss: 0.571617066860199, Accuracy: 0.8212890625\n",
      "Batch: 86, Loss: 0.6698950529098511, Accuracy: 0.775390625\n",
      "Batch: 87, Loss: 0.5957589149475098, Accuracy: 0.8037109375\n",
      "Batch: 88, Loss: 0.622464120388031, Accuracy: 0.8095703125\n",
      "Batch: 89, Loss: 0.6341181993484497, Accuracy: 0.791015625\n",
      "Batch: 90, Loss: 0.5808137655258179, Accuracy: 0.81640625\n",
      "Batch: 91, Loss: 0.57393479347229, Accuracy: 0.8056640625\n",
      "Batch: 92, Loss: 0.621113657951355, Accuracy: 0.806640625\n",
      "Batch: 93, Loss: 0.6320347785949707, Accuracy: 0.8095703125\n",
      "Batch: 94, Loss: 0.6443512439727783, Accuracy: 0.794921875\n",
      "Batch: 95, Loss: 0.6060742735862732, Accuracy: 0.798828125\n",
      "Batch: 96, Loss: 0.6127816438674927, Accuracy: 0.802734375\n",
      "Batch: 97, Loss: 0.5118862390518188, Accuracy: 0.82421875\n",
      "Batch: 98, Loss: 0.6377999782562256, Accuracy: 0.7958984375\n",
      "Batch: 99, Loss: 0.5906612873077393, Accuracy: 0.8046875\n",
      "Batch: 100, Loss: 0.6237119436264038, Accuracy: 0.8046875\n",
      "Batch: 101, Loss: 0.6389669179916382, Accuracy: 0.7841796875\n",
      "Batch: 102, Loss: 0.6165922284126282, Accuracy: 0.802734375\n",
      "Batch: 103, Loss: 0.6084757447242737, Accuracy: 0.8017578125\n",
      "Batch: 104, Loss: 0.5644118785858154, Accuracy: 0.8154296875\n",
      "Batch: 105, Loss: 0.6013065576553345, Accuracy: 0.806640625\n",
      "Batch: 106, Loss: 0.562363862991333, Accuracy: 0.806640625\n",
      "Batch: 107, Loss: 0.6157675981521606, Accuracy: 0.80078125\n",
      "Batch: 108, Loss: 0.6003021597862244, Accuracy: 0.814453125\n",
      "Batch: 109, Loss: 0.6308804154396057, Accuracy: 0.7890625\n",
      "Batch: 110, Loss: 0.5637136697769165, Accuracy: 0.8134765625\n",
      "Batch: 111, Loss: 0.5840772390365601, Accuracy: 0.8046875\n",
      "Batch: 112, Loss: 0.6112778186798096, Accuracy: 0.7900390625\n",
      "Batch: 113, Loss: 0.594865083694458, Accuracy: 0.8056640625\n",
      "Batch: 114, Loss: 0.646216630935669, Accuracy: 0.7802734375\n",
      "Batch: 115, Loss: 0.6863952875137329, Accuracy: 0.7880859375\n",
      "Batch: 116, Loss: 0.611140251159668, Accuracy: 0.8076171875\n",
      "Batch: 117, Loss: 0.6609586477279663, Accuracy: 0.7802734375\n",
      "Batch: 118, Loss: 0.5744349956512451, Accuracy: 0.822265625\n",
      "Batch: 119, Loss: 0.531561017036438, Accuracy: 0.8310546875\n",
      "Batch: 120, Loss: 0.602040708065033, Accuracy: 0.8056640625\n",
      "Batch: 121, Loss: 0.6340104341506958, Accuracy: 0.787109375\n",
      "Batch: 122, Loss: 0.6395601034164429, Accuracy: 0.794921875\n",
      "Batch: 123, Loss: 0.568960428237915, Accuracy: 0.8212890625\n",
      "Batch: 124, Loss: 0.6228699088096619, Accuracy: 0.79296875\n",
      "Batch: 125, Loss: 0.6596057415008545, Accuracy: 0.7763671875\n",
      "Batch: 126, Loss: 0.6192474365234375, Accuracy: 0.80078125\n",
      "Batch: 127, Loss: 0.5714497566223145, Accuracy: 0.826171875\n",
      "Batch: 128, Loss: 0.6688945293426514, Accuracy: 0.78125\n",
      "Batch: 129, Loss: 0.5694729089736938, Accuracy: 0.8125\n",
      "Batch: 130, Loss: 0.6501160860061646, Accuracy: 0.7880859375\n",
      "Batch: 131, Loss: 0.6206761598587036, Accuracy: 0.810546875\n",
      "Batch: 132, Loss: 0.6662853360176086, Accuracy: 0.7890625\n",
      "Batch: 133, Loss: 0.6052626371383667, Accuracy: 0.8056640625\n",
      "Batch: 134, Loss: 0.6098952293395996, Accuracy: 0.7900390625\n",
      "Batch: 135, Loss: 0.5741750597953796, Accuracy: 0.828125\n",
      "Batch: 136, Loss: 0.6013384461402893, Accuracy: 0.7998046875\n",
      "Batch: 137, Loss: 0.6496530771255493, Accuracy: 0.78125\n",
      "Batch: 138, Loss: 0.5638140439987183, Accuracy: 0.7939453125\n",
      "Batch: 139, Loss: 0.5843625068664551, Accuracy: 0.8056640625\n",
      "Batch: 140, Loss: 0.6136938333511353, Accuracy: 0.80859375\n",
      "Batch: 141, Loss: 0.6872689723968506, Accuracy: 0.7724609375\n",
      "Batch: 142, Loss: 0.6806608438491821, Accuracy: 0.7763671875\n",
      "Batch: 143, Loss: 0.6058261394500732, Accuracy: 0.794921875\n",
      "Batch: 144, Loss: 0.638471782207489, Accuracy: 0.79296875\n",
      "Batch: 145, Loss: 0.5572067499160767, Accuracy: 0.810546875\n",
      "Batch: 146, Loss: 0.5967540740966797, Accuracy: 0.8037109375\n",
      "Batch: 147, Loss: 0.585983157157898, Accuracy: 0.8076171875\n",
      "Batch: 148, Loss: 0.6558955907821655, Accuracy: 0.78515625\n",
      "Batch: 149, Loss: 0.5930969715118408, Accuracy: 0.79296875\n",
      "Batch: 150, Loss: 0.6039174795150757, Accuracy: 0.7958984375\n",
      "Batch: 151, Loss: 0.5895650386810303, Accuracy: 0.8095703125\n",
      "Epoch 65/80\n",
      "Batch: 1, Loss: 0.8108527064323425, Accuracy: 0.7529296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2, Loss: 0.659329891204834, Accuracy: 0.76171875\n",
      "Batch: 3, Loss: 0.5868120193481445, Accuracy: 0.8056640625\n",
      "Batch: 4, Loss: 0.5755529403686523, Accuracy: 0.8271484375\n",
      "Batch: 5, Loss: 0.6164025068283081, Accuracy: 0.80078125\n",
      "Batch: 6, Loss: 0.6117591857910156, Accuracy: 0.787109375\n",
      "Batch: 7, Loss: 0.6538450121879578, Accuracy: 0.7724609375\n",
      "Batch: 8, Loss: 0.6054543256759644, Accuracy: 0.796875\n",
      "Batch: 9, Loss: 0.5742242932319641, Accuracy: 0.8017578125\n",
      "Batch: 10, Loss: 0.5870202779769897, Accuracy: 0.8037109375\n",
      "Batch: 11, Loss: 0.6516871452331543, Accuracy: 0.7822265625\n",
      "Batch: 12, Loss: 0.6366709470748901, Accuracy: 0.7958984375\n",
      "Batch: 13, Loss: 0.5453354120254517, Accuracy: 0.814453125\n",
      "Batch: 14, Loss: 0.6833915710449219, Accuracy: 0.7734375\n",
      "Batch: 15, Loss: 0.5902571678161621, Accuracy: 0.814453125\n",
      "Batch: 16, Loss: 0.5562580227851868, Accuracy: 0.8203125\n",
      "Batch: 17, Loss: 0.6089403629302979, Accuracy: 0.796875\n",
      "Batch: 18, Loss: 0.6157358884811401, Accuracy: 0.7841796875\n",
      "Batch: 19, Loss: 0.6264781951904297, Accuracy: 0.8056640625\n",
      "Batch: 20, Loss: 0.5639848709106445, Accuracy: 0.826171875\n",
      "Batch: 21, Loss: 0.5509387850761414, Accuracy: 0.8154296875\n",
      "Batch: 22, Loss: 0.7105351686477661, Accuracy: 0.76171875\n",
      "Batch: 23, Loss: 0.6443824768066406, Accuracy: 0.77734375\n",
      "Batch: 24, Loss: 0.6310537457466125, Accuracy: 0.8076171875\n",
      "Batch: 25, Loss: 0.5872498750686646, Accuracy: 0.8115234375\n",
      "Batch: 26, Loss: 0.5057468414306641, Accuracy: 0.833984375\n",
      "Batch: 27, Loss: 0.5800325870513916, Accuracy: 0.7978515625\n",
      "Batch: 28, Loss: 0.6094076633453369, Accuracy: 0.806640625\n",
      "Batch: 29, Loss: 0.5860589742660522, Accuracy: 0.80859375\n",
      "Batch: 30, Loss: 0.565792977809906, Accuracy: 0.818359375\n",
      "Batch: 31, Loss: 0.48219752311706543, Accuracy: 0.8515625\n",
      "Batch: 32, Loss: 0.5551575422286987, Accuracy: 0.82421875\n",
      "Batch: 33, Loss: 0.6365213394165039, Accuracy: 0.794921875\n",
      "Batch: 34, Loss: 0.6505366563796997, Accuracy: 0.794921875\n",
      "Batch: 35, Loss: 0.6153461933135986, Accuracy: 0.80859375\n",
      "Batch: 36, Loss: 0.6080868244171143, Accuracy: 0.810546875\n",
      "Batch: 37, Loss: 0.6460918188095093, Accuracy: 0.791015625\n",
      "Batch: 38, Loss: 0.6504572629928589, Accuracy: 0.7763671875\n",
      "Batch: 39, Loss: 0.6184974908828735, Accuracy: 0.7900390625\n",
      "Batch: 40, Loss: 0.6233025789260864, Accuracy: 0.787109375\n",
      "Batch: 41, Loss: 0.5382524132728577, Accuracy: 0.822265625\n",
      "Batch: 42, Loss: 0.45448026061058044, Accuracy: 0.8505859375\n",
      "Batch: 43, Loss: 0.5478278994560242, Accuracy: 0.822265625\n",
      "Batch: 44, Loss: 0.6285383701324463, Accuracy: 0.7998046875\n",
      "Batch: 45, Loss: 0.5123307704925537, Accuracy: 0.83203125\n",
      "Batch: 46, Loss: 0.5416779518127441, Accuracy: 0.8125\n",
      "Batch: 47, Loss: 0.5930718183517456, Accuracy: 0.8076171875\n",
      "Batch: 48, Loss: 0.556892991065979, Accuracy: 0.814453125\n",
      "Batch: 49, Loss: 0.6376097202301025, Accuracy: 0.79296875\n",
      "Batch: 50, Loss: 0.5753083229064941, Accuracy: 0.8115234375\n",
      "Batch: 51, Loss: 0.631639838218689, Accuracy: 0.7900390625\n",
      "Batch: 52, Loss: 0.566288948059082, Accuracy: 0.8125\n",
      "Batch: 53, Loss: 0.5519096851348877, Accuracy: 0.8193359375\n",
      "Batch: 54, Loss: 0.5286716818809509, Accuracy: 0.8310546875\n",
      "Batch: 55, Loss: 0.6433342695236206, Accuracy: 0.7861328125\n",
      "Batch: 56, Loss: 0.6338161826133728, Accuracy: 0.78515625\n",
      "Batch: 57, Loss: 0.6447266340255737, Accuracy: 0.7900390625\n",
      "Batch: 58, Loss: 0.7032116651535034, Accuracy: 0.7744140625\n",
      "Batch: 59, Loss: 0.5936589241027832, Accuracy: 0.810546875\n",
      "Batch: 60, Loss: 0.5894030928611755, Accuracy: 0.8125\n",
      "Batch: 61, Loss: 0.6272977590560913, Accuracy: 0.79296875\n",
      "Batch: 62, Loss: 0.5606082081794739, Accuracy: 0.818359375\n",
      "Batch: 63, Loss: 0.6255694627761841, Accuracy: 0.80078125\n",
      "Batch: 64, Loss: 0.6025428771972656, Accuracy: 0.806640625\n",
      "Batch: 65, Loss: 0.6166619062423706, Accuracy: 0.7998046875\n",
      "Batch: 66, Loss: 0.5989346504211426, Accuracy: 0.8046875\n",
      "Batch: 67, Loss: 0.6565858721733093, Accuracy: 0.7861328125\n",
      "Batch: 68, Loss: 0.7010230422019958, Accuracy: 0.7646484375\n",
      "Batch: 69, Loss: 0.6297123432159424, Accuracy: 0.7978515625\n",
      "Batch: 70, Loss: 0.65056312084198, Accuracy: 0.798828125\n",
      "Batch: 71, Loss: 0.6509985327720642, Accuracy: 0.7900390625\n",
      "Batch: 72, Loss: 0.5823243856430054, Accuracy: 0.802734375\n",
      "Batch: 73, Loss: 0.5726938247680664, Accuracy: 0.8125\n",
      "Batch: 74, Loss: 0.5515487194061279, Accuracy: 0.83984375\n",
      "Batch: 75, Loss: 0.5377174615859985, Accuracy: 0.82421875\n",
      "Batch: 76, Loss: 0.6173779964447021, Accuracy: 0.7958984375\n",
      "Batch: 77, Loss: 0.5619213581085205, Accuracy: 0.826171875\n",
      "Batch: 78, Loss: 0.5927046537399292, Accuracy: 0.8037109375\n",
      "Batch: 79, Loss: 0.5751667022705078, Accuracy: 0.81640625\n",
      "Batch: 80, Loss: 0.5528753995895386, Accuracy: 0.8330078125\n",
      "Batch: 81, Loss: 0.6189496517181396, Accuracy: 0.77734375\n",
      "Batch: 82, Loss: 0.6231628060340881, Accuracy: 0.8037109375\n",
      "Batch: 83, Loss: 0.5335399508476257, Accuracy: 0.8388671875\n",
      "Batch: 84, Loss: 0.6299529075622559, Accuracy: 0.7919921875\n",
      "Batch: 85, Loss: 0.582394540309906, Accuracy: 0.8232421875\n",
      "Batch: 86, Loss: 0.6988345384597778, Accuracy: 0.779296875\n",
      "Batch: 87, Loss: 0.5670101642608643, Accuracy: 0.822265625\n",
      "Batch: 88, Loss: 0.6401403546333313, Accuracy: 0.7939453125\n",
      "Batch: 89, Loss: 0.6007214188575745, Accuracy: 0.806640625\n",
      "Batch: 90, Loss: 0.5728050470352173, Accuracy: 0.8212890625\n",
      "Batch: 91, Loss: 0.5816759467124939, Accuracy: 0.7880859375\n",
      "Batch: 92, Loss: 0.6478240489959717, Accuracy: 0.8017578125\n",
      "Batch: 93, Loss: 0.6360968351364136, Accuracy: 0.7783203125\n",
      "Batch: 94, Loss: 0.6538683176040649, Accuracy: 0.7978515625\n",
      "Batch: 95, Loss: 0.6088595390319824, Accuracy: 0.794921875\n",
      "Batch: 96, Loss: 0.6026296019554138, Accuracy: 0.8115234375\n",
      "Batch: 97, Loss: 0.5148155689239502, Accuracy: 0.830078125\n",
      "Batch: 98, Loss: 0.617435872554779, Accuracy: 0.8056640625\n",
      "Batch: 99, Loss: 0.5897201299667358, Accuracy: 0.8125\n",
      "Batch: 100, Loss: 0.6198850870132446, Accuracy: 0.7998046875\n",
      "Batch: 101, Loss: 0.6517113447189331, Accuracy: 0.78515625\n",
      "Batch: 102, Loss: 0.6033757328987122, Accuracy: 0.79296875\n",
      "Batch: 103, Loss: 0.6386984586715698, Accuracy: 0.7880859375\n",
      "Batch: 104, Loss: 0.606630265712738, Accuracy: 0.80078125\n",
      "Batch: 105, Loss: 0.58815598487854, Accuracy: 0.8076171875\n",
      "Batch: 106, Loss: 0.5758338570594788, Accuracy: 0.8125\n",
      "Batch: 107, Loss: 0.6147589683532715, Accuracy: 0.798828125\n",
      "Batch: 108, Loss: 0.5847984552383423, Accuracy: 0.80859375\n",
      "Batch: 109, Loss: 0.6625889539718628, Accuracy: 0.7900390625\n",
      "Batch: 110, Loss: 0.5610490441322327, Accuracy: 0.8125\n",
      "Batch: 111, Loss: 0.6262269020080566, Accuracy: 0.8056640625\n",
      "Batch: 112, Loss: 0.6368791460990906, Accuracy: 0.77734375\n",
      "Batch: 113, Loss: 0.589623212814331, Accuracy: 0.8115234375\n",
      "Batch: 114, Loss: 0.643531322479248, Accuracy: 0.794921875\n",
      "Batch: 115, Loss: 0.6938648223876953, Accuracy: 0.779296875\n",
      "Batch: 116, Loss: 0.6254379153251648, Accuracy: 0.794921875\n",
      "Batch: 117, Loss: 0.6467346549034119, Accuracy: 0.7822265625\n",
      "Batch: 118, Loss: 0.5659787654876709, Accuracy: 0.8056640625\n",
      "Batch: 119, Loss: 0.5233808755874634, Accuracy: 0.8291015625\n",
      "Batch: 120, Loss: 0.622604489326477, Accuracy: 0.78125\n",
      "Batch: 121, Loss: 0.6796048879623413, Accuracy: 0.77734375\n",
      "Batch: 122, Loss: 0.6064906120300293, Accuracy: 0.7978515625\n",
      "Batch: 123, Loss: 0.5712970495223999, Accuracy: 0.8173828125\n",
      "Batch: 124, Loss: 0.5765550136566162, Accuracy: 0.828125\n",
      "Batch: 125, Loss: 0.6378769278526306, Accuracy: 0.796875\n",
      "Batch: 126, Loss: 0.6127481460571289, Accuracy: 0.806640625\n",
      "Batch: 127, Loss: 0.5518808364868164, Accuracy: 0.8291015625\n",
      "Batch: 128, Loss: 0.6756551265716553, Accuracy: 0.7861328125\n",
      "Batch: 129, Loss: 0.5608134865760803, Accuracy: 0.822265625\n",
      "Batch: 130, Loss: 0.7142571210861206, Accuracy: 0.771484375\n",
      "Batch: 131, Loss: 0.6534168124198914, Accuracy: 0.787109375\n",
      "Batch: 132, Loss: 0.6511249542236328, Accuracy: 0.791015625\n",
      "Batch: 133, Loss: 0.5944489240646362, Accuracy: 0.7978515625\n",
      "Batch: 134, Loss: 0.6193561553955078, Accuracy: 0.7880859375\n",
      "Batch: 135, Loss: 0.5963277220726013, Accuracy: 0.814453125\n",
      "Batch: 136, Loss: 0.6566727161407471, Accuracy: 0.7861328125\n",
      "Batch: 137, Loss: 0.6581814885139465, Accuracy: 0.7802734375\n",
      "Batch: 138, Loss: 0.5395342111587524, Accuracy: 0.8095703125\n",
      "Batch: 139, Loss: 0.5629535913467407, Accuracy: 0.81640625\n",
      "Batch: 140, Loss: 0.653191089630127, Accuracy: 0.7861328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 141, Loss: 0.6669800281524658, Accuracy: 0.783203125\n",
      "Batch: 142, Loss: 0.6800112128257751, Accuracy: 0.7744140625\n",
      "Batch: 143, Loss: 0.5883837938308716, Accuracy: 0.7998046875\n",
      "Batch: 144, Loss: 0.6317896842956543, Accuracy: 0.7939453125\n",
      "Batch: 145, Loss: 0.5581358075141907, Accuracy: 0.80078125\n",
      "Batch: 146, Loss: 0.6397620439529419, Accuracy: 0.791015625\n",
      "Batch: 147, Loss: 0.6050071716308594, Accuracy: 0.8076171875\n",
      "Batch: 148, Loss: 0.6737937927246094, Accuracy: 0.78125\n",
      "Batch: 149, Loss: 0.6060528755187988, Accuracy: 0.7939453125\n",
      "Batch: 150, Loss: 0.6534791588783264, Accuracy: 0.791015625\n",
      "Batch: 151, Loss: 0.5786758661270142, Accuracy: 0.81640625\n",
      "Epoch 66/80\n",
      "Batch: 1, Loss: 0.7901028394699097, Accuracy: 0.740234375\n",
      "Batch: 2, Loss: 0.6505049467086792, Accuracy: 0.787109375\n",
      "Batch: 3, Loss: 0.6016898155212402, Accuracy: 0.7958984375\n",
      "Batch: 4, Loss: 0.5698367357254028, Accuracy: 0.81640625\n",
      "Batch: 5, Loss: 0.5766023993492126, Accuracy: 0.810546875\n",
      "Batch: 6, Loss: 0.5861559510231018, Accuracy: 0.8076171875\n",
      "Batch: 7, Loss: 0.5949817299842834, Accuracy: 0.79296875\n",
      "Batch: 8, Loss: 0.5584930777549744, Accuracy: 0.8115234375\n",
      "Batch: 9, Loss: 0.5996652841567993, Accuracy: 0.8017578125\n",
      "Batch: 10, Loss: 0.568915605545044, Accuracy: 0.8125\n",
      "Batch: 11, Loss: 0.6282323598861694, Accuracy: 0.7890625\n",
      "Batch: 12, Loss: 0.6317136287689209, Accuracy: 0.7880859375\n",
      "Batch: 13, Loss: 0.5070352554321289, Accuracy: 0.82421875\n",
      "Batch: 14, Loss: 0.6534872055053711, Accuracy: 0.787109375\n",
      "Batch: 15, Loss: 0.5560092926025391, Accuracy: 0.8349609375\n",
      "Batch: 16, Loss: 0.5589475631713867, Accuracy: 0.8212890625\n",
      "Batch: 17, Loss: 0.6160938739776611, Accuracy: 0.79296875\n",
      "Batch: 18, Loss: 0.645135760307312, Accuracy: 0.798828125\n",
      "Batch: 19, Loss: 0.6101298332214355, Accuracy: 0.806640625\n",
      "Batch: 20, Loss: 0.5664381980895996, Accuracy: 0.8310546875\n",
      "Batch: 21, Loss: 0.521293044090271, Accuracy: 0.8232421875\n",
      "Batch: 22, Loss: 0.6405256986618042, Accuracy: 0.78515625\n",
      "Batch: 23, Loss: 0.639373779296875, Accuracy: 0.794921875\n",
      "Batch: 24, Loss: 0.623404324054718, Accuracy: 0.7998046875\n",
      "Batch: 25, Loss: 0.554133951663971, Accuracy: 0.810546875\n",
      "Batch: 26, Loss: 0.5333007574081421, Accuracy: 0.8251953125\n",
      "Batch: 27, Loss: 0.6013327836990356, Accuracy: 0.7978515625\n",
      "Batch: 28, Loss: 0.5879240036010742, Accuracy: 0.80859375\n",
      "Batch: 29, Loss: 0.5729324817657471, Accuracy: 0.8154296875\n",
      "Batch: 30, Loss: 0.5366910696029663, Accuracy: 0.828125\n",
      "Batch: 31, Loss: 0.5093579292297363, Accuracy: 0.8310546875\n",
      "Batch: 32, Loss: 0.5791972875595093, Accuracy: 0.8095703125\n",
      "Batch: 33, Loss: 0.6669184565544128, Accuracy: 0.7744140625\n",
      "Batch: 34, Loss: 0.6474598050117493, Accuracy: 0.791015625\n",
      "Batch: 35, Loss: 0.6076698303222656, Accuracy: 0.8056640625\n",
      "Batch: 36, Loss: 0.6138229966163635, Accuracy: 0.8046875\n",
      "Batch: 37, Loss: 0.6211514472961426, Accuracy: 0.798828125\n",
      "Batch: 38, Loss: 0.6585791110992432, Accuracy: 0.7841796875\n",
      "Batch: 39, Loss: 0.6118708252906799, Accuracy: 0.8046875\n",
      "Batch: 40, Loss: 0.6125512719154358, Accuracy: 0.791015625\n",
      "Batch: 41, Loss: 0.560920774936676, Accuracy: 0.81640625\n",
      "Batch: 42, Loss: 0.46600067615509033, Accuracy: 0.83984375\n",
      "Batch: 43, Loss: 0.5655523538589478, Accuracy: 0.8232421875\n",
      "Batch: 44, Loss: 0.6126258373260498, Accuracy: 0.802734375\n",
      "Batch: 45, Loss: 0.5436311960220337, Accuracy: 0.8203125\n",
      "Batch: 46, Loss: 0.5890399217605591, Accuracy: 0.7958984375\n",
      "Batch: 47, Loss: 0.610071063041687, Accuracy: 0.806640625\n",
      "Batch: 48, Loss: 0.5819954872131348, Accuracy: 0.810546875\n",
      "Batch: 49, Loss: 0.6053603291511536, Accuracy: 0.8046875\n",
      "Batch: 50, Loss: 0.5925766229629517, Accuracy: 0.806640625\n",
      "Batch: 51, Loss: 0.6152139902114868, Accuracy: 0.7978515625\n",
      "Batch: 52, Loss: 0.5835479497909546, Accuracy: 0.7998046875\n",
      "Batch: 53, Loss: 0.5322930812835693, Accuracy: 0.8203125\n",
      "Batch: 54, Loss: 0.5804240703582764, Accuracy: 0.8115234375\n",
      "Batch: 55, Loss: 0.6497149467468262, Accuracy: 0.7841796875\n",
      "Batch: 56, Loss: 0.6676311492919922, Accuracy: 0.76953125\n",
      "Batch: 57, Loss: 0.632920503616333, Accuracy: 0.7939453125\n",
      "Batch: 58, Loss: 0.6616916060447693, Accuracy: 0.787109375\n",
      "Batch: 59, Loss: 0.6228632926940918, Accuracy: 0.7998046875\n",
      "Batch: 60, Loss: 0.5735279321670532, Accuracy: 0.8056640625\n",
      "Batch: 61, Loss: 0.6110559105873108, Accuracy: 0.798828125\n",
      "Batch: 62, Loss: 0.5579617023468018, Accuracy: 0.8046875\n",
      "Batch: 63, Loss: 0.6328697204589844, Accuracy: 0.798828125\n",
      "Batch: 64, Loss: 0.5986193418502808, Accuracy: 0.8017578125\n",
      "Batch: 65, Loss: 0.6068522334098816, Accuracy: 0.7998046875\n",
      "Batch: 66, Loss: 0.606717586517334, Accuracy: 0.7998046875\n",
      "Batch: 67, Loss: 0.6825480461120605, Accuracy: 0.7890625\n",
      "Batch: 68, Loss: 0.6763478517532349, Accuracy: 0.78125\n",
      "Batch: 69, Loss: 0.6097062826156616, Accuracy: 0.7939453125\n",
      "Batch: 70, Loss: 0.6006506681442261, Accuracy: 0.810546875\n",
      "Batch: 71, Loss: 0.6795753240585327, Accuracy: 0.7802734375\n",
      "Batch: 72, Loss: 0.5869854688644409, Accuracy: 0.7978515625\n",
      "Batch: 73, Loss: 0.5434689521789551, Accuracy: 0.8349609375\n",
      "Batch: 74, Loss: 0.5113702416419983, Accuracy: 0.8388671875\n",
      "Batch: 75, Loss: 0.4867115616798401, Accuracy: 0.8515625\n",
      "Batch: 76, Loss: 0.6157225370407104, Accuracy: 0.791015625\n",
      "Batch: 77, Loss: 0.5342404842376709, Accuracy: 0.837890625\n",
      "Batch: 78, Loss: 0.5488864779472351, Accuracy: 0.8271484375\n",
      "Batch: 79, Loss: 0.5760761499404907, Accuracy: 0.81640625\n",
      "Batch: 80, Loss: 0.5716931819915771, Accuracy: 0.8076171875\n",
      "Batch: 81, Loss: 0.6443181037902832, Accuracy: 0.7880859375\n",
      "Batch: 82, Loss: 0.6031167507171631, Accuracy: 0.8046875\n",
      "Batch: 83, Loss: 0.5635155439376831, Accuracy: 0.826171875\n",
      "Batch: 84, Loss: 0.6251466274261475, Accuracy: 0.798828125\n",
      "Batch: 85, Loss: 0.5833333730697632, Accuracy: 0.8154296875\n",
      "Batch: 86, Loss: 0.7076621055603027, Accuracy: 0.7802734375\n",
      "Batch: 87, Loss: 0.5902825593948364, Accuracy: 0.7998046875\n",
      "Batch: 88, Loss: 0.6263482570648193, Accuracy: 0.80859375\n",
      "Batch: 89, Loss: 0.5934690833091736, Accuracy: 0.806640625\n",
      "Batch: 90, Loss: 0.585031270980835, Accuracy: 0.8076171875\n",
      "Batch: 91, Loss: 0.5961489677429199, Accuracy: 0.7900390625\n",
      "Batch: 92, Loss: 0.6402081251144409, Accuracy: 0.79296875\n",
      "Batch: 93, Loss: 0.615827739238739, Accuracy: 0.798828125\n",
      "Batch: 94, Loss: 0.6373799443244934, Accuracy: 0.7939453125\n",
      "Batch: 95, Loss: 0.6029927730560303, Accuracy: 0.806640625\n",
      "Batch: 96, Loss: 0.5885308384895325, Accuracy: 0.806640625\n",
      "Batch: 97, Loss: 0.47909700870513916, Accuracy: 0.8564453125\n",
      "Batch: 98, Loss: 0.6342090368270874, Accuracy: 0.7900390625\n",
      "Batch: 99, Loss: 0.6085373163223267, Accuracy: 0.7998046875\n",
      "Batch: 100, Loss: 0.6452710032463074, Accuracy: 0.78515625\n",
      "Batch: 101, Loss: 0.6337763071060181, Accuracy: 0.779296875\n",
      "Batch: 102, Loss: 0.6270382404327393, Accuracy: 0.802734375\n",
      "Batch: 103, Loss: 0.6171423196792603, Accuracy: 0.794921875\n",
      "Batch: 104, Loss: 0.5794395208358765, Accuracy: 0.8125\n",
      "Batch: 105, Loss: 0.6199093461036682, Accuracy: 0.8037109375\n",
      "Batch: 106, Loss: 0.5598102807998657, Accuracy: 0.8115234375\n",
      "Batch: 107, Loss: 0.5994259119033813, Accuracy: 0.8125\n",
      "Batch: 108, Loss: 0.5701908469200134, Accuracy: 0.8291015625\n",
      "Batch: 109, Loss: 0.6254730224609375, Accuracy: 0.787109375\n",
      "Batch: 110, Loss: 0.5888620018959045, Accuracy: 0.81640625\n",
      "Batch: 111, Loss: 0.6255214810371399, Accuracy: 0.79296875\n",
      "Batch: 112, Loss: 0.6224744319915771, Accuracy: 0.796875\n",
      "Batch: 113, Loss: 0.5769751667976379, Accuracy: 0.814453125\n",
      "Batch: 114, Loss: 0.6283875703811646, Accuracy: 0.802734375\n",
      "Batch: 115, Loss: 0.6462010741233826, Accuracy: 0.7919921875\n",
      "Batch: 116, Loss: 0.6260730624198914, Accuracy: 0.7900390625\n",
      "Batch: 117, Loss: 0.6530003547668457, Accuracy: 0.791015625\n",
      "Batch: 118, Loss: 0.5543961524963379, Accuracy: 0.8251953125\n",
      "Batch: 119, Loss: 0.5205973386764526, Accuracy: 0.8203125\n",
      "Batch: 120, Loss: 0.5947180986404419, Accuracy: 0.7861328125\n",
      "Batch: 121, Loss: 0.6522762775421143, Accuracy: 0.7919921875\n",
      "Batch: 122, Loss: 0.5904396772384644, Accuracy: 0.80859375\n",
      "Batch: 123, Loss: 0.578387975692749, Accuracy: 0.818359375\n",
      "Batch: 124, Loss: 0.5865485668182373, Accuracy: 0.8017578125\n",
      "Batch: 125, Loss: 0.6421495079994202, Accuracy: 0.7900390625\n",
      "Batch: 126, Loss: 0.6279876232147217, Accuracy: 0.8037109375\n",
      "Batch: 127, Loss: 0.5276679992675781, Accuracy: 0.826171875\n",
      "Batch: 128, Loss: 0.659788966178894, Accuracy: 0.791015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 129, Loss: 0.5831009149551392, Accuracy: 0.80859375\n",
      "Batch: 130, Loss: 0.6600992679595947, Accuracy: 0.7783203125\n",
      "Batch: 131, Loss: 0.5985901355743408, Accuracy: 0.796875\n",
      "Batch: 132, Loss: 0.6390044689178467, Accuracy: 0.7919921875\n",
      "Batch: 133, Loss: 0.6228181719779968, Accuracy: 0.796875\n",
      "Batch: 134, Loss: 0.6119701862335205, Accuracy: 0.7783203125\n",
      "Batch: 135, Loss: 0.5707485675811768, Accuracy: 0.8193359375\n",
      "Batch: 136, Loss: 0.6268390417098999, Accuracy: 0.80078125\n",
      "Batch: 137, Loss: 0.6153515577316284, Accuracy: 0.77734375\n",
      "Batch: 138, Loss: 0.5449663400650024, Accuracy: 0.806640625\n",
      "Batch: 139, Loss: 0.5606773495674133, Accuracy: 0.8037109375\n",
      "Batch: 140, Loss: 0.6032750606536865, Accuracy: 0.7998046875\n",
      "Batch: 141, Loss: 0.648844838142395, Accuracy: 0.787109375\n",
      "Batch: 142, Loss: 0.6947306990623474, Accuracy: 0.7802734375\n",
      "Batch: 143, Loss: 0.5998529195785522, Accuracy: 0.79296875\n",
      "Batch: 144, Loss: 0.6331228017807007, Accuracy: 0.7998046875\n",
      "Batch: 145, Loss: 0.5783271789550781, Accuracy: 0.8134765625\n",
      "Batch: 146, Loss: 0.613510251045227, Accuracy: 0.7939453125\n",
      "Batch: 147, Loss: 0.5819389820098877, Accuracy: 0.8125\n",
      "Batch: 148, Loss: 0.6543240547180176, Accuracy: 0.7861328125\n",
      "Batch: 149, Loss: 0.5955692529678345, Accuracy: 0.8037109375\n",
      "Batch: 150, Loss: 0.624136745929718, Accuracy: 0.7939453125\n",
      "Batch: 151, Loss: 0.5799910426139832, Accuracy: 0.8115234375\n",
      "Epoch 67/80\n",
      "Batch: 1, Loss: 0.7934672832489014, Accuracy: 0.7421875\n",
      "Batch: 2, Loss: 0.6476014852523804, Accuracy: 0.787109375\n",
      "Batch: 3, Loss: 0.5889973044395447, Accuracy: 0.8037109375\n",
      "Batch: 4, Loss: 0.5652936697006226, Accuracy: 0.814453125\n",
      "Batch: 5, Loss: 0.6117211580276489, Accuracy: 0.794921875\n",
      "Batch: 6, Loss: 0.5708099603652954, Accuracy: 0.8203125\n",
      "Batch: 7, Loss: 0.6098272800445557, Accuracy: 0.8017578125\n",
      "Batch: 8, Loss: 0.5556000471115112, Accuracy: 0.8232421875\n",
      "Batch: 9, Loss: 0.586098313331604, Accuracy: 0.806640625\n",
      "Batch: 10, Loss: 0.5455325841903687, Accuracy: 0.818359375\n",
      "Batch: 11, Loss: 0.6348005533218384, Accuracy: 0.7939453125\n",
      "Batch: 12, Loss: 0.5739806890487671, Accuracy: 0.806640625\n",
      "Batch: 13, Loss: 0.5309354066848755, Accuracy: 0.830078125\n",
      "Batch: 14, Loss: 0.6164640784263611, Accuracy: 0.7822265625\n",
      "Batch: 15, Loss: 0.5592323541641235, Accuracy: 0.826171875\n",
      "Batch: 16, Loss: 0.5448105335235596, Accuracy: 0.82421875\n",
      "Batch: 17, Loss: 0.6077187657356262, Accuracy: 0.8017578125\n",
      "Batch: 18, Loss: 0.6542447805404663, Accuracy: 0.7705078125\n",
      "Batch: 19, Loss: 0.6313326358795166, Accuracy: 0.8046875\n",
      "Batch: 20, Loss: 0.5685927271842957, Accuracy: 0.8291015625\n",
      "Batch: 21, Loss: 0.5331969261169434, Accuracy: 0.8212890625\n",
      "Batch: 22, Loss: 0.6886677742004395, Accuracy: 0.7744140625\n",
      "Batch: 23, Loss: 0.6471003293991089, Accuracy: 0.775390625\n",
      "Batch: 24, Loss: 0.609123945236206, Accuracy: 0.8095703125\n",
      "Batch: 25, Loss: 0.5690834522247314, Accuracy: 0.8232421875\n",
      "Batch: 26, Loss: 0.5147159099578857, Accuracy: 0.8349609375\n",
      "Batch: 27, Loss: 0.5786987543106079, Accuracy: 0.806640625\n",
      "Batch: 28, Loss: 0.5863691568374634, Accuracy: 0.8134765625\n",
      "Batch: 29, Loss: 0.5938565731048584, Accuracy: 0.7939453125\n",
      "Batch: 30, Loss: 0.5325124859809875, Accuracy: 0.826171875\n",
      "Batch: 31, Loss: 0.524288535118103, Accuracy: 0.8173828125\n",
      "Batch: 32, Loss: 0.548747181892395, Accuracy: 0.814453125\n",
      "Batch: 33, Loss: 0.601824164390564, Accuracy: 0.7998046875\n",
      "Batch: 34, Loss: 0.6208126544952393, Accuracy: 0.802734375\n",
      "Batch: 35, Loss: 0.5797715783119202, Accuracy: 0.806640625\n",
      "Batch: 36, Loss: 0.5823562145233154, Accuracy: 0.8154296875\n",
      "Batch: 37, Loss: 0.6307762265205383, Accuracy: 0.787109375\n",
      "Batch: 38, Loss: 0.631850004196167, Accuracy: 0.7783203125\n",
      "Batch: 39, Loss: 0.6088414192199707, Accuracy: 0.794921875\n",
      "Batch: 40, Loss: 0.5770817399024963, Accuracy: 0.7998046875\n",
      "Batch: 41, Loss: 0.5371430516242981, Accuracy: 0.818359375\n",
      "Batch: 42, Loss: 0.4575504660606384, Accuracy: 0.849609375\n",
      "Batch: 43, Loss: 0.558114230632782, Accuracy: 0.8251953125\n",
      "Batch: 44, Loss: 0.5925459861755371, Accuracy: 0.8046875\n",
      "Batch: 45, Loss: 0.5290497541427612, Accuracy: 0.833984375\n",
      "Batch: 46, Loss: 0.5620770454406738, Accuracy: 0.8251953125\n",
      "Batch: 47, Loss: 0.6384150981903076, Accuracy: 0.796875\n",
      "Batch: 48, Loss: 0.5589122772216797, Accuracy: 0.81640625\n",
      "Batch: 49, Loss: 0.6498074531555176, Accuracy: 0.802734375\n",
      "Batch: 50, Loss: 0.5643472075462341, Accuracy: 0.8251953125\n",
      "Batch: 51, Loss: 0.6222697496414185, Accuracy: 0.7978515625\n",
      "Batch: 52, Loss: 0.5769290924072266, Accuracy: 0.8212890625\n",
      "Batch: 53, Loss: 0.5358463525772095, Accuracy: 0.828125\n",
      "Batch: 54, Loss: 0.5678238868713379, Accuracy: 0.81640625\n",
      "Batch: 55, Loss: 0.6265354156494141, Accuracy: 0.7919921875\n",
      "Batch: 56, Loss: 0.6565622091293335, Accuracy: 0.775390625\n",
      "Batch: 57, Loss: 0.6077926754951477, Accuracy: 0.7978515625\n",
      "Batch: 58, Loss: 0.6552613377571106, Accuracy: 0.7861328125\n",
      "Batch: 59, Loss: 0.6256338357925415, Accuracy: 0.798828125\n",
      "Batch: 60, Loss: 0.5382809042930603, Accuracy: 0.8046875\n",
      "Batch: 61, Loss: 0.6378735899925232, Accuracy: 0.7958984375\n",
      "Batch: 62, Loss: 0.548160195350647, Accuracy: 0.814453125\n",
      "Batch: 63, Loss: 0.6534728407859802, Accuracy: 0.7841796875\n",
      "Batch: 64, Loss: 0.5566148161888123, Accuracy: 0.8076171875\n",
      "Batch: 65, Loss: 0.618385910987854, Accuracy: 0.79296875\n",
      "Batch: 66, Loss: 0.5743604898452759, Accuracy: 0.8154296875\n",
      "Batch: 67, Loss: 0.6445236206054688, Accuracy: 0.794921875\n",
      "Batch: 68, Loss: 0.6616987586021423, Accuracy: 0.7919921875\n",
      "Batch: 69, Loss: 0.6212424039840698, Accuracy: 0.80859375\n",
      "Batch: 70, Loss: 0.6417686939239502, Accuracy: 0.80078125\n",
      "Batch: 71, Loss: 0.6180851459503174, Accuracy: 0.81640625\n",
      "Batch: 72, Loss: 0.5840314626693726, Accuracy: 0.8076171875\n",
      "Batch: 73, Loss: 0.5160207748413086, Accuracy: 0.8349609375\n",
      "Batch: 74, Loss: 0.5237694382667542, Accuracy: 0.8232421875\n",
      "Batch: 75, Loss: 0.5245615839958191, Accuracy: 0.8349609375\n",
      "Batch: 76, Loss: 0.5895478129386902, Accuracy: 0.8134765625\n",
      "Batch: 77, Loss: 0.5493223667144775, Accuracy: 0.814453125\n",
      "Batch: 78, Loss: 0.5331190824508667, Accuracy: 0.828125\n",
      "Batch: 79, Loss: 0.5772189497947693, Accuracy: 0.818359375\n",
      "Batch: 80, Loss: 0.5613422393798828, Accuracy: 0.8212890625\n",
      "Batch: 81, Loss: 0.6184952259063721, Accuracy: 0.7822265625\n",
      "Batch: 82, Loss: 0.601321280002594, Accuracy: 0.7900390625\n",
      "Batch: 83, Loss: 0.5446805953979492, Accuracy: 0.8310546875\n",
      "Batch: 84, Loss: 0.571332573890686, Accuracy: 0.8056640625\n",
      "Batch: 85, Loss: 0.6056839227676392, Accuracy: 0.8095703125\n",
      "Batch: 86, Loss: 0.693388819694519, Accuracy: 0.7626953125\n",
      "Batch: 87, Loss: 0.55487060546875, Accuracy: 0.826171875\n",
      "Batch: 88, Loss: 0.6102067232131958, Accuracy: 0.818359375\n",
      "Batch: 89, Loss: 0.626986563205719, Accuracy: 0.79296875\n",
      "Batch: 90, Loss: 0.5423781275749207, Accuracy: 0.8212890625\n",
      "Batch: 91, Loss: 0.5581600069999695, Accuracy: 0.7978515625\n",
      "Batch: 92, Loss: 0.637643575668335, Accuracy: 0.7958984375\n",
      "Batch: 93, Loss: 0.6252191066741943, Accuracy: 0.7958984375\n",
      "Batch: 94, Loss: 0.6158742308616638, Accuracy: 0.7939453125\n",
      "Batch: 95, Loss: 0.5967993140220642, Accuracy: 0.802734375\n",
      "Batch: 96, Loss: 0.5736521482467651, Accuracy: 0.818359375\n",
      "Batch: 97, Loss: 0.49798154830932617, Accuracy: 0.8388671875\n",
      "Batch: 98, Loss: 0.60383141040802, Accuracy: 0.80859375\n",
      "Batch: 99, Loss: 0.5975171327590942, Accuracy: 0.7890625\n",
      "Batch: 100, Loss: 0.5965272784233093, Accuracy: 0.806640625\n",
      "Batch: 101, Loss: 0.659430980682373, Accuracy: 0.77734375\n",
      "Batch: 102, Loss: 0.6066328287124634, Accuracy: 0.8017578125\n",
      "Batch: 103, Loss: 0.5859794616699219, Accuracy: 0.8193359375\n",
      "Batch: 104, Loss: 0.5569188594818115, Accuracy: 0.826171875\n",
      "Batch: 105, Loss: 0.6057244539260864, Accuracy: 0.787109375\n",
      "Batch: 106, Loss: 0.5522111058235168, Accuracy: 0.8154296875\n",
      "Batch: 107, Loss: 0.5793589353561401, Accuracy: 0.8115234375\n",
      "Batch: 108, Loss: 0.58087158203125, Accuracy: 0.8056640625\n",
      "Batch: 109, Loss: 0.6248540282249451, Accuracy: 0.7861328125\n",
      "Batch: 110, Loss: 0.5595986247062683, Accuracy: 0.82421875\n",
      "Batch: 111, Loss: 0.6102755069732666, Accuracy: 0.7880859375\n",
      "Batch: 112, Loss: 0.6178774833679199, Accuracy: 0.7998046875\n",
      "Batch: 113, Loss: 0.6073833703994751, Accuracy: 0.796875\n",
      "Batch: 114, Loss: 0.6057957410812378, Accuracy: 0.7998046875\n",
      "Batch: 115, Loss: 0.6683981418609619, Accuracy: 0.7900390625\n",
      "Batch: 116, Loss: 0.6107054948806763, Accuracy: 0.806640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 117, Loss: 0.6360392570495605, Accuracy: 0.79296875\n",
      "Batch: 118, Loss: 0.5613660216331482, Accuracy: 0.8251953125\n",
      "Batch: 119, Loss: 0.5406312346458435, Accuracy: 0.82421875\n",
      "Batch: 120, Loss: 0.5656551122665405, Accuracy: 0.8017578125\n",
      "Batch: 121, Loss: 0.6674764156341553, Accuracy: 0.7822265625\n",
      "Batch: 122, Loss: 0.5989697575569153, Accuracy: 0.8046875\n",
      "Batch: 123, Loss: 0.5414381623268127, Accuracy: 0.822265625\n",
      "Batch: 124, Loss: 0.6186996102333069, Accuracy: 0.798828125\n",
      "Batch: 125, Loss: 0.666863739490509, Accuracy: 0.7783203125\n",
      "Batch: 126, Loss: 0.6072692275047302, Accuracy: 0.7978515625\n",
      "Batch: 127, Loss: 0.5642180442810059, Accuracy: 0.814453125\n",
      "Batch: 128, Loss: 0.6900444030761719, Accuracy: 0.7783203125\n",
      "Batch: 129, Loss: 0.5365124344825745, Accuracy: 0.8359375\n",
      "Batch: 130, Loss: 0.689727246761322, Accuracy: 0.7578125\n",
      "Batch: 131, Loss: 0.6031787991523743, Accuracy: 0.8076171875\n",
      "Batch: 132, Loss: 0.6257449388504028, Accuracy: 0.806640625\n",
      "Batch: 133, Loss: 0.5698626041412354, Accuracy: 0.8017578125\n",
      "Batch: 134, Loss: 0.6138548851013184, Accuracy: 0.7939453125\n",
      "Batch: 135, Loss: 0.5570932030677795, Accuracy: 0.8193359375\n",
      "Batch: 136, Loss: 0.5951840877532959, Accuracy: 0.80859375\n",
      "Batch: 137, Loss: 0.6300733089447021, Accuracy: 0.7734375\n",
      "Batch: 138, Loss: 0.5396095514297485, Accuracy: 0.8154296875\n",
      "Batch: 139, Loss: 0.5780061483383179, Accuracy: 0.80859375\n",
      "Batch: 140, Loss: 0.6117205619812012, Accuracy: 0.8046875\n",
      "Batch: 141, Loss: 0.633898138999939, Accuracy: 0.8076171875\n",
      "Batch: 142, Loss: 0.6848958134651184, Accuracy: 0.783203125\n",
      "Batch: 143, Loss: 0.5755575895309448, Accuracy: 0.8056640625\n",
      "Batch: 144, Loss: 0.615562915802002, Accuracy: 0.78125\n",
      "Batch: 145, Loss: 0.5699975490570068, Accuracy: 0.80078125\n",
      "Batch: 146, Loss: 0.6315842270851135, Accuracy: 0.7890625\n",
      "Batch: 147, Loss: 0.5521934032440186, Accuracy: 0.822265625\n",
      "Batch: 148, Loss: 0.6485795974731445, Accuracy: 0.79296875\n",
      "Batch: 149, Loss: 0.5518755912780762, Accuracy: 0.7998046875\n",
      "Batch: 150, Loss: 0.636347234249115, Accuracy: 0.7939453125\n",
      "Batch: 151, Loss: 0.5662173628807068, Accuracy: 0.8232421875\n",
      "Epoch 68/80\n",
      "Batch: 1, Loss: 0.8175623416900635, Accuracy: 0.7607421875\n",
      "Batch: 2, Loss: 0.6338080167770386, Accuracy: 0.7822265625\n",
      "Batch: 3, Loss: 0.5677173137664795, Accuracy: 0.8095703125\n",
      "Batch: 4, Loss: 0.5601043105125427, Accuracy: 0.8203125\n",
      "Batch: 5, Loss: 0.5820969343185425, Accuracy: 0.8095703125\n",
      "Batch: 6, Loss: 0.6187136769294739, Accuracy: 0.798828125\n",
      "Batch: 7, Loss: 0.5934680700302124, Accuracy: 0.8046875\n",
      "Batch: 8, Loss: 0.5572481155395508, Accuracy: 0.8251953125\n",
      "Batch: 9, Loss: 0.5919628739356995, Accuracy: 0.80078125\n",
      "Batch: 10, Loss: 0.5406768918037415, Accuracy: 0.818359375\n",
      "Batch: 11, Loss: 0.6617516279220581, Accuracy: 0.7880859375\n",
      "Batch: 12, Loss: 0.6135724186897278, Accuracy: 0.80078125\n",
      "Batch: 13, Loss: 0.4971943497657776, Accuracy: 0.8359375\n",
      "Batch: 14, Loss: 0.6495277285575867, Accuracy: 0.78125\n",
      "Batch: 15, Loss: 0.5426048636436462, Accuracy: 0.8271484375\n",
      "Batch: 16, Loss: 0.5484896302223206, Accuracy: 0.8232421875\n",
      "Batch: 17, Loss: 0.6076033115386963, Accuracy: 0.802734375\n",
      "Batch: 18, Loss: 0.599139392375946, Accuracy: 0.802734375\n",
      "Batch: 19, Loss: 0.6008289456367493, Accuracy: 0.8095703125\n",
      "Batch: 20, Loss: 0.5659250020980835, Accuracy: 0.8291015625\n",
      "Batch: 21, Loss: 0.5440442562103271, Accuracy: 0.826171875\n",
      "Batch: 22, Loss: 0.6371355056762695, Accuracy: 0.7705078125\n",
      "Batch: 23, Loss: 0.6144798994064331, Accuracy: 0.794921875\n",
      "Batch: 24, Loss: 0.594313383102417, Accuracy: 0.80859375\n",
      "Batch: 25, Loss: 0.541394829750061, Accuracy: 0.8203125\n",
      "Batch: 26, Loss: 0.513035774230957, Accuracy: 0.83203125\n",
      "Batch: 27, Loss: 0.5546555519104004, Accuracy: 0.810546875\n",
      "Batch: 28, Loss: 0.593657374382019, Accuracy: 0.8056640625\n",
      "Batch: 29, Loss: 0.534827709197998, Accuracy: 0.8349609375\n",
      "Batch: 30, Loss: 0.526220977306366, Accuracy: 0.8349609375\n",
      "Batch: 31, Loss: 0.5177448987960815, Accuracy: 0.826171875\n",
      "Batch: 32, Loss: 0.5533289313316345, Accuracy: 0.8154296875\n",
      "Batch: 33, Loss: 0.6382169127464294, Accuracy: 0.7822265625\n",
      "Batch: 34, Loss: 0.6477262377738953, Accuracy: 0.7861328125\n",
      "Batch: 35, Loss: 0.5997375249862671, Accuracy: 0.80078125\n",
      "Batch: 36, Loss: 0.5785543322563171, Accuracy: 0.8115234375\n",
      "Batch: 37, Loss: 0.6215169429779053, Accuracy: 0.8115234375\n",
      "Batch: 38, Loss: 0.6287598609924316, Accuracy: 0.7958984375\n",
      "Batch: 39, Loss: 0.5963990092277527, Accuracy: 0.798828125\n",
      "Batch: 40, Loss: 0.5656497478485107, Accuracy: 0.8037109375\n",
      "Batch: 41, Loss: 0.5253906846046448, Accuracy: 0.833984375\n",
      "Batch: 42, Loss: 0.43170562386512756, Accuracy: 0.8515625\n",
      "Batch: 43, Loss: 0.5663381814956665, Accuracy: 0.8251953125\n",
      "Batch: 44, Loss: 0.6102710962295532, Accuracy: 0.810546875\n",
      "Batch: 45, Loss: 0.5103716254234314, Accuracy: 0.8271484375\n",
      "Batch: 46, Loss: 0.559927225112915, Accuracy: 0.8173828125\n",
      "Batch: 47, Loss: 0.5940179824829102, Accuracy: 0.826171875\n",
      "Batch: 48, Loss: 0.5454325675964355, Accuracy: 0.818359375\n",
      "Batch: 49, Loss: 0.6206473112106323, Accuracy: 0.80078125\n",
      "Batch: 50, Loss: 0.55278480052948, Accuracy: 0.8173828125\n",
      "Batch: 51, Loss: 0.6046448945999146, Accuracy: 0.8076171875\n",
      "Batch: 52, Loss: 0.5640662908554077, Accuracy: 0.8154296875\n",
      "Batch: 53, Loss: 0.5254139304161072, Accuracy: 0.8193359375\n",
      "Batch: 54, Loss: 0.5893369913101196, Accuracy: 0.8193359375\n",
      "Batch: 55, Loss: 0.6311355829238892, Accuracy: 0.779296875\n",
      "Batch: 56, Loss: 0.6491448879241943, Accuracy: 0.7978515625\n",
      "Batch: 57, Loss: 0.6141780614852905, Accuracy: 0.79296875\n",
      "Batch: 58, Loss: 0.6992647051811218, Accuracy: 0.7822265625\n",
      "Batch: 59, Loss: 0.5909121036529541, Accuracy: 0.8154296875\n",
      "Batch: 60, Loss: 0.5543876886367798, Accuracy: 0.81640625\n",
      "Batch: 61, Loss: 0.6203207969665527, Accuracy: 0.794921875\n",
      "Batch: 62, Loss: 0.5347466468811035, Accuracy: 0.814453125\n",
      "Batch: 63, Loss: 0.5981483459472656, Accuracy: 0.791015625\n",
      "Batch: 64, Loss: 0.5765784978866577, Accuracy: 0.8076171875\n",
      "Batch: 65, Loss: 0.6204310059547424, Accuracy: 0.806640625\n",
      "Batch: 66, Loss: 0.6156450510025024, Accuracy: 0.8095703125\n",
      "Batch: 67, Loss: 0.6639835834503174, Accuracy: 0.787109375\n",
      "Batch: 68, Loss: 0.6554394960403442, Accuracy: 0.7890625\n",
      "Batch: 69, Loss: 0.6248617172241211, Accuracy: 0.7802734375\n",
      "Batch: 70, Loss: 0.6481389999389648, Accuracy: 0.802734375\n",
      "Batch: 71, Loss: 0.6371316313743591, Accuracy: 0.791015625\n",
      "Batch: 72, Loss: 0.5901911854743958, Accuracy: 0.8115234375\n",
      "Batch: 73, Loss: 0.5469778180122375, Accuracy: 0.8291015625\n",
      "Batch: 74, Loss: 0.5178837180137634, Accuracy: 0.8349609375\n",
      "Batch: 75, Loss: 0.5163341164588928, Accuracy: 0.8369140625\n",
      "Batch: 76, Loss: 0.6210788488388062, Accuracy: 0.7900390625\n",
      "Batch: 77, Loss: 0.5529118776321411, Accuracy: 0.8173828125\n",
      "Batch: 78, Loss: 0.5470610857009888, Accuracy: 0.8154296875\n",
      "Batch: 79, Loss: 0.5997297763824463, Accuracy: 0.818359375\n",
      "Batch: 80, Loss: 0.53873610496521, Accuracy: 0.8271484375\n",
      "Batch: 81, Loss: 0.6284879446029663, Accuracy: 0.7900390625\n",
      "Batch: 82, Loss: 0.5851156711578369, Accuracy: 0.7998046875\n",
      "Batch: 83, Loss: 0.5040906071662903, Accuracy: 0.8369140625\n",
      "Batch: 84, Loss: 0.5847271680831909, Accuracy: 0.8125\n",
      "Batch: 85, Loss: 0.5757279992103577, Accuracy: 0.8154296875\n",
      "Batch: 86, Loss: 0.6763806343078613, Accuracy: 0.787109375\n",
      "Batch: 87, Loss: 0.5750938057899475, Accuracy: 0.8134765625\n",
      "Batch: 88, Loss: 0.6155073046684265, Accuracy: 0.8046875\n",
      "Batch: 89, Loss: 0.6130204200744629, Accuracy: 0.7978515625\n",
      "Batch: 90, Loss: 0.5485408902168274, Accuracy: 0.8095703125\n",
      "Batch: 91, Loss: 0.5451999306678772, Accuracy: 0.8115234375\n",
      "Batch: 92, Loss: 0.6159818768501282, Accuracy: 0.798828125\n",
      "Batch: 93, Loss: 0.5700641870498657, Accuracy: 0.810546875\n",
      "Batch: 94, Loss: 0.6159076690673828, Accuracy: 0.7939453125\n",
      "Batch: 95, Loss: 0.5801830291748047, Accuracy: 0.7939453125\n",
      "Batch: 96, Loss: 0.5872676372528076, Accuracy: 0.8076171875\n",
      "Batch: 97, Loss: 0.4958594739437103, Accuracy: 0.8369140625\n",
      "Batch: 98, Loss: 0.579653263092041, Accuracy: 0.814453125\n",
      "Batch: 99, Loss: 0.5673753023147583, Accuracy: 0.8046875\n",
      "Batch: 100, Loss: 0.5825437307357788, Accuracy: 0.7998046875\n",
      "Batch: 101, Loss: 0.6238189935684204, Accuracy: 0.7939453125\n",
      "Batch: 102, Loss: 0.6489024758338928, Accuracy: 0.78125\n",
      "Batch: 103, Loss: 0.5862418413162231, Accuracy: 0.8203125\n",
      "Batch: 104, Loss: 0.56341153383255, Accuracy: 0.8134765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 105, Loss: 0.578683614730835, Accuracy: 0.8046875\n",
      "Batch: 106, Loss: 0.5281640291213989, Accuracy: 0.826171875\n",
      "Batch: 107, Loss: 0.6075172424316406, Accuracy: 0.8115234375\n",
      "Batch: 108, Loss: 0.6052218079566956, Accuracy: 0.8046875\n",
      "Batch: 109, Loss: 0.6108113527297974, Accuracy: 0.779296875\n",
      "Batch: 110, Loss: 0.5282232165336609, Accuracy: 0.8203125\n",
      "Batch: 111, Loss: 0.6149401664733887, Accuracy: 0.8017578125\n",
      "Batch: 112, Loss: 0.600188136100769, Accuracy: 0.802734375\n",
      "Batch: 113, Loss: 0.5757956504821777, Accuracy: 0.80078125\n",
      "Batch: 114, Loss: 0.6125062108039856, Accuracy: 0.8056640625\n",
      "Batch: 115, Loss: 0.6649339199066162, Accuracy: 0.7939453125\n",
      "Batch: 116, Loss: 0.615750789642334, Accuracy: 0.79296875\n",
      "Batch: 117, Loss: 0.6211837530136108, Accuracy: 0.8017578125\n",
      "Batch: 118, Loss: 0.55256187915802, Accuracy: 0.83203125\n",
      "Batch: 119, Loss: 0.5172868967056274, Accuracy: 0.83984375\n",
      "Batch: 120, Loss: 0.5352605581283569, Accuracy: 0.8076171875\n",
      "Batch: 121, Loss: 0.6735503673553467, Accuracy: 0.779296875\n",
      "Batch: 122, Loss: 0.6028642654418945, Accuracy: 0.806640625\n",
      "Batch: 123, Loss: 0.5367345809936523, Accuracy: 0.828125\n",
      "Batch: 124, Loss: 0.5836024284362793, Accuracy: 0.8134765625\n",
      "Batch: 125, Loss: 0.6079297065734863, Accuracy: 0.8154296875\n",
      "Batch: 126, Loss: 0.5975639820098877, Accuracy: 0.8037109375\n",
      "Batch: 127, Loss: 0.5353289842605591, Accuracy: 0.82421875\n",
      "Batch: 128, Loss: 0.6579113602638245, Accuracy: 0.7919921875\n",
      "Batch: 129, Loss: 0.5819087028503418, Accuracy: 0.8125\n",
      "Batch: 130, Loss: 0.6765180826187134, Accuracy: 0.7802734375\n",
      "Batch: 131, Loss: 0.6228618621826172, Accuracy: 0.779296875\n",
      "Batch: 132, Loss: 0.6031190156936646, Accuracy: 0.8076171875\n",
      "Batch: 133, Loss: 0.6061063408851624, Accuracy: 0.802734375\n",
      "Batch: 134, Loss: 0.6019884347915649, Accuracy: 0.7841796875\n",
      "Batch: 135, Loss: 0.5521485805511475, Accuracy: 0.8173828125\n",
      "Batch: 136, Loss: 0.6275589466094971, Accuracy: 0.8046875\n",
      "Batch: 137, Loss: 0.625385046005249, Accuracy: 0.775390625\n",
      "Batch: 138, Loss: 0.5370994806289673, Accuracy: 0.810546875\n",
      "Batch: 139, Loss: 0.5568910241127014, Accuracy: 0.7998046875\n",
      "Batch: 140, Loss: 0.6209158897399902, Accuracy: 0.80078125\n",
      "Batch: 141, Loss: 0.6551533937454224, Accuracy: 0.7861328125\n",
      "Batch: 142, Loss: 0.6720410585403442, Accuracy: 0.794921875\n",
      "Batch: 143, Loss: 0.5808954238891602, Accuracy: 0.8017578125\n",
      "Batch: 144, Loss: 0.6471045017242432, Accuracy: 0.79296875\n",
      "Batch: 145, Loss: 0.5435753464698792, Accuracy: 0.8115234375\n",
      "Batch: 146, Loss: 0.6114250421524048, Accuracy: 0.7880859375\n",
      "Batch: 147, Loss: 0.556262731552124, Accuracy: 0.8212890625\n",
      "Batch: 148, Loss: 0.629625678062439, Accuracy: 0.794921875\n",
      "Batch: 149, Loss: 0.5750874876976013, Accuracy: 0.80859375\n",
      "Batch: 150, Loss: 0.6168484687805176, Accuracy: 0.7978515625\n",
      "Batch: 151, Loss: 0.5339256525039673, Accuracy: 0.8173828125\n",
      "Epoch 69/80\n",
      "Batch: 1, Loss: 0.7426925897598267, Accuracy: 0.7724609375\n",
      "Batch: 2, Loss: 0.66083163022995, Accuracy: 0.7626953125\n",
      "Batch: 3, Loss: 0.5729060769081116, Accuracy: 0.8115234375\n",
      "Batch: 4, Loss: 0.5394001007080078, Accuracy: 0.8310546875\n",
      "Batch: 5, Loss: 0.574578046798706, Accuracy: 0.8115234375\n",
      "Batch: 6, Loss: 0.5813055038452148, Accuracy: 0.8115234375\n",
      "Batch: 7, Loss: 0.5659473538398743, Accuracy: 0.8193359375\n",
      "Batch: 8, Loss: 0.5747321844100952, Accuracy: 0.814453125\n",
      "Batch: 9, Loss: 0.5730724334716797, Accuracy: 0.8037109375\n",
      "Batch: 10, Loss: 0.5463100671768188, Accuracy: 0.82421875\n",
      "Batch: 11, Loss: 0.6266411542892456, Accuracy: 0.787109375\n",
      "Batch: 12, Loss: 0.5959399342536926, Accuracy: 0.80078125\n",
      "Batch: 13, Loss: 0.5180745720863342, Accuracy: 0.837890625\n",
      "Batch: 14, Loss: 0.5914901494979858, Accuracy: 0.8017578125\n",
      "Batch: 15, Loss: 0.5261340141296387, Accuracy: 0.8203125\n",
      "Batch: 16, Loss: 0.5202447772026062, Accuracy: 0.8369140625\n",
      "Batch: 17, Loss: 0.5923659801483154, Accuracy: 0.80859375\n",
      "Batch: 18, Loss: 0.624199390411377, Accuracy: 0.794921875\n",
      "Batch: 19, Loss: 0.6237553358078003, Accuracy: 0.80859375\n",
      "Batch: 20, Loss: 0.5433984994888306, Accuracy: 0.8212890625\n",
      "Batch: 21, Loss: 0.5596069097518921, Accuracy: 0.814453125\n",
      "Batch: 22, Loss: 0.6250760555267334, Accuracy: 0.796875\n",
      "Batch: 23, Loss: 0.6607444286346436, Accuracy: 0.7802734375\n",
      "Batch: 24, Loss: 0.6289852261543274, Accuracy: 0.791015625\n",
      "Batch: 25, Loss: 0.5552628040313721, Accuracy: 0.8134765625\n",
      "Batch: 26, Loss: 0.47337281703948975, Accuracy: 0.837890625\n",
      "Batch: 27, Loss: 0.5535509586334229, Accuracy: 0.8095703125\n",
      "Batch: 28, Loss: 0.5823814272880554, Accuracy: 0.802734375\n",
      "Batch: 29, Loss: 0.5723515748977661, Accuracy: 0.802734375\n",
      "Batch: 30, Loss: 0.5349840521812439, Accuracy: 0.8291015625\n",
      "Batch: 31, Loss: 0.486457496881485, Accuracy: 0.84375\n",
      "Batch: 32, Loss: 0.535673975944519, Accuracy: 0.826171875\n",
      "Batch: 33, Loss: 0.611538290977478, Accuracy: 0.7919921875\n",
      "Batch: 34, Loss: 0.6499702334403992, Accuracy: 0.7890625\n",
      "Batch: 35, Loss: 0.5951291918754578, Accuracy: 0.8125\n",
      "Batch: 36, Loss: 0.5980566740036011, Accuracy: 0.814453125\n",
      "Batch: 37, Loss: 0.5733281970024109, Accuracy: 0.8046875\n",
      "Batch: 38, Loss: 0.5857430100440979, Accuracy: 0.7900390625\n",
      "Batch: 39, Loss: 0.5915181040763855, Accuracy: 0.7998046875\n",
      "Batch: 40, Loss: 0.5820611119270325, Accuracy: 0.8046875\n",
      "Batch: 41, Loss: 0.5050633549690247, Accuracy: 0.837890625\n",
      "Batch: 42, Loss: 0.44999733567237854, Accuracy: 0.8447265625\n",
      "Batch: 43, Loss: 0.574575662612915, Accuracy: 0.80859375\n",
      "Batch: 44, Loss: 0.5948929786682129, Accuracy: 0.8017578125\n",
      "Batch: 45, Loss: 0.5224200487136841, Accuracy: 0.8291015625\n",
      "Batch: 46, Loss: 0.5678040981292725, Accuracy: 0.8115234375\n",
      "Batch: 47, Loss: 0.6011641621589661, Accuracy: 0.8154296875\n",
      "Batch: 48, Loss: 0.5450925230979919, Accuracy: 0.8291015625\n",
      "Batch: 49, Loss: 0.6027672290802002, Accuracy: 0.7998046875\n",
      "Batch: 50, Loss: 0.5738027095794678, Accuracy: 0.8056640625\n",
      "Batch: 51, Loss: 0.6057473421096802, Accuracy: 0.8017578125\n",
      "Batch: 52, Loss: 0.5835205316543579, Accuracy: 0.81640625\n",
      "Batch: 53, Loss: 0.5078350305557251, Accuracy: 0.841796875\n",
      "Batch: 54, Loss: 0.5422037839889526, Accuracy: 0.8203125\n",
      "Batch: 55, Loss: 0.6413928270339966, Accuracy: 0.783203125\n",
      "Batch: 56, Loss: 0.6464409828186035, Accuracy: 0.7939453125\n",
      "Batch: 57, Loss: 0.6168895959854126, Accuracy: 0.7861328125\n",
      "Batch: 58, Loss: 0.6954246163368225, Accuracy: 0.7734375\n",
      "Batch: 59, Loss: 0.6057825684547424, Accuracy: 0.8203125\n",
      "Batch: 60, Loss: 0.5463392734527588, Accuracy: 0.8232421875\n",
      "Batch: 61, Loss: 0.6239978671073914, Accuracy: 0.791015625\n",
      "Batch: 62, Loss: 0.5749264359474182, Accuracy: 0.82421875\n",
      "Batch: 63, Loss: 0.5887194871902466, Accuracy: 0.8056640625\n",
      "Batch: 64, Loss: 0.5739871263504028, Accuracy: 0.8056640625\n",
      "Batch: 65, Loss: 0.606191098690033, Accuracy: 0.7998046875\n",
      "Batch: 66, Loss: 0.6218010783195496, Accuracy: 0.7998046875\n",
      "Batch: 67, Loss: 0.6532440185546875, Accuracy: 0.7919921875\n",
      "Batch: 68, Loss: 0.6753637790679932, Accuracy: 0.771484375\n",
      "Batch: 69, Loss: 0.6135115623474121, Accuracy: 0.80078125\n",
      "Batch: 70, Loss: 0.6346362829208374, Accuracy: 0.794921875\n",
      "Batch: 71, Loss: 0.62189781665802, Accuracy: 0.7890625\n",
      "Batch: 72, Loss: 0.5292807817459106, Accuracy: 0.8251953125\n",
      "Batch: 73, Loss: 0.5396673679351807, Accuracy: 0.8359375\n",
      "Batch: 74, Loss: 0.5074807405471802, Accuracy: 0.8359375\n",
      "Batch: 75, Loss: 0.5196207761764526, Accuracy: 0.8310546875\n",
      "Batch: 76, Loss: 0.589214563369751, Accuracy: 0.8076171875\n",
      "Batch: 77, Loss: 0.5169386267662048, Accuracy: 0.818359375\n",
      "Batch: 78, Loss: 0.5498298406600952, Accuracy: 0.833984375\n",
      "Batch: 79, Loss: 0.5298685431480408, Accuracy: 0.8408203125\n",
      "Batch: 80, Loss: 0.5302777290344238, Accuracy: 0.82421875\n",
      "Batch: 81, Loss: 0.6051450967788696, Accuracy: 0.796875\n",
      "Batch: 82, Loss: 0.5702570080757141, Accuracy: 0.8232421875\n",
      "Batch: 83, Loss: 0.5323539972305298, Accuracy: 0.837890625\n",
      "Batch: 84, Loss: 0.5814296007156372, Accuracy: 0.8037109375\n",
      "Batch: 85, Loss: 0.5800396203994751, Accuracy: 0.8076171875\n",
      "Batch: 86, Loss: 0.6765894293785095, Accuracy: 0.7900390625\n",
      "Batch: 87, Loss: 0.5783848762512207, Accuracy: 0.8115234375\n",
      "Batch: 88, Loss: 0.5994333624839783, Accuracy: 0.8134765625\n",
      "Batch: 89, Loss: 0.5895894765853882, Accuracy: 0.8076171875\n",
      "Batch: 90, Loss: 0.5950678586959839, Accuracy: 0.796875\n",
      "Batch: 91, Loss: 0.5204609632492065, Accuracy: 0.83203125\n",
      "Batch: 92, Loss: 0.5832397937774658, Accuracy: 0.7998046875\n",
      "Batch: 93, Loss: 0.6000897884368896, Accuracy: 0.798828125\n",
      "Batch: 94, Loss: 0.5964521169662476, Accuracy: 0.7998046875\n",
      "Batch: 95, Loss: 0.5943862795829773, Accuracy: 0.80859375\n",
      "Batch: 96, Loss: 0.5846519470214844, Accuracy: 0.8095703125\n",
      "Batch: 97, Loss: 0.48558148741722107, Accuracy: 0.8447265625\n",
      "Batch: 98, Loss: 0.5635945796966553, Accuracy: 0.810546875\n",
      "Batch: 99, Loss: 0.5738114714622498, Accuracy: 0.810546875\n",
      "Batch: 100, Loss: 0.5888208150863647, Accuracy: 0.8017578125\n",
      "Batch: 101, Loss: 0.6089134216308594, Accuracy: 0.802734375\n",
      "Batch: 102, Loss: 0.6099942922592163, Accuracy: 0.8056640625\n",
      "Batch: 103, Loss: 0.5835198760032654, Accuracy: 0.8056640625\n",
      "Batch: 104, Loss: 0.574905276298523, Accuracy: 0.8203125\n",
      "Batch: 105, Loss: 0.587329626083374, Accuracy: 0.8046875\n",
      "Batch: 106, Loss: 0.5569981336593628, Accuracy: 0.8251953125\n",
      "Batch: 107, Loss: 0.5722562074661255, Accuracy: 0.8134765625\n",
      "Batch: 108, Loss: 0.5775822997093201, Accuracy: 0.7919921875\n",
      "Batch: 109, Loss: 0.6300959587097168, Accuracy: 0.7900390625\n",
      "Batch: 110, Loss: 0.5316999554634094, Accuracy: 0.82421875\n",
      "Batch: 111, Loss: 0.592922568321228, Accuracy: 0.8046875\n",
      "Batch: 112, Loss: 0.6202097535133362, Accuracy: 0.8017578125\n",
      "Batch: 113, Loss: 0.5782464742660522, Accuracy: 0.806640625\n",
      "Batch: 114, Loss: 0.6159152388572693, Accuracy: 0.7861328125\n",
      "Batch: 115, Loss: 0.6563957333564758, Accuracy: 0.7744140625\n",
      "Batch: 116, Loss: 0.6014046669006348, Accuracy: 0.79296875\n",
      "Batch: 117, Loss: 0.6484434604644775, Accuracy: 0.7919921875\n",
      "Batch: 118, Loss: 0.5443331003189087, Accuracy: 0.826171875\n",
      "Batch: 119, Loss: 0.4971569776535034, Accuracy: 0.83984375\n",
      "Batch: 120, Loss: 0.5813460350036621, Accuracy: 0.8037109375\n",
      "Batch: 121, Loss: 0.6373635530471802, Accuracy: 0.7939453125\n",
      "Batch: 122, Loss: 0.6010793447494507, Accuracy: 0.8046875\n",
      "Batch: 123, Loss: 0.5261052846908569, Accuracy: 0.83203125\n",
      "Batch: 124, Loss: 0.5774943828582764, Accuracy: 0.8095703125\n",
      "Batch: 125, Loss: 0.6226909160614014, Accuracy: 0.79296875\n",
      "Batch: 126, Loss: 0.5821367502212524, Accuracy: 0.8154296875\n",
      "Batch: 127, Loss: 0.5356211066246033, Accuracy: 0.8212890625\n",
      "Batch: 128, Loss: 0.6501994132995605, Accuracy: 0.7939453125\n",
      "Batch: 129, Loss: 0.5361992716789246, Accuracy: 0.8203125\n",
      "Batch: 130, Loss: 0.6494604349136353, Accuracy: 0.7744140625\n",
      "Batch: 131, Loss: 0.6355547904968262, Accuracy: 0.79296875\n",
      "Batch: 132, Loss: 0.627439022064209, Accuracy: 0.8046875\n",
      "Batch: 133, Loss: 0.6067527532577515, Accuracy: 0.8017578125\n",
      "Batch: 134, Loss: 0.5862594246864319, Accuracy: 0.806640625\n",
      "Batch: 135, Loss: 0.5349782109260559, Accuracy: 0.8359375\n",
      "Batch: 136, Loss: 0.607168972492218, Accuracy: 0.7919921875\n",
      "Batch: 137, Loss: 0.5799601674079895, Accuracy: 0.8017578125\n",
      "Batch: 138, Loss: 0.5522977709770203, Accuracy: 0.80859375\n",
      "Batch: 139, Loss: 0.5453445315361023, Accuracy: 0.8095703125\n",
      "Batch: 140, Loss: 0.596123456954956, Accuracy: 0.8125\n",
      "Batch: 141, Loss: 0.6465783715248108, Accuracy: 0.783203125\n",
      "Batch: 142, Loss: 0.661510169506073, Accuracy: 0.7890625\n",
      "Batch: 143, Loss: 0.5818793773651123, Accuracy: 0.8134765625\n",
      "Batch: 144, Loss: 0.6157598495483398, Accuracy: 0.8125\n",
      "Batch: 145, Loss: 0.5118722319602966, Accuracy: 0.83203125\n",
      "Batch: 146, Loss: 0.6058166027069092, Accuracy: 0.8154296875\n",
      "Batch: 147, Loss: 0.5742483139038086, Accuracy: 0.80859375\n",
      "Batch: 148, Loss: 0.6408028602600098, Accuracy: 0.7958984375\n",
      "Batch: 149, Loss: 0.5449603199958801, Accuracy: 0.8173828125\n",
      "Batch: 150, Loss: 0.5911720991134644, Accuracy: 0.8046875\n",
      "Batch: 151, Loss: 0.5339613556861877, Accuracy: 0.8212890625\n",
      "Epoch 70/80\n",
      "Batch: 1, Loss: 0.7730723023414612, Accuracy: 0.7685546875\n",
      "Batch: 2, Loss: 0.6436724662780762, Accuracy: 0.77734375\n",
      "Batch: 3, Loss: 0.5886286497116089, Accuracy: 0.7958984375\n",
      "Batch: 4, Loss: 0.5427152514457703, Accuracy: 0.814453125\n",
      "Batch: 5, Loss: 0.5813350677490234, Accuracy: 0.80859375\n",
      "Batch: 6, Loss: 0.6085824966430664, Accuracy: 0.7890625\n",
      "Batch: 7, Loss: 0.5654890537261963, Accuracy: 0.814453125\n",
      "Batch: 8, Loss: 0.562059760093689, Accuracy: 0.822265625\n",
      "Batch: 9, Loss: 0.5761816501617432, Accuracy: 0.8125\n",
      "Batch: 10, Loss: 0.5319415330886841, Accuracy: 0.82421875\n",
      "Batch: 11, Loss: 0.6280637979507446, Accuracy: 0.7919921875\n",
      "Batch: 12, Loss: 0.6192363500595093, Accuracy: 0.80078125\n",
      "Batch: 13, Loss: 0.5182697772979736, Accuracy: 0.841796875\n",
      "Batch: 14, Loss: 0.5959364175796509, Accuracy: 0.7919921875\n",
      "Batch: 15, Loss: 0.5352342128753662, Accuracy: 0.830078125\n",
      "Batch: 16, Loss: 0.5187530517578125, Accuracy: 0.8251953125\n",
      "Batch: 17, Loss: 0.5683859586715698, Accuracy: 0.8173828125\n",
      "Batch: 18, Loss: 0.6173581480979919, Accuracy: 0.791015625\n",
      "Batch: 19, Loss: 0.6042689681053162, Accuracy: 0.8037109375\n",
      "Batch: 20, Loss: 0.549453616142273, Accuracy: 0.818359375\n",
      "Batch: 21, Loss: 0.5503556132316589, Accuracy: 0.8173828125\n",
      "Batch: 22, Loss: 0.6514109969139099, Accuracy: 0.787109375\n",
      "Batch: 23, Loss: 0.5907537937164307, Accuracy: 0.8076171875\n",
      "Batch: 24, Loss: 0.5979080200195312, Accuracy: 0.814453125\n",
      "Batch: 25, Loss: 0.5301693677902222, Accuracy: 0.8212890625\n",
      "Batch: 26, Loss: 0.484026163816452, Accuracy: 0.845703125\n",
      "Batch: 27, Loss: 0.5399584174156189, Accuracy: 0.8115234375\n",
      "Batch: 28, Loss: 0.5918704271316528, Accuracy: 0.7939453125\n",
      "Batch: 29, Loss: 0.5370839834213257, Accuracy: 0.8271484375\n",
      "Batch: 30, Loss: 0.543417751789093, Accuracy: 0.8349609375\n",
      "Batch: 31, Loss: 0.4773246645927429, Accuracy: 0.84765625\n",
      "Batch: 32, Loss: 0.5375174283981323, Accuracy: 0.8359375\n",
      "Batch: 33, Loss: 0.6062092781066895, Accuracy: 0.8046875\n",
      "Batch: 34, Loss: 0.6377734541893005, Accuracy: 0.7900390625\n",
      "Batch: 35, Loss: 0.5870078802108765, Accuracy: 0.796875\n",
      "Batch: 36, Loss: 0.5768282413482666, Accuracy: 0.8056640625\n",
      "Batch: 37, Loss: 0.6418348550796509, Accuracy: 0.7822265625\n",
      "Batch: 38, Loss: 0.6252016425132751, Accuracy: 0.7841796875\n",
      "Batch: 39, Loss: 0.6157804131507874, Accuracy: 0.8076171875\n",
      "Batch: 40, Loss: 0.5481358170509338, Accuracy: 0.828125\n",
      "Batch: 41, Loss: 0.5374346375465393, Accuracy: 0.8212890625\n",
      "Batch: 42, Loss: 0.4415452182292938, Accuracy: 0.8544921875\n",
      "Batch: 43, Loss: 0.5440332293510437, Accuracy: 0.8212890625\n",
      "Batch: 44, Loss: 0.606813371181488, Accuracy: 0.80078125\n",
      "Batch: 45, Loss: 0.5227413177490234, Accuracy: 0.8212890625\n",
      "Batch: 46, Loss: 0.5168274641036987, Accuracy: 0.8251953125\n",
      "Batch: 47, Loss: 0.601527988910675, Accuracy: 0.828125\n",
      "Batch: 48, Loss: 0.5552683472633362, Accuracy: 0.8173828125\n",
      "Batch: 49, Loss: 0.6077726483345032, Accuracy: 0.80859375\n",
      "Batch: 50, Loss: 0.5435534715652466, Accuracy: 0.8193359375\n",
      "Batch: 51, Loss: 0.607261598110199, Accuracy: 0.7958984375\n",
      "Batch: 52, Loss: 0.5588631629943848, Accuracy: 0.8173828125\n",
      "Batch: 53, Loss: 0.4988277554512024, Accuracy: 0.8291015625\n",
      "Batch: 54, Loss: 0.540303111076355, Accuracy: 0.828125\n",
      "Batch: 55, Loss: 0.6393563747406006, Accuracy: 0.7841796875\n",
      "Batch: 56, Loss: 0.6335804462432861, Accuracy: 0.7958984375\n",
      "Batch: 57, Loss: 0.6202672719955444, Accuracy: 0.791015625\n",
      "Batch: 58, Loss: 0.6677568554878235, Accuracy: 0.7822265625\n",
      "Batch: 59, Loss: 0.5855861902236938, Accuracy: 0.8115234375\n",
      "Batch: 60, Loss: 0.5269449949264526, Accuracy: 0.8115234375\n",
      "Batch: 61, Loss: 0.6013782620429993, Accuracy: 0.8037109375\n",
      "Batch: 62, Loss: 0.5418614149093628, Accuracy: 0.8251953125\n",
      "Batch: 63, Loss: 0.6189225912094116, Accuracy: 0.8037109375\n",
      "Batch: 64, Loss: 0.5498169660568237, Accuracy: 0.8232421875\n",
      "Batch: 65, Loss: 0.6108294129371643, Accuracy: 0.8212890625\n",
      "Batch: 66, Loss: 0.6000547409057617, Accuracy: 0.80859375\n",
      "Batch: 67, Loss: 0.6539936065673828, Accuracy: 0.7978515625\n",
      "Batch: 68, Loss: 0.6502146124839783, Accuracy: 0.7900390625\n",
      "Batch: 69, Loss: 0.6211313009262085, Accuracy: 0.7958984375\n",
      "Batch: 70, Loss: 0.5958951115608215, Accuracy: 0.8203125\n",
      "Batch: 71, Loss: 0.6265764832496643, Accuracy: 0.791015625\n",
      "Batch: 72, Loss: 0.5982602834701538, Accuracy: 0.81640625\n",
      "Batch: 73, Loss: 0.5437605381011963, Accuracy: 0.8310546875\n",
      "Batch: 74, Loss: 0.50484699010849, Accuracy: 0.833984375\n",
      "Batch: 75, Loss: 0.49685364961624146, Accuracy: 0.8447265625\n",
      "Batch: 76, Loss: 0.6097065210342407, Accuracy: 0.80078125\n",
      "Batch: 77, Loss: 0.5151935815811157, Accuracy: 0.8388671875\n",
      "Batch: 78, Loss: 0.5413339138031006, Accuracy: 0.822265625\n",
      "Batch: 79, Loss: 0.5892022848129272, Accuracy: 0.818359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 80, Loss: 0.5472947359085083, Accuracy: 0.826171875\n",
      "Batch: 81, Loss: 0.5645190477371216, Accuracy: 0.80078125\n",
      "Batch: 82, Loss: 0.5636897683143616, Accuracy: 0.8154296875\n",
      "Batch: 83, Loss: 0.5029519200325012, Accuracy: 0.8427734375\n",
      "Batch: 84, Loss: 0.5676159262657166, Accuracy: 0.8125\n",
      "Batch: 85, Loss: 0.5801849961280823, Accuracy: 0.814453125\n",
      "Batch: 86, Loss: 0.6292984485626221, Accuracy: 0.7978515625\n",
      "Batch: 87, Loss: 0.5869709253311157, Accuracy: 0.81640625\n",
      "Batch: 88, Loss: 0.5861618518829346, Accuracy: 0.8046875\n",
      "Batch: 89, Loss: 0.5633029937744141, Accuracy: 0.8115234375\n",
      "Batch: 90, Loss: 0.5626322031021118, Accuracy: 0.8046875\n",
      "Batch: 91, Loss: 0.546522855758667, Accuracy: 0.8115234375\n",
      "Batch: 92, Loss: 0.596524178981781, Accuracy: 0.8056640625\n",
      "Batch: 93, Loss: 0.619855523109436, Accuracy: 0.79296875\n",
      "Batch: 94, Loss: 0.6031292676925659, Accuracy: 0.79296875\n",
      "Batch: 95, Loss: 0.5758056640625, Accuracy: 0.8056640625\n",
      "Batch: 96, Loss: 0.5948944091796875, Accuracy: 0.806640625\n",
      "Batch: 97, Loss: 0.496012806892395, Accuracy: 0.8427734375\n",
      "Batch: 98, Loss: 0.5748898983001709, Accuracy: 0.8046875\n",
      "Batch: 99, Loss: 0.5657361745834351, Accuracy: 0.8115234375\n",
      "Batch: 100, Loss: 0.5883979797363281, Accuracy: 0.78515625\n",
      "Batch: 101, Loss: 0.6267731189727783, Accuracy: 0.7880859375\n",
      "Batch: 102, Loss: 0.5862748026847839, Accuracy: 0.8115234375\n",
      "Batch: 103, Loss: 0.5724242329597473, Accuracy: 0.8046875\n",
      "Batch: 104, Loss: 0.575225830078125, Accuracy: 0.8212890625\n",
      "Batch: 105, Loss: 0.5713016986846924, Accuracy: 0.8017578125\n",
      "Batch: 106, Loss: 0.5280831456184387, Accuracy: 0.822265625\n",
      "Batch: 107, Loss: 0.5988286733627319, Accuracy: 0.8056640625\n",
      "Batch: 108, Loss: 0.5731052160263062, Accuracy: 0.8046875\n",
      "Batch: 109, Loss: 0.6074573993682861, Accuracy: 0.796875\n",
      "Batch: 110, Loss: 0.5611962080001831, Accuracy: 0.8095703125\n",
      "Batch: 111, Loss: 0.590021550655365, Accuracy: 0.8037109375\n",
      "Batch: 112, Loss: 0.5760585069656372, Accuracy: 0.80859375\n",
      "Batch: 113, Loss: 0.5802955627441406, Accuracy: 0.806640625\n",
      "Batch: 114, Loss: 0.6213577389717102, Accuracy: 0.7890625\n",
      "Batch: 115, Loss: 0.6180465817451477, Accuracy: 0.798828125\n",
      "Batch: 116, Loss: 0.5629017353057861, Accuracy: 0.814453125\n",
      "Batch: 117, Loss: 0.6084492206573486, Accuracy: 0.794921875\n",
      "Batch: 118, Loss: 0.5312049388885498, Accuracy: 0.8251953125\n",
      "Batch: 119, Loss: 0.5076006650924683, Accuracy: 0.8408203125\n",
      "Batch: 120, Loss: 0.5450130701065063, Accuracy: 0.8134765625\n",
      "Batch: 121, Loss: 0.6247813701629639, Accuracy: 0.80078125\n",
      "Batch: 122, Loss: 0.5811959505081177, Accuracy: 0.8173828125\n",
      "Batch: 123, Loss: 0.5482312440872192, Accuracy: 0.8271484375\n",
      "Batch: 124, Loss: 0.6119024157524109, Accuracy: 0.8046875\n",
      "Batch: 125, Loss: 0.6097829341888428, Accuracy: 0.8017578125\n",
      "Batch: 126, Loss: 0.6007906198501587, Accuracy: 0.80078125\n",
      "Batch: 127, Loss: 0.5550172924995422, Accuracy: 0.8173828125\n",
      "Batch: 128, Loss: 0.6567225456237793, Accuracy: 0.8056640625\n",
      "Batch: 129, Loss: 0.5504682064056396, Accuracy: 0.8154296875\n",
      "Batch: 130, Loss: 0.6568806171417236, Accuracy: 0.78515625\n",
      "Batch: 131, Loss: 0.6173201203346252, Accuracy: 0.7939453125\n",
      "Batch: 132, Loss: 0.6256898641586304, Accuracy: 0.802734375\n",
      "Batch: 133, Loss: 0.5825976133346558, Accuracy: 0.8095703125\n",
      "Batch: 134, Loss: 0.588263750076294, Accuracy: 0.7978515625\n",
      "Batch: 135, Loss: 0.5488916635513306, Accuracy: 0.82421875\n",
      "Batch: 136, Loss: 0.6089193224906921, Accuracy: 0.806640625\n",
      "Batch: 137, Loss: 0.5979611873626709, Accuracy: 0.791015625\n",
      "Batch: 138, Loss: 0.5443501472473145, Accuracy: 0.8076171875\n",
      "Batch: 139, Loss: 0.5203945636749268, Accuracy: 0.8271484375\n",
      "Batch: 140, Loss: 0.5553997755050659, Accuracy: 0.8251953125\n",
      "Batch: 141, Loss: 0.6114346981048584, Accuracy: 0.79296875\n",
      "Batch: 142, Loss: 0.6886348724365234, Accuracy: 0.771484375\n",
      "Batch: 143, Loss: 0.5739139914512634, Accuracy: 0.8046875\n",
      "Batch: 144, Loss: 0.5817036628723145, Accuracy: 0.8134765625\n",
      "Batch: 145, Loss: 0.5368694067001343, Accuracy: 0.8212890625\n",
      "Batch: 146, Loss: 0.6196531057357788, Accuracy: 0.791015625\n",
      "Batch: 147, Loss: 0.5724499225616455, Accuracy: 0.8134765625\n",
      "Batch: 148, Loss: 0.6181389689445496, Accuracy: 0.8037109375\n",
      "Batch: 149, Loss: 0.5594610571861267, Accuracy: 0.8203125\n",
      "Batch: 150, Loss: 0.5995980501174927, Accuracy: 0.8076171875\n",
      "Batch: 151, Loss: 0.5456719398498535, Accuracy: 0.8251953125\n",
      "Saved Weights at epoch 70 to file Weights_70.h5\n",
      "Epoch 71/80\n",
      "Batch: 1, Loss: 0.7524664402008057, Accuracy: 0.771484375\n",
      "Batch: 2, Loss: 0.6515146493911743, Accuracy: 0.7734375\n",
      "Batch: 3, Loss: 0.5623933672904968, Accuracy: 0.8046875\n",
      "Batch: 4, Loss: 0.5490463972091675, Accuracy: 0.82421875\n",
      "Batch: 5, Loss: 0.5881665945053101, Accuracy: 0.794921875\n",
      "Batch: 6, Loss: 0.5995237827301025, Accuracy: 0.806640625\n",
      "Batch: 7, Loss: 0.560941219329834, Accuracy: 0.8037109375\n",
      "Batch: 8, Loss: 0.5517190098762512, Accuracy: 0.8095703125\n",
      "Batch: 9, Loss: 0.5471009016036987, Accuracy: 0.814453125\n",
      "Batch: 10, Loss: 0.5427326560020447, Accuracy: 0.8310546875\n",
      "Batch: 11, Loss: 0.6052937507629395, Accuracy: 0.7939453125\n",
      "Batch: 12, Loss: 0.5900336503982544, Accuracy: 0.810546875\n",
      "Batch: 13, Loss: 0.4825146496295929, Accuracy: 0.8369140625\n",
      "Batch: 14, Loss: 0.6031410694122314, Accuracy: 0.7939453125\n",
      "Batch: 15, Loss: 0.5560249090194702, Accuracy: 0.8173828125\n",
      "Batch: 16, Loss: 0.559307336807251, Accuracy: 0.83203125\n",
      "Batch: 17, Loss: 0.5902825593948364, Accuracy: 0.8154296875\n",
      "Batch: 18, Loss: 0.6118099689483643, Accuracy: 0.7939453125\n",
      "Batch: 19, Loss: 0.5781286358833313, Accuracy: 0.810546875\n",
      "Batch: 20, Loss: 0.5275225639343262, Accuracy: 0.8291015625\n",
      "Batch: 21, Loss: 0.5352472066879272, Accuracy: 0.8212890625\n",
      "Batch: 22, Loss: 0.6326647996902466, Accuracy: 0.787109375\n",
      "Batch: 23, Loss: 0.6412005424499512, Accuracy: 0.779296875\n",
      "Batch: 24, Loss: 0.6266223788261414, Accuracy: 0.80078125\n",
      "Batch: 25, Loss: 0.5675250291824341, Accuracy: 0.8095703125\n",
      "Batch: 26, Loss: 0.4651259779930115, Accuracy: 0.8544921875\n",
      "Batch: 27, Loss: 0.5433753728866577, Accuracy: 0.814453125\n",
      "Batch: 28, Loss: 0.5440456867218018, Accuracy: 0.814453125\n",
      "Batch: 29, Loss: 0.556622326374054, Accuracy: 0.8310546875\n",
      "Batch: 30, Loss: 0.5304431915283203, Accuracy: 0.8271484375\n",
      "Batch: 31, Loss: 0.48809415102005005, Accuracy: 0.8408203125\n",
      "Batch: 32, Loss: 0.5536503195762634, Accuracy: 0.82421875\n",
      "Batch: 33, Loss: 0.6113339066505432, Accuracy: 0.7919921875\n",
      "Batch: 34, Loss: 0.6335031390190125, Accuracy: 0.787109375\n",
      "Batch: 35, Loss: 0.5940564870834351, Accuracy: 0.8115234375\n",
      "Batch: 36, Loss: 0.5905904173851013, Accuracy: 0.81640625\n",
      "Batch: 37, Loss: 0.5999566316604614, Accuracy: 0.796875\n",
      "Batch: 38, Loss: 0.6105164885520935, Accuracy: 0.7998046875\n",
      "Batch: 39, Loss: 0.5895015001296997, Accuracy: 0.822265625\n",
      "Batch: 40, Loss: 0.5549670457839966, Accuracy: 0.802734375\n",
      "Batch: 41, Loss: 0.5623127818107605, Accuracy: 0.8173828125\n",
      "Batch: 42, Loss: 0.4683578312397003, Accuracy: 0.833984375\n",
      "Batch: 43, Loss: 0.548263669013977, Accuracy: 0.82421875\n",
      "Batch: 44, Loss: 0.5924015045166016, Accuracy: 0.8046875\n",
      "Batch: 45, Loss: 0.5193192958831787, Accuracy: 0.83984375\n",
      "Batch: 46, Loss: 0.5273182988166809, Accuracy: 0.830078125\n",
      "Batch: 47, Loss: 0.6020451188087463, Accuracy: 0.814453125\n",
      "Batch: 48, Loss: 0.5403948426246643, Accuracy: 0.81640625\n",
      "Batch: 49, Loss: 0.5650472640991211, Accuracy: 0.8173828125\n",
      "Batch: 50, Loss: 0.5274850130081177, Accuracy: 0.8359375\n",
      "Batch: 51, Loss: 0.5656077265739441, Accuracy: 0.81640625\n",
      "Batch: 52, Loss: 0.5757170915603638, Accuracy: 0.8154296875\n",
      "Batch: 53, Loss: 0.5274178385734558, Accuracy: 0.8232421875\n",
      "Batch: 54, Loss: 0.5559918284416199, Accuracy: 0.828125\n",
      "Batch: 55, Loss: 0.6178622841835022, Accuracy: 0.7861328125\n",
      "Batch: 56, Loss: 0.6154295206069946, Accuracy: 0.8046875\n",
      "Batch: 57, Loss: 0.6102290153503418, Accuracy: 0.7919921875\n",
      "Batch: 58, Loss: 0.6658776998519897, Accuracy: 0.7958984375\n",
      "Batch: 59, Loss: 0.5787317752838135, Accuracy: 0.8125\n",
      "Batch: 60, Loss: 0.5161025524139404, Accuracy: 0.833984375\n",
      "Batch: 61, Loss: 0.631991982460022, Accuracy: 0.7919921875\n",
      "Batch: 62, Loss: 0.5281365513801575, Accuracy: 0.8232421875\n",
      "Batch: 63, Loss: 0.5978057980537415, Accuracy: 0.8017578125\n",
      "Batch: 64, Loss: 0.5549678206443787, Accuracy: 0.8154296875\n",
      "Batch: 65, Loss: 0.6048987507820129, Accuracy: 0.8046875\n",
      "Batch: 66, Loss: 0.6160656213760376, Accuracy: 0.8056640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 67, Loss: 0.638072669506073, Accuracy: 0.8095703125\n",
      "Batch: 68, Loss: 0.6331630945205688, Accuracy: 0.7890625\n",
      "Batch: 69, Loss: 0.6074328422546387, Accuracy: 0.79296875\n",
      "Batch: 70, Loss: 0.6136749982833862, Accuracy: 0.8193359375\n",
      "Batch: 71, Loss: 0.618114709854126, Accuracy: 0.796875\n",
      "Batch: 72, Loss: 0.5385257601737976, Accuracy: 0.830078125\n",
      "Batch: 73, Loss: 0.5387074947357178, Accuracy: 0.8388671875\n",
      "Batch: 74, Loss: 0.5303794145584106, Accuracy: 0.837890625\n",
      "Batch: 75, Loss: 0.47956383228302, Accuracy: 0.8447265625\n",
      "Batch: 76, Loss: 0.5938299894332886, Accuracy: 0.810546875\n",
      "Batch: 77, Loss: 0.5058023929595947, Accuracy: 0.8330078125\n",
      "Batch: 78, Loss: 0.5169954895973206, Accuracy: 0.8232421875\n",
      "Batch: 79, Loss: 0.5301290154457092, Accuracy: 0.8447265625\n",
      "Batch: 80, Loss: 0.5408788919448853, Accuracy: 0.81640625\n",
      "Batch: 81, Loss: 0.592151939868927, Accuracy: 0.802734375\n",
      "Batch: 82, Loss: 0.5795550346374512, Accuracy: 0.8076171875\n",
      "Batch: 83, Loss: 0.5138028264045715, Accuracy: 0.83203125\n",
      "Batch: 84, Loss: 0.5893620252609253, Accuracy: 0.826171875\n",
      "Batch: 85, Loss: 0.5483521223068237, Accuracy: 0.8173828125\n",
      "Batch: 86, Loss: 0.6263375878334045, Accuracy: 0.794921875\n",
      "Batch: 87, Loss: 0.5420091152191162, Accuracy: 0.826171875\n",
      "Batch: 88, Loss: 0.5888155102729797, Accuracy: 0.8212890625\n",
      "Batch: 89, Loss: 0.5421316623687744, Accuracy: 0.826171875\n",
      "Batch: 90, Loss: 0.565951943397522, Accuracy: 0.8115234375\n",
      "Batch: 91, Loss: 0.5359241962432861, Accuracy: 0.818359375\n",
      "Batch: 92, Loss: 0.6338701248168945, Accuracy: 0.7802734375\n",
      "Batch: 93, Loss: 0.6091823577880859, Accuracy: 0.8017578125\n",
      "Batch: 94, Loss: 0.6272891759872437, Accuracy: 0.7880859375\n",
      "Batch: 95, Loss: 0.5691261291503906, Accuracy: 0.810546875\n",
      "Batch: 96, Loss: 0.5929244756698608, Accuracy: 0.7998046875\n",
      "Batch: 97, Loss: 0.4649421274662018, Accuracy: 0.8505859375\n",
      "Batch: 98, Loss: 0.5847945213317871, Accuracy: 0.8134765625\n",
      "Batch: 99, Loss: 0.5525238513946533, Accuracy: 0.810546875\n",
      "Batch: 100, Loss: 0.5854246616363525, Accuracy: 0.796875\n",
      "Batch: 101, Loss: 0.6310546398162842, Accuracy: 0.7822265625\n",
      "Batch: 102, Loss: 0.5900479555130005, Accuracy: 0.8115234375\n",
      "Batch: 103, Loss: 0.636856734752655, Accuracy: 0.8017578125\n",
      "Batch: 104, Loss: 0.5418275594711304, Accuracy: 0.8271484375\n",
      "Batch: 105, Loss: 0.5707210302352905, Accuracy: 0.8095703125\n",
      "Batch: 106, Loss: 0.5120474100112915, Accuracy: 0.83203125\n",
      "Batch: 107, Loss: 0.5913437008857727, Accuracy: 0.802734375\n",
      "Batch: 108, Loss: 0.5680788159370422, Accuracy: 0.8193359375\n",
      "Batch: 109, Loss: 0.5986015796661377, Accuracy: 0.7900390625\n",
      "Batch: 110, Loss: 0.5330827236175537, Accuracy: 0.8291015625\n",
      "Batch: 111, Loss: 0.5562499761581421, Accuracy: 0.8115234375\n",
      "Batch: 112, Loss: 0.5520561933517456, Accuracy: 0.806640625\n",
      "Batch: 113, Loss: 0.5634904503822327, Accuracy: 0.8154296875\n",
      "Batch: 114, Loss: 0.596406102180481, Accuracy: 0.8095703125\n",
      "Batch: 115, Loss: 0.6700326800346375, Accuracy: 0.7783203125\n",
      "Batch: 116, Loss: 0.6029679775238037, Accuracy: 0.7939453125\n",
      "Batch: 117, Loss: 0.5885881185531616, Accuracy: 0.81640625\n",
      "Batch: 118, Loss: 0.5602712631225586, Accuracy: 0.806640625\n",
      "Batch: 119, Loss: 0.5134148597717285, Accuracy: 0.8330078125\n",
      "Batch: 120, Loss: 0.5564630031585693, Accuracy: 0.8115234375\n",
      "Batch: 121, Loss: 0.6376087665557861, Accuracy: 0.7978515625\n",
      "Batch: 122, Loss: 0.5528424978256226, Accuracy: 0.8271484375\n",
      "Batch: 123, Loss: 0.525004506111145, Accuracy: 0.826171875\n",
      "Batch: 124, Loss: 0.5925942063331604, Accuracy: 0.8154296875\n",
      "Batch: 125, Loss: 0.6076902151107788, Accuracy: 0.791015625\n",
      "Batch: 126, Loss: 0.6013302206993103, Accuracy: 0.806640625\n",
      "Batch: 127, Loss: 0.49857282638549805, Accuracy: 0.8447265625\n",
      "Batch: 128, Loss: 0.6447683572769165, Accuracy: 0.796875\n",
      "Batch: 129, Loss: 0.4854776859283447, Accuracy: 0.837890625\n",
      "Batch: 130, Loss: 0.6603176593780518, Accuracy: 0.7998046875\n",
      "Batch: 131, Loss: 0.6069124937057495, Accuracy: 0.8056640625\n",
      "Batch: 132, Loss: 0.6082233190536499, Accuracy: 0.7939453125\n",
      "Batch: 133, Loss: 0.5534954071044922, Accuracy: 0.8193359375\n",
      "Batch: 134, Loss: 0.5627345442771912, Accuracy: 0.81640625\n",
      "Batch: 135, Loss: 0.5374794006347656, Accuracy: 0.830078125\n",
      "Batch: 136, Loss: 0.5945330858230591, Accuracy: 0.8115234375\n",
      "Batch: 137, Loss: 0.5941001176834106, Accuracy: 0.791015625\n",
      "Batch: 138, Loss: 0.5190523266792297, Accuracy: 0.8330078125\n",
      "Batch: 139, Loss: 0.5527623891830444, Accuracy: 0.822265625\n",
      "Batch: 140, Loss: 0.5712227821350098, Accuracy: 0.806640625\n",
      "Batch: 141, Loss: 0.6135473251342773, Accuracy: 0.7998046875\n",
      "Batch: 142, Loss: 0.6526091694831848, Accuracy: 0.7978515625\n",
      "Batch: 143, Loss: 0.5490686893463135, Accuracy: 0.822265625\n",
      "Batch: 144, Loss: 0.5959337949752808, Accuracy: 0.810546875\n",
      "Batch: 145, Loss: 0.5457254648208618, Accuracy: 0.8056640625\n",
      "Batch: 146, Loss: 0.595073938369751, Accuracy: 0.8095703125\n",
      "Batch: 147, Loss: 0.5262194275856018, Accuracy: 0.828125\n",
      "Batch: 148, Loss: 0.6199967265129089, Accuracy: 0.794921875\n",
      "Batch: 149, Loss: 0.5318425297737122, Accuracy: 0.8212890625\n",
      "Batch: 150, Loss: 0.6058333516120911, Accuracy: 0.8125\n",
      "Batch: 151, Loss: 0.5597134232521057, Accuracy: 0.828125\n",
      "Epoch 72/80\n",
      "Batch: 1, Loss: 0.7530989646911621, Accuracy: 0.7578125\n",
      "Batch: 2, Loss: 0.6417748928070068, Accuracy: 0.7783203125\n",
      "Batch: 3, Loss: 0.5440640449523926, Accuracy: 0.8134765625\n",
      "Batch: 4, Loss: 0.5533169507980347, Accuracy: 0.8291015625\n",
      "Batch: 5, Loss: 0.5607811808586121, Accuracy: 0.8115234375\n",
      "Batch: 6, Loss: 0.5707632303237915, Accuracy: 0.8134765625\n",
      "Batch: 7, Loss: 0.568610668182373, Accuracy: 0.810546875\n",
      "Batch: 8, Loss: 0.5383231043815613, Accuracy: 0.8193359375\n",
      "Batch: 9, Loss: 0.5778882503509521, Accuracy: 0.814453125\n",
      "Batch: 10, Loss: 0.5464251041412354, Accuracy: 0.8125\n",
      "Batch: 11, Loss: 0.618278980255127, Accuracy: 0.7763671875\n",
      "Batch: 12, Loss: 0.5673160552978516, Accuracy: 0.818359375\n",
      "Batch: 13, Loss: 0.48165494203567505, Accuracy: 0.83984375\n",
      "Batch: 14, Loss: 0.5897340178489685, Accuracy: 0.791015625\n",
      "Batch: 15, Loss: 0.489568829536438, Accuracy: 0.849609375\n",
      "Batch: 16, Loss: 0.5375779271125793, Accuracy: 0.822265625\n",
      "Batch: 17, Loss: 0.5808293223381042, Accuracy: 0.80859375\n",
      "Batch: 18, Loss: 0.5938944816589355, Accuracy: 0.8056640625\n",
      "Batch: 19, Loss: 0.5727907419204712, Accuracy: 0.8173828125\n",
      "Batch: 20, Loss: 0.5239987373352051, Accuracy: 0.8388671875\n",
      "Batch: 21, Loss: 0.510780930519104, Accuracy: 0.83984375\n",
      "Batch: 22, Loss: 0.6676722764968872, Accuracy: 0.779296875\n",
      "Batch: 23, Loss: 0.6170564889907837, Accuracy: 0.783203125\n",
      "Batch: 24, Loss: 0.5928513407707214, Accuracy: 0.8076171875\n",
      "Batch: 25, Loss: 0.5519196391105652, Accuracy: 0.8203125\n",
      "Batch: 26, Loss: 0.47834455966949463, Accuracy: 0.8427734375\n",
      "Batch: 27, Loss: 0.5435072183609009, Accuracy: 0.8232421875\n",
      "Batch: 28, Loss: 0.5530592203140259, Accuracy: 0.8125\n",
      "Batch: 29, Loss: 0.5567508935928345, Accuracy: 0.8173828125\n",
      "Batch: 30, Loss: 0.5116218328475952, Accuracy: 0.8447265625\n",
      "Batch: 31, Loss: 0.5090300440788269, Accuracy: 0.8271484375\n",
      "Batch: 32, Loss: 0.508521318435669, Accuracy: 0.841796875\n",
      "Batch: 33, Loss: 0.5756137371063232, Accuracy: 0.8095703125\n",
      "Batch: 34, Loss: 0.6100574731826782, Accuracy: 0.8037109375\n",
      "Batch: 35, Loss: 0.5570332407951355, Accuracy: 0.81640625\n",
      "Batch: 36, Loss: 0.5815862417221069, Accuracy: 0.8125\n",
      "Batch: 37, Loss: 0.6084606051445007, Accuracy: 0.8017578125\n",
      "Batch: 38, Loss: 0.6202934384346008, Accuracy: 0.7900390625\n",
      "Batch: 39, Loss: 0.5798296928405762, Accuracy: 0.8037109375\n",
      "Batch: 40, Loss: 0.569553792476654, Accuracy: 0.8046875\n",
      "Batch: 41, Loss: 0.5153036117553711, Accuracy: 0.818359375\n",
      "Batch: 42, Loss: 0.456872820854187, Accuracy: 0.8408203125\n",
      "Batch: 43, Loss: 0.5485526919364929, Accuracy: 0.8193359375\n",
      "Batch: 44, Loss: 0.5856773257255554, Accuracy: 0.8125\n",
      "Batch: 45, Loss: 0.4908503592014313, Accuracy: 0.845703125\n",
      "Batch: 46, Loss: 0.5166816115379333, Accuracy: 0.8359375\n",
      "Batch: 47, Loss: 0.5969264507293701, Accuracy: 0.814453125\n",
      "Batch: 48, Loss: 0.5586527585983276, Accuracy: 0.8173828125\n",
      "Batch: 49, Loss: 0.6000809073448181, Accuracy: 0.8115234375\n",
      "Batch: 50, Loss: 0.5877416729927063, Accuracy: 0.810546875\n",
      "Batch: 51, Loss: 0.5678660869598389, Accuracy: 0.81640625\n",
      "Batch: 52, Loss: 0.5254238843917847, Accuracy: 0.8271484375\n",
      "Batch: 53, Loss: 0.5176587104797363, Accuracy: 0.828125\n",
      "Batch: 54, Loss: 0.5483640432357788, Accuracy: 0.822265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 55, Loss: 0.5996512174606323, Accuracy: 0.7978515625\n",
      "Batch: 56, Loss: 0.6109433770179749, Accuracy: 0.7958984375\n",
      "Batch: 57, Loss: 0.589690089225769, Accuracy: 0.8046875\n",
      "Batch: 58, Loss: 0.6673581600189209, Accuracy: 0.78125\n",
      "Batch: 59, Loss: 0.6134074330329895, Accuracy: 0.8076171875\n",
      "Batch: 60, Loss: 0.5424736142158508, Accuracy: 0.8212890625\n",
      "Batch: 61, Loss: 0.5836970806121826, Accuracy: 0.802734375\n",
      "Batch: 62, Loss: 0.5177707672119141, Accuracy: 0.833984375\n",
      "Batch: 63, Loss: 0.5809754133224487, Accuracy: 0.8017578125\n",
      "Batch: 64, Loss: 0.5729049444198608, Accuracy: 0.8017578125\n",
      "Batch: 65, Loss: 0.5862736701965332, Accuracy: 0.806640625\n",
      "Batch: 66, Loss: 0.6073147058486938, Accuracy: 0.791015625\n",
      "Batch: 67, Loss: 0.6193132996559143, Accuracy: 0.7978515625\n",
      "Batch: 68, Loss: 0.6068921089172363, Accuracy: 0.80859375\n",
      "Batch: 69, Loss: 0.6125668287277222, Accuracy: 0.798828125\n",
      "Batch: 70, Loss: 0.6112182140350342, Accuracy: 0.8115234375\n",
      "Batch: 71, Loss: 0.6075190305709839, Accuracy: 0.8115234375\n",
      "Batch: 72, Loss: 0.5662420988082886, Accuracy: 0.8095703125\n",
      "Batch: 73, Loss: 0.5481071472167969, Accuracy: 0.8251953125\n",
      "Batch: 74, Loss: 0.5064573287963867, Accuracy: 0.8427734375\n",
      "Batch: 75, Loss: 0.47510114312171936, Accuracy: 0.8359375\n",
      "Batch: 76, Loss: 0.5852028727531433, Accuracy: 0.8125\n",
      "Batch: 77, Loss: 0.5258157253265381, Accuracy: 0.82421875\n",
      "Batch: 78, Loss: 0.5295389890670776, Accuracy: 0.8388671875\n",
      "Batch: 79, Loss: 0.547149658203125, Accuracy: 0.841796875\n",
      "Batch: 80, Loss: 0.5179448127746582, Accuracy: 0.8427734375\n",
      "Batch: 81, Loss: 0.5977569818496704, Accuracy: 0.7978515625\n",
      "Batch: 82, Loss: 0.5923693180084229, Accuracy: 0.7978515625\n",
      "Batch: 83, Loss: 0.4903114438056946, Accuracy: 0.85546875\n",
      "Batch: 84, Loss: 0.5459523797035217, Accuracy: 0.8212890625\n",
      "Batch: 85, Loss: 0.555976152420044, Accuracy: 0.814453125\n",
      "Batch: 86, Loss: 0.6580193042755127, Accuracy: 0.7958984375\n",
      "Batch: 87, Loss: 0.5472605228424072, Accuracy: 0.81640625\n",
      "Batch: 88, Loss: 0.5940582752227783, Accuracy: 0.8037109375\n",
      "Batch: 89, Loss: 0.560649037361145, Accuracy: 0.8125\n",
      "Batch: 90, Loss: 0.5392822027206421, Accuracy: 0.8251953125\n",
      "Batch: 91, Loss: 0.5315757989883423, Accuracy: 0.814453125\n",
      "Batch: 92, Loss: 0.6163477897644043, Accuracy: 0.8076171875\n",
      "Batch: 93, Loss: 0.5918989181518555, Accuracy: 0.7958984375\n",
      "Batch: 94, Loss: 0.5678252577781677, Accuracy: 0.7978515625\n",
      "Batch: 95, Loss: 0.5391501188278198, Accuracy: 0.8251953125\n",
      "Batch: 96, Loss: 0.5787479877471924, Accuracy: 0.818359375\n",
      "Batch: 97, Loss: 0.48301488161087036, Accuracy: 0.845703125\n",
      "Batch: 98, Loss: 0.577774703502655, Accuracy: 0.8173828125\n",
      "Batch: 99, Loss: 0.5751134157180786, Accuracy: 0.806640625\n",
      "Batch: 100, Loss: 0.5811185836791992, Accuracy: 0.8115234375\n",
      "Batch: 101, Loss: 0.6201553344726562, Accuracy: 0.7919921875\n",
      "Batch: 102, Loss: 0.5834144353866577, Accuracy: 0.8173828125\n",
      "Batch: 103, Loss: 0.5563418865203857, Accuracy: 0.8173828125\n",
      "Batch: 104, Loss: 0.544768750667572, Accuracy: 0.8193359375\n",
      "Batch: 105, Loss: 0.5967832803726196, Accuracy: 0.7958984375\n",
      "Batch: 106, Loss: 0.5392934679985046, Accuracy: 0.830078125\n",
      "Batch: 107, Loss: 0.5823720693588257, Accuracy: 0.8125\n",
      "Batch: 108, Loss: 0.5766633152961731, Accuracy: 0.818359375\n",
      "Batch: 109, Loss: 0.5877425670623779, Accuracy: 0.80859375\n",
      "Batch: 110, Loss: 0.5427591800689697, Accuracy: 0.8232421875\n",
      "Batch: 111, Loss: 0.5723238587379456, Accuracy: 0.7978515625\n",
      "Batch: 112, Loss: 0.6198897957801819, Accuracy: 0.7919921875\n",
      "Batch: 113, Loss: 0.5703846216201782, Accuracy: 0.81640625\n",
      "Batch: 114, Loss: 0.589747428894043, Accuracy: 0.814453125\n",
      "Batch: 115, Loss: 0.6345342993736267, Accuracy: 0.7841796875\n",
      "Batch: 116, Loss: 0.5820273160934448, Accuracy: 0.810546875\n",
      "Batch: 117, Loss: 0.6137359738349915, Accuracy: 0.796875\n",
      "Batch: 118, Loss: 0.5296778678894043, Accuracy: 0.8232421875\n",
      "Batch: 119, Loss: 0.48300862312316895, Accuracy: 0.853515625\n",
      "Batch: 120, Loss: 0.6027904748916626, Accuracy: 0.7890625\n",
      "Batch: 121, Loss: 0.6496015787124634, Accuracy: 0.794921875\n",
      "Batch: 122, Loss: 0.6031160354614258, Accuracy: 0.8095703125\n",
      "Batch: 123, Loss: 0.5279487371444702, Accuracy: 0.8232421875\n",
      "Batch: 124, Loss: 0.5857380032539368, Accuracy: 0.8125\n",
      "Batch: 125, Loss: 0.6168623566627502, Accuracy: 0.7939453125\n",
      "Batch: 126, Loss: 0.5522663593292236, Accuracy: 0.8154296875\n",
      "Batch: 127, Loss: 0.5060829520225525, Accuracy: 0.8388671875\n",
      "Batch: 128, Loss: 0.6452133655548096, Accuracy: 0.796875\n",
      "Batch: 129, Loss: 0.5456500053405762, Accuracy: 0.8203125\n",
      "Batch: 130, Loss: 0.6272692680358887, Accuracy: 0.7783203125\n",
      "Batch: 131, Loss: 0.6026479005813599, Accuracy: 0.8037109375\n",
      "Batch: 132, Loss: 0.6456986665725708, Accuracy: 0.7939453125\n",
      "Batch: 133, Loss: 0.6161794662475586, Accuracy: 0.794921875\n",
      "Batch: 134, Loss: 0.5816150307655334, Accuracy: 0.7998046875\n",
      "Batch: 135, Loss: 0.55907142162323, Accuracy: 0.822265625\n",
      "Batch: 136, Loss: 0.6389003396034241, Accuracy: 0.7939453125\n",
      "Batch: 137, Loss: 0.583318829536438, Accuracy: 0.8046875\n",
      "Batch: 138, Loss: 0.5344440340995789, Accuracy: 0.8173828125\n",
      "Batch: 139, Loss: 0.5499603748321533, Accuracy: 0.8154296875\n",
      "Batch: 140, Loss: 0.567654550075531, Accuracy: 0.8154296875\n",
      "Batch: 141, Loss: 0.629677414894104, Accuracy: 0.8037109375\n",
      "Batch: 142, Loss: 0.6614652872085571, Accuracy: 0.7822265625\n",
      "Batch: 143, Loss: 0.5879538059234619, Accuracy: 0.7919921875\n",
      "Batch: 144, Loss: 0.5990673303604126, Accuracy: 0.8017578125\n",
      "Batch: 145, Loss: 0.5814857482910156, Accuracy: 0.7978515625\n",
      "Batch: 146, Loss: 0.5981560349464417, Accuracy: 0.7978515625\n",
      "Batch: 147, Loss: 0.5731338858604431, Accuracy: 0.8134765625\n",
      "Batch: 148, Loss: 0.6087148189544678, Accuracy: 0.8046875\n",
      "Batch: 149, Loss: 0.5067663788795471, Accuracy: 0.8193359375\n",
      "Batch: 150, Loss: 0.5757938623428345, Accuracy: 0.8134765625\n",
      "Batch: 151, Loss: 0.5277494788169861, Accuracy: 0.828125\n",
      "Epoch 73/80\n",
      "Batch: 1, Loss: 0.7694137692451477, Accuracy: 0.755859375\n",
      "Batch: 2, Loss: 0.6623799800872803, Accuracy: 0.7724609375\n",
      "Batch: 3, Loss: 0.551124095916748, Accuracy: 0.81640625\n",
      "Batch: 4, Loss: 0.5108557939529419, Accuracy: 0.826171875\n",
      "Batch: 5, Loss: 0.5485936403274536, Accuracy: 0.8251953125\n",
      "Batch: 6, Loss: 0.5692398548126221, Accuracy: 0.8154296875\n",
      "Batch: 7, Loss: 0.5553229451179504, Accuracy: 0.8095703125\n",
      "Batch: 8, Loss: 0.5418433547019958, Accuracy: 0.8193359375\n",
      "Batch: 9, Loss: 0.5529791116714478, Accuracy: 0.8154296875\n",
      "Batch: 10, Loss: 0.5419718027114868, Accuracy: 0.818359375\n",
      "Batch: 11, Loss: 0.6134016513824463, Accuracy: 0.791015625\n",
      "Batch: 12, Loss: 0.5773593187332153, Accuracy: 0.8232421875\n",
      "Batch: 13, Loss: 0.4852506220340729, Accuracy: 0.8271484375\n",
      "Batch: 14, Loss: 0.5973491668701172, Accuracy: 0.7939453125\n",
      "Batch: 15, Loss: 0.5210214257240295, Accuracy: 0.84375\n",
      "Batch: 16, Loss: 0.5361151695251465, Accuracy: 0.8359375\n",
      "Batch: 17, Loss: 0.5571166276931763, Accuracy: 0.828125\n",
      "Batch: 18, Loss: 0.6204966306686401, Accuracy: 0.7890625\n",
      "Batch: 19, Loss: 0.5787428617477417, Accuracy: 0.81640625\n",
      "Batch: 20, Loss: 0.5000676512718201, Accuracy: 0.8544921875\n",
      "Batch: 21, Loss: 0.5147088170051575, Accuracy: 0.8251953125\n",
      "Batch: 22, Loss: 0.6436578035354614, Accuracy: 0.783203125\n",
      "Batch: 23, Loss: 0.5903186798095703, Accuracy: 0.791015625\n",
      "Batch: 24, Loss: 0.5850877165794373, Accuracy: 0.8115234375\n",
      "Batch: 25, Loss: 0.5537525415420532, Accuracy: 0.818359375\n",
      "Batch: 26, Loss: 0.44937360286712646, Accuracy: 0.8505859375\n",
      "Batch: 27, Loss: 0.5422707796096802, Accuracy: 0.8310546875\n",
      "Batch: 28, Loss: 0.5445006489753723, Accuracy: 0.814453125\n",
      "Batch: 29, Loss: 0.5558990240097046, Accuracy: 0.8173828125\n",
      "Batch: 30, Loss: 0.49848005175590515, Accuracy: 0.8427734375\n",
      "Batch: 31, Loss: 0.5006181597709656, Accuracy: 0.8271484375\n",
      "Batch: 32, Loss: 0.5354669094085693, Accuracy: 0.81640625\n",
      "Batch: 33, Loss: 0.5734939575195312, Accuracy: 0.8046875\n",
      "Batch: 34, Loss: 0.6271995306015015, Accuracy: 0.7900390625\n",
      "Batch: 35, Loss: 0.5788978338241577, Accuracy: 0.810546875\n",
      "Batch: 36, Loss: 0.5749047994613647, Accuracy: 0.8203125\n",
      "Batch: 37, Loss: 0.5744290947914124, Accuracy: 0.814453125\n",
      "Batch: 38, Loss: 0.5767607688903809, Accuracy: 0.8125\n",
      "Batch: 39, Loss: 0.5782881379127502, Accuracy: 0.8095703125\n",
      "Batch: 40, Loss: 0.5526406764984131, Accuracy: 0.8134765625\n",
      "Batch: 41, Loss: 0.5066413879394531, Accuracy: 0.828125\n",
      "Batch: 42, Loss: 0.4519665837287903, Accuracy: 0.8466796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 43, Loss: 0.5185302495956421, Accuracy: 0.828125\n",
      "Batch: 44, Loss: 0.5769703388214111, Accuracy: 0.7958984375\n",
      "Batch: 45, Loss: 0.4979400932788849, Accuracy: 0.826171875\n",
      "Batch: 46, Loss: 0.5083205699920654, Accuracy: 0.83984375\n",
      "Batch: 47, Loss: 0.5883514285087585, Accuracy: 0.833984375\n",
      "Batch: 48, Loss: 0.5540781021118164, Accuracy: 0.8115234375\n",
      "Batch: 49, Loss: 0.6088879704475403, Accuracy: 0.80078125\n",
      "Batch: 50, Loss: 0.5649110078811646, Accuracy: 0.8125\n",
      "Batch: 51, Loss: 0.5588477849960327, Accuracy: 0.8193359375\n",
      "Batch: 52, Loss: 0.5606397390365601, Accuracy: 0.810546875\n",
      "Batch: 53, Loss: 0.5289753675460815, Accuracy: 0.8310546875\n",
      "Batch: 54, Loss: 0.5580292344093323, Accuracy: 0.8232421875\n",
      "Batch: 55, Loss: 0.6040821075439453, Accuracy: 0.7939453125\n",
      "Batch: 56, Loss: 0.6345831155776978, Accuracy: 0.779296875\n",
      "Batch: 57, Loss: 0.5844289064407349, Accuracy: 0.8115234375\n",
      "Batch: 58, Loss: 0.6461657881736755, Accuracy: 0.79296875\n",
      "Batch: 59, Loss: 0.5698037147521973, Accuracy: 0.796875\n",
      "Batch: 60, Loss: 0.5428586006164551, Accuracy: 0.82421875\n",
      "Batch: 61, Loss: 0.6023192405700684, Accuracy: 0.80078125\n",
      "Batch: 62, Loss: 0.5429919362068176, Accuracy: 0.83203125\n",
      "Batch: 63, Loss: 0.5749925374984741, Accuracy: 0.818359375\n",
      "Batch: 64, Loss: 0.5438153743743896, Accuracy: 0.814453125\n",
      "Batch: 65, Loss: 0.5887615084648132, Accuracy: 0.8115234375\n",
      "Batch: 66, Loss: 0.5954378247261047, Accuracy: 0.806640625\n",
      "Batch: 67, Loss: 0.652899980545044, Accuracy: 0.7880859375\n",
      "Batch: 68, Loss: 0.6341066956520081, Accuracy: 0.787109375\n",
      "Batch: 69, Loss: 0.6097476482391357, Accuracy: 0.806640625\n",
      "Batch: 70, Loss: 0.6196403503417969, Accuracy: 0.8154296875\n",
      "Batch: 71, Loss: 0.5946040749549866, Accuracy: 0.7998046875\n",
      "Batch: 72, Loss: 0.5221635103225708, Accuracy: 0.8173828125\n",
      "Batch: 73, Loss: 0.532975971698761, Accuracy: 0.8232421875\n",
      "Batch: 74, Loss: 0.509811282157898, Accuracy: 0.837890625\n",
      "Batch: 75, Loss: 0.50626540184021, Accuracy: 0.8310546875\n",
      "Batch: 76, Loss: 0.5805352926254272, Accuracy: 0.814453125\n",
      "Batch: 77, Loss: 0.48388803005218506, Accuracy: 0.84765625\n",
      "Batch: 78, Loss: 0.5558496117591858, Accuracy: 0.8203125\n",
      "Batch: 79, Loss: 0.5535331964492798, Accuracy: 0.8251953125\n",
      "Batch: 80, Loss: 0.53420090675354, Accuracy: 0.822265625\n",
      "Batch: 81, Loss: 0.5632232427597046, Accuracy: 0.8203125\n",
      "Batch: 82, Loss: 0.5867522954940796, Accuracy: 0.8095703125\n",
      "Batch: 83, Loss: 0.4948086738586426, Accuracy: 0.8408203125\n",
      "Batch: 84, Loss: 0.5850013494491577, Accuracy: 0.8037109375\n",
      "Batch: 85, Loss: 0.564935564994812, Accuracy: 0.8173828125\n",
      "Batch: 86, Loss: 0.6289476156234741, Accuracy: 0.7958984375\n",
      "Batch: 87, Loss: 0.5418083667755127, Accuracy: 0.8330078125\n",
      "Batch: 88, Loss: 0.5843151211738586, Accuracy: 0.8291015625\n",
      "Batch: 89, Loss: 0.5693079829216003, Accuracy: 0.822265625\n",
      "Batch: 90, Loss: 0.5455535650253296, Accuracy: 0.82421875\n",
      "Batch: 91, Loss: 0.5286149978637695, Accuracy: 0.828125\n",
      "Batch: 92, Loss: 0.5797058939933777, Accuracy: 0.8046875\n",
      "Batch: 93, Loss: 0.6136906147003174, Accuracy: 0.796875\n",
      "Batch: 94, Loss: 0.5505330562591553, Accuracy: 0.82421875\n",
      "Batch: 95, Loss: 0.5577619075775146, Accuracy: 0.8056640625\n",
      "Batch: 96, Loss: 0.5484927892684937, Accuracy: 0.8251953125\n",
      "Batch: 97, Loss: 0.47317755222320557, Accuracy: 0.8388671875\n",
      "Batch: 98, Loss: 0.5672001838684082, Accuracy: 0.810546875\n",
      "Batch: 99, Loss: 0.5358097553253174, Accuracy: 0.818359375\n",
      "Batch: 100, Loss: 0.5814758539199829, Accuracy: 0.806640625\n",
      "Batch: 101, Loss: 0.6134654879570007, Accuracy: 0.8017578125\n",
      "Batch: 102, Loss: 0.5686396360397339, Accuracy: 0.8271484375\n",
      "Batch: 103, Loss: 0.5755093097686768, Accuracy: 0.8212890625\n",
      "Batch: 104, Loss: 0.5307328701019287, Accuracy: 0.8330078125\n",
      "Batch: 105, Loss: 0.5368589758872986, Accuracy: 0.8154296875\n",
      "Batch: 106, Loss: 0.49613678455352783, Accuracy: 0.8427734375\n",
      "Batch: 107, Loss: 0.5700476765632629, Accuracy: 0.8271484375\n",
      "Batch: 108, Loss: 0.5706934928894043, Accuracy: 0.8154296875\n",
      "Batch: 109, Loss: 0.5636692047119141, Accuracy: 0.8193359375\n",
      "Batch: 110, Loss: 0.550041913986206, Accuracy: 0.8173828125\n",
      "Batch: 111, Loss: 0.5476131439208984, Accuracy: 0.82421875\n",
      "Batch: 112, Loss: 0.5923076868057251, Accuracy: 0.8037109375\n",
      "Batch: 113, Loss: 0.5390112996101379, Accuracy: 0.8349609375\n",
      "Batch: 114, Loss: 0.6018136739730835, Accuracy: 0.8056640625\n",
      "Batch: 115, Loss: 0.6282589435577393, Accuracy: 0.7841796875\n",
      "Batch: 116, Loss: 0.5751461982727051, Accuracy: 0.806640625\n",
      "Batch: 117, Loss: 0.6097722053527832, Accuracy: 0.80078125\n",
      "Batch: 118, Loss: 0.5484853982925415, Accuracy: 0.82421875\n",
      "Batch: 119, Loss: 0.49066030979156494, Accuracy: 0.83203125\n",
      "Batch: 120, Loss: 0.5813285112380981, Accuracy: 0.802734375\n",
      "Batch: 121, Loss: 0.6087982058525085, Accuracy: 0.8046875\n",
      "Batch: 122, Loss: 0.5554971098899841, Accuracy: 0.8232421875\n",
      "Batch: 123, Loss: 0.5311211943626404, Accuracy: 0.8193359375\n",
      "Batch: 124, Loss: 0.5842007398605347, Accuracy: 0.80078125\n",
      "Batch: 125, Loss: 0.6056039929389954, Accuracy: 0.79296875\n",
      "Batch: 126, Loss: 0.571950376033783, Accuracy: 0.818359375\n",
      "Batch: 127, Loss: 0.48650041222572327, Accuracy: 0.84375\n",
      "Batch: 128, Loss: 0.6258531212806702, Accuracy: 0.7939453125\n",
      "Batch: 129, Loss: 0.5129442811012268, Accuracy: 0.8310546875\n",
      "Batch: 130, Loss: 0.6309938430786133, Accuracy: 0.77734375\n",
      "Batch: 131, Loss: 0.5823439359664917, Accuracy: 0.796875\n",
      "Batch: 132, Loss: 0.5842954516410828, Accuracy: 0.8212890625\n",
      "Batch: 133, Loss: 0.573491096496582, Accuracy: 0.80859375\n",
      "Batch: 134, Loss: 0.5560461282730103, Accuracy: 0.8115234375\n",
      "Batch: 135, Loss: 0.5280879139900208, Accuracy: 0.837890625\n",
      "Batch: 136, Loss: 0.5837260484695435, Accuracy: 0.8134765625\n",
      "Batch: 137, Loss: 0.5773053169250488, Accuracy: 0.8017578125\n",
      "Batch: 138, Loss: 0.5561106204986572, Accuracy: 0.8203125\n",
      "Batch: 139, Loss: 0.5426750183105469, Accuracy: 0.794921875\n",
      "Batch: 140, Loss: 0.584001898765564, Accuracy: 0.806640625\n",
      "Batch: 141, Loss: 0.656427264213562, Accuracy: 0.779296875\n",
      "Batch: 142, Loss: 0.6529937982559204, Accuracy: 0.7890625\n",
      "Batch: 143, Loss: 0.5441856384277344, Accuracy: 0.8154296875\n",
      "Batch: 144, Loss: 0.5772697329521179, Accuracy: 0.8125\n",
      "Batch: 145, Loss: 0.5251031517982483, Accuracy: 0.8134765625\n",
      "Batch: 146, Loss: 0.588485836982727, Accuracy: 0.7998046875\n",
      "Batch: 147, Loss: 0.5294440984725952, Accuracy: 0.8271484375\n",
      "Batch: 148, Loss: 0.6070870161056519, Accuracy: 0.7939453125\n",
      "Batch: 149, Loss: 0.5231070518493652, Accuracy: 0.8232421875\n",
      "Batch: 150, Loss: 0.6027200818061829, Accuracy: 0.80859375\n",
      "Batch: 151, Loss: 0.5254170894622803, Accuracy: 0.8408203125\n",
      "Epoch 74/80\n",
      "Batch: 1, Loss: 0.7081854939460754, Accuracy: 0.7861328125\n",
      "Batch: 2, Loss: 0.5925410985946655, Accuracy: 0.794921875\n",
      "Batch: 3, Loss: 0.570178747177124, Accuracy: 0.8125\n",
      "Batch: 4, Loss: 0.5264692306518555, Accuracy: 0.8212890625\n",
      "Batch: 5, Loss: 0.5383843183517456, Accuracy: 0.8193359375\n",
      "Batch: 6, Loss: 0.536881685256958, Accuracy: 0.8193359375\n",
      "Batch: 7, Loss: 0.5556209087371826, Accuracy: 0.8125\n",
      "Batch: 8, Loss: 0.5561026334762573, Accuracy: 0.81640625\n",
      "Batch: 9, Loss: 0.5559244155883789, Accuracy: 0.8095703125\n",
      "Batch: 10, Loss: 0.4954656660556793, Accuracy: 0.8271484375\n",
      "Batch: 11, Loss: 0.5934171676635742, Accuracy: 0.7958984375\n",
      "Batch: 12, Loss: 0.5792714357376099, Accuracy: 0.8203125\n",
      "Batch: 13, Loss: 0.5024266242980957, Accuracy: 0.8291015625\n",
      "Batch: 14, Loss: 0.5677443742752075, Accuracy: 0.8076171875\n",
      "Batch: 15, Loss: 0.5161676406860352, Accuracy: 0.8330078125\n",
      "Batch: 16, Loss: 0.5462877750396729, Accuracy: 0.81640625\n",
      "Batch: 17, Loss: 0.5577607154846191, Accuracy: 0.8203125\n",
      "Batch: 18, Loss: 0.5726467967033386, Accuracy: 0.8095703125\n",
      "Batch: 19, Loss: 0.5586689114570618, Accuracy: 0.8251953125\n",
      "Batch: 20, Loss: 0.4979694187641144, Accuracy: 0.8447265625\n",
      "Batch: 21, Loss: 0.500213623046875, Accuracy: 0.8291015625\n",
      "Batch: 22, Loss: 0.6621184349060059, Accuracy: 0.7724609375\n",
      "Batch: 23, Loss: 0.6312459111213684, Accuracy: 0.7900390625\n",
      "Batch: 24, Loss: 0.6181329488754272, Accuracy: 0.798828125\n",
      "Batch: 25, Loss: 0.5375676155090332, Accuracy: 0.8212890625\n",
      "Batch: 26, Loss: 0.4738420248031616, Accuracy: 0.8349609375\n",
      "Batch: 27, Loss: 0.5249252319335938, Accuracy: 0.828125\n",
      "Batch: 28, Loss: 0.5660368800163269, Accuracy: 0.8173828125\n",
      "Batch: 29, Loss: 0.5277184247970581, Accuracy: 0.8115234375\n",
      "Batch: 30, Loss: 0.49672773480415344, Accuracy: 0.83984375\n",
      "Batch: 31, Loss: 0.5175424814224243, Accuracy: 0.826171875\n",
      "Batch: 32, Loss: 0.5297384858131409, Accuracy: 0.830078125\n",
      "Batch: 33, Loss: 0.5836597681045532, Accuracy: 0.796875\n",
      "Batch: 34, Loss: 0.6249427795410156, Accuracy: 0.796875\n",
      "Batch: 35, Loss: 0.5843151807785034, Accuracy: 0.8095703125\n",
      "Batch: 36, Loss: 0.591709554195404, Accuracy: 0.8251953125\n",
      "Batch: 37, Loss: 0.5882436633110046, Accuracy: 0.810546875\n",
      "Batch: 38, Loss: 0.6019917726516724, Accuracy: 0.7939453125\n",
      "Batch: 39, Loss: 0.6100931167602539, Accuracy: 0.8017578125\n",
      "Batch: 40, Loss: 0.5480502843856812, Accuracy: 0.814453125\n",
      "Batch: 41, Loss: 0.5124693512916565, Accuracy: 0.8349609375\n",
      "Batch: 42, Loss: 0.42534059286117554, Accuracy: 0.8525390625\n",
      "Batch: 43, Loss: 0.5281488299369812, Accuracy: 0.8271484375\n",
      "Batch: 44, Loss: 0.5920078754425049, Accuracy: 0.8173828125\n",
      "Batch: 45, Loss: 0.4918012022972107, Accuracy: 0.8408203125\n",
      "Batch: 46, Loss: 0.5399443507194519, Accuracy: 0.8134765625\n",
      "Batch: 47, Loss: 0.5704919099807739, Accuracy: 0.818359375\n",
      "Batch: 48, Loss: 0.5424621105194092, Accuracy: 0.8330078125\n",
      "Batch: 49, Loss: 0.6026632189750671, Accuracy: 0.8095703125\n",
      "Batch: 50, Loss: 0.5539373159408569, Accuracy: 0.833984375\n",
      "Batch: 51, Loss: 0.5545593500137329, Accuracy: 0.82421875\n",
      "Batch: 52, Loss: 0.5489984154701233, Accuracy: 0.8271484375\n",
      "Batch: 53, Loss: 0.5034418106079102, Accuracy: 0.8486328125\n",
      "Batch: 54, Loss: 0.5420109033584595, Accuracy: 0.8251953125\n",
      "Batch: 55, Loss: 0.6109013557434082, Accuracy: 0.796875\n",
      "Batch: 56, Loss: 0.6214786767959595, Accuracy: 0.783203125\n",
      "Batch: 57, Loss: 0.6010392904281616, Accuracy: 0.787109375\n",
      "Batch: 58, Loss: 0.6214690208435059, Accuracy: 0.8046875\n",
      "Batch: 59, Loss: 0.5619206428527832, Accuracy: 0.8271484375\n",
      "Batch: 60, Loss: 0.5462992191314697, Accuracy: 0.81640625\n",
      "Batch: 61, Loss: 0.5925261974334717, Accuracy: 0.8095703125\n",
      "Batch: 62, Loss: 0.5144743919372559, Accuracy: 0.8310546875\n",
      "Batch: 63, Loss: 0.5660149455070496, Accuracy: 0.8017578125\n",
      "Batch: 64, Loss: 0.5527387857437134, Accuracy: 0.8251953125\n",
      "Batch: 65, Loss: 0.5768895149230957, Accuracy: 0.826171875\n",
      "Batch: 66, Loss: 0.57696932554245, Accuracy: 0.818359375\n",
      "Batch: 67, Loss: 0.6471369862556458, Accuracy: 0.791015625\n",
      "Batch: 68, Loss: 0.652974009513855, Accuracy: 0.79296875\n",
      "Batch: 69, Loss: 0.5734556317329407, Accuracy: 0.8037109375\n",
      "Batch: 70, Loss: 0.6207734942436218, Accuracy: 0.80859375\n",
      "Batch: 71, Loss: 0.642697811126709, Accuracy: 0.7841796875\n",
      "Batch: 72, Loss: 0.5463401079177856, Accuracy: 0.8193359375\n",
      "Batch: 73, Loss: 0.5345213413238525, Accuracy: 0.8408203125\n",
      "Batch: 74, Loss: 0.5245824456214905, Accuracy: 0.8369140625\n",
      "Batch: 75, Loss: 0.4818625748157501, Accuracy: 0.8369140625\n",
      "Batch: 76, Loss: 0.5949835777282715, Accuracy: 0.810546875\n",
      "Batch: 77, Loss: 0.5088015198707581, Accuracy: 0.833984375\n",
      "Batch: 78, Loss: 0.5166441202163696, Accuracy: 0.8251953125\n",
      "Batch: 79, Loss: 0.5141226053237915, Accuracy: 0.83984375\n",
      "Batch: 80, Loss: 0.5601663589477539, Accuracy: 0.8095703125\n",
      "Batch: 81, Loss: 0.5740774869918823, Accuracy: 0.79296875\n",
      "Batch: 82, Loss: 0.5762708783149719, Accuracy: 0.8154296875\n",
      "Batch: 83, Loss: 0.4943115711212158, Accuracy: 0.845703125\n",
      "Batch: 84, Loss: 0.5697207450866699, Accuracy: 0.806640625\n",
      "Batch: 85, Loss: 0.5337514281272888, Accuracy: 0.833984375\n",
      "Batch: 86, Loss: 0.5949951410293579, Accuracy: 0.7998046875\n",
      "Batch: 87, Loss: 0.5276311635971069, Accuracy: 0.830078125\n",
      "Batch: 88, Loss: 0.5840983390808105, Accuracy: 0.8271484375\n",
      "Batch: 89, Loss: 0.6065586805343628, Accuracy: 0.8076171875\n",
      "Batch: 90, Loss: 0.5406850576400757, Accuracy: 0.8271484375\n",
      "Batch: 91, Loss: 0.5132282972335815, Accuracy: 0.8203125\n",
      "Batch: 92, Loss: 0.5735560059547424, Accuracy: 0.806640625\n",
      "Batch: 93, Loss: 0.5720963478088379, Accuracy: 0.7998046875\n",
      "Batch: 94, Loss: 0.6172240972518921, Accuracy: 0.7998046875\n",
      "Batch: 95, Loss: 0.5483261346817017, Accuracy: 0.8115234375\n",
      "Batch: 96, Loss: 0.561277449131012, Accuracy: 0.8125\n",
      "Batch: 97, Loss: 0.4479772448539734, Accuracy: 0.8525390625\n",
      "Batch: 98, Loss: 0.5521215200424194, Accuracy: 0.8203125\n",
      "Batch: 99, Loss: 0.5370265245437622, Accuracy: 0.8125\n",
      "Batch: 100, Loss: 0.5431137084960938, Accuracy: 0.81640625\n",
      "Batch: 101, Loss: 0.5853586196899414, Accuracy: 0.8154296875\n",
      "Batch: 102, Loss: 0.5663295388221741, Accuracy: 0.8251953125\n",
      "Batch: 103, Loss: 0.5721856355667114, Accuracy: 0.8134765625\n",
      "Batch: 104, Loss: 0.5271121263504028, Accuracy: 0.8251953125\n",
      "Batch: 105, Loss: 0.5610576868057251, Accuracy: 0.806640625\n",
      "Batch: 106, Loss: 0.5343791246414185, Accuracy: 0.8291015625\n",
      "Batch: 107, Loss: 0.551357090473175, Accuracy: 0.841796875\n",
      "Batch: 108, Loss: 0.5373882055282593, Accuracy: 0.8271484375\n",
      "Batch: 109, Loss: 0.5810997486114502, Accuracy: 0.8017578125\n",
      "Batch: 110, Loss: 0.5471633672714233, Accuracy: 0.80859375\n",
      "Batch: 111, Loss: 0.5787129402160645, Accuracy: 0.8076171875\n",
      "Batch: 112, Loss: 0.6130187511444092, Accuracy: 0.7861328125\n",
      "Batch: 113, Loss: 0.5525810718536377, Accuracy: 0.8291015625\n",
      "Batch: 114, Loss: 0.5851353406906128, Accuracy: 0.7998046875\n",
      "Batch: 115, Loss: 0.6471784114837646, Accuracy: 0.7861328125\n",
      "Batch: 116, Loss: 0.5728847980499268, Accuracy: 0.814453125\n",
      "Batch: 117, Loss: 0.5716800689697266, Accuracy: 0.8203125\n",
      "Batch: 118, Loss: 0.5556300282478333, Accuracy: 0.818359375\n",
      "Batch: 119, Loss: 0.483642041683197, Accuracy: 0.8505859375\n",
      "Batch: 120, Loss: 0.5351710319519043, Accuracy: 0.8291015625\n",
      "Batch: 121, Loss: 0.647831916809082, Accuracy: 0.7958984375\n",
      "Batch: 122, Loss: 0.5990078449249268, Accuracy: 0.8056640625\n",
      "Batch: 123, Loss: 0.5271615982055664, Accuracy: 0.826171875\n",
      "Batch: 124, Loss: 0.5595738887786865, Accuracy: 0.8173828125\n",
      "Batch: 125, Loss: 0.5673380494117737, Accuracy: 0.8076171875\n",
      "Batch: 126, Loss: 0.6079071164131165, Accuracy: 0.8056640625\n",
      "Batch: 127, Loss: 0.4942511022090912, Accuracy: 0.83203125\n",
      "Batch: 128, Loss: 0.6204991340637207, Accuracy: 0.8046875\n",
      "Batch: 129, Loss: 0.5397003293037415, Accuracy: 0.822265625\n",
      "Batch: 130, Loss: 0.6256503462791443, Accuracy: 0.79296875\n",
      "Batch: 131, Loss: 0.5996495485305786, Accuracy: 0.796875\n",
      "Batch: 132, Loss: 0.6117348670959473, Accuracy: 0.8076171875\n",
      "Batch: 133, Loss: 0.5646910071372986, Accuracy: 0.814453125\n",
      "Batch: 134, Loss: 0.6061317920684814, Accuracy: 0.794921875\n",
      "Batch: 135, Loss: 0.5213574171066284, Accuracy: 0.8349609375\n",
      "Batch: 136, Loss: 0.5852614641189575, Accuracy: 0.8056640625\n",
      "Batch: 137, Loss: 0.5811553001403809, Accuracy: 0.798828125\n",
      "Batch: 138, Loss: 0.516492486000061, Accuracy: 0.830078125\n",
      "Batch: 139, Loss: 0.5101293325424194, Accuracy: 0.810546875\n",
      "Batch: 140, Loss: 0.5561058521270752, Accuracy: 0.8095703125\n",
      "Batch: 141, Loss: 0.6205451488494873, Accuracy: 0.7939453125\n",
      "Batch: 142, Loss: 0.6160635352134705, Accuracy: 0.8017578125\n",
      "Batch: 143, Loss: 0.5790455341339111, Accuracy: 0.81640625\n",
      "Batch: 144, Loss: 0.5832552909851074, Accuracy: 0.81640625\n",
      "Batch: 145, Loss: 0.5223401784896851, Accuracy: 0.8203125\n",
      "Batch: 146, Loss: 0.5667338371276855, Accuracy: 0.8212890625\n",
      "Batch: 147, Loss: 0.5101380348205566, Accuracy: 0.8310546875\n",
      "Batch: 148, Loss: 0.5990340709686279, Accuracy: 0.791015625\n",
      "Batch: 149, Loss: 0.5132095813751221, Accuracy: 0.826171875\n",
      "Batch: 150, Loss: 0.5963342785835266, Accuracy: 0.8095703125\n",
      "Batch: 151, Loss: 0.5353597402572632, Accuracy: 0.8310546875\n",
      "Epoch 75/80\n",
      "Batch: 1, Loss: 0.7034683227539062, Accuracy: 0.763671875\n",
      "Batch: 2, Loss: 0.6262620091438293, Accuracy: 0.783203125\n",
      "Batch: 3, Loss: 0.5446677803993225, Accuracy: 0.82421875\n",
      "Batch: 4, Loss: 0.5261027812957764, Accuracy: 0.8232421875\n",
      "Batch: 5, Loss: 0.5648062825202942, Accuracy: 0.818359375\n",
      "Batch: 6, Loss: 0.5450391173362732, Accuracy: 0.818359375\n",
      "Batch: 7, Loss: 0.5891083478927612, Accuracy: 0.80859375\n",
      "Batch: 8, Loss: 0.4981122314929962, Accuracy: 0.830078125\n",
      "Batch: 9, Loss: 0.5493379831314087, Accuracy: 0.8212890625\n",
      "Batch: 10, Loss: 0.5028035640716553, Accuracy: 0.8251953125\n",
      "Batch: 11, Loss: 0.5730931162834167, Accuracy: 0.806640625\n",
      "Batch: 12, Loss: 0.575857400894165, Accuracy: 0.8076171875\n",
      "Batch: 13, Loss: 0.47973233461380005, Accuracy: 0.83984375\n",
      "Batch: 14, Loss: 0.577919602394104, Accuracy: 0.8017578125\n",
      "Batch: 15, Loss: 0.5083713531494141, Accuracy: 0.8388671875\n",
      "Batch: 16, Loss: 0.5042719841003418, Accuracy: 0.837890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 17, Loss: 0.5377064943313599, Accuracy: 0.8193359375\n",
      "Batch: 18, Loss: 0.588769257068634, Accuracy: 0.8037109375\n",
      "Batch: 19, Loss: 0.5607610940933228, Accuracy: 0.826171875\n",
      "Batch: 20, Loss: 0.5200577974319458, Accuracy: 0.83203125\n",
      "Batch: 21, Loss: 0.5163825154304504, Accuracy: 0.841796875\n",
      "Batch: 22, Loss: 0.6046569347381592, Accuracy: 0.78515625\n",
      "Batch: 23, Loss: 0.6099181175231934, Accuracy: 0.7890625\n",
      "Batch: 24, Loss: 0.5815776586532593, Accuracy: 0.814453125\n",
      "Batch: 25, Loss: 0.5396323800086975, Accuracy: 0.8251953125\n",
      "Batch: 26, Loss: 0.46942633390426636, Accuracy: 0.841796875\n",
      "Batch: 27, Loss: 0.5493725538253784, Accuracy: 0.8134765625\n",
      "Batch: 28, Loss: 0.5419312715530396, Accuracy: 0.822265625\n",
      "Batch: 29, Loss: 0.5411391854286194, Accuracy: 0.8212890625\n",
      "Batch: 30, Loss: 0.5084934830665588, Accuracy: 0.8349609375\n",
      "Batch: 31, Loss: 0.43338000774383545, Accuracy: 0.8525390625\n",
      "Batch: 32, Loss: 0.5290766358375549, Accuracy: 0.8271484375\n",
      "Batch: 33, Loss: 0.5722315311431885, Accuracy: 0.81640625\n",
      "Batch: 34, Loss: 0.5872625112533569, Accuracy: 0.80078125\n",
      "Batch: 35, Loss: 0.5728971362113953, Accuracy: 0.8056640625\n",
      "Batch: 36, Loss: 0.5384024381637573, Accuracy: 0.826171875\n",
      "Batch: 37, Loss: 0.5842227935791016, Accuracy: 0.8232421875\n",
      "Batch: 38, Loss: 0.5846084952354431, Accuracy: 0.794921875\n",
      "Batch: 39, Loss: 0.5609712600708008, Accuracy: 0.8056640625\n",
      "Batch: 40, Loss: 0.5582126975059509, Accuracy: 0.8212890625\n",
      "Batch: 41, Loss: 0.4814603328704834, Accuracy: 0.8408203125\n",
      "Batch: 42, Loss: 0.41705334186553955, Accuracy: 0.86328125\n",
      "Batch: 43, Loss: 0.5226129293441772, Accuracy: 0.826171875\n",
      "Batch: 44, Loss: 0.5650445222854614, Accuracy: 0.8212890625\n",
      "Batch: 45, Loss: 0.5195037722587585, Accuracy: 0.8310546875\n",
      "Batch: 46, Loss: 0.524660587310791, Accuracy: 0.83203125\n",
      "Batch: 47, Loss: 0.5440303087234497, Accuracy: 0.8203125\n",
      "Batch: 48, Loss: 0.5565035939216614, Accuracy: 0.80859375\n",
      "Batch: 49, Loss: 0.5647786855697632, Accuracy: 0.8212890625\n",
      "Batch: 50, Loss: 0.5185843706130981, Accuracy: 0.8349609375\n",
      "Batch: 51, Loss: 0.5718276500701904, Accuracy: 0.8203125\n",
      "Batch: 52, Loss: 0.525958776473999, Accuracy: 0.833984375\n",
      "Batch: 53, Loss: 0.505415678024292, Accuracy: 0.8447265625\n",
      "Batch: 54, Loss: 0.553015947341919, Accuracy: 0.8251953125\n",
      "Batch: 55, Loss: 0.5784626007080078, Accuracy: 0.8125\n",
      "Batch: 56, Loss: 0.6181902289390564, Accuracy: 0.8017578125\n",
      "Batch: 57, Loss: 0.593716561794281, Accuracy: 0.7998046875\n",
      "Batch: 58, Loss: 0.6230207085609436, Accuracy: 0.79296875\n",
      "Batch: 59, Loss: 0.5428685545921326, Accuracy: 0.8134765625\n",
      "Batch: 60, Loss: 0.5124882459640503, Accuracy: 0.8251953125\n",
      "Batch: 61, Loss: 0.5712246298789978, Accuracy: 0.8134765625\n",
      "Batch: 62, Loss: 0.49456456303596497, Accuracy: 0.8349609375\n",
      "Batch: 63, Loss: 0.5656439065933228, Accuracy: 0.8017578125\n",
      "Batch: 64, Loss: 0.519180178642273, Accuracy: 0.8232421875\n",
      "Batch: 65, Loss: 0.5895735025405884, Accuracy: 0.806640625\n",
      "Batch: 66, Loss: 0.5560227632522583, Accuracy: 0.8232421875\n",
      "Batch: 67, Loss: 0.6330869793891907, Accuracy: 0.7998046875\n",
      "Batch: 68, Loss: 0.6479167938232422, Accuracy: 0.7900390625\n",
      "Batch: 69, Loss: 0.5726253986358643, Accuracy: 0.8115234375\n",
      "Batch: 70, Loss: 0.6428234577178955, Accuracy: 0.79296875\n",
      "Batch: 71, Loss: 0.6208104491233826, Accuracy: 0.802734375\n",
      "Batch: 72, Loss: 0.5216010808944702, Accuracy: 0.8203125\n",
      "Batch: 73, Loss: 0.4995458722114563, Accuracy: 0.8359375\n",
      "Batch: 74, Loss: 0.5147792100906372, Accuracy: 0.8369140625\n",
      "Batch: 75, Loss: 0.45962387323379517, Accuracy: 0.8447265625\n",
      "Batch: 76, Loss: 0.5571955442428589, Accuracy: 0.8154296875\n",
      "Batch: 77, Loss: 0.4893158972263336, Accuracy: 0.849609375\n",
      "Batch: 78, Loss: 0.532913327217102, Accuracy: 0.837890625\n",
      "Batch: 79, Loss: 0.5541626214981079, Accuracy: 0.8232421875\n",
      "Batch: 80, Loss: 0.5400198698043823, Accuracy: 0.828125\n",
      "Batch: 81, Loss: 0.5593312978744507, Accuracy: 0.8076171875\n",
      "Batch: 82, Loss: 0.5882236361503601, Accuracy: 0.8125\n",
      "Batch: 83, Loss: 0.5100210309028625, Accuracy: 0.84765625\n",
      "Batch: 84, Loss: 0.5743483304977417, Accuracy: 0.8125\n",
      "Batch: 85, Loss: 0.5594916343688965, Accuracy: 0.8291015625\n",
      "Batch: 86, Loss: 0.6437258720397949, Accuracy: 0.794921875\n",
      "Batch: 87, Loss: 0.5242974162101746, Accuracy: 0.8251953125\n",
      "Batch: 88, Loss: 0.5752682089805603, Accuracy: 0.830078125\n",
      "Batch: 89, Loss: 0.5490841865539551, Accuracy: 0.830078125\n",
      "Batch: 90, Loss: 0.5061105489730835, Accuracy: 0.8251953125\n",
      "Batch: 91, Loss: 0.5018675923347473, Accuracy: 0.8359375\n",
      "Batch: 92, Loss: 0.56757652759552, Accuracy: 0.810546875\n",
      "Batch: 93, Loss: 0.5764374732971191, Accuracy: 0.791015625\n",
      "Batch: 94, Loss: 0.5819973945617676, Accuracy: 0.8037109375\n",
      "Batch: 95, Loss: 0.5810095071792603, Accuracy: 0.81640625\n",
      "Batch: 96, Loss: 0.5515925288200378, Accuracy: 0.8251953125\n",
      "Batch: 97, Loss: 0.48485416173934937, Accuracy: 0.8408203125\n",
      "Batch: 98, Loss: 0.5557490587234497, Accuracy: 0.814453125\n",
      "Batch: 99, Loss: 0.5510187149047852, Accuracy: 0.818359375\n",
      "Batch: 100, Loss: 0.5554200410842896, Accuracy: 0.8125\n",
      "Batch: 101, Loss: 0.5839231014251709, Accuracy: 0.798828125\n",
      "Batch: 102, Loss: 0.5682478547096252, Accuracy: 0.8212890625\n",
      "Batch: 103, Loss: 0.5477889180183411, Accuracy: 0.826171875\n",
      "Batch: 104, Loss: 0.5314003229141235, Accuracy: 0.8271484375\n",
      "Batch: 105, Loss: 0.5387029051780701, Accuracy: 0.822265625\n",
      "Batch: 106, Loss: 0.5194085836410522, Accuracy: 0.8271484375\n",
      "Batch: 107, Loss: 0.5892802476882935, Accuracy: 0.8251953125\n",
      "Batch: 108, Loss: 0.5539635419845581, Accuracy: 0.818359375\n",
      "Batch: 109, Loss: 0.6001866459846497, Accuracy: 0.7919921875\n",
      "Batch: 110, Loss: 0.5435434579849243, Accuracy: 0.818359375\n",
      "Batch: 111, Loss: 0.5575929880142212, Accuracy: 0.814453125\n",
      "Batch: 112, Loss: 0.608954906463623, Accuracy: 0.7900390625\n",
      "Batch: 113, Loss: 0.5350345373153687, Accuracy: 0.83984375\n",
      "Batch: 114, Loss: 0.5822610855102539, Accuracy: 0.8076171875\n",
      "Batch: 115, Loss: 0.6381289958953857, Accuracy: 0.7978515625\n",
      "Batch: 116, Loss: 0.559450089931488, Accuracy: 0.8037109375\n",
      "Batch: 117, Loss: 0.5857783555984497, Accuracy: 0.8037109375\n",
      "Batch: 118, Loss: 0.5153136849403381, Accuracy: 0.8466796875\n",
      "Batch: 119, Loss: 0.5325350165367126, Accuracy: 0.8193359375\n",
      "Batch: 120, Loss: 0.5445325374603271, Accuracy: 0.81640625\n",
      "Batch: 121, Loss: 0.6004088521003723, Accuracy: 0.796875\n",
      "Batch: 122, Loss: 0.5853575468063354, Accuracy: 0.8046875\n",
      "Batch: 123, Loss: 0.5103709697723389, Accuracy: 0.8310546875\n",
      "Batch: 124, Loss: 0.5604381561279297, Accuracy: 0.8134765625\n",
      "Batch: 125, Loss: 0.59744793176651, Accuracy: 0.8056640625\n",
      "Batch: 126, Loss: 0.5590135455131531, Accuracy: 0.81640625\n",
      "Batch: 127, Loss: 0.5114402174949646, Accuracy: 0.83203125\n",
      "Batch: 128, Loss: 0.6035942435264587, Accuracy: 0.810546875\n",
      "Batch: 129, Loss: 0.5273271799087524, Accuracy: 0.8203125\n",
      "Batch: 130, Loss: 0.6176268458366394, Accuracy: 0.8017578125\n",
      "Batch: 131, Loss: 0.5820989608764648, Accuracy: 0.7900390625\n",
      "Batch: 132, Loss: 0.6228230595588684, Accuracy: 0.7939453125\n",
      "Batch: 133, Loss: 0.6194503903388977, Accuracy: 0.806640625\n",
      "Batch: 134, Loss: 0.5946953296661377, Accuracy: 0.8056640625\n",
      "Batch: 135, Loss: 0.55419921875, Accuracy: 0.830078125\n",
      "Batch: 136, Loss: 0.5954626202583313, Accuracy: 0.80859375\n",
      "Batch: 137, Loss: 0.588796854019165, Accuracy: 0.7734375\n",
      "Batch: 138, Loss: 0.5594027042388916, Accuracy: 0.8125\n",
      "Batch: 139, Loss: 0.5290325284004211, Accuracy: 0.818359375\n",
      "Batch: 140, Loss: 0.55933678150177, Accuracy: 0.8134765625\n",
      "Batch: 141, Loss: 0.6022328734397888, Accuracy: 0.80859375\n",
      "Batch: 142, Loss: 0.6082741618156433, Accuracy: 0.8056640625\n",
      "Batch: 143, Loss: 0.5564571619033813, Accuracy: 0.8203125\n",
      "Batch: 144, Loss: 0.5996140241622925, Accuracy: 0.8046875\n",
      "Batch: 145, Loss: 0.5330188274383545, Accuracy: 0.8125\n",
      "Batch: 146, Loss: 0.5925997495651245, Accuracy: 0.8134765625\n",
      "Batch: 147, Loss: 0.5059188008308411, Accuracy: 0.8466796875\n",
      "Batch: 148, Loss: 0.6284481287002563, Accuracy: 0.796875\n",
      "Batch: 149, Loss: 0.5334137678146362, Accuracy: 0.826171875\n",
      "Batch: 150, Loss: 0.5855973362922668, Accuracy: 0.8017578125\n",
      "Batch: 151, Loss: 0.5200750231742859, Accuracy: 0.8369140625\n",
      "Epoch 76/80\n",
      "Batch: 1, Loss: 0.7061084508895874, Accuracy: 0.79296875\n",
      "Batch: 2, Loss: 0.6147488355636597, Accuracy: 0.7822265625\n",
      "Batch: 3, Loss: 0.5454498529434204, Accuracy: 0.82421875\n",
      "Batch: 4, Loss: 0.5359504818916321, Accuracy: 0.83203125\n",
      "Batch: 5, Loss: 0.5333762764930725, Accuracy: 0.828125\n",
      "Batch: 6, Loss: 0.5571081638336182, Accuracy: 0.8173828125\n",
      "Batch: 7, Loss: 0.5791726112365723, Accuracy: 0.8046875\n",
      "Batch: 8, Loss: 0.5265473127365112, Accuracy: 0.8232421875\n",
      "Batch: 9, Loss: 0.5338538885116577, Accuracy: 0.8193359375\n",
      "Batch: 10, Loss: 0.4947850704193115, Accuracy: 0.8359375\n",
      "Batch: 11, Loss: 0.6270546913146973, Accuracy: 0.7958984375\n",
      "Batch: 12, Loss: 0.568608283996582, Accuracy: 0.806640625\n",
      "Batch: 13, Loss: 0.48166316747665405, Accuracy: 0.8359375\n",
      "Batch: 14, Loss: 0.5569295883178711, Accuracy: 0.806640625\n",
      "Batch: 15, Loss: 0.5223029255867004, Accuracy: 0.8486328125\n",
      "Batch: 16, Loss: 0.5199894905090332, Accuracy: 0.833984375\n",
      "Batch: 17, Loss: 0.5698338150978088, Accuracy: 0.82421875\n",
      "Batch: 18, Loss: 0.5603160262107849, Accuracy: 0.8037109375\n",
      "Batch: 19, Loss: 0.5751469731330872, Accuracy: 0.8310546875\n",
      "Batch: 20, Loss: 0.5307762622833252, Accuracy: 0.830078125\n",
      "Batch: 21, Loss: 0.46646973490715027, Accuracy: 0.84375\n",
      "Batch: 22, Loss: 0.6283137798309326, Accuracy: 0.7822265625\n",
      "Batch: 23, Loss: 0.6320375204086304, Accuracy: 0.7890625\n",
      "Batch: 24, Loss: 0.5620208382606506, Accuracy: 0.822265625\n",
      "Batch: 25, Loss: 0.5185275673866272, Accuracy: 0.8154296875\n",
      "Batch: 26, Loss: 0.4688718318939209, Accuracy: 0.84765625\n",
      "Batch: 27, Loss: 0.4908539056777954, Accuracy: 0.84375\n",
      "Batch: 28, Loss: 0.5457630157470703, Accuracy: 0.8154296875\n",
      "Batch: 29, Loss: 0.5544847249984741, Accuracy: 0.8076171875\n",
      "Batch: 30, Loss: 0.5063390731811523, Accuracy: 0.8330078125\n",
      "Batch: 31, Loss: 0.4839613139629364, Accuracy: 0.8388671875\n",
      "Batch: 32, Loss: 0.4911651611328125, Accuracy: 0.8447265625\n",
      "Batch: 33, Loss: 0.5774631500244141, Accuracy: 0.80859375\n",
      "Batch: 34, Loss: 0.610817015171051, Accuracy: 0.79296875\n",
      "Batch: 35, Loss: 0.5560168027877808, Accuracy: 0.8203125\n",
      "Batch: 36, Loss: 0.5461201071739197, Accuracy: 0.822265625\n",
      "Batch: 37, Loss: 0.5945241451263428, Accuracy: 0.8125\n",
      "Batch: 38, Loss: 0.5636914372444153, Accuracy: 0.826171875\n",
      "Batch: 39, Loss: 0.5377657413482666, Accuracy: 0.8212890625\n",
      "Batch: 40, Loss: 0.5799797773361206, Accuracy: 0.81640625\n",
      "Batch: 41, Loss: 0.504990816116333, Accuracy: 0.8330078125\n",
      "Batch: 42, Loss: 0.4358959197998047, Accuracy: 0.8642578125\n",
      "Batch: 43, Loss: 0.5336049199104309, Accuracy: 0.8212890625\n",
      "Batch: 44, Loss: 0.5739433765411377, Accuracy: 0.814453125\n",
      "Batch: 45, Loss: 0.48412272334098816, Accuracy: 0.841796875\n",
      "Batch: 46, Loss: 0.5331470966339111, Accuracy: 0.837890625\n",
      "Batch: 47, Loss: 0.5762729644775391, Accuracy: 0.8212890625\n",
      "Batch: 48, Loss: 0.5092687606811523, Accuracy: 0.8251953125\n",
      "Batch: 49, Loss: 0.5710239410400391, Accuracy: 0.7998046875\n",
      "Batch: 50, Loss: 0.5331814885139465, Accuracy: 0.8203125\n",
      "Batch: 51, Loss: 0.5789588689804077, Accuracy: 0.814453125\n",
      "Batch: 52, Loss: 0.5575438737869263, Accuracy: 0.818359375\n",
      "Batch: 53, Loss: 0.4842796325683594, Accuracy: 0.8447265625\n",
      "Batch: 54, Loss: 0.5575425028800964, Accuracy: 0.8251953125\n",
      "Batch: 55, Loss: 0.6077682971954346, Accuracy: 0.7880859375\n",
      "Batch: 56, Loss: 0.5869981050491333, Accuracy: 0.7978515625\n",
      "Batch: 57, Loss: 0.556244969367981, Accuracy: 0.822265625\n",
      "Batch: 58, Loss: 0.6344031691551208, Accuracy: 0.794921875\n",
      "Batch: 59, Loss: 0.538105845451355, Accuracy: 0.8232421875\n",
      "Batch: 60, Loss: 0.5079657435417175, Accuracy: 0.8330078125\n",
      "Batch: 61, Loss: 0.5885512232780457, Accuracy: 0.8046875\n",
      "Batch: 62, Loss: 0.5120688080787659, Accuracy: 0.833984375\n",
      "Batch: 63, Loss: 0.5963996648788452, Accuracy: 0.802734375\n",
      "Batch: 64, Loss: 0.5534292459487915, Accuracy: 0.8251953125\n",
      "Batch: 65, Loss: 0.5819276571273804, Accuracy: 0.8193359375\n",
      "Batch: 66, Loss: 0.5987968444824219, Accuracy: 0.802734375\n",
      "Batch: 67, Loss: 0.6045442223548889, Accuracy: 0.796875\n",
      "Batch: 68, Loss: 0.6412076950073242, Accuracy: 0.7900390625\n",
      "Batch: 69, Loss: 0.5620578527450562, Accuracy: 0.810546875\n",
      "Batch: 70, Loss: 0.5959635972976685, Accuracy: 0.8154296875\n",
      "Batch: 71, Loss: 0.6161370873451233, Accuracy: 0.7861328125\n",
      "Batch: 72, Loss: 0.5292956233024597, Accuracy: 0.830078125\n",
      "Batch: 73, Loss: 0.5102868676185608, Accuracy: 0.837890625\n",
      "Batch: 74, Loss: 0.5207763314247131, Accuracy: 0.837890625\n",
      "Batch: 75, Loss: 0.46003440022468567, Accuracy: 0.8564453125\n",
      "Batch: 76, Loss: 0.5473029613494873, Accuracy: 0.814453125\n",
      "Batch: 77, Loss: 0.5193747282028198, Accuracy: 0.8291015625\n",
      "Batch: 78, Loss: 0.4944111406803131, Accuracy: 0.845703125\n",
      "Batch: 79, Loss: 0.5207257866859436, Accuracy: 0.828125\n",
      "Batch: 80, Loss: 0.5130611658096313, Accuracy: 0.8310546875\n",
      "Batch: 81, Loss: 0.6082834005355835, Accuracy: 0.7939453125\n",
      "Batch: 82, Loss: 0.5506070852279663, Accuracy: 0.826171875\n",
      "Batch: 83, Loss: 0.4666447639465332, Accuracy: 0.8564453125\n",
      "Batch: 84, Loss: 0.5585643649101257, Accuracy: 0.8212890625\n",
      "Batch: 85, Loss: 0.5542201399803162, Accuracy: 0.8193359375\n",
      "Batch: 86, Loss: 0.5974245667457581, Accuracy: 0.80859375\n",
      "Batch: 87, Loss: 0.5225715041160583, Accuracy: 0.8369140625\n",
      "Batch: 88, Loss: 0.5770809054374695, Accuracy: 0.830078125\n",
      "Batch: 89, Loss: 0.5640603303909302, Accuracy: 0.810546875\n",
      "Batch: 90, Loss: 0.4913052022457123, Accuracy: 0.8359375\n",
      "Batch: 91, Loss: 0.5194588303565979, Accuracy: 0.830078125\n",
      "Batch: 92, Loss: 0.5519713163375854, Accuracy: 0.826171875\n",
      "Batch: 93, Loss: 0.6047846674919128, Accuracy: 0.798828125\n",
      "Batch: 94, Loss: 0.5744179487228394, Accuracy: 0.8154296875\n",
      "Batch: 95, Loss: 0.5644456148147583, Accuracy: 0.794921875\n",
      "Batch: 96, Loss: 0.5102527141571045, Accuracy: 0.828125\n",
      "Batch: 97, Loss: 0.44023582339286804, Accuracy: 0.86328125\n",
      "Batch: 98, Loss: 0.5496016144752502, Accuracy: 0.8125\n",
      "Batch: 99, Loss: 0.5647885799407959, Accuracy: 0.8203125\n",
      "Batch: 100, Loss: 0.5613257884979248, Accuracy: 0.8125\n",
      "Batch: 101, Loss: 0.5958194732666016, Accuracy: 0.7900390625\n",
      "Batch: 102, Loss: 0.5746446847915649, Accuracy: 0.830078125\n",
      "Batch: 103, Loss: 0.5920627117156982, Accuracy: 0.8017578125\n",
      "Batch: 104, Loss: 0.5464442372322083, Accuracy: 0.8154296875\n",
      "Batch: 105, Loss: 0.5684568285942078, Accuracy: 0.8173828125\n",
      "Batch: 106, Loss: 0.5015837550163269, Accuracy: 0.830078125\n",
      "Batch: 107, Loss: 0.5414741635322571, Accuracy: 0.828125\n",
      "Batch: 108, Loss: 0.5629570484161377, Accuracy: 0.8134765625\n",
      "Batch: 109, Loss: 0.5986694097518921, Accuracy: 0.7919921875\n",
      "Batch: 110, Loss: 0.5489356517791748, Accuracy: 0.81640625\n",
      "Batch: 111, Loss: 0.5740902423858643, Accuracy: 0.80859375\n",
      "Batch: 112, Loss: 0.5463839173316956, Accuracy: 0.826171875\n",
      "Batch: 113, Loss: 0.5254626274108887, Accuracy: 0.822265625\n",
      "Batch: 114, Loss: 0.6055471301078796, Accuracy: 0.794921875\n",
      "Batch: 115, Loss: 0.634322464466095, Accuracy: 0.791015625\n",
      "Batch: 116, Loss: 0.5567677617073059, Accuracy: 0.8291015625\n",
      "Batch: 117, Loss: 0.5428359508514404, Accuracy: 0.8203125\n",
      "Batch: 118, Loss: 0.5461145639419556, Accuracy: 0.822265625\n",
      "Batch: 119, Loss: 0.4725765585899353, Accuracy: 0.849609375\n",
      "Batch: 120, Loss: 0.5398922562599182, Accuracy: 0.8203125\n",
      "Batch: 121, Loss: 0.6203474998474121, Accuracy: 0.8037109375\n",
      "Batch: 122, Loss: 0.5837910175323486, Accuracy: 0.806640625\n",
      "Batch: 123, Loss: 0.5365822315216064, Accuracy: 0.830078125\n",
      "Batch: 124, Loss: 0.5635512471199036, Accuracy: 0.8173828125\n",
      "Batch: 125, Loss: 0.5918136239051819, Accuracy: 0.8212890625\n",
      "Batch: 126, Loss: 0.5709144473075867, Accuracy: 0.8115234375\n",
      "Batch: 127, Loss: 0.49333256483078003, Accuracy: 0.83984375\n",
      "Batch: 128, Loss: 0.5890535712242126, Accuracy: 0.802734375\n",
      "Batch: 129, Loss: 0.5307908058166504, Accuracy: 0.822265625\n",
      "Batch: 130, Loss: 0.5982280969619751, Accuracy: 0.796875\n",
      "Batch: 131, Loss: 0.5933810472488403, Accuracy: 0.78515625\n",
      "Batch: 132, Loss: 0.5800563097000122, Accuracy: 0.8271484375\n",
      "Batch: 133, Loss: 0.557280421257019, Accuracy: 0.826171875\n",
      "Batch: 134, Loss: 0.555076003074646, Accuracy: 0.8193359375\n",
      "Batch: 135, Loss: 0.5428001880645752, Accuracy: 0.822265625\n",
      "Batch: 136, Loss: 0.5500390529632568, Accuracy: 0.828125\n",
      "Batch: 137, Loss: 0.5586947202682495, Accuracy: 0.7919921875\n",
      "Batch: 138, Loss: 0.5063962936401367, Accuracy: 0.8291015625\n",
      "Batch: 139, Loss: 0.509211003780365, Accuracy: 0.8388671875\n",
      "Batch: 140, Loss: 0.548601508140564, Accuracy: 0.818359375\n",
      "Batch: 141, Loss: 0.6279082298278809, Accuracy: 0.80078125\n",
      "Batch: 142, Loss: 0.6579203605651855, Accuracy: 0.78515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 143, Loss: 0.5337377190589905, Accuracy: 0.814453125\n",
      "Batch: 144, Loss: 0.5916186571121216, Accuracy: 0.80078125\n",
      "Batch: 145, Loss: 0.5293035507202148, Accuracy: 0.810546875\n",
      "Batch: 146, Loss: 0.5715523958206177, Accuracy: 0.814453125\n",
      "Batch: 147, Loss: 0.5379571914672852, Accuracy: 0.8212890625\n",
      "Batch: 148, Loss: 0.5892858505249023, Accuracy: 0.8017578125\n",
      "Batch: 149, Loss: 0.5369942784309387, Accuracy: 0.8271484375\n",
      "Batch: 150, Loss: 0.5571648478507996, Accuracy: 0.8076171875\n",
      "Batch: 151, Loss: 0.5250194668769836, Accuracy: 0.8369140625\n",
      "Epoch 77/80\n",
      "Batch: 1, Loss: 0.718835175037384, Accuracy: 0.779296875\n",
      "Batch: 2, Loss: 0.5920394659042358, Accuracy: 0.7939453125\n",
      "Batch: 3, Loss: 0.5525756478309631, Accuracy: 0.810546875\n",
      "Batch: 4, Loss: 0.5173795819282532, Accuracy: 0.830078125\n",
      "Batch: 5, Loss: 0.5221748948097229, Accuracy: 0.8291015625\n",
      "Batch: 6, Loss: 0.5450299382209778, Accuracy: 0.8232421875\n",
      "Batch: 7, Loss: 0.5248335599899292, Accuracy: 0.818359375\n",
      "Batch: 8, Loss: 0.5356613397598267, Accuracy: 0.826171875\n",
      "Batch: 9, Loss: 0.5297856330871582, Accuracy: 0.81640625\n",
      "Batch: 10, Loss: 0.5174812078475952, Accuracy: 0.8251953125\n",
      "Batch: 11, Loss: 0.5783718228340149, Accuracy: 0.8046875\n",
      "Batch: 12, Loss: 0.5354131460189819, Accuracy: 0.8271484375\n",
      "Batch: 13, Loss: 0.4790470600128174, Accuracy: 0.8427734375\n",
      "Batch: 14, Loss: 0.5646981000900269, Accuracy: 0.8193359375\n",
      "Batch: 15, Loss: 0.4747565984725952, Accuracy: 0.845703125\n",
      "Batch: 16, Loss: 0.5078994035720825, Accuracy: 0.845703125\n",
      "Batch: 17, Loss: 0.5222819447517395, Accuracy: 0.8271484375\n",
      "Batch: 18, Loss: 0.5842688679695129, Accuracy: 0.7998046875\n",
      "Batch: 19, Loss: 0.555413007736206, Accuracy: 0.828125\n",
      "Batch: 20, Loss: 0.5320906639099121, Accuracy: 0.8271484375\n",
      "Batch: 21, Loss: 0.4937969446182251, Accuracy: 0.837890625\n",
      "Batch: 22, Loss: 0.5956228971481323, Accuracy: 0.7890625\n",
      "Batch: 23, Loss: 0.5684861540794373, Accuracy: 0.8154296875\n",
      "Batch: 24, Loss: 0.5747725963592529, Accuracy: 0.8056640625\n",
      "Batch: 25, Loss: 0.5269356966018677, Accuracy: 0.8291015625\n",
      "Batch: 26, Loss: 0.46033668518066406, Accuracy: 0.845703125\n",
      "Batch: 27, Loss: 0.5378270149230957, Accuracy: 0.8134765625\n",
      "Batch: 28, Loss: 0.5164352655410767, Accuracy: 0.822265625\n",
      "Batch: 29, Loss: 0.5276519060134888, Accuracy: 0.828125\n",
      "Batch: 30, Loss: 0.45666974782943726, Accuracy: 0.8515625\n",
      "Batch: 31, Loss: 0.4518282413482666, Accuracy: 0.853515625\n",
      "Batch: 32, Loss: 0.49459725618362427, Accuracy: 0.833984375\n",
      "Batch: 33, Loss: 0.5755777955055237, Accuracy: 0.8115234375\n",
      "Batch: 34, Loss: 0.6215956211090088, Accuracy: 0.8037109375\n",
      "Batch: 35, Loss: 0.5593816041946411, Accuracy: 0.8212890625\n",
      "Batch: 36, Loss: 0.5519639253616333, Accuracy: 0.81640625\n",
      "Batch: 37, Loss: 0.6008344292640686, Accuracy: 0.7958984375\n",
      "Batch: 38, Loss: 0.5562554597854614, Accuracy: 0.8046875\n",
      "Batch: 39, Loss: 0.556992769241333, Accuracy: 0.8212890625\n",
      "Batch: 40, Loss: 0.547549307346344, Accuracy: 0.826171875\n",
      "Batch: 41, Loss: 0.4946552515029907, Accuracy: 0.83203125\n",
      "Batch: 42, Loss: 0.4053425192832947, Accuracy: 0.86328125\n",
      "Batch: 43, Loss: 0.527567446231842, Accuracy: 0.8271484375\n",
      "Batch: 44, Loss: 0.5697252750396729, Accuracy: 0.8173828125\n",
      "Batch: 45, Loss: 0.5218095183372498, Accuracy: 0.82421875\n",
      "Batch: 46, Loss: 0.5225780010223389, Accuracy: 0.826171875\n",
      "Batch: 47, Loss: 0.5723222494125366, Accuracy: 0.818359375\n",
      "Batch: 48, Loss: 0.5499894618988037, Accuracy: 0.81640625\n",
      "Batch: 49, Loss: 0.5511504411697388, Accuracy: 0.822265625\n",
      "Batch: 50, Loss: 0.5075377225875854, Accuracy: 0.8349609375\n",
      "Batch: 51, Loss: 0.5868791341781616, Accuracy: 0.8037109375\n",
      "Batch: 52, Loss: 0.5329716205596924, Accuracy: 0.8369140625\n",
      "Batch: 53, Loss: 0.5342957973480225, Accuracy: 0.818359375\n",
      "Batch: 54, Loss: 0.5342228412628174, Accuracy: 0.83984375\n",
      "Batch: 55, Loss: 0.6208101511001587, Accuracy: 0.7880859375\n",
      "Batch: 56, Loss: 0.6000919342041016, Accuracy: 0.8076171875\n",
      "Batch: 57, Loss: 0.6069448590278625, Accuracy: 0.7978515625\n",
      "Batch: 58, Loss: 0.6285330057144165, Accuracy: 0.78515625\n",
      "Batch: 59, Loss: 0.5704964995384216, Accuracy: 0.8115234375\n",
      "Batch: 60, Loss: 0.5246156454086304, Accuracy: 0.822265625\n",
      "Batch: 61, Loss: 0.5632579326629639, Accuracy: 0.8154296875\n",
      "Batch: 62, Loss: 0.5381038784980774, Accuracy: 0.8271484375\n",
      "Batch: 63, Loss: 0.6074950098991394, Accuracy: 0.7958984375\n",
      "Batch: 64, Loss: 0.5011067986488342, Accuracy: 0.8212890625\n",
      "Batch: 65, Loss: 0.5706690549850464, Accuracy: 0.8291015625\n",
      "Batch: 66, Loss: 0.6014406681060791, Accuracy: 0.806640625\n",
      "Batch: 67, Loss: 0.6416904926300049, Accuracy: 0.7763671875\n",
      "Batch: 68, Loss: 0.6085920333862305, Accuracy: 0.8017578125\n",
      "Batch: 69, Loss: 0.5735068321228027, Accuracy: 0.8173828125\n",
      "Batch: 70, Loss: 0.5599944591522217, Accuracy: 0.822265625\n",
      "Batch: 71, Loss: 0.5876322984695435, Accuracy: 0.7978515625\n",
      "Batch: 72, Loss: 0.5418640375137329, Accuracy: 0.8193359375\n",
      "Batch: 73, Loss: 0.48348188400268555, Accuracy: 0.84375\n",
      "Batch: 74, Loss: 0.4791828393936157, Accuracy: 0.8623046875\n",
      "Batch: 75, Loss: 0.45704615116119385, Accuracy: 0.8515625\n",
      "Batch: 76, Loss: 0.5731135606765747, Accuracy: 0.8115234375\n",
      "Batch: 77, Loss: 0.5057228207588196, Accuracy: 0.8359375\n",
      "Batch: 78, Loss: 0.49334588646888733, Accuracy: 0.8466796875\n",
      "Batch: 79, Loss: 0.5293987989425659, Accuracy: 0.8330078125\n",
      "Batch: 80, Loss: 0.5202535390853882, Accuracy: 0.8388671875\n",
      "Batch: 81, Loss: 0.5921361446380615, Accuracy: 0.798828125\n",
      "Batch: 82, Loss: 0.5395451784133911, Accuracy: 0.828125\n",
      "Batch: 83, Loss: 0.4798286259174347, Accuracy: 0.841796875\n",
      "Batch: 84, Loss: 0.548963189125061, Accuracy: 0.8193359375\n",
      "Batch: 85, Loss: 0.5265160799026489, Accuracy: 0.818359375\n",
      "Batch: 86, Loss: 0.61318439245224, Accuracy: 0.8037109375\n",
      "Batch: 87, Loss: 0.4961709678173065, Accuracy: 0.8486328125\n",
      "Batch: 88, Loss: 0.5657659769058228, Accuracy: 0.8154296875\n",
      "Batch: 89, Loss: 0.5343809127807617, Accuracy: 0.8271484375\n",
      "Batch: 90, Loss: 0.5197232961654663, Accuracy: 0.83984375\n",
      "Batch: 91, Loss: 0.523821234703064, Accuracy: 0.8134765625\n",
      "Batch: 92, Loss: 0.591335117816925, Accuracy: 0.8095703125\n",
      "Batch: 93, Loss: 0.5432246923446655, Accuracy: 0.8271484375\n",
      "Batch: 94, Loss: 0.5560271739959717, Accuracy: 0.818359375\n",
      "Batch: 95, Loss: 0.5312156081199646, Accuracy: 0.826171875\n",
      "Batch: 96, Loss: 0.53666090965271, Accuracy: 0.822265625\n",
      "Batch: 97, Loss: 0.4508647918701172, Accuracy: 0.8544921875\n",
      "Batch: 98, Loss: 0.5420745611190796, Accuracy: 0.83203125\n",
      "Batch: 99, Loss: 0.5212684869766235, Accuracy: 0.828125\n",
      "Batch: 100, Loss: 0.5393954515457153, Accuracy: 0.8193359375\n",
      "Batch: 101, Loss: 0.5600417256355286, Accuracy: 0.8173828125\n",
      "Batch: 102, Loss: 0.5584393739700317, Accuracy: 0.8154296875\n",
      "Batch: 103, Loss: 0.5906060934066772, Accuracy: 0.818359375\n",
      "Batch: 104, Loss: 0.5271165370941162, Accuracy: 0.845703125\n",
      "Batch: 105, Loss: 0.5817802548408508, Accuracy: 0.80078125\n",
      "Batch: 106, Loss: 0.5106155872344971, Accuracy: 0.837890625\n",
      "Batch: 107, Loss: 0.5500465035438538, Accuracy: 0.83984375\n",
      "Batch: 108, Loss: 0.545398473739624, Accuracy: 0.8271484375\n",
      "Batch: 109, Loss: 0.5730372071266174, Accuracy: 0.806640625\n",
      "Batch: 110, Loss: 0.5203502774238586, Accuracy: 0.826171875\n",
      "Batch: 111, Loss: 0.5243320465087891, Accuracy: 0.8388671875\n",
      "Batch: 112, Loss: 0.5688515901565552, Accuracy: 0.8095703125\n",
      "Batch: 113, Loss: 0.5275697708129883, Accuracy: 0.826171875\n",
      "Batch: 114, Loss: 0.5760115385055542, Accuracy: 0.82421875\n",
      "Batch: 115, Loss: 0.6345161199569702, Accuracy: 0.7958984375\n",
      "Batch: 116, Loss: 0.5642899870872498, Accuracy: 0.8134765625\n",
      "Batch: 117, Loss: 0.5827842950820923, Accuracy: 0.8173828125\n",
      "Batch: 118, Loss: 0.5135337114334106, Accuracy: 0.837890625\n",
      "Batch: 119, Loss: 0.4843812882900238, Accuracy: 0.8359375\n",
      "Batch: 120, Loss: 0.547942578792572, Accuracy: 0.8125\n",
      "Batch: 121, Loss: 0.5995076894760132, Accuracy: 0.806640625\n",
      "Batch: 122, Loss: 0.5543999671936035, Accuracy: 0.8203125\n",
      "Batch: 123, Loss: 0.4974832534790039, Accuracy: 0.8408203125\n",
      "Batch: 124, Loss: 0.5861594676971436, Accuracy: 0.8046875\n",
      "Batch: 125, Loss: 0.5955532789230347, Accuracy: 0.810546875\n",
      "Batch: 126, Loss: 0.5919411182403564, Accuracy: 0.8056640625\n",
      "Batch: 127, Loss: 0.49192696809768677, Accuracy: 0.8369140625\n",
      "Batch: 128, Loss: 0.5816491842269897, Accuracy: 0.8134765625\n",
      "Batch: 129, Loss: 0.49856650829315186, Accuracy: 0.8359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 130, Loss: 0.6086351871490479, Accuracy: 0.7978515625\n",
      "Batch: 131, Loss: 0.6035014390945435, Accuracy: 0.80859375\n",
      "Batch: 132, Loss: 0.5924664735794067, Accuracy: 0.8115234375\n",
      "Batch: 133, Loss: 0.5308132767677307, Accuracy: 0.8125\n",
      "Batch: 134, Loss: 0.5823171734809875, Accuracy: 0.814453125\n",
      "Batch: 135, Loss: 0.5154836177825928, Accuracy: 0.8388671875\n",
      "Batch: 136, Loss: 0.571234941482544, Accuracy: 0.8154296875\n",
      "Batch: 137, Loss: 0.6089539527893066, Accuracy: 0.791015625\n",
      "Batch: 138, Loss: 0.502289354801178, Accuracy: 0.826171875\n",
      "Batch: 139, Loss: 0.5147804021835327, Accuracy: 0.833984375\n",
      "Batch: 140, Loss: 0.5744067430496216, Accuracy: 0.806640625\n",
      "Batch: 141, Loss: 0.6199896931648254, Accuracy: 0.794921875\n",
      "Batch: 142, Loss: 0.6212446689605713, Accuracy: 0.796875\n",
      "Batch: 143, Loss: 0.5469122529029846, Accuracy: 0.818359375\n",
      "Batch: 144, Loss: 0.5660789012908936, Accuracy: 0.8134765625\n",
      "Batch: 145, Loss: 0.5134136080741882, Accuracy: 0.8232421875\n",
      "Batch: 146, Loss: 0.562064528465271, Accuracy: 0.8076171875\n",
      "Batch: 147, Loss: 0.5507284998893738, Accuracy: 0.8330078125\n",
      "Batch: 148, Loss: 0.5813781023025513, Accuracy: 0.8154296875\n",
      "Batch: 149, Loss: 0.5368338823318481, Accuracy: 0.8271484375\n",
      "Batch: 150, Loss: 0.5396350026130676, Accuracy: 0.8212890625\n",
      "Batch: 151, Loss: 0.4999297261238098, Accuracy: 0.837890625\n",
      "Epoch 78/80\n",
      "Batch: 1, Loss: 0.7154512405395508, Accuracy: 0.77734375\n",
      "Batch: 2, Loss: 0.5772738456726074, Accuracy: 0.7919921875\n",
      "Batch: 3, Loss: 0.5647039413452148, Accuracy: 0.8193359375\n",
      "Batch: 4, Loss: 0.5164529085159302, Accuracy: 0.84375\n",
      "Batch: 5, Loss: 0.5377581119537354, Accuracy: 0.822265625\n",
      "Batch: 6, Loss: 0.5185085535049438, Accuracy: 0.8291015625\n",
      "Batch: 7, Loss: 0.5774129033088684, Accuracy: 0.8115234375\n",
      "Batch: 8, Loss: 0.5192051529884338, Accuracy: 0.81640625\n",
      "Batch: 9, Loss: 0.5524485111236572, Accuracy: 0.81640625\n",
      "Batch: 10, Loss: 0.5013912916183472, Accuracy: 0.82421875\n",
      "Batch: 11, Loss: 0.5526782274246216, Accuracy: 0.8193359375\n",
      "Batch: 12, Loss: 0.5649431943893433, Accuracy: 0.8212890625\n",
      "Batch: 13, Loss: 0.45028984546661377, Accuracy: 0.849609375\n",
      "Batch: 14, Loss: 0.569179892539978, Accuracy: 0.810546875\n",
      "Batch: 15, Loss: 0.5243157744407654, Accuracy: 0.8349609375\n",
      "Batch: 16, Loss: 0.5228639841079712, Accuracy: 0.826171875\n",
      "Batch: 17, Loss: 0.5309398174285889, Accuracy: 0.83203125\n",
      "Batch: 18, Loss: 0.5675582885742188, Accuracy: 0.80859375\n",
      "Batch: 19, Loss: 0.5556161403656006, Accuracy: 0.8369140625\n",
      "Batch: 20, Loss: 0.4878980219364166, Accuracy: 0.84375\n",
      "Batch: 21, Loss: 0.4777821898460388, Accuracy: 0.837890625\n",
      "Batch: 22, Loss: 0.6249756217002869, Accuracy: 0.79296875\n",
      "Batch: 23, Loss: 0.6299718618392944, Accuracy: 0.7880859375\n",
      "Batch: 24, Loss: 0.5775905251502991, Accuracy: 0.810546875\n",
      "Batch: 25, Loss: 0.5102278590202332, Accuracy: 0.837890625\n",
      "Batch: 26, Loss: 0.4531750977039337, Accuracy: 0.84765625\n",
      "Batch: 27, Loss: 0.47650599479675293, Accuracy: 0.837890625\n",
      "Batch: 28, Loss: 0.5298349261283875, Accuracy: 0.83203125\n",
      "Batch: 29, Loss: 0.5093065500259399, Accuracy: 0.8271484375\n",
      "Batch: 30, Loss: 0.48190224170684814, Accuracy: 0.8486328125\n",
      "Batch: 31, Loss: 0.4940987229347229, Accuracy: 0.8359375\n",
      "Batch: 32, Loss: 0.496783047914505, Accuracy: 0.83203125\n",
      "Batch: 33, Loss: 0.5508946180343628, Accuracy: 0.810546875\n",
      "Batch: 34, Loss: 0.569534182548523, Accuracy: 0.8154296875\n",
      "Batch: 35, Loss: 0.554938554763794, Accuracy: 0.8173828125\n",
      "Batch: 36, Loss: 0.5825332999229431, Accuracy: 0.814453125\n",
      "Batch: 37, Loss: 0.5878389477729797, Accuracy: 0.80078125\n",
      "Batch: 38, Loss: 0.5863097310066223, Accuracy: 0.8037109375\n",
      "Batch: 39, Loss: 0.5756486654281616, Accuracy: 0.8076171875\n",
      "Batch: 40, Loss: 0.5451585054397583, Accuracy: 0.8154296875\n",
      "Batch: 41, Loss: 0.5080374479293823, Accuracy: 0.8203125\n",
      "Batch: 42, Loss: 0.4169202446937561, Accuracy: 0.859375\n",
      "Batch: 43, Loss: 0.49083757400512695, Accuracy: 0.8408203125\n",
      "Batch: 44, Loss: 0.5355022549629211, Accuracy: 0.8203125\n",
      "Batch: 45, Loss: 0.4874994158744812, Accuracy: 0.8388671875\n",
      "Batch: 46, Loss: 0.507477879524231, Accuracy: 0.8349609375\n",
      "Batch: 47, Loss: 0.5767732262611389, Accuracy: 0.8251953125\n",
      "Batch: 48, Loss: 0.5394662022590637, Accuracy: 0.8212890625\n",
      "Batch: 49, Loss: 0.5739520192146301, Accuracy: 0.80859375\n",
      "Batch: 50, Loss: 0.5268586874008179, Accuracy: 0.8203125\n",
      "Batch: 51, Loss: 0.5583264827728271, Accuracy: 0.8310546875\n",
      "Batch: 52, Loss: 0.5263066291809082, Accuracy: 0.8388671875\n",
      "Batch: 53, Loss: 0.5195378065109253, Accuracy: 0.8408203125\n",
      "Batch: 54, Loss: 0.5282256603240967, Accuracy: 0.8134765625\n",
      "Batch: 55, Loss: 0.6025094389915466, Accuracy: 0.7939453125\n",
      "Batch: 56, Loss: 0.5888059139251709, Accuracy: 0.7978515625\n",
      "Batch: 57, Loss: 0.5809799432754517, Accuracy: 0.8056640625\n",
      "Batch: 58, Loss: 0.6237723231315613, Accuracy: 0.78515625\n",
      "Batch: 59, Loss: 0.560921311378479, Accuracy: 0.8232421875\n",
      "Batch: 60, Loss: 0.5194385051727295, Accuracy: 0.8251953125\n",
      "Batch: 61, Loss: 0.5413629412651062, Accuracy: 0.828125\n",
      "Batch: 62, Loss: 0.5044679045677185, Accuracy: 0.822265625\n",
      "Batch: 63, Loss: 0.5872659683227539, Accuracy: 0.810546875\n",
      "Batch: 64, Loss: 0.5278987288475037, Accuracy: 0.826171875\n",
      "Batch: 65, Loss: 0.5799393653869629, Accuracy: 0.818359375\n",
      "Batch: 66, Loss: 0.5973889827728271, Accuracy: 0.8076171875\n",
      "Batch: 67, Loss: 0.6141639947891235, Accuracy: 0.810546875\n",
      "Batch: 68, Loss: 0.6314880847930908, Accuracy: 0.802734375\n",
      "Batch: 69, Loss: 0.5634570121765137, Accuracy: 0.80078125\n",
      "Batch: 70, Loss: 0.5846819281578064, Accuracy: 0.8193359375\n",
      "Batch: 71, Loss: 0.5803873538970947, Accuracy: 0.7998046875\n",
      "Batch: 72, Loss: 0.5329656600952148, Accuracy: 0.8203125\n",
      "Batch: 73, Loss: 0.5172077417373657, Accuracy: 0.8310546875\n",
      "Batch: 74, Loss: 0.5327168703079224, Accuracy: 0.8369140625\n",
      "Batch: 75, Loss: 0.4630064368247986, Accuracy: 0.83984375\n",
      "Batch: 76, Loss: 0.5679789781570435, Accuracy: 0.8056640625\n",
      "Batch: 77, Loss: 0.4662435054779053, Accuracy: 0.84375\n",
      "Batch: 78, Loss: 0.5213115811347961, Accuracy: 0.8212890625\n",
      "Batch: 79, Loss: 0.5153055191040039, Accuracy: 0.8349609375\n",
      "Batch: 80, Loss: 0.5435253381729126, Accuracy: 0.8193359375\n",
      "Batch: 81, Loss: 0.53996741771698, Accuracy: 0.8173828125\n",
      "Batch: 82, Loss: 0.5383628606796265, Accuracy: 0.828125\n",
      "Batch: 83, Loss: 0.5025184154510498, Accuracy: 0.833984375\n",
      "Batch: 84, Loss: 0.5516883134841919, Accuracy: 0.818359375\n",
      "Batch: 85, Loss: 0.5104541182518005, Accuracy: 0.83203125\n",
      "Batch: 86, Loss: 0.6619240641593933, Accuracy: 0.7890625\n",
      "Batch: 87, Loss: 0.5353761315345764, Accuracy: 0.8251953125\n",
      "Batch: 88, Loss: 0.5320560932159424, Accuracy: 0.8291015625\n",
      "Batch: 89, Loss: 0.5060616135597229, Accuracy: 0.8349609375\n",
      "Batch: 90, Loss: 0.5544071197509766, Accuracy: 0.8193359375\n",
      "Batch: 91, Loss: 0.5140261650085449, Accuracy: 0.830078125\n",
      "Batch: 92, Loss: 0.5808882713317871, Accuracy: 0.8173828125\n",
      "Batch: 93, Loss: 0.567173957824707, Accuracy: 0.810546875\n",
      "Batch: 94, Loss: 0.5618582963943481, Accuracy: 0.8203125\n",
      "Batch: 95, Loss: 0.5449885129928589, Accuracy: 0.806640625\n",
      "Batch: 96, Loss: 0.5094963312149048, Accuracy: 0.826171875\n",
      "Batch: 97, Loss: 0.4507526159286499, Accuracy: 0.8505859375\n",
      "Batch: 98, Loss: 0.5545297861099243, Accuracy: 0.8154296875\n",
      "Batch: 99, Loss: 0.5277242660522461, Accuracy: 0.8232421875\n",
      "Batch: 100, Loss: 0.5562748312950134, Accuracy: 0.814453125\n",
      "Batch: 101, Loss: 0.5780481696128845, Accuracy: 0.81640625\n",
      "Batch: 102, Loss: 0.5679202675819397, Accuracy: 0.8095703125\n",
      "Batch: 103, Loss: 0.5479766726493835, Accuracy: 0.833984375\n",
      "Batch: 104, Loss: 0.5195372104644775, Accuracy: 0.8369140625\n",
      "Batch: 105, Loss: 0.5602725744247437, Accuracy: 0.80859375\n",
      "Batch: 106, Loss: 0.5035898089408875, Accuracy: 0.83984375\n",
      "Batch: 107, Loss: 0.5416396260261536, Accuracy: 0.8310546875\n",
      "Batch: 108, Loss: 0.5486796498298645, Accuracy: 0.822265625\n",
      "Batch: 109, Loss: 0.616862416267395, Accuracy: 0.7919921875\n",
      "Batch: 110, Loss: 0.5310090780258179, Accuracy: 0.82421875\n",
      "Batch: 111, Loss: 0.5549653172492981, Accuracy: 0.8154296875\n",
      "Batch: 112, Loss: 0.579268753528595, Accuracy: 0.8056640625\n",
      "Batch: 113, Loss: 0.5302602648735046, Accuracy: 0.8310546875\n",
      "Batch: 114, Loss: 0.5644175410270691, Accuracy: 0.826171875\n",
      "Batch: 115, Loss: 0.6082547903060913, Accuracy: 0.7978515625\n",
      "Batch: 116, Loss: 0.5651828050613403, Accuracy: 0.8076171875\n",
      "Batch: 117, Loss: 0.586112916469574, Accuracy: 0.8125\n",
      "Batch: 118, Loss: 0.5034483075141907, Accuracy: 0.8369140625\n",
      "Batch: 119, Loss: 0.49735361337661743, Accuracy: 0.845703125\n",
      "Batch: 120, Loss: 0.5107046365737915, Accuracy: 0.8251953125\n",
      "Batch: 121, Loss: 0.6144751906394958, Accuracy: 0.814453125\n",
      "Batch: 122, Loss: 0.5343778133392334, Accuracy: 0.830078125\n",
      "Batch: 123, Loss: 0.4899614453315735, Accuracy: 0.849609375\n",
      "Batch: 124, Loss: 0.5344188213348389, Accuracy: 0.8232421875\n",
      "Batch: 125, Loss: 0.5942033529281616, Accuracy: 0.798828125\n",
      "Batch: 126, Loss: 0.5767866373062134, Accuracy: 0.8095703125\n",
      "Batch: 127, Loss: 0.4930887222290039, Accuracy: 0.8359375\n",
      "Batch: 128, Loss: 0.6162505745887756, Accuracy: 0.80859375\n",
      "Batch: 129, Loss: 0.48433172702789307, Accuracy: 0.8388671875\n",
      "Batch: 130, Loss: 0.5831018686294556, Accuracy: 0.8154296875\n",
      "Batch: 131, Loss: 0.5381866693496704, Accuracy: 0.8212890625\n",
      "Batch: 132, Loss: 0.5746392011642456, Accuracy: 0.8076171875\n",
      "Batch: 133, Loss: 0.5523250102996826, Accuracy: 0.8154296875\n",
      "Batch: 134, Loss: 0.5591962337493896, Accuracy: 0.7998046875\n",
      "Batch: 135, Loss: 0.5209833383560181, Accuracy: 0.83984375\n",
      "Batch: 136, Loss: 0.5800852179527283, Accuracy: 0.8095703125\n",
      "Batch: 137, Loss: 0.5605608224868774, Accuracy: 0.8076171875\n",
      "Batch: 138, Loss: 0.513227105140686, Accuracy: 0.828125\n",
      "Batch: 139, Loss: 0.5169838666915894, Accuracy: 0.8203125\n",
      "Batch: 140, Loss: 0.554128110408783, Accuracy: 0.822265625\n",
      "Batch: 141, Loss: 0.5605638027191162, Accuracy: 0.8232421875\n",
      "Batch: 142, Loss: 0.6114943623542786, Accuracy: 0.7998046875\n",
      "Batch: 143, Loss: 0.5457116365432739, Accuracy: 0.8115234375\n",
      "Batch: 144, Loss: 0.5503174066543579, Accuracy: 0.8232421875\n",
      "Batch: 145, Loss: 0.495065838098526, Accuracy: 0.8291015625\n",
      "Batch: 146, Loss: 0.6033365726470947, Accuracy: 0.794921875\n",
      "Batch: 147, Loss: 0.49437761306762695, Accuracy: 0.8447265625\n",
      "Batch: 148, Loss: 0.5506783723831177, Accuracy: 0.826171875\n",
      "Batch: 149, Loss: 0.5459595918655396, Accuracy: 0.8310546875\n",
      "Batch: 150, Loss: 0.5142176151275635, Accuracy: 0.833984375\n",
      "Batch: 151, Loss: 0.5357678532600403, Accuracy: 0.822265625\n",
      "Epoch 79/80\n",
      "Batch: 1, Loss: 0.7197142243385315, Accuracy: 0.7861328125\n",
      "Batch: 2, Loss: 0.5741604566574097, Accuracy: 0.791015625\n",
      "Batch: 3, Loss: 0.5112185478210449, Accuracy: 0.8359375\n",
      "Batch: 4, Loss: 0.4873884916305542, Accuracy: 0.8447265625\n",
      "Batch: 5, Loss: 0.515830397605896, Accuracy: 0.83203125\n",
      "Batch: 6, Loss: 0.5645055770874023, Accuracy: 0.810546875\n",
      "Batch: 7, Loss: 0.548471212387085, Accuracy: 0.7939453125\n",
      "Batch: 8, Loss: 0.5244760513305664, Accuracy: 0.81640625\n",
      "Batch: 9, Loss: 0.5212271213531494, Accuracy: 0.814453125\n",
      "Batch: 10, Loss: 0.5280001163482666, Accuracy: 0.814453125\n",
      "Batch: 11, Loss: 0.5479198694229126, Accuracy: 0.82421875\n",
      "Batch: 12, Loss: 0.5502854585647583, Accuracy: 0.8203125\n",
      "Batch: 13, Loss: 0.4565083384513855, Accuracy: 0.8515625\n",
      "Batch: 14, Loss: 0.5356968641281128, Accuracy: 0.8095703125\n",
      "Batch: 15, Loss: 0.49815627932548523, Accuracy: 0.84375\n",
      "Batch: 16, Loss: 0.5122887492179871, Accuracy: 0.8369140625\n",
      "Batch: 17, Loss: 0.5355948209762573, Accuracy: 0.806640625\n",
      "Batch: 18, Loss: 0.5117533802986145, Accuracy: 0.8359375\n",
      "Batch: 19, Loss: 0.5484259724617004, Accuracy: 0.8125\n",
      "Batch: 20, Loss: 0.5064306259155273, Accuracy: 0.8349609375\n",
      "Batch: 21, Loss: 0.49143677949905396, Accuracy: 0.830078125\n",
      "Batch: 22, Loss: 0.6115951538085938, Accuracy: 0.8046875\n",
      "Batch: 23, Loss: 0.6193365454673767, Accuracy: 0.7900390625\n",
      "Batch: 24, Loss: 0.5645028352737427, Accuracy: 0.82421875\n",
      "Batch: 25, Loss: 0.47245872020721436, Accuracy: 0.849609375\n",
      "Batch: 26, Loss: 0.4440828561782837, Accuracy: 0.865234375\n",
      "Batch: 27, Loss: 0.5142867565155029, Accuracy: 0.8349609375\n",
      "Batch: 28, Loss: 0.5360813140869141, Accuracy: 0.826171875\n",
      "Batch: 29, Loss: 0.49584871530532837, Accuracy: 0.8349609375\n",
      "Batch: 30, Loss: 0.4751759171485901, Accuracy: 0.84375\n",
      "Batch: 31, Loss: 0.4432268440723419, Accuracy: 0.8525390625\n",
      "Batch: 32, Loss: 0.4903505742549896, Accuracy: 0.841796875\n",
      "Batch: 33, Loss: 0.5606599450111389, Accuracy: 0.822265625\n",
      "Batch: 34, Loss: 0.5980339050292969, Accuracy: 0.806640625\n",
      "Batch: 35, Loss: 0.575459361076355, Accuracy: 0.810546875\n",
      "Batch: 36, Loss: 0.5284748077392578, Accuracy: 0.828125\n",
      "Batch: 37, Loss: 0.544978678226471, Accuracy: 0.8134765625\n",
      "Batch: 38, Loss: 0.5815770030021667, Accuracy: 0.7998046875\n",
      "Batch: 39, Loss: 0.5495612621307373, Accuracy: 0.8154296875\n",
      "Batch: 40, Loss: 0.527554988861084, Accuracy: 0.8212890625\n",
      "Batch: 41, Loss: 0.5098670721054077, Accuracy: 0.8349609375\n",
      "Batch: 42, Loss: 0.41259995102882385, Accuracy: 0.8583984375\n",
      "Batch: 43, Loss: 0.504326581954956, Accuracy: 0.8408203125\n",
      "Batch: 44, Loss: 0.5961806774139404, Accuracy: 0.8134765625\n",
      "Batch: 45, Loss: 0.46084946393966675, Accuracy: 0.853515625\n",
      "Batch: 46, Loss: 0.5104831457138062, Accuracy: 0.830078125\n",
      "Batch: 47, Loss: 0.5547287464141846, Accuracy: 0.826171875\n",
      "Batch: 48, Loss: 0.5007363557815552, Accuracy: 0.8369140625\n",
      "Batch: 49, Loss: 0.5348144769668579, Accuracy: 0.8212890625\n",
      "Batch: 50, Loss: 0.5140853524208069, Accuracy: 0.8271484375\n",
      "Batch: 51, Loss: 0.5553203821182251, Accuracy: 0.8154296875\n",
      "Batch: 52, Loss: 0.5048589706420898, Accuracy: 0.8291015625\n",
      "Batch: 53, Loss: 0.4793999493122101, Accuracy: 0.828125\n",
      "Batch: 54, Loss: 0.5172067880630493, Accuracy: 0.8310546875\n",
      "Batch: 55, Loss: 0.5643196702003479, Accuracy: 0.8154296875\n",
      "Batch: 56, Loss: 0.5675819516181946, Accuracy: 0.8046875\n",
      "Batch: 57, Loss: 0.5610936880111694, Accuracy: 0.8046875\n",
      "Batch: 58, Loss: 0.6035661697387695, Accuracy: 0.8017578125\n",
      "Batch: 59, Loss: 0.5777239799499512, Accuracy: 0.818359375\n",
      "Batch: 60, Loss: 0.4995554983615875, Accuracy: 0.8291015625\n",
      "Batch: 61, Loss: 0.5571004152297974, Accuracy: 0.8212890625\n",
      "Batch: 62, Loss: 0.4944368004798889, Accuracy: 0.8271484375\n",
      "Batch: 63, Loss: 0.56890469789505, Accuracy: 0.7998046875\n",
      "Batch: 64, Loss: 0.5235499739646912, Accuracy: 0.8349609375\n",
      "Batch: 65, Loss: 0.5678354501724243, Accuracy: 0.8212890625\n",
      "Batch: 66, Loss: 0.5625318288803101, Accuracy: 0.822265625\n",
      "Batch: 67, Loss: 0.5783929228782654, Accuracy: 0.810546875\n",
      "Batch: 68, Loss: 0.6014947891235352, Accuracy: 0.7900390625\n",
      "Batch: 69, Loss: 0.5823847055435181, Accuracy: 0.8115234375\n",
      "Batch: 70, Loss: 0.590645432472229, Accuracy: 0.8193359375\n",
      "Batch: 71, Loss: 0.5677887201309204, Accuracy: 0.826171875\n",
      "Batch: 72, Loss: 0.5171709060668945, Accuracy: 0.828125\n",
      "Batch: 73, Loss: 0.5056449770927429, Accuracy: 0.8466796875\n",
      "Batch: 74, Loss: 0.5022899508476257, Accuracy: 0.8505859375\n",
      "Batch: 75, Loss: 0.4500771760940552, Accuracy: 0.8505859375\n",
      "Batch: 76, Loss: 0.5624166131019592, Accuracy: 0.8251953125\n",
      "Batch: 77, Loss: 0.45289915800094604, Accuracy: 0.857421875\n",
      "Batch: 78, Loss: 0.49658775329589844, Accuracy: 0.8427734375\n",
      "Batch: 79, Loss: 0.5277807712554932, Accuracy: 0.828125\n",
      "Batch: 80, Loss: 0.5269101858139038, Accuracy: 0.8251953125\n",
      "Batch: 81, Loss: 0.5734224319458008, Accuracy: 0.8125\n",
      "Batch: 82, Loss: 0.5290021896362305, Accuracy: 0.82421875\n",
      "Batch: 83, Loss: 0.4762752950191498, Accuracy: 0.85546875\n",
      "Batch: 84, Loss: 0.584865927696228, Accuracy: 0.818359375\n",
      "Batch: 85, Loss: 0.5420066118240356, Accuracy: 0.830078125\n",
      "Batch: 86, Loss: 0.5760109424591064, Accuracy: 0.81640625\n",
      "Batch: 87, Loss: 0.517566442489624, Accuracy: 0.837890625\n",
      "Batch: 88, Loss: 0.5565344095230103, Accuracy: 0.8232421875\n",
      "Batch: 89, Loss: 0.5254267454147339, Accuracy: 0.83984375\n",
      "Batch: 90, Loss: 0.5474694967269897, Accuracy: 0.8193359375\n",
      "Batch: 91, Loss: 0.5249624252319336, Accuracy: 0.828125\n",
      "Batch: 92, Loss: 0.5519988536834717, Accuracy: 0.814453125\n",
      "Batch: 93, Loss: 0.5424529314041138, Accuracy: 0.8251953125\n",
      "Batch: 94, Loss: 0.5857797861099243, Accuracy: 0.80078125\n",
      "Batch: 95, Loss: 0.553199291229248, Accuracy: 0.8154296875\n",
      "Batch: 96, Loss: 0.5530551075935364, Accuracy: 0.826171875\n",
      "Batch: 97, Loss: 0.44000211358070374, Accuracy: 0.8515625\n",
      "Batch: 98, Loss: 0.5485583543777466, Accuracy: 0.818359375\n",
      "Batch: 99, Loss: 0.523461103439331, Accuracy: 0.8291015625\n",
      "Batch: 100, Loss: 0.5406559109687805, Accuracy: 0.8212890625\n",
      "Batch: 101, Loss: 0.5932775735855103, Accuracy: 0.802734375\n",
      "Batch: 102, Loss: 0.5486047267913818, Accuracy: 0.822265625\n",
      "Batch: 103, Loss: 0.5665352940559387, Accuracy: 0.8173828125\n",
      "Batch: 104, Loss: 0.5151721239089966, Accuracy: 0.83203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 105, Loss: 0.5420881509780884, Accuracy: 0.8203125\n",
      "Batch: 106, Loss: 0.48552197217941284, Accuracy: 0.845703125\n",
      "Batch: 107, Loss: 0.5340393781661987, Accuracy: 0.8271484375\n",
      "Batch: 108, Loss: 0.5196688175201416, Accuracy: 0.828125\n",
      "Batch: 109, Loss: 0.5787539482116699, Accuracy: 0.794921875\n",
      "Batch: 110, Loss: 0.5169410705566406, Accuracy: 0.8203125\n",
      "Batch: 111, Loss: 0.5588822364807129, Accuracy: 0.8173828125\n",
      "Batch: 112, Loss: 0.5685603022575378, Accuracy: 0.8173828125\n",
      "Batch: 113, Loss: 0.5129558444023132, Accuracy: 0.8310546875\n",
      "Batch: 114, Loss: 0.5745334625244141, Accuracy: 0.8134765625\n",
      "Batch: 115, Loss: 0.6137423515319824, Accuracy: 0.798828125\n",
      "Batch: 116, Loss: 0.554692804813385, Accuracy: 0.8017578125\n",
      "Batch: 117, Loss: 0.5618748068809509, Accuracy: 0.8154296875\n",
      "Batch: 118, Loss: 0.526528000831604, Accuracy: 0.830078125\n",
      "Batch: 119, Loss: 0.46586543321609497, Accuracy: 0.8447265625\n",
      "Batch: 120, Loss: 0.5205382108688354, Accuracy: 0.830078125\n",
      "Batch: 121, Loss: 0.5951483249664307, Accuracy: 0.7978515625\n",
      "Batch: 122, Loss: 0.5306610465049744, Accuracy: 0.8271484375\n",
      "Batch: 123, Loss: 0.5094578862190247, Accuracy: 0.8330078125\n",
      "Batch: 124, Loss: 0.5401737689971924, Accuracy: 0.8173828125\n",
      "Batch: 125, Loss: 0.5766279101371765, Accuracy: 0.8115234375\n",
      "Batch: 126, Loss: 0.5515832901000977, Accuracy: 0.8251953125\n",
      "Batch: 127, Loss: 0.4697619378566742, Accuracy: 0.857421875\n",
      "Batch: 128, Loss: 0.5814732909202576, Accuracy: 0.81640625\n",
      "Batch: 129, Loss: 0.5143846869468689, Accuracy: 0.8388671875\n",
      "Batch: 130, Loss: 0.5751203298568726, Accuracy: 0.8056640625\n",
      "Batch: 131, Loss: 0.5778523087501526, Accuracy: 0.8115234375\n",
      "Batch: 132, Loss: 0.5886867046356201, Accuracy: 0.8056640625\n",
      "Batch: 133, Loss: 0.5409132242202759, Accuracy: 0.818359375\n",
      "Batch: 134, Loss: 0.531635582447052, Accuracy: 0.8134765625\n",
      "Batch: 135, Loss: 0.5205873250961304, Accuracy: 0.826171875\n",
      "Batch: 136, Loss: 0.5558277368545532, Accuracy: 0.8232421875\n",
      "Batch: 137, Loss: 0.5482960939407349, Accuracy: 0.796875\n",
      "Batch: 138, Loss: 0.49799466133117676, Accuracy: 0.8310546875\n",
      "Batch: 139, Loss: 0.5159616470336914, Accuracy: 0.826171875\n",
      "Batch: 140, Loss: 0.5755714774131775, Accuracy: 0.814453125\n",
      "Batch: 141, Loss: 0.5751603245735168, Accuracy: 0.810546875\n",
      "Batch: 142, Loss: 0.6108245849609375, Accuracy: 0.810546875\n",
      "Batch: 143, Loss: 0.5109630823135376, Accuracy: 0.830078125\n",
      "Batch: 144, Loss: 0.5586031079292297, Accuracy: 0.8291015625\n",
      "Batch: 145, Loss: 0.5202260613441467, Accuracy: 0.8251953125\n",
      "Batch: 146, Loss: 0.5471431612968445, Accuracy: 0.8173828125\n",
      "Batch: 147, Loss: 0.5178323984146118, Accuracy: 0.8349609375\n",
      "Batch: 148, Loss: 0.5831002593040466, Accuracy: 0.818359375\n",
      "Batch: 149, Loss: 0.5503586530685425, Accuracy: 0.8173828125\n",
      "Batch: 150, Loss: 0.5400422811508179, Accuracy: 0.81640625\n",
      "Batch: 151, Loss: 0.5024241209030151, Accuracy: 0.8291015625\n",
      "Epoch 80/80\n",
      "Batch: 1, Loss: 0.7229949235916138, Accuracy: 0.765625\n",
      "Batch: 2, Loss: 0.5553115606307983, Accuracy: 0.7978515625\n",
      "Batch: 3, Loss: 0.5237398147583008, Accuracy: 0.826171875\n",
      "Batch: 4, Loss: 0.464785635471344, Accuracy: 0.853515625\n",
      "Batch: 5, Loss: 0.5309693217277527, Accuracy: 0.822265625\n",
      "Batch: 6, Loss: 0.5222781300544739, Accuracy: 0.818359375\n",
      "Batch: 7, Loss: 0.5058127641677856, Accuracy: 0.8212890625\n",
      "Batch: 8, Loss: 0.5149341821670532, Accuracy: 0.84375\n",
      "Batch: 9, Loss: 0.5418332815170288, Accuracy: 0.8232421875\n",
      "Batch: 10, Loss: 0.5283719301223755, Accuracy: 0.8193359375\n",
      "Batch: 11, Loss: 0.5799070596694946, Accuracy: 0.7861328125\n",
      "Batch: 12, Loss: 0.5697743892669678, Accuracy: 0.806640625\n",
      "Batch: 13, Loss: 0.46857911348342896, Accuracy: 0.841796875\n",
      "Batch: 14, Loss: 0.5728368759155273, Accuracy: 0.810546875\n",
      "Batch: 15, Loss: 0.5055279731750488, Accuracy: 0.8359375\n",
      "Batch: 16, Loss: 0.49234485626220703, Accuracy: 0.853515625\n",
      "Batch: 17, Loss: 0.519600510597229, Accuracy: 0.830078125\n",
      "Batch: 18, Loss: 0.5788507461547852, Accuracy: 0.8203125\n",
      "Batch: 19, Loss: 0.5509792566299438, Accuracy: 0.8251953125\n",
      "Batch: 20, Loss: 0.4798572063446045, Accuracy: 0.84765625\n",
      "Batch: 21, Loss: 0.4693288803100586, Accuracy: 0.8310546875\n",
      "Batch: 22, Loss: 0.5788066983222961, Accuracy: 0.8056640625\n",
      "Batch: 23, Loss: 0.5862017869949341, Accuracy: 0.79296875\n",
      "Batch: 24, Loss: 0.5691941976547241, Accuracy: 0.8115234375\n",
      "Batch: 25, Loss: 0.5157207250595093, Accuracy: 0.8271484375\n",
      "Batch: 26, Loss: 0.45146769285202026, Accuracy: 0.8564453125\n",
      "Batch: 27, Loss: 0.5045238137245178, Accuracy: 0.8359375\n",
      "Batch: 28, Loss: 0.5112589001655579, Accuracy: 0.8359375\n",
      "Batch: 29, Loss: 0.49485355615615845, Accuracy: 0.8330078125\n",
      "Batch: 30, Loss: 0.4676785469055176, Accuracy: 0.8466796875\n",
      "Batch: 31, Loss: 0.45888158679008484, Accuracy: 0.849609375\n",
      "Batch: 32, Loss: 0.5157259702682495, Accuracy: 0.8359375\n",
      "Batch: 33, Loss: 0.5848706960678101, Accuracy: 0.8095703125\n",
      "Batch: 34, Loss: 0.5920883417129517, Accuracy: 0.8076171875\n",
      "Batch: 35, Loss: 0.5509966611862183, Accuracy: 0.822265625\n",
      "Batch: 36, Loss: 0.5683302879333496, Accuracy: 0.8076171875\n",
      "Batch: 37, Loss: 0.5909311771392822, Accuracy: 0.81640625\n",
      "Batch: 38, Loss: 0.6010929942131042, Accuracy: 0.7978515625\n",
      "Batch: 39, Loss: 0.5188994407653809, Accuracy: 0.830078125\n",
      "Batch: 40, Loss: 0.5124878883361816, Accuracy: 0.8369140625\n",
      "Batch: 41, Loss: 0.4689124524593353, Accuracy: 0.8466796875\n",
      "Batch: 42, Loss: 0.4237416982650757, Accuracy: 0.859375\n",
      "Batch: 43, Loss: 0.5220136046409607, Accuracy: 0.84375\n",
      "Batch: 44, Loss: 0.5341705083847046, Accuracy: 0.8203125\n",
      "Batch: 45, Loss: 0.4762136936187744, Accuracy: 0.8349609375\n",
      "Batch: 46, Loss: 0.4669404625892639, Accuracy: 0.8486328125\n",
      "Batch: 47, Loss: 0.5354976654052734, Accuracy: 0.8232421875\n",
      "Batch: 48, Loss: 0.49856826663017273, Accuracy: 0.8349609375\n",
      "Batch: 49, Loss: 0.5404480695724487, Accuracy: 0.822265625\n",
      "Batch: 50, Loss: 0.5528361797332764, Accuracy: 0.822265625\n",
      "Batch: 51, Loss: 0.5113075971603394, Accuracy: 0.8369140625\n",
      "Batch: 52, Loss: 0.525987982749939, Accuracy: 0.814453125\n",
      "Batch: 53, Loss: 0.4748554825782776, Accuracy: 0.845703125\n",
      "Batch: 54, Loss: 0.5249254703521729, Accuracy: 0.822265625\n",
      "Batch: 55, Loss: 0.5732325315475464, Accuracy: 0.7958984375\n",
      "Batch: 56, Loss: 0.5793110132217407, Accuracy: 0.806640625\n",
      "Batch: 57, Loss: 0.5850629210472107, Accuracy: 0.81640625\n",
      "Batch: 58, Loss: 0.6247182488441467, Accuracy: 0.8037109375\n",
      "Batch: 59, Loss: 0.5241057872772217, Accuracy: 0.8212890625\n",
      "Batch: 60, Loss: 0.5037615299224854, Accuracy: 0.8251953125\n",
      "Batch: 61, Loss: 0.5437256097793579, Accuracy: 0.8193359375\n",
      "Batch: 62, Loss: 0.502647876739502, Accuracy: 0.8388671875\n",
      "Batch: 63, Loss: 0.5502721667289734, Accuracy: 0.8076171875\n",
      "Batch: 64, Loss: 0.5263669490814209, Accuracy: 0.8271484375\n",
      "Batch: 65, Loss: 0.5651691555976868, Accuracy: 0.8232421875\n",
      "Batch: 66, Loss: 0.573500394821167, Accuracy: 0.8310546875\n",
      "Batch: 67, Loss: 0.590930163860321, Accuracy: 0.798828125\n",
      "Batch: 68, Loss: 0.5908538103103638, Accuracy: 0.802734375\n",
      "Batch: 69, Loss: 0.5960912704467773, Accuracy: 0.80078125\n",
      "Batch: 70, Loss: 0.5916862487792969, Accuracy: 0.8095703125\n",
      "Batch: 71, Loss: 0.5852724313735962, Accuracy: 0.806640625\n",
      "Batch: 72, Loss: 0.5158792734146118, Accuracy: 0.830078125\n",
      "Batch: 73, Loss: 0.5142662525177002, Accuracy: 0.8408203125\n",
      "Batch: 74, Loss: 0.49499794840812683, Accuracy: 0.8427734375\n",
      "Batch: 75, Loss: 0.45302268862724304, Accuracy: 0.8515625\n",
      "Batch: 76, Loss: 0.5710307359695435, Accuracy: 0.826171875\n",
      "Batch: 77, Loss: 0.4758942723274231, Accuracy: 0.8447265625\n",
      "Batch: 78, Loss: 0.49474388360977173, Accuracy: 0.841796875\n",
      "Batch: 79, Loss: 0.4928833842277527, Accuracy: 0.84765625\n",
      "Batch: 80, Loss: 0.5255007743835449, Accuracy: 0.82421875\n",
      "Batch: 81, Loss: 0.5433095693588257, Accuracy: 0.8046875\n",
      "Batch: 82, Loss: 0.5421080589294434, Accuracy: 0.833984375\n",
      "Batch: 83, Loss: 0.4819604158401489, Accuracy: 0.8525390625\n",
      "Batch: 84, Loss: 0.5553147792816162, Accuracy: 0.828125\n",
      "Batch: 85, Loss: 0.5340225696563721, Accuracy: 0.830078125\n",
      "Batch: 86, Loss: 0.5969260334968567, Accuracy: 0.8173828125\n",
      "Batch: 87, Loss: 0.5034124851226807, Accuracy: 0.8330078125\n",
      "Batch: 88, Loss: 0.5171511173248291, Accuracy: 0.828125\n",
      "Batch: 89, Loss: 0.518446683883667, Accuracy: 0.8330078125\n",
      "Batch: 90, Loss: 0.5340166687965393, Accuracy: 0.830078125\n",
      "Batch: 91, Loss: 0.46379750967025757, Accuracy: 0.8427734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 92, Loss: 0.5714088082313538, Accuracy: 0.8203125\n",
      "Batch: 93, Loss: 0.5546552538871765, Accuracy: 0.8232421875\n",
      "Batch: 94, Loss: 0.5627726316452026, Accuracy: 0.8232421875\n",
      "Batch: 95, Loss: 0.5498627424240112, Accuracy: 0.8203125\n",
      "Batch: 96, Loss: 0.5293312668800354, Accuracy: 0.8251953125\n",
      "Batch: 97, Loss: 0.43617743253707886, Accuracy: 0.837890625\n",
      "Batch: 98, Loss: 0.5407483577728271, Accuracy: 0.8232421875\n",
      "Batch: 99, Loss: 0.5076850652694702, Accuracy: 0.8359375\n",
      "Batch: 100, Loss: 0.5537816882133484, Accuracy: 0.8095703125\n",
      "Batch: 101, Loss: 0.5573771595954895, Accuracy: 0.818359375\n",
      "Batch: 102, Loss: 0.540254533290863, Accuracy: 0.828125\n",
      "Batch: 103, Loss: 0.5629477500915527, Accuracy: 0.8154296875\n",
      "Batch: 104, Loss: 0.5341058969497681, Accuracy: 0.828125\n",
      "Batch: 105, Loss: 0.5836514234542847, Accuracy: 0.810546875\n",
      "Batch: 106, Loss: 0.5000268816947937, Accuracy: 0.8232421875\n",
      "Batch: 107, Loss: 0.549080491065979, Accuracy: 0.826171875\n",
      "Batch: 108, Loss: 0.5400720238685608, Accuracy: 0.822265625\n",
      "Batch: 109, Loss: 0.5601944327354431, Accuracy: 0.8173828125\n",
      "Batch: 110, Loss: 0.49239271879196167, Accuracy: 0.830078125\n",
      "Batch: 111, Loss: 0.5209994912147522, Accuracy: 0.8271484375\n",
      "Batch: 112, Loss: 0.5696840286254883, Accuracy: 0.8115234375\n",
      "Batch: 113, Loss: 0.5360196232795715, Accuracy: 0.8369140625\n",
      "Batch: 114, Loss: 0.6028099060058594, Accuracy: 0.802734375\n",
      "Batch: 115, Loss: 0.643521785736084, Accuracy: 0.7998046875\n",
      "Batch: 116, Loss: 0.532920241355896, Accuracy: 0.80859375\n",
      "Batch: 117, Loss: 0.5981955528259277, Accuracy: 0.8037109375\n",
      "Batch: 118, Loss: 0.4792425334453583, Accuracy: 0.841796875\n",
      "Batch: 119, Loss: 0.4946000874042511, Accuracy: 0.822265625\n",
      "Batch: 120, Loss: 0.5472567081451416, Accuracy: 0.8154296875\n",
      "Batch: 121, Loss: 0.5811364650726318, Accuracy: 0.8134765625\n",
      "Batch: 122, Loss: 0.5487624406814575, Accuracy: 0.8154296875\n",
      "Batch: 123, Loss: 0.4973037540912628, Accuracy: 0.833984375\n",
      "Batch: 124, Loss: 0.5585660338401794, Accuracy: 0.82421875\n",
      "Batch: 125, Loss: 0.5903555154800415, Accuracy: 0.8095703125\n",
      "Batch: 126, Loss: 0.5431867241859436, Accuracy: 0.826171875\n",
      "Batch: 127, Loss: 0.5042548179626465, Accuracy: 0.828125\n",
      "Batch: 128, Loss: 0.5933008193969727, Accuracy: 0.814453125\n",
      "Batch: 129, Loss: 0.5034105777740479, Accuracy: 0.8359375\n",
      "Batch: 130, Loss: 0.5844162106513977, Accuracy: 0.810546875\n",
      "Batch: 131, Loss: 0.5610160231590271, Accuracy: 0.8203125\n",
      "Batch: 132, Loss: 0.5687227249145508, Accuracy: 0.8125\n",
      "Batch: 133, Loss: 0.56410813331604, Accuracy: 0.8232421875\n",
      "Batch: 134, Loss: 0.5467007756233215, Accuracy: 0.8193359375\n",
      "Batch: 135, Loss: 0.5188875198364258, Accuracy: 0.828125\n",
      "Batch: 136, Loss: 0.5422775745391846, Accuracy: 0.8134765625\n",
      "Batch: 137, Loss: 0.5553101301193237, Accuracy: 0.7998046875\n",
      "Batch: 138, Loss: 0.5039660930633545, Accuracy: 0.8251953125\n",
      "Batch: 139, Loss: 0.4997934103012085, Accuracy: 0.83203125\n",
      "Batch: 140, Loss: 0.5392715930938721, Accuracy: 0.8173828125\n",
      "Batch: 141, Loss: 0.5804742574691772, Accuracy: 0.8115234375\n",
      "Batch: 142, Loss: 0.6172971129417419, Accuracy: 0.8125\n",
      "Batch: 143, Loss: 0.5032992362976074, Accuracy: 0.8427734375\n",
      "Batch: 144, Loss: 0.5768958330154419, Accuracy: 0.814453125\n",
      "Batch: 145, Loss: 0.5123924016952515, Accuracy: 0.8359375\n",
      "Batch: 146, Loss: 0.5583910942077637, Accuracy: 0.8203125\n",
      "Batch: 147, Loss: 0.5165390372276306, Accuracy: 0.8173828125\n",
      "Batch: 148, Loss: 0.55609130859375, Accuracy: 0.7998046875\n",
      "Batch: 149, Loss: 0.53352952003479, Accuracy: 0.818359375\n",
      "Batch: 150, Loss: 0.5665731430053711, Accuracy: 0.806640625\n",
      "Batch: 151, Loss: 0.5376318693161011, Accuracy: 0.8369140625\n",
      "Saved Weights at epoch 80 to file Weights_80.h5\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(data_directory, data_file), mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "if __name__ == \"__main__\":\n",
    "    training_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.048923</td>\n",
       "      <td>0.207031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.367002</td>\n",
       "      <td>0.372070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.017084</td>\n",
       "      <td>0.465820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.811540</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.653432</td>\n",
       "      <td>0.527344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.518596</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.422271</td>\n",
       "      <td>0.591797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.345086</td>\n",
       "      <td>0.602539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.287593</td>\n",
       "      <td>0.613281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.239141</td>\n",
       "      <td>0.621094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.229339</td>\n",
       "      <td>0.622070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.163764</td>\n",
       "      <td>0.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.126664</td>\n",
       "      <td>0.646484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.107288</td>\n",
       "      <td>0.659180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.078864</td>\n",
       "      <td>0.653320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.035428</td>\n",
       "      <td>0.663086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.028517</td>\n",
       "      <td>0.666016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.982775</td>\n",
       "      <td>0.686523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.956311</td>\n",
       "      <td>0.692383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.939447</td>\n",
       "      <td>0.699219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.924667</td>\n",
       "      <td>0.698242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.908245</td>\n",
       "      <td>0.713867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.896699</td>\n",
       "      <td>0.723633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.865951</td>\n",
       "      <td>0.729492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.869717</td>\n",
       "      <td>0.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.858346</td>\n",
       "      <td>0.730469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.837637</td>\n",
       "      <td>0.731445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.816526</td>\n",
       "      <td>0.732422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.829862</td>\n",
       "      <td>0.740234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.783542</td>\n",
       "      <td>0.736328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>0.640212</td>\n",
       "      <td>0.791992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>0.618536</td>\n",
       "      <td>0.802734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>0.636361</td>\n",
       "      <td>0.792969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>0.625218</td>\n",
       "      <td>0.798828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>0.633062</td>\n",
       "      <td>0.799805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>0.586930</td>\n",
       "      <td>0.806641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>0.580273</td>\n",
       "      <td>0.811523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>0.631247</td>\n",
       "      <td>0.803711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>0.597318</td>\n",
       "      <td>0.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>0.597988</td>\n",
       "      <td>0.805664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>0.580904</td>\n",
       "      <td>0.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>0.575500</td>\n",
       "      <td>0.824219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>0.556664</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>0.589565</td>\n",
       "      <td>0.809570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>0.578676</td>\n",
       "      <td>0.816406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>0.579991</td>\n",
       "      <td>0.811523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>0.566217</td>\n",
       "      <td>0.823242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>0.533926</td>\n",
       "      <td>0.817383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>0.533961</td>\n",
       "      <td>0.821289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>0.545672</td>\n",
       "      <td>0.825195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>0.559713</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>0.527749</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>0.525417</td>\n",
       "      <td>0.840820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>0.535360</td>\n",
       "      <td>0.831055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>0.520075</td>\n",
       "      <td>0.836914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>0.525019</td>\n",
       "      <td>0.836914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>0.499930</td>\n",
       "      <td>0.837891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>0.535768</td>\n",
       "      <td>0.822266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>0.502424</td>\n",
       "      <td>0.829102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>0.537632</td>\n",
       "      <td>0.836914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch      Loss  Accuracy\n",
       "0       1  3.048923  0.207031\n",
       "1       2  2.367002  0.372070\n",
       "2       3  2.017084  0.465820\n",
       "3       4  1.811540  0.500000\n",
       "4       5  1.653432  0.527344\n",
       "5       6  1.518596  0.562500\n",
       "6       7  1.422271  0.591797\n",
       "7       8  1.345086  0.602539\n",
       "8       9  1.287593  0.613281\n",
       "9      10  1.239141  0.621094\n",
       "10     11  1.229339  0.622070\n",
       "11     12  1.163764  0.640625\n",
       "12     13  1.126664  0.646484\n",
       "13     14  1.107288  0.659180\n",
       "14     15  1.078864  0.653320\n",
       "15     16  1.035428  0.663086\n",
       "16     17  1.028517  0.666016\n",
       "17     18  0.982775  0.686523\n",
       "18     19  0.956311  0.692383\n",
       "19     20  0.939447  0.699219\n",
       "20     21  0.924667  0.698242\n",
       "21     22  0.908245  0.713867\n",
       "22     23  0.896699  0.723633\n",
       "23     24  0.865951  0.729492\n",
       "24     25  0.869717  0.726562\n",
       "25     26  0.858346  0.730469\n",
       "26     27  0.837637  0.731445\n",
       "27     28  0.816526  0.732422\n",
       "28     29  0.829862  0.740234\n",
       "29     30  0.783542  0.736328\n",
       "..    ...       ...       ...\n",
       "50     51  0.640212  0.791992\n",
       "51     52  0.618536  0.802734\n",
       "52     53  0.636361  0.792969\n",
       "53     54  0.625218  0.798828\n",
       "54     55  0.633062  0.799805\n",
       "55     56  0.586930  0.806641\n",
       "56     57  0.580273  0.811523\n",
       "57     58  0.631247  0.803711\n",
       "58     59  0.597318  0.804688\n",
       "59     60  0.597988  0.805664\n",
       "60     61  0.580904  0.818359\n",
       "61     62  0.575500  0.824219\n",
       "62     63  0.556664  0.828125\n",
       "63     64  0.589565  0.809570\n",
       "64     65  0.578676  0.816406\n",
       "65     66  0.579991  0.811523\n",
       "66     67  0.566217  0.823242\n",
       "67     68  0.533926  0.817383\n",
       "68     69  0.533961  0.821289\n",
       "69     70  0.545672  0.825195\n",
       "70     71  0.559713  0.828125\n",
       "71     72  0.527749  0.828125\n",
       "72     73  0.525417  0.840820\n",
       "73     74  0.535360  0.831055\n",
       "74     75  0.520075  0.836914\n",
       "75     76  0.525019  0.836914\n",
       "76     77  0.499930  0.837891\n",
       "77     78  0.535768  0.822266\n",
       "78     79  0.502424  0.829102\n",
       "79     80  0.537632  0.836914\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv(os.path.join(data_directory, \"log.csv\"))\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
